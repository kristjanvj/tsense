% This file was created with JabRef 2.3.1.
% Encoding: UTF8

@OTHER{2007,
  author = {wiki.theory.org},
  booktitle = {http://wiki.theory.org/BitTorrentSpecification},
  citeulike-article-id = {805271},
  date_accessed = {31.01.2007},
  howpublished = {http://wiki.theory.org/BitTorrentSpecification},
  journal = {http://wiki.theory.org/BitTorrentSpecification},
  keywords = {bittorrent, p2p, systems},
  month = {January},
  owner = {kristjan},
  priority = {3},
  publisher = {Theory.org},
  timestamp = {2008.09.19},
  title = {Bittorrent Protocol Specification v1.0},
  url = {http://wiki.theory.org/BitTorrentSpecification},
  year = {2007}
}

@ARTICLE{von-ahn-2004,
  author = {Luis {von Ahn} and Manuel Blum and John Langford},
  title = {Telling humans and computers apart automatically},
  journal = {Commun. ACM},
  year = {2004},
  volume = {47},
  pages = {56--60},
  number = {2},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/966389.966390},
  file = {:von_ahm_2004.pdf:PDF},
  issn = {0001-0782},
  keywords = {authentication, CAPTCHA},
  publisher = {ACM}
}

@TECHREPORT{van-dijk-2006,
  author = {Marten {van Dijk} and Luis F. G. Sarmenta and Charles W. O’Donnell
	and Srinivas Devadas},
  title = {Proof of Freshness: How to efficiency use an online single secure
	clock to secure shared untrusted memory},
  institution = {MIT Computer Science and Artificial Intelligence Laboratory ({CSAIL})},
  year = {2006},
  abstract = {We address the problem of using an untrusted server with a small trusted
	module to provide trusted storage for a large number of clients,
	where each client may own and use several different devices that
	may be ofﬂine at different times and may not be able to communicate
	with each other except through the untrusted server. We introduce
	a new cryptographic primitive: freshness schemes. We show and prove
	how the primitive can be used to implement tamper-evident trusted
	storage for a large number of users using a single constant-sized
	trusted secure clock and constant communication cost per operation,
	regardless of the number of clients and devices per client.},
  file = {van-dijk-2006.pdf:van-dijk-2006.pdf:PDF},
  keywords = {untrusted storage, freshness, integrity checking, authenticated search
	tree, certiﬁcate list, secure clock, TPM},
  owner = {kristjan},
  timestamp = {2010.01.19}
}

@INCOLLECTION{van_renesse_2003,
  author = {Robbert {van Renesse}},
  title = {The importance of aggregation},
  booktitle = {Lecture notes in computer science},
  publisher = {Springer-Verlag},
  year = {2003},
  editor = {A. Schiper and A.A. Shvatsman and H. Weatherspoon and B.Y. Zhao},
  volume = {2584},
  pages = {87-92},
  file = {ImportanceAggregation.pdf:ImportanceAggregation.pdf:PDF},
  journal = {Future Directions in Distrubuted Computing, Lecture Notes in Computer
	Science},
  keywords = {p2p, distributed aggregation, astrolabe},
  owner = {kristjan},
  review = {Aggregation defined as the ability to summarize information. (IMPORTANT:
	Not just p2p mechanisms!) Address aggregation of the Internet provides
	scalability, DNS address resolution in a number of smaller steps
	etc. SQL aggregation combining data from a number of tables etc.
	Discuss Astrolabe (see refs) a p2p aggregation facility which does
	not involve any servers. Scalable publish/subscribe implemented and
	sensor network solution planned. Number of utilizations incl leader
	election, voting, multicast routing, resource location, load balancing/object
	placement and error recovery discussed. Goes on to describe Astrolabe
	-- a p2p system which uses epidemic (gossip) protocol for information
	diffusion. There is though a hierarchy of domain tables, implying
	a tree like structure with a root node. SQL like aggregation functions
	are used to populate the domain tables. The epidemic protocol is
	used to propagate updates to all agents within the domain. 
	
	
	Some open issues re. astrolable: Tradeoffs between consistency and
	scalability, high latency associated with epidemic aggregation, problems
	with the hierarchial structure, limited expressiveness of SQL. Of
	particular interest is the entirely unanswered problem of weak security.
	Astrolabe uses public key cryptography which has both high computational
	cost and does by no means prevent problems.},
  timestamp = {2008.03.27}
}

@INCOLLECTION{van-renesse-2002,
  author = {Robbert {van Renesse} and Kenneth Birman and Dan Dumitriu and Werner
	Vogels},
  title = {Scalable Management and Data Mining Using Astrolabe},
  booktitle = {Lecture Notes in Computer Science. Peer-to-Peer Systems.},
  publisher = {Springer Berlin / Heidelberg},
  year = {2002},
  volume = {2429/2002},
  pages = {280-294},
  abstract = {Astrolabe is a new kind of peer-to-peer system implementing a hierarchical
	distributed database abstraction. Although deigned for scalable management
	and data mining, the system can also support wide-area multicast
	and offers powerful aggregation mechanisms that permit applications
	to build customized virtual databases by extracting and summarizing
	data located throughout a large network. In contrast to other peer-to-peer
	systems, the Astrolabe hierarchy is purely an abstraction constructed
	by running our protocol on the participating hosts - there are no
	servers, and the system doesn’t superimpose a specialized routing
	infrastructure or employ a DHT. This paper focuses on wide-area implementation
	challenges.},
  file = {van-renesse-2002.pdf:van-renesse-2002.pdf:PDF},
  keywords = {network management, network monitoring},
  owner = {kristjan},
  review = {See also van_renesse_2003. Astrolabe uses a combined approach of hierarchy
	of domains and epidemic aggregation within domains.},
  timestamp = {2009.08.12}
}

@INPROCEEDINGS{van-der-meyden-2007,
  author = {Ron {van der Meyden} and Thomas Wilke},
  title = {Preservation of epistemic properties in security protocol implementations},
  booktitle = {{TARK '07: Proceedings of the 11th conference on Theoretical aspects
	of rationality and knowledge}},
  year = {2007},
  pages = {212--221},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We introduce (i) a general class of security protocols with private
	channel as cryptographic primitive and (ii) a probabilistic epistemic
	logic to express properties of security protocols. Our main theorem
	says that when a property expressed in our logic holds for an ideal
	protocol (where "ideal" means that the private channel hides everything),
	then it also holds when the private channel is implemented using
	an encryption scheme that guarantees perfect secrecy (in the sense
	of Shannon). Our class of protocols contains, for instance, an oblivious
	transfer protocol by Rivest and Chaum's solution to the dining cryptographers
	problem. In our logic we can express fundamental security properties
	of these protocols. The proof of the main theorem is based on a notion
	of refinement for probabilistic Kripke structures.},
  doi = {http://doi.acm.org/10.1145/1324249.1324278},
  file = {van-der-meyden-2007.pdf:van-der-meyden-2007.pdf:PDF},
  location = {Brussels, Belgium},
  review = {We introduce (i) a general class of security protocols with private
	channel as cryptographic primitive and (ii) a probabilistic epistemic
	logic to express properties of security protocols. Our main theorem
	says that when a property expressed in our logic holds for an ideal
	protocol (where “ideal” means that the private channel hides everything),
	then it also holds when the private channel is implemented using
	an encryption scheme that guarantees perfect secrecy (in the sense
	of Shannon). Our class of protocols contains, for instance, an oblivious
	transfer protocol by Rivest and Chaum’s solution to the dining cryptographers
	problem. In our logic we can express fundamental security properties
	of these protocols. The proof of the main theorem is based on a notion
	of reﬁnement for probabilistic Kripke structures.}
}

@ARTICLE{oke2007,
  author = {G\"{u}lay \"{O}ke and Georgios Loukas},
  title = {A {Denial of Service} Detector based on Maximum Likelihood Detection
	and the Random Neural Network},
  journal = {Comput. J.},
  year = {2007},
  volume = {50},
  pages = {717--727},
  number = {6},
  abstract = {Due to the simplicity of the concept and the availability of attack
	tools, launching a DoS attack is relatively easy, while defending
	a network resource against it is disproportionately difficult. The
	first step of a protection scheme against DoS must be the detection
	of its existence, ideally before the destructive traffic build-up.
	In this paper we propose a DoS detection approach which uses the
	maximum likelihood criterion with the random neural network (RNN).
	Our method is based on measuring various instantaneous and statistical
	variables describing the incoming network traffic, acquiring a likelihood
	estimation and fusing the information gathered from the individual
	input features using likelihood averaging and different architectures
	of RNNs. We present and compare seven variations of it and evaluate
	our experimental results obtained in a large networking testbed.},
  address = {Oxford, UK},
  doi = {http://dx.doi.org/10.1093/comjnl/bxm066},
  file = {oke2007.pdf:oke2007.pdf:PDF},
  issn = {0010-4620},
  publisher = {Oxford University Press}
}

@INPROCEEDINGS{onen2007,
  author = {Suna Melek {\"{O}}nen and Refik Molva},
  title = {Secure data aggregation with multiple data encryption},
  booktitle = {European Wireless Sensor Networks Conference {(EWSN)}},
  year = {2007},
  __markedentry = {[kristjan]},
  abstract = {Data aggregation has been put forward as an essential technique to
	achieve power eﬃciency in sensor networks. Data aggregation consists
	of processing data collected by source nodes at each intermediate
	node enroute to the sink in order to reduce redundancy and minimize
	bandwidth usage.
	
	
	The deployment of sensor networks in hostile environments call for
	security measures such as data encryption and authentication to prevent
	data tampering by intruders or disclosure by compromised nodes. Aggregation
	of encrypted and/or integrity-protected data by intermediate nodes
	that are not necessarily trusted due to potential node compromise
	is a challenging problem. We propose a secure data aggregation scheme
	that ensures that sensors participating to the aggregation mechanism
	do not have access to the content of the data while adding their
	sensed values thanks to the use of an eﬃcient homomorphic encryption
	scheme. We provide a layered secure aggregation mechanism and the
	related key attribution algorithm that limits the impact of security
	threats such as node compromises. We also evaluate the robustness
	of the scheme against node failures and show that such failures are
	eﬃciently recovered by a small subset of nodes that are at most m
	hops away from the failure.},
  file = {onen2007.pdf:onen2007.pdf:PDF},
  keywords = {sensor networks, homomorphic encryption},
  owner = {kristjan},
  review = {Additive homomorphism with a keystream. Use counter mode CTR proposed
	by Bellare. Unique symmetric keys distributed to all participants.},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{capkun2003,
  author = {\v{C}apkun, Srdjan and Hubaux, Jean-Pierre},
  title = {{BISS}: building secure routing out of an incomplete set of security
	associations},
  booktitle = {{WiSe} '03: Proceedings of the 2nd {ACM} workshop on Wireless security},
  year = {2003},
  pages = {21--29},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/941311.941316},
  file = {capkun2003.pdf:capkun2003.pdf:PDF},
  isbn = {1-58113-769-9},
  keywords = {mobile ad-hoc network, security, secure routing},
  location = {San Diego, CA, USA}
}

@INPROCEEDINGS{abadi_borealis_2005,
  author = {Daniel J. Abadi and Yanif Ahmad and Magdalena Balazinska and U\v{g}ur
	\c{C}etintemel and Mitch Cherniack and Jeong-Hyon Hwang and Wolfgang
	Lindner and Anurag S. Maskey and Alexander Rasin and Esther Ryvkina
	and Nesime Tatbul and Ying Xing and Stan Zdonik},
  title = {The Design of the Borealis Stream Processing Engine},
  booktitle = {{Proceedings of the 2nd Conference on Classless Inter-Domain Routing
	(CIDR)}},
  year = {2005},
  pages = {277-289},
  month = {january},
  abstract = {Borealis is a second-generation distributed stream processing engine
	that is being developed at Brandeis University, Brown University,
	and MIT. Borealis inherits core stream processing functionality from
	Aurora [14] and distribution functionality from Medusa [51]. Borealis
	modiﬁes and extends both systems in non-trivial and critical ways
	to provide advanced capabilities that are commonly required by newly-emerging
	stream processing applications.
	
	In this paper, we outline the basic design and functionality of Borealis.
	Through sample real-world applications, we motivate the need for
	dynamically revising query results and modifying query speciﬁcations.
	We then describe how Borealis addresses these challenges through
	an innovative set of features, including revision records, time travel,
	and control lines. Finally, we present a highly ﬂexible and scalable
	QoS-based optimization model that operates across server and sensor
	networks and a new fault-tolerance model with ﬂexible consistency-availability
	trade-offs.},
  file = {cidr05.pdf:cidr05.pdf:PDF},
  keywords = {databases, stream query processing},
  owner = {kristjan},
  timestamp = {2008.03.06}
}

@INPROCEEDINGS{abadi2009,
  author = {Mart\'{i}n Abadi and Bruno Blanchet and Hubert Comon-Lundh},
  title = {Models and Proofs of Protocol Security: A Progress Report},
  booktitle = {21st International Conference on Computer Aided Verification},
  year = {2009},
  file = {abadi2009.pdf:abadi2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.15}
}

@INPROCEEDINGS{abadi2005,
  author = {Martin Abadi and Mihai Budiu and \'{U}lfar Erlingsson and Jay Ligatti},
  title = {Control-flow integrity. Principles, Implementations, and Applications.},
  booktitle = {CCS '05: Proceedings of the 12th ACM conference on Computer and communications
	security},
  year = {2005},
  pages = {340--353},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Current software attacks often build on exploits that subvert machine-code
	execution. The enforcement of a basic safety property, Control-Flow
	Integrity (CFI), can prevent such attacks from arbitrarily controlling
	program behavior. CFI enforcement is simple, and its guarantees can
	be established formally, even with respect to powerful adversaries.
	Moreover, CFI enforcement is practical: it is compatible with existing
	software and can be done efﬁciently using software rewriting in commodity
	systems. Finally, CFI provides a useful foundation for enforcing
	further security policies, as we demonstrate with efﬁcient software
	implementations of a pro tected shadow call stack and of access control
	for memory regions.},
  doi = {http://doi.acm.org/10.1145/1102120.1102165},
  file = {p340-abadi.pdf:p340-abadi.pdf:PDF},
  isbn = {1-59593-226-7},
  keywords = {computer security},
  location = {Alexandria, VA, USA}
}

@INPROCEEDINGS{abadi2005a,
  author = {Martin Abadi and Mihai Budiu and {\'{U}}lfar Erlingsson and Jay Ligatti},
  title = {A Theory of Secure Control Flow},
  booktitle = {{Proc. 7th International Conference on Formal Engineering Methods
	(ICFEM'05)}},
  year = {2005},
  address = {Manchester, UK},
  month = {November},
  abstract = {Control-Flow Integrity (CFI) means that the execution of a program
	dynamically follows only certain paths, in accordance with a static
	policy. CFI can prevent attacks that, by exploiting buﬀer overﬂows
	and other vulnerabilities, attempt to control program behavior. This
	paper develops the basic theory that underlies two practical techniques
	for CFI enforcement, with precise formulations of hypotheses and
	guarantees.},
  file = {icfem05-cfi.pdf:icfem05-cfi.pdf:PDF},
  keywords = {computer security},
  owner = {kristjan},
  timestamp = {2008.02.27}
}

@INPROCEEDINGS{abadi2006,
  author = {Martin Abadi and Cormac Flanagan and Stephen N. Freund},
  title = {Types for safe locking: Static race detection for Java},
  booktitle = {ACM Transactions on Programming Languages and Systems},
  year = {2006},
  volume = {28},
  number = {2},
  pages = {207--255},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This article presents a static race-detection analysis for multithreaded
	shared-memory programs, focusing on the Java programming language.
	The analysis is based on a type system that captures many common
	synchronization patterns. It supports classes with internal synchronization,
	classes that require client-side synchronization, and thread-local
	classes. In order to demonstrate the effectiveness of the type system,
	we have implemented it in a checker and applied it to over 40,000
	lines of hand-annotated Java code. We found a number of race conditions
	in the standard Java libraries and other test programs. The checker
	required fewer than 20 additional type annotations per 1,000 lines
	of code. This article also describes two improvements that facilitate
	checking much larger programs: an algorithm for annotation inference
	and a user interface that clariﬁes warnings
	
	generated by the checker. These extensions have enabled us to use
	the checker for identifying race conditions in large-scale software
	systems with up to 500,000 lines of code.},
  doi = {http://doi.acm.org/10.1145/1119479.1119480},
  file = {p207-abadi.pdf:p207-abadi.pdf:PDF},
  issn = {0164-0925},
  journal = {ACM Trans. Program. Lang. Syst.},
  keywords = {computer security}
}

@ARTICLE{abadi1999,
  author = {Martin Abadi and Andrew D. Gordon},
  title = {A calculus for cryptographic protocols: The spi calculus},
  journal = {Information and Computation},
  year = {1999},
  volume = {148},
  pages = {36--47},
  file = {abadi1999.pdf:abadi1999.pdf:PDF}
}

@INPROCEEDINGS{abdelmalek2005,
  author = {Abd-El-Malek, Michael and Ganger, Gregory R. and Goodson, Garth R.
	and Reiter, Michael K. and Wylie, Jay J.},
  title = {Fault-scalable Byzantine fault-tolerant services},
  booktitle = {{SOSP} '05: Proceedings of the twentieth {ACM} symposium on Operating
	systems principles},
  year = {2005},
  pages = {59--74},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A fault-scalable service can be configured to tolerate increasing
	numbers of faults without significant decreases in performance. The
	Query/Update (Q/U) protocol is a new tool that enables construction
	of fault-scalable Byzantine fault-tolerant services. The optimistic
	quorum-based nature of the Q/U protocol allows it to provide better
	throughput and fault-scalability than replicated state machines using
	agreement-based protocols. A prototype service built using the Q/U
	protocol outperforms the same service built using a popular replicated
	state machine implementation at all system sizes in experiments that
	permit an optimistic execution. Moreover, the performance of the
	Q/U protocol decreases by only 36% as the number of Byzantine faults
	tolerated increases from one to five, whereas the performance of
	the replicated state machine decreases by 83%.},
  doi = {http://doi.acm.org/10.1145/1095810.1095817},
  file = {abdelmalek2005.pdf:abdelmalek2005.pdf:PDF},
  isbn = {1-59593-079-5},
  location = {Brighton, United Kingdom}
}

@MISC{abdul-rahman-1997a,
  author = {Abdul-Rahman},
  title = {The PGP Trust Model},
  howpublished = {EDI-Forum: the Journal of Electronic Commerce},
  year = {1997},
  file = {abdul-rahman-1997a.pdf:abdul-rahman-1997a.pdf:PDF},
  keywords = {computer security, trust management},
  owner = {kristjan},
  timestamp = {2009.04.08}
}

@INPROCEEDINGS{abdul-rahman-1997,
  author = {Alfarez {Abdul-Rahman} and Stephen Hailes},
  title = {A distributed trust model},
  booktitle = {NSPW '97: Proceedings of the 1997 workshop on New security paradigms},
  year = {1997},
  pages = {48--60},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The widespread use of the Internet signals the need for a better
	
	understanding of trust as a basis for secure on-line interaction.
	In
	
	the face of increasing uncertainty and risk, users must be allowed
	
	to reason flectively about the trustworthiness of on-line entities.
	
	In this paper, we outline the shortcomings of current security
	
	approaches for managing trust and propose a model for trust,
	
	based on distributed recommendations.},
  doi = {http://doi.acm.org/10.1145/283699.283739},
  file = {abdul-rahman-1997.pdf:abdul-rahman-1997.pdf:PDF},
  isbn = {0-89791-986-6},
  keywords = {computer security, trust management},
  location = {Langdale, Cumbria, United Kingdom}
}

@BOOK{Abraham2005,
  title = {Operating Systems Concepts},
  publisher = {Wiley},
  year = {2005},
  author = {Abraham Silberschatz, Peter Baer Galvin, Greg Gagne},
  keywords = {operating systems},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{abraham2006,
  author = {J. Abraham and K.S. Ramanatha},
  title = {Security Protocols for Wireless Sensor Networks based on Tiny Diffusion
	and Elliptic Curves},
  booktitle = {Networks and Communication Systems},
  year = {2006},
  abstract = {Network security to Wireless Sensor Networks is a very essential requirement
	because they are easily susceptible to many threats like Denial-of-Service
	attacks [15]. The most important security services required are confidentiality
	and authentication. Many researchers have tried to provide security
	by using only symmetric key mechanisms thinking that public key cryptosystems
	are not feasible to implement in these networks because they are
	constrained with less resources. This paper discusses implementation
	of minimally required set of security protocols for sensor networks.
	This set includes 1) a shared key establishment protocol 2) a secure
	data transfer protocol and 3) authenticated periodic rekeying protocol.
	The implementation uses Elliptic Curve Cryptography as a public key
	system and Tiny Diffusion protocol for the underlying network communication.
	The protocols are tested in POWER TOSSIM simulator and the results
	are found to be efficient with memory requirement and communication
	delay.},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{acharya2005,
  author = {Acharya, Mithun and Girao, Joao and Westhoff, Dirk},
  title = {Secure Comparison of Encrypted Data in Wireless Sensor Networks},
  booktitle = {WIOPT '05: Proceedings of the Third International Symposium on Modeling
	and Optimization in Mobile, Ad Hoc, and Wireless Networks},
  year = {2005},
  pages = {47--53},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[kristjan]},
  doi = {http://dx.doi.org/10.1109/WIOPT.2005.44},
  file = {acharya2005.pdf:acharya2005.pdf:PDF},
  isbn = {0-7695-2267-X},
  keywords = {wireless sensor network, encryption, comparison},
  review = {See later for work on confidentiality in aggregation of data w comparison
	operations.}
}

@TECHREPORT{adam2005,
  author = {C. Adam and K.S. Lim and R. Stadler},
  title = {Decentralizing Network Management},
  institution = {KTH},
  year = {2005},
  month = {December},
  abstract = {We argue that effective management of future large and dynamic networks
	must be based on adaptive, decentralized control, in order to overcome
	the drawbacks of today’s management systems with centralized and
	static structures. The challenge in engineering decentralized management
	systems is to come up with concepts for distributing management operations
	in a manner that they (a) execute efficiently in large networks and
	(b) dynamically adapt to network failures and other changes in state
	and network configuration. Our approach to decentralized management
	systems centers around the concept of navigation patterns, which
	are based on graph traversal algorithms that control the execution
	of decentralized management operations. We present our research in
	decentralized management, from the concept of the navigation pattern,
	via the implementation of a management platform built around this
	concept, to the realization of a real-time monitoring capability
	designed to be effective in large and dynamic network environments.},
  file = {:DECENTRALIZING-KTHTR-2005.pdf:PDF},
  keywords = {network management, distributed management, scalability, fault tolerance,
	pattern based management, ECHO pattern},
  owner = {kristjan},
  timestamp = {2009.03.10}
}

@INPROCEEDINGS{adam2004,
  author = {C. Adam and R. Stadler},
  title = {Patterns for Routing and Self-Stabilization},
  booktitle = {Network Operations \& Management Symposium ({NOMS 2004})},
  year = {2004},
  pages = {200},
  address = {Seoul, Korea},
  abstract = {This paper contributes towards engineering self-stabilizing networks
	and services. We propose the use of navigation patterns, which define
	how information for state updates is disseminated in the system,
	as fundamental building blocks for selfstabilizing systems. We present
	two navigation patterns for self-stabilization: the progressive wave
	pattern and the stationary wave pattern. The progressive wave pattern
	defines the update dissemination in Internet routing systems running
	the DUAL and OSPF protocols. Similarly, the stationary wave pattern
	defines the interactions of peer nodes in structured peer-to-peer
	systems, including Chord, Pastry, Tapestry, and CAN. It turns out
	that both patterns are related. They both disseminate information
	in form of waves, i.e, sets of messages that originate from single
	events. Patterns can be instrumented to obtain wave statistics, which
	enables monitoring the process of self-stabilization in a system.
	We focus on Internet routing and peer-topeer systems in this work,
	since we believe that studying these (existing) systems can lead
	to engineering principles for self-stabilizing system in various
	application areas.},
  file = {adam2004.pdf:adam2004.pdf:PDF}
}

@INPROCEEDINGS{adida2007,
  author = {Ben Adida},
  title = {BeamAuth: Two-Factor Web Authentication with a Bookmark},
  booktitle = {CCS},
  year = {2007},
  address = {Alexandria, Virginia, USA},
  month = {October},
  abstract = {We propose BeamAuth, a two-factor web authentication tech-
	
	nique where the second factor is a specially crafted book-
	
	mark. BeamAuth presents two interesting features: (1) only
	
	server-side deployment is required alongside any modern,
	
	out-of-the-box web browser on the client side, and (2) cre-
	
	dentials remain safe against many types of phishing attacks,
	
	even if the user fails to check proper user interface indicators.
	
	BeamAuth is deployable immediately by any login-protected
	
	web server with only minimal work, and it neither weakens
	
	nor interferes with other anti-phishing techniques. We be-
	
	lieve BeamAuth may be most useful in preventing a number
	
	of phishing attacks at high-value single sign-on sites, e.g.
	
	OpenID providers.},
  file = {beamauth-ccs2007.pdf:beamauth-ccs2007.pdf:PDF},
  keywords = {computer security, authentication},
  owner = {kristjan},
  review = {BeamAuth is a scheme to implement two factor authentication of users
	by utilizing a specially
	
	crafted bookmark. Such schemes have commonly been implemented using
	a cookie which is vulnerable
	
	to cookie theft attacks. BeamAuth uses the fragment identifier to
	embed a unique identifier generated for each
	
	user in the url for the login site. The login web page prompts the
	user to click on the special url which is then 
	
	loaded into the script code and removed from the link display in the
	browser. A hash of the special key and the
	
	users password is then created and sent to the web server for authentication.
	This approach is safe from
	
	phishing as a false site could at most obtain the password, but not
	the secret token. This is because the 
	
	fragment identifier is always local to the page. 
	
	
	Weaknesses with this approach: The bookmark is stored in plaintext
	on the users computer. Social engineering
	
	tricks could be applied to make the user reveal the secret token.
	Could browser bugs (or future "enhancements"
	
	cause fragments to be sent and thus disclose the secret? What happens
	if a phishing site disables JavaScript in
	
	the users browser? Will the fragment identifier be seen in the browser
	bar? Could open the door for social
	
	engineering attacks like placing a phony support link on the phishing
	login page where the user would be 
	
	prompted to email the complete link in case of problems.},
  timestamp = {2008.02.25}
}

@ARTICLE{ahituv1987,
  author = {Ahituv, Niv and Lapid, Yeheskel and Neumann, Seev},
  title = {Processing encrypted data},
  journal = {{Commun. ACM}},
  year = {1987},
  volume = {30},
  pages = {777--780},
  number = {9},
  abstract = {A severe problem in the processing of encrypted data is that very
	often, in order to perform arithmetic operations on the data, one
	has to convert the data back to its nonencrypted origin before performing
	the required operations. This paper addresses the issue of processing
	data that have been encrypted while the data are in an encrypted
	mode. It develops a new approach for encryption models that can facilitate
	the processing of such data. The advantages of this approach are
	reviewed, and a basic algorithm is developed to prove the feasibility
	of the approach.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/30401.30404},
  file = {ahituv1987.pdf:ahituv1987.pdf:PDF},
  issn = {0001-0782},
  keywords = {cryptography, homomorphic encryption},
  publisher = {ACM},
  review = {Ref'd by jadia2004 on the homomorphism used by their protocol -- symmetric
	homomorphic cipher with one time (counter-derived) keys.}
}

@ARTICLE{ahmad2006,
  author = {W. Ahmad and A. Khokhar},
  title = {{NISp1-08:} Secure Aggregation in Large Scale Overlay Networks},
  journal = {{Global Telecommunications Conference, 2006. GLOBECOM '06. IEEE}},
  year = {2006},
  pages = {1-5},
  month = {27 2006-Dec. 1},
  abstract = {Overlay networks have been very useful in solving large scale data
	dissemination problems. In this paper, we consider the case of data
	gathering which is the inverse of dissemination problem. In particular,
	we focus on a scenario where an organization or a constellation of
	organizations is interested in gathering data from large number of
	nodes spread across the administrative boundaries. Providing individual
	nodes with full assurance that the privacy of their data won’t be
	compromised is a critical problem in achieving the true beneﬁts of
	this collaborative process. We provide a novel solution to the problem
	by employing a threshold homomorphic cryptosystem which allows processing
	of encrypted data without revealing anything about the underlying
	private data. The threshold property of the cryptosystem ensures
	that no single node is able to decrypt the aggregate results. The
	proposed solution provides excellent scale-up properties while preserving
	privacy and secrecy of the data even among malicious adversaries.},
  doi = {10.1109/GLOCOM.2006.315},
  file = {:ahmad2006.pdf:PDF},
  issn = {1930-529X},
  keywords = {cryptography, data privacy, telecommunication security, data encryption,
	data gathering, data privacy, large scale overlay networks, secure
	aggregation protocol, threshold homomorphic cryptosystem}
}

@INPROCEEDINGS{al-karaki-2004,
  author = {Jamal N. AI-Karaki and Raza UI-Mustafa and Ahmed E. Kamal},
  title = {Data Aggregation in Wireless Sensor Networks Exact and Approximate
	Algorithms},
  booktitle = {Workshop on High Performance Switching and Routing},
  year = {2004},
  pages = {241-245},
  __markedentry = {[kristjan]},
  abstract = {A fundamental challenge in the derlgo of Wireless Sen-
	
	sor Network (WSNs) Is to maximhe their lifetimes. Data aggrrgation
	
	has emerged as a basic approach in WSNs lo order to d u c e the
	
	number of transmissions of sensor nodes, and hence minimizing
	
	the overall power mnsumption in the network. In thh paper, we
	
	study optimal data aggregation in WSNs. Data aggregation Is alfrrted
	
	by several factors such as the placement of aggrrgalion points, the
	
	aggregation function, and the density of the sensors in the network.
	
	The determination of an optimal selection of aggregation point b lhw
	
	extremely important. We present an exact as well as appmximale
	
	algorithms to find the minimum number of aggregation pints in
	
	order to maximize the network lifetime. Our algorithms we s fixed
	
	virtual wireless backbane that h h i l t on top of the physical topdogy.
	
	We also study the tradeoffs between enogy ravings and the potmtial
	
	delay involved in the data aggregation pmcess. Numerical results show
	
	that our approach provides subslanlial energy savings.},
  file = {al-karaki-2004.pdf:al-karaki-2004.pdf:PDF},
  keywords = {sensor network, power efficiency, routing, aggregation},
  owner = {kristjan},
  review = {A good number of citations -- may be worth reading. Focus on distribution
	of aggregators in a WSN to produce maximum energy saving. Construction
	of a virtual routing backbone on top of SN.},
  timestamp = {2010.05.25}
}

@INPROCEEDINGS{Aiyer2005,
  author = {Amitanand S. Aiyer and Lorenzo Alvisi and Allen Clement and Mike
	Dahlin and Jean-Philippe Martin and Carl Porth},
  title = {{BAR} fault tolerance for cooperative services},
  booktitle = {{SOSP'05 20th ACM Symposium on Operating Systems Principles}},
  year = {2005},
  pages = {45-58},
  address = {Brighton, United Kingdom},
  month = {October},
  abstract = {This paper describes a general approach to constructing cooperative
	services that span multiple administrative domains. In such environments,
	protocols must tolerate both Byzantine behaviors when broken, misconﬁgured,
	or malicious nodes arbitrarily deviate from their speciﬁcation and
	rational behaviors when selﬁsh nodes deviate from their speciﬁcation
	to increase their local beneﬁt. The paper makes three contributions:
	(1) It introduces the BAR (Byzantine, Altruistic, Rational) model
	as a foundation for reasoning about cooperative services; (2) It
	proposes a general three-level architecture to reduce the complexity
	of building services under the BAR model; and (3) It describes an
	implementation of BAR-B, the ﬁrst cooperative backup service to tolerate
	both Byzantine users and an unbounded number of rational users. At
	the core of BAR-B is an asynchronous replicated state machine that
	provides the customary safety and liveness guarantees despite nodes
	exhibiting both Byzantine and rational behaviors. Our prototype provides
	acceptable performance for our application: our BAR-tolerant state
	machine executes 15 requests per second, and our BAR-B backup service
	can back up 100 MB of data in under 4 minutes.},
  file = {p45-aiyer.pdf:p45-aiyer.pdf:PDF},
  keywords = {fault tolerance, byzantine, BAR},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{akinwande2009,
  author = {Mufutau Akinwande},
  title = {Advances in Homomorphic Cryptosystems},
  journal = {Journal of Universal Computer Science},
  year = {2009},
  volume = {15},
  pages = {506-522},
  number = {3},
  __markedentry = {[kristjan]},
  abstract = {During the last few years homomorphic encryption techniques have been
	studied extensively since they have become more and more important
	in many different cryptographic protocols such as voting protocols,
	lottery protocols, anonymity, privacy, and electronic auctions.
	
	
	This paper critically summarizes the current state-of-art of homomorphic
	cryptosystems. It recalls the basic ideas, discusses their parameters,
	performances and security issues. And, finally we present their capabilities
	in the future applications.},
  file = {akinwande2009.pdf:akinwande2009.pdf:PDF},
  keywords = {Probability encryption, Homomorphic encryption, Cryptosystems},
  owner = {kristjan},
  timestamp = {2010.05.07}
}

@ARTICLE{akkaya2008,
  author = {Akkaya, Kemal and Demirbas, Murat and Aygun, R. Savas},
  title = {The impact of data aggregation on the performance of wireless sensor
	networks},
  journal = {Wirel. Commun. Mob. Comput.},
  year = {2008},
  volume = {8},
  pages = {171--193},
  number = {2},
  __markedentry = {[kristjan]},
  abstract = {@article{1340987,
	
	 author = {Akkaya, Kemal and Demirbas, Murat and Aygun, R. Savas},
	
	 title = {The impact of data aggregation on the performance of wireless
	sensor networks},
	
	 journal = {Wirel. Commun. Mob. Comput.},
	
	 volume = {8},
	
	 number = {2},
	
	 year = {2008},
	
	 issn = {1530-8669},
	
	 pages = {171--193},
	
	 doi = {http://dx.doi.org/10.1002/wcm.v8:2},
	
	 publisher = {John Wiley and Sons Ltd.},
	
	 address = {Chichester, UK},
	
	 }},
  address = {Chichester, UK},
  doi = {http://dx.doi.org/10.1002/wcm.v8:2},
  issn = {1530-8669},
  keywords = {wireless sensor network, aggregation},
  publisher = {John Wiley and Sons Ltd.}
}

@INPROCEEDINGS{akkoyunlu1975,
  author = {Akkoyunlu, E. A. and Ekanadham, K. and Huber, R. V.},
  title = {Some constraints and tradeoffs in the design of network communications},
  booktitle = {{SOSP '75: Proceedings of the fifth ACM symposium on Operating systems
	principles}},
  year = {1975},
  pages = {67--74},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A number of properties and features of interprocess communication
	systems are presented, with emphasis on those necessary or desirable
	in a network environment. The interactions between these features
	are examined, and the consequences of their inclusion in a system
	are explored. Of special interest are the time-out feature which
	forces all system table entries to “die of old age” after they have
	remained unused for some period of time, and the insertion property
	which states that it is always possible to design a process which
	may be invisibly inserted into the communication path between any
	two processes. Though not tied to any particular system, the discussion
	concentrates on distributed systems of sequential processes (no interrupts)
	with no system buffering.},
  doi = {http://doi.acm.org/10.1145/800213.806523},
  file = {akkoyunlu1975.pdf:akkoyunlu1975.pdf:PDF},
  keywords = {networks, interprocess communications, byzantine generals problem},
  location = {Austin, Texas, United States},
  review = {Uses the two generals problem to illustrate network communications
	problems. Gives the two generals impossibility proof.}
}

@ARTICLE{akyildiz2002,
  author = {I. F. Akyildiz and W. Su and Y. Sankarasubramaniam and E. Cayirci},
  title = {Wireless sensor networks: a survey},
  journal = {Computer Networks},
  year = {2002},
  volume = {38},
  number = {4},
  month = {March},
  abstract = {This paper describes the concept of sensor networks which has been
	made viable by the convergence of micro-electro-mechanical systems
	technology, wireless communications and digital electronics. First,
	the sensing tasks and the potential sensor networks applications
	are explored, and a review of factors inﬂuencing the design of sensor
	networks is provided. Then, the communication architecture for sensor
	networks is outlined, and the algorithms and protocols developed
	for each layer in the literature are explored. Open research issues
	for the realization of sensor networks are also discussed.},
  file = {akyildiz2002.pdf:akyildiz2002.pdf:PDF},
  keywords = {networks, sensor networks, survey},
  owner = {kristjan},
  page = {393-422},
  publisher = {Elsevier Science B.V.},
  timestamp = {2008.09.19}
}

@ARTICLE{al-karaki-2009,
  author = {Al-Karaki, Jamal N. and Ul-Mustafa, Raza and Kamal, Ahmed E.},
  title = {Data aggregation and routing in Wireless Sensor Networks: Optimal
	and heuristic algorithms},
  journal = {Comput. Netw.},
  year = {2009},
  volume = {53},
  pages = {945--960},
  number = {7},
  abstract = {@article{1518354,
	
	 author = {Al-Karaki, Jamal N. and Ul-Mustafa, Raza and Kamal, Ahmed
	E.},
	
	 title = {Data aggregation and routing in Wireless Sensor Networks:
	Optimal and heuristic algorithms},
	
	 journal = {Comput. Netw.},
	
	 volume = {53},
	
	 number = {7},
	
	 year = {2009},
	
	 issn = {1389-1286},
	
	 pages = {945--960},
	
	 doi = {http://dx.doi.org/10.1016/j.comnet.2008.12.001},
	
	 publisher = {Elsevier North-Holland, Inc.},
	
	 address = {New York, NY, USA},
	
	 }},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.comnet.2008.12.001},
  issn = {1389-1286},
  publisher = {Elsevier North-Holland, Inc.},
  review = {No citations at all!}
}

@MISC{al-kayali-2004,
  author = {Ahmad Khaled M. Al-Kayali},
  title = {Elliptic Curve Cryptography and Smart Cards},
  year = {2004},
  file = {al-kayali-2004.pdf:al-kayali-2004.pdf:PDF},
  keywords = {elliptic curve cryptography, smart cards, EC, EC DSA},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@INPROCEEDINGS{Al-Mamou2007,
  author = {Abd Al-Basset Al-Mamou and Houda Labiod},
  title = {ScatterPastry: An Overlay Routing Using a DHT over Wireless Sensor
	Networks},
  booktitle = {{IPC}: The 2007 International Conference on Intelligent Pervasive
	Computing.},
  year = {2007},
  pages = {274-279},
  abstract = {Using Distributed Hash Tables (DHTs) over ad-hoc wireless sensor networks
	(WSNs) has gained a lot of attention in the research arena in last
	years. In WSN's world, the most important issue in routing is to
	gather the routed information coming from sensor nodes to the sink
	node regardless of the identity of the donating node. The problem
	in this context is to locate efficiently the sensor node, which holds
	the data item with the minimum number of intermediate nodes to save
	network energy. DHTs based on the Internet are used for this purpose.
	This paper presents a ScatterPastry platform based on Pastry DHT
	as an overlay routing platform for distributed applications over
	WSNs using Scatterweb nodes, a real-world wireless sensor platform.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://doi.ieeecomputersociety.org/10.1109/IPC.2007.109},
  keywords = {Wireless sensor network, DHT, Pastry}
}

@INCOLLECTION{al-riyami-2003,
  author = {Sattam S. Al-Riyami and Kenneth G. Paterson},
  title = {Certificateless Public Key Cryptography},
  booktitle = {Advances in Cryptology - {ASIACRYPT}},
  publisher = {Springer Berlin/Heidelberg},
  year = {2003},
  abstract = {This paper introduces and makes concrete the concept of certificateless
	public key cryptography (CL-PKC), a model for the use of public key
	cryptography which avoids the inherent escrow of identity-based cryptography
	and yet which does not require certificates to guarantee the authenticity
	of public keys. The lack of certificates and the presence of an adversary
	who has access to a master key necessitates the careful development
	of a new security model. We focus on certificateless public key encryption
	(CL-PKE), showing that a concrete pairing-based CL-PKE scheme is
	secure provided that an underlying problem closely related to the
	Bilinear Diffie-Hellman Problem is hard.},
  file = {al-riyami-2003.pdf:al-riyami-2003.pdf:PDF},
  keywords = {crypto, certificates, certificateless public key crypto, CL-PKC, identity
	based crypto},
  owner = {kristjan},
  timestamp = {2010.05.16}
}

@ARTICLE{al-shaer-2004,
  author = {E.S. Al-Shaer and H.H. Hamed},
  title = {Modeling and Management of Firewall Policies},
  journal = {{IEEE Transactsons on Network and Service Management (TNMS)}},
  year = {2004},
  file = {al-shaer-2004.pdf:al-shaer-2004.pdf:PDF},
  keywords = {networks, firewall policies},
  owner = {kristjan},
  timestamp = {2009.03.16}
}

@MISC{al-shaer-2000,
  author = {Ehab Al-Shaer and Yongning Tang},
  title = {Toward Integrating {IP} Multicasting in Internet Network Management
	Protocols},
  year = {2000},
  abstract = {Supporting multi-point group communications in network management
	platforms is essential for improving scalability and responsiveness
	of management applications. With the deployment of IP multicasting
	as the standard infrastructure for multi-point group communications
	in the Internet, the integration of IP multicasting in SNMP becomes
	signi cantly important to achieve these goals. This paper presents
	a highly exible, e cient and easy-to-integrate framework for integrating
	IP Multicast in standard SNMP agents. The proposed framework enables
	managers to re-con gure the agents' group membership and the communication
	model (e.g., one-to-many, many-to-one and many-to-many) dynamically
	based on the application requirements. This framework exploits the
	advantages of IP multicasting without requiring any signi cant changes
	or performance overhead in the protocol or the agent architecture.
	The resulting framework can be easily adopted by exiting SNMP agents
	of various network management platforms. Although the other approaches
	provide group communications through broker agents in the management
	platform, integrating IP multicasting in SNMP agents is more e cient
	and a simpler approach. Our ultimate goal is to promote the integration
	of IP multicasting as a standard service in SNMP agents.},
  file = {al-shaer-2000.pdf:al-shaer-2000.pdf:PDF},
  keywords = {Distributed Network Management, IP multicast, SNMP},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{albath2009,
  author = {Albath, Julia and Madria, Sanjay},
  title = {Secure hierarchical data aggregation in wireless sensor networks},
  booktitle = {{WCNC}'09: Proceedings of the 2009 {IEEE} conference on Wireless
	Communications \& Networking Conference},
  year = {2009},
  pages = {2420--2425},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  abstract = {Communication in wireless sensor networks uses the majority of a sensor's
	limited energy. Using aggregation in wireless sensor network reduces
	the overall communication cost. Security in wireless sensor networks
	entails many different challenges. Traditional end-to-end security
	is not suitable for use with in-network aggregation. A corrupted
	sensor has access to the data and can falsify results. Additively
	homomorphic encryption allows for aggregation of encrypted values,
	with the result being the same as the result when unencrypted data
	was aggregated. Using public key cryptography, digital signatures
	can be used to achieve integrity. We propose a new algorithm using
	homomorphic encryption and additive digital signatures to achieve
	confidentiality, integrity and availability for in-network aggregation
	in wireless sensor networks.We prove that our digital signature algorithm
	which is based on the Elliptic Curve Digital Signature Algorithm
	(ECDSA) is as secure as ECDSA.},
  file = {albath2009.pdf:albath2009.pdf:PDF},
  isbn = {978-1-4244-2947-9},
  keywords = {sensor network, aggregation, homomorphic encryption},
  location = {Budapest, Hungary},
  review = {Confidentiality handled with ElGamal encryption. Consider sum and
	average functions.
	
	Integrity solution more interesting: propose additive digital signatures,
	based on ECDSA. Is this a known concept? See \cite{johnson2002} on
	additive homomorphic signature schemes and their inherent insecurity.
	
	
	Citation count zero -- not a high impact paper.}
}

@INPROCEEDINGS{albath2007,
  author = {Albath, Julia and Madria, Sanjay},
  title = {Practical algorithm for data security {(PADS)} in wireless sensor
	networks},
  booktitle = {{MobiDE} '07: Proceedings of the 6th {ACM} international workshop
	on Data engineering for wireless and mobile access},
  year = {2007},
  pages = {9--16},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {When data are generated in sensor networks, high-speed data streams
	travel through the network. Traditional security approaches are often
	unable to keep up with the rates of the streams or they introduce
	overhead, which shortens the life of the network. The approach proposed
	in this paper is one that solves the problems posed above. By embedding
	a one-time pad, the actual value is distorted enough to make any
	information gleaned from eavesdropping useless to an attacker. The
	use of the one-time pad ensures that the data were indeed received
	from a particular sensor, and it gives adequate protection against
	injected messages. The simulation shows this approach provides security
	with negligible overhead while the throughput is similar to the same
	network without security.},
  doi = {http://doi.acm.org/10.1145/1254850.1254853},
  file = {albath2007.pdf:albath2007.pdf:PDF},
  isbn = {978-1-59593-765-0},
  location = {Beijing, China},
  review = {I think this work is severely flawed. Cited by one (self-citation)
	so really no impact at all.
	
	
	End-to-end encryption -- do not consider in-network aggregation.
	
	
	Propose an OTP scheme, where the OTP is generated from a MAC (CBC-MAC
	w. SkipJack from TinySec). Time synchronization with base station
	(the intended receiver) is used to derive an [alpha,beta] subsequence
	of the MAC computed over the invariant parts of the message -- the
	MAC is attached to the message in the clear and used as authentication
	by the receiver.
	
	The subsequence is repeated enough times to be the same lenght as
	the message and encrypted as normal.
	
	
	Problems:
	
	* Depends on the adversary not being able to timesynch with the base
	station and sender, an unreasonable assumption in my mind for an
	insider adversary at least. 
	
	* If the adversary can timesynch, the key can be trivially extracted
	from the plaintext MAC -- the shared secret key is absolutely not
	needed!
	
	* The OTP is not a true OTP -- it is constructed of very short subsequences
	of the MAC. Much more like a periodic cipher than a OTP!
	
	* A minor weakness is the dependence on a shared secret key. The application
	of it is really the problem.
	
	
	Overall, pretty useless.}
}

@ARTICLE{albert2002,
  author = {R\'{e}ka Albert and Albert-L\'{a}szl\'{o} Barab\'{a}si},
  title = {Statistical mechanics of complex networks},
  journal = {{Rev. Mod. Physics}},
  year = {2002},
  volume = {74},
  number = {47},
  abstract = {Complex networks describe a wide range of systems in nature and society.
	Frequently cited examples include the cell, a network of chemicals
	linked by chemical reactions, and the Internet, a network of routers
	and computers connected by physical links. While traditionally these
	systems have been modeled as random graphs, it is increasingly recognized
	that the topology and evolution of real networks are governed by
	robust organizing principles. This article reviews the recent advances
	in the ﬁeld of complex networks, focusing on the statistical mechanics
	of network topology and dynamics. After reviewing the empirical data
	that motivated the recent interest in networks, the authors discuss
	the main models and analytical tools, covering random graphs, small-world
	and scale-free networks, the emerging theory of evolving networks,
	and the interplay between topology and the network’s robustness against
	failures and attacks.},
  file = {albert2002.pdf:albert2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@ARTICLE{albert2000,
  author = {R\'{e}ka Albert and Albert-L\'{a}szl\'{o} Barab\'{a}si},
  title = {Topology of Evolving Networks: Local Events and Universality},
  journal = {Physical Review Letters},
  year = {2000},
  volume = {85},
  number = {24},
  month = {December},
  abstract = {Networks grow and evolve by local events, such as the addition of
	new nodes and links, or rewiring of links from one node to another.
	We show that depending on the frequency of these processes two topologically
	different networks can emerge, the connectivity distribution following
	either a generalized power law or an exponential. We propose a continuum
	theory that predicts these two regimes as well as the scaling function
	and the exponents, in good agreement with numerical results. Finally,
	we use the obtained predictions to ﬁt the connectivity distribution
	of the network describing the professional links between movie actors.},
  file = {albert2000.pdf:albert2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@MISC{alcorn2005,
  author = {Wade Alcorn},
  title = {The Cross-site Scripting Virus},
  month = {September},
  keywords = {computer security, XSS, virus, web security},
  owner = {kristjan},
  project = {phd},
  timestamp = {2008.09.08},
  url = {http://www.bindshell.net/papers/xssv}
}

@INPROCEEDINGS{ali2004,
  author = {Muneeb Ali and Zartash Afzal Uzmi},
  title = {{CSN:} A Network Protocol for Serving Dynamic Queries in Large-Scale
	Wireless Sensor Networks},
  booktitle = {Proc. 2nd Annual Conf. on Communication Networks and Services Research
	(CNSR'04)},
  year = {2004},
  pages = {165-174},
  address = {Fredericton, N.B, Canada},
  month = MAY,
  doi = {http://dx.doi.org/10.1109/DNSR.2004.1344725},
  file = {ali2004.pdf:ali2004.pdf:PDF},
  keywords = {sensor network, DHT, Chord}
}

@ARTICLE{alon1999,
  author = {Alon, Noga and Matias, Yossi and Szegedy, Mario},
  title = {The space complexity of approximating the frequency moments},
  journal = {J. Comput. Syst. Sci.},
  year = {1999},
  volume = {58},
  pages = {137--147},
  number = {1},
  abstract = {The frequency moments of a sequence containing mi elements of type
	i, for 1 ≤ i ≤ n, are
	
	the numbers Fk = i=1 mk . We consider the space complexity of randomized
	algorithms that
	
	approximate the numbers Fk , when the elements of the sequence are
	given one by one and cannot
	
	be stored. Surprisingly, it turns out that the numbers F0 , F1 and
	F2 can be approximated in
	
	logarithmic space, whereas the approximation of Fk for k ≥ 6 requires
	nΩ(1) space. Applications
	
	to data bases are mentioned as well.},
  address = {Orlando, FL, USA},
  doi = {http://dx.doi.org/10.1006/jcss.1997.1545},
  file = {alon1999.pdf:alon1999.pdf:PDF},
  issn = {0022-0000},
  publisher = {Academic Press, Inc.}
}

@ARTICLE{alvisi2007,
  author = {Alvisi, Lorenzo and Doumen, Jeroen and Guerraoui, Rachid and Koldehofe,
	Boris and Li, Harry and van Renesse, Robbert and Tredan, Gilles},
  title = {How robust are gossip-based communication protocols?},
  journal = {{SIGOPS} Oper. Syst. Rev.},
  year = {2007},
  volume = {41},
  pages = {14--18},
  number = {5},
  abstract = {Gossip-based communication protocols are often touted as being robust.
	Not surprisingly, such a claim relies on assumptions under which
	gossip protocols are supposed to operate. In this paper, we discuss
	and in some cases expose some of these assumptions and discuss how
	sensitive the robustness of gossip is to these assumptions. This
	analysis gives rise to a collection of new research challenges.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1317379.1317383},
  file = {alvisi2007.pdf:alvisi2007.pdf:PDF},
  issn = {0163-5980},
  keywords = {gossip protocol, robustness},
  publisher = {ACM},
  review = {A good overview of the robustness of gossip protocols. Do not consider
	aggregation protocols (I dont think). Discuss crash failures and
	byzantine failures. Several good references. 
	
	Discuss the hidden assumptions in most gossip protocols and how these
	may not hold up in real systems.
	
	Discuss challenges in robust gossiping.}
}

@INPROCEEDINGS{alzaid2008,
  author = {Alzaid, Hani and Foo, Ernest and Nieto, Juan Gonzalez},
  title = {Secure data aggregation in wireless sensor network: a survey},
  booktitle = {{AISC '08}: Proceedings of the sixth Australasian conference on Information
	security},
  year = {2008},
  pages = {93--105},
  address = {Darlinghurst, Australia, Australia},
  publisher = {Australian Computer Society, Inc.},
  abstract = {Recent advances in wireless sensor networks (WSNs) have led to many
	new promising applications including habitat monitoring and target
	tracking. However, data communication between nodes consumes a large
	portion of the total energy consumption of the WSNs. Consequently,
	data aggregation techniques can greatly help to reduce the energy
	consumption by eliminating redundant data traveling back to the base
	station. The security issues such as data integrity, confidentiality,
	and freshness in data aggregation become crucial when the WSN is
	deployed in a remote or hostile environment where sensors are prone
	to node failures and compromises. There is currently research potential
	in securing data aggregation in the WSN. With this in mind, the security
	issues in data aggregation for the WSN will be discussed in this
	paper. Then, the adversarial model that can be used in any aggregation
	scheme will be explained. After that, the "state-of-the-art" proposed
	secure data aggregation schemes will be surveyed and then classified
	into two categories based on the number of aggregator nodes and the
	existence of the verification phase. Finally, a conceptual framework
	will be proposed to provide new designs with the minimum security
	requirements against certain type of adversary. This framework gives
	a better understanding of those schemes and facilitates the evaluation
	process.},
  file = {alzaid2008.pdf:alzaid2008.pdf:PDF},
  isbn = {978-1-920682-62-0},
  keywords = {security, aggregation, wireless sensor network, survey},
  location = {Wollongong, NSW, Australia},
  review = {Very weak. Basically useless except as a list of useful refs. Long
	and rambling (inaccurate in places) on the entire field of secure
	aggregation. Can be used as a basis for taxonomy of secure aggregation
	proposals.
	
	Perhaps useable as a general starting point for a taxonomy or classification
	of attacks, vulnerabilities and previous efforts in secure aggregation.}
}

@INPROCEEDINGS{anand2005,
  author = {Anand, Madhukar and Ives, Zachary and Lee, Insup},
  title = {Quantifying eavesdropping vulnerability in sensor networks},
  booktitle = {{DMSN} '05: Proceedings of the 2nd international workshop on Data
	management for sensor networks},
  year = {2005},
  pages = {3--9},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {With respect to security, sensor networks have a number of considerations
	that separate them from traditional distributed systems. First, sensor
	devices are typically vulnerable to physical compromise. Second,
	they have significant power and processing constraints. Third, the
	most critical security issue is protecting the (statistically derived)
	aggregate output of the system, even if individual nodes may be compromised.
	We suggest that these considerations merit a rethinking of traditional
	security techniques: rather than depending on the resilience of cryptographic
	techniques, in this paper we develop new techniques to tolerate compromised
	nodes and to even mislead an adversary. We present our initial work
	on probabilistically quantifying the security of sensor network protocols,
	with respect to sensor data distributions and network topologies.
	Beginning with a taxonomy of attacks based on an adversary's goals,
	we focus on how to evaluate the vulnerability of sensor network protocols
	to eavesdropping. Different topologies and aggregation functions
	provide different probabilistic guarantees about system security,
	and make different trade-offs in power and accuracy.},
  doi = {http://doi.acm.org/10.1145/1080885.1080887},
  file = {anand2005.pdf:anand2005.pdf:PDF},
  isbn = {1-59593-206-2},
  location = {Trondheim, Norway},
  review = {Ref'd by buttyan2006. Show how probability of "meaningful" eavesdropping
	can be calculated -- here referring to that the information obtained
	by eavesdropper helps to calculate a good estimate of the real aggregate.}
}

@INPROCEEDINGS{andersen2001,
  author = {David G. Andersen and Hari Balakrishnan and M. Frans Kaashoek and
	Robert Morris.},
  title = {Resilient Overlay Networks},
  booktitle = {{SOSP}},
  year = {2001},
  abstract = {A Resilient Overlay Network (RON) is an architecture that allows distributed
	Internet applications to detect and recover from path outages and
	periods of degraded performance within several seconds, improving
	over today's wide-area routing protocols that take at least several
	minutes to recover. A RON is an application-layer overlay on top
	of the existing Internet routing substrate. The RON nodes monitor
	the functioning and quality of the Internet paths among themselves,
	and use this information to decide whether to route packets directly
	over the Internet or by way of other RON nodes, optimizing application-specific
	routing metrics.
	
	
	Results from two sets of measurements of a working RON deployed at
	sites scattered across the Internet demonstrate the benefits of our
	architecture. For instance, over a 64-hour sampling period in March
	2001 across a twelve-node RON, there were 32 significant outages,
	each lasting over thirty minutes, over the 132 measured paths. RON's
	routing mechanism was able to detect, recover, and route around {\em
	all} of them, in less than twenty seconds on average, showing that
	its methods for fault detection and recovery work well at discovering
	alternate paths in the Internet. Furthermore, RON was able to improve
	the loss rate, latency, or throughput perceived by data transfers;
	for example, about 5\% of the transfers doubled their TCP throughput
	and 5\% of our transfers saw their loss probability reduced by 0.05.
	We found that forwarding packets via at most one intermediate RON
	node is sufficient to overcome faults and improve performance in
	most cases. These improvements, particularly in the area of fault
	detection and recovery, demonstrate the benefits of moving some of
	the control over routing into the hands of end-systems.},
  file = {andersen2001.pdf:andersen2001.pdf:PDF},
  keywords = {overlay network, distributed system, routing, resilient routing, robust
	routing},
  owner = {kristjan},
  timestamp = {2009.09.02}
}

@TECHREPORT{anderson1980,
  author = {J.P. Anderson},
  title = {Computer security threat monitoring and surveillance},
  institution = {James P. Anderson Co.},
  year = {1980},
  file = {ande80.pdf:ande80.pdf:PDF},
  keywords = {computer security},
  owner = {kristjan},
  review = {[SEMINAL PAPER]},
  timestamp = {2008.03.03}
}

@TECHREPORT{anderson1972,
  author = {James P. Anderson},
  title = {Computer Security Technology Planning Study},
  institution = {U.S. Airforce Electronic Systems Division, Deputy for Command and
	Management Systems, HQ Electronic Systems Division},
  year = {1972},
  number = {ESD-TR-73-51},
  month = {October},
  file = {:ande72.pdf:PDF},
  keywords = {computer security},
  owner = {kristjan},
  timestamp = {2009.02.27}
}

@INCOLLECTION{anderson1996a,
  author = {Ross Anderson and Eli Biham},
  title = {Tiger: A fast new hash function},
  booktitle = {Fast Software Encryption},
  publisher = {Springer Berlin / Heidelberg},
  year = {1996},
  abstract = {Among those cryptographic hash function which are not based on block
	ciphers, MD4 and Snefru seemed initially quite attractive for applications
	requiring fast software hashing. However collisions for Snefru were
	found in 1990, and recently a collision of MD4 was also found. This
	casts doubt on how long these functions' variants, such as RIPE-MD,
	MD5, SHA, SHA1 and Snefru-8, will remain unbroken. Furthermore, all
	these functions were designed for 32-bit processors, and cannot be
	implemented efficiently on the new generation of 64-bit processors
	such as the DEC Alpha. We therefore present a new hash function which
	we believe to be secure; it is designed to run quickly on 64-bit
	processors, without being too slow on existing machines.},
  file = {anderson1996a.pdf:anderson1996a.pdf:PDF},
  keywords = {block cipher, cryptographically secure hash function},
  owner = {kristjan},
  timestamp = {2010.07.02}
}

@INPROCEEDINGS{anderson2004,
  author = {Ross Anderson and Haowen Chan and Adrian Perrig},
  title = {Key Infection: Smart Trust for Smart Dust},
  booktitle = {12th {IEEE} International Conference on Network Protocols {(ICNP)}},
  year = {2004},
  abstract = {Future distributed systems may include large selforganizing networks
	of locally communicating sensor nodes, any small number of which
	may be subverted by an adversary. Providing security for these sensor
	networks is important, but the problem is complicated by the fact
	that managing cryptographic key material is hard: low-cost nodes
	are neither tamper-proof nor capable of performing public key cryptography
	efﬁciently.
	
	
	 In this paper, we show how the key distribution problem can be dealt
	with in environments with a partially present, passive adversary:
	a node wishing to communicate securely with other nodes simply generates
	a symmetric key and sends it in the clear to its neighbours. Despite
	the apparent insecurity of this primitive, we can use mechanisms
	for key updating, multipath secrecy ampliﬁcation and multihop key
	propagation to build up extremely resilient trust networks where
	at most a ﬁxed proportion of communications links can be eavesdropped.
	We discuss applications in which this assumption is sensible.
	
	
	 Many systems must perforce cope with principals who are authenticated
	weakly, if at all; the resulting issues have often been left in the
	‘too hard’ tray. One particular interest of sensor networks is that
	they present a sufﬁciently compact and tractable version of this
	problem. We can perform quantitative analyses and simulations of
	alternative strategies, some of which we present here. We also hope
	that this paper may start to challenge the common belief that authentication
	is substantially about bootstrapping trust. We argue that, in distributed
	systems where the opponent can subvert any small proportion of nodes,
	it is more economic to invest in resilience than in bootstrapping.},
  file = {anderson2004.pdf:anderson2004.pdf:PDF},
  owner = {kristjan},
  review = {see on trust establishment via distribution of cryptographic material
	in the clear. Applicable to non-critical sensor networks. See discussion
	by Sorniotti.},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{anderson1996,
  author = {Ross Anderson and Markus Kuhn},
  title = {Tamper Resistance -- a Cautionary Note},
  booktitle = {he Second USENIX Workshop on Electronic Commerce Proceedings},
  year = {1996},
  pages = {1 -- 11},
  abstract = {An increasing number of systems, from pay-TV to electronic purses,
	rely on the tamper resistance of smartcards and other security processors.
	We describe a number of attacks on such systems - some old, some
	new and some that are simply little known outside the chip testing
	community. We conclude that trusting tamper resistance is problematic;
	smartcards are broken routinely, and even a device that was described
	by a government signals agency as `the most secure processor generally
	available' turns out to be vulnerable. Designers of secure systems
	should consider the consequences with care.},
  file = {anderson1996.pdf:anderson1996.pdf:PDF},
  keywords = {systems security, tamper resistance, tamper proof},
  owner = {kristjan},
  timestamp = {2010.05.11}
}

@ARTICLE{antonatos2008,
  author = {Spiros Antonatos and Periklis Akritidis and Vinh The Lam and Kostas
	G. Anagnostakis},
  title = {Puppetnets: Misusing Web Browsers as a Distributed Attack Infrastructure},
  journal = {ACM Trans. Inf. Syst. Secur.},
  year = {2008},
  volume = {12},
  pages = {1--38},
  number = {2},
  abstract = {Most of the recent work on Web security focuses on preventing attacks
	that directly harm the browser’s host machine and user. In this paper
	we attempt to quantify the threat of browsers being indirectly misused
	for attacking third parties. Specifically, we look at how the existing
	Web infrastructure (e.g., the languages, protocols, and security
	policies) can be exploited by malicious or subverted Web sites to
	remotely instruct browsers to orchestrate actions including denial
	of service attacks, worm propagation, and reconnaissance scans. We
	show that attackers are able to create powerful botnet-like infrastructures
	that can cause significant damage. We explore the effectiveness of
	countermeasures including anomaly detection and more fine-grained
	browser security policies.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1455518.1455524.},
  file = {:a12-anagnostakis.pdf:PDF},
  issn = {1094-9224},
  keywords = {networks, security, web applications, puppetnets},
  publisher = {ACM}
}

@TECHREPORT{Ari2004,
  author = {Ismail Ari and Bo Hong and Ethan L. Miller and Scott A. Brandt and
	Darrell D. E. Long},
  title = {Modeling, Analysis and Simulation of Flash Crowds on the Internet},
  institution = {UCSC},
  year = {2004},
  number = {UCSC-CRL-03-15},
  file = {ari04modeling.pdf:ari04modeling.pdf:PDF},
  keywords = {networks, simulation, modeling, flash crowd},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/ari04modeling.html}
}

@INPROCEEDINGS{Ari2003,
  author = {Ismail Ari and Bo Hong and Ethan L. Miller and Scott A. Brandt and
	Darrell D. E. Long},
  title = {Managing Flash Crowds on the Internet},
  booktitle = {{11th IEEE/ACM International Symposium on Modeling, Analysis and
	Simulation of Computer and Telecommunication Systems (MASCOTS 03)}},
  year = {2003},
  pages = {246--249},
  address = {Orlando, FL},
  month = {October},
  abstract = {A ﬂash crowd is a surge in trafﬁc to a particular Web site
	
	that causes the site to be virtually unreachable. We present
	
	a model of ﬂash crowd events and evaluate the performance
	
	of various multi-level caching techniques suitable for man-
	
	aging these events. By using well-dispersed caches and with
	
	judicious choice of replacement algorithms we show reduc-
	
	tions in client response times by as much as a factor of 25.
	
	We also show that these caches eliminate the server and
	
	network hot spots by distributing the load over the entire
	
	network.},
  file = {ari03managing.pdf:ari03managing.pdf:PDF},
  keywords = {networks, flash crowd},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{cryptoeprint:2008:422,
  author = {Frederik Armknecht and Ahmad-Reza Sadeghi},
  title = {A New Approach for Algebraically Homomorphic Encryption},
  howpublished = {Cryptology ePrint Archive, Report 2008/422},
  year = {2008},
  note = {\url{http://eprint.iacr.org/}}
}

@ARTICLE{arora2004,
  author = {A. Arora and P. Dutta and S. Bap\`{a}t and V. Kulathumani and H.
	Zhang and V. Naik and V. Mittal and H. Cao and M. Demirbas and M.
	Gouda and Y. Choi and T. Herman and S. Kulkarni and U. Arumugam and
	M. Nesterenko and A. Vora and M. Miyashita},
  title = {A line in the sand: a wireless sensor network for target detection,
	classification, and tracking},
  journal = {Computer Networks},
  year = {2004},
  volume = {46},
  pages = {605–634},
  abstract = {Intrusion detection is a surveillance problem of practical import
	that is well suited to wireless sensor networks. In this paper, we
	study the application of sensor networks to the intrusion detection
	problem and the related problems of classifying and tracking targets.
	Our approach is based on a dense, distributed, wireless network of
	multi-modal resource-poor sensors combined into loosely coherent
	sensor arrays that perform in situ detection, estimation, compression,
	and exfiltration. We ground our study in the context of a security
	scenario called ‘‘A Line in the Sand’’ and accordingly define the
	target, system, environment, and fault models. Based on the performance
	requirements of the scenario and the sensing, communication, energy,
	and computation ability of the sensor network, we explore the design
	space of sensors, signal processing algorithms, communications, networking,
	and middleware services. We introduce the influence field, which
	can be estimated from a network of binary sensors, as the basis for
	a novel classifier. A contribution of our work is that we do not
	assume a reliable network; on the contrary, we quantitatively analyze
	the effects of network unreliability on application performance.
	Our work includes multiple experimental deployments of over 90 sensor
	nodes at MacDill Air Force Base in Tampa, FL, as well as other field
	experiments of comparable scale. Based on these experiences, we identify
	a set of key lessons and articulate a few of the challenges facing
	extreme scaling to tens or hundreds of thousands of sensor nodes.},
  file = {arora2004.pdf:arora2004.pdf:PDF},
  keywords = {sensor network, target detection},
  owner = {kristjan},
  review = {Example utilization of a sensor network for intrusion detection --
	that is, in the physical sense rather than the anomaly detection
	one.},
  timestamp = {2010.05.21}
}

@MISC{arora,
  author = {Sumit Arora and Hyunyoung Lee and Ramakrishna Thurimella},
  title = {Algorithms for Finding Disjoint Paths in Mobile Networks},
  abstract = {Disjoint paths are useful in mobile networks for fault tolerance,
	increasing bandwidth, and
	
	achieving better load balance. Communication over multiple disjoint
	paths is a less expensive
	
	alternative to flooding the network. We present a distributed algorithm
	for finding k disjoint
	
	paths, for any given k, between a source S and a destination T in
	mobile networks where the
	
	links have uniform weight. Our algorithm runs in O(kn) time using
	O(km) messages where n
	
	is the number of nodes and m is the number of links in the network,
	and k is the number of
	
	paths to be found. We also present a resilient version of this algorithm
	that may be suitable for
	
	networks whose topology changes frequently.},
  file = {arora.pdf:arora.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.21}
}

@INPROCEEDINGS{artan2007,
  author = {N. Sertac Artan and Kaustubh Sinkar and Jalpa Patel and H. Jonathan
	Chao},
  title = {Aggregated Bloom Filters for Intrusion Detection and Prevention Hardware},
  booktitle = {{IEEE GLOBECOM}},
  year = {2007},
  file = {artan2007.pdf:artan2007.pdf:PDF},
  keywords = {networks, intrusion detection, bloom filters, aggregated bloom filters},
  owner = {kristjan},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{atakli2008,
  author = {Atakli, Idris M. and Hu, Hongbing and Chen, Yu and Ku, Wei Shinn
	and Su, Zhou},
  title = {Malicious node detection in wireless sensor networks using weighted
	trust evaluation},
  booktitle = {{SpringSim} '08: Proceedings of the 2008 Spring simulation multiconference},
  year = {2008},
  pages = {836--843},
  address = {San Diego, CA, USA},
  publisher = {Society for Computer Simulation International},
  abstract = {Deployed in a hostile environment, individual nodes of a wireless
	sensor network (WSN) could be easily compromised by the adversary
	due to the constraints such as limited battery lifetime, memory space
	and computing capability. It is critical to detect and isolate the
	compromised nodes in order to avoid being misled by the falsified
	information injected by the adversary through compromised nodes.
	However, it is challenging to secure the flat topology networks efficiently
	because of the poor scalability and high communication overhead.
	On top of a hierarchical WSN architecture, in this paper we proposed
	a novel scheme based on weighted-trust evaluation to detect malicious
	nodes. The hierarchical network can reduce the communication overhead
	between sensor nodes by utilizing clustered topology. Through intensive
	simulation, we verified the correctness and efficiency of our detection
	scheme.},
  file = {atakli2008.pdf:atakli2008.pdf:PDF},
  isbn = {1-56555-319-5},
  location = {Ottawa, Canada},
  review = {WEAK. Quick take: Consider a very restrictive scenario of untrusted
	nodes communicating directly with a (trusted aggregator) which in
	turn forwards over multiple hops to the top aggregator. Employ weighted
	trust evaluation to detect malicious nodes. Exact mechanism unclear
	-- seems dodgy -- based on weights which are supposed to decrease
	as nodes provide more bad data, but not obvious how updated.}
}

@INPROCEEDINGS{atasu2004,
  author = {Kubilay Atasu and Luca Breveglieri and Marco Macchetti},
  title = {Efficient {AES} Implementations for ARM Based Platforms},
  booktitle = {{ACM} Symposium on Applied Computing},
  year = {2004},
  file = {atasu2004.pdf:atasu2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.02.12}
}

@INCOLLECTION{athanasopoulos2008,
  author = {Elias Athanasopoulos and A. Makridakis and S. Antonatos and D. Antoniades
	and Sotiris Ioannidis and K. G. Anagnostakis and Evangelos P. Markatos},
  title = {Antisocial Networks: Turning a Social Network into a Botnet},
  booktitle = {Information Security},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  volume = {5222/2008},
  keywords = {networks, security, botnets},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@MISC{atmel-atmega-series-2010,
  author = {Atmel},
  title = {Data sheet: ATmega48A/48PA/88A/88PA/168A/168PA/328/328P},
  year = {2010},
  file = {:atmel-atmega-series-2010.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.02}
}

@MISC{auger2007,
  author = {Robert Auger},
  title = {The Cross Site Scripting (XSS) FAQ},
  howpublished = {[online] http://www.xssed.com/article/11/Paper\_The\_Cross\_Site\_Scripting\_XSS_FAQ},
  month = {October},
  year = {2007},
  keywords = {XSS, virus, web security},
  owner = {kristjan},
  project = {phd},
  review = {Its interesting that the author classifies XSS as "emerging" despite
	the problem having been known for a decade (see [[ross2000]]). This
	implies that there is still a lot of vulnerable web sites and general
	confusion about this class of attacks.},
  timestamp = {2008.04.11},
  url = {http://www.xssed.com/article/11/Paper_The_Cross_Site_Scripting_XSS_FAQ}
}

@ARTICLE{aurell2009,
  author = {Erik Aurell and Ren\'{e} Pfitzner},
  title = {Gaussian Belief with dynamic data and in dynamic network},
  year = {2009},
  month = {May},
  abstract = {In this paper we analyse Belief Propagation over a Gaussian model
	in a dynamic environment. Recently, this has been proposed as a method
	to average local measurement values by a distributed protocol ("Consensus
	Propagation", Moallemi \&amp; Van Roy, 2006), where the average is
	available for read-out at every single node. In the case that the
	underlying network is constant but the values to be averaged fluctuate
	("dynamic data"), convergence and accuracy are determined by the
	spectral properties of an associated Ruelle-Perron-Frobenius operator.
	For Gaussian models on Erdos-Renyi graphs, numerical computation
	points to a spectral gap remaining in the large-size limit, implying
	exceptionally good scalability. In a model where the underlying network
	also fluctuates ("dynamic network"), averaging is more effective
	than in the dynamic data case. Altogether, this implies very good
	performance of these methods in very large systems, and opens a new
	field of statistical physics of large (and dynamic) information systems.},
  citeulike-article-id = {4463150},
  eprint = {0905.0266},
  file = {aurell2009.pdf:aurell2009.pdf:PDF},
  keywords = {networking, distributed aggregation, belief propagation},
  posted-at = {2009-05-05 11:19:39},
  priority = {2},
  url = {http://arxiv.org/abs/0905.0266}
}

@PHDTHESIS{avancha2005,
  author = {Sasikanth Avancha},
  title = {A Holistic Approach to Secure Sensor Networks},
  school = {University of Maryland},
  year = {2005},
  abstract = {Wireless sensor networks (WSNs) form a unique class of ad hoc networks
	consisting of heterogeneous
	
	but highly resource-constrained devices that can sense their environment
	and report sensed data to desig-
	
	nated nodes in the network. We present a holistic approach to improve
	the performance of wireless sensor
	
	networks with respect to security, longevity and connectivity under
	changing environmental conditions. Our
	
	approach is two-fold: We have created a framework for adaptability
	that detects, classifies and responds to
	
	environmental variations affecting WSN performance. We have also designed
	security mechanisms in our
	
	framework to demonstrate WSN adaptations. Our security mechanisms
	can be used as basic building blocks
	
	in WSN designs. The adaptability framework is generic and ensures
	that WSNs can respond to a variety of
	
	changes in environmental conditions, such as variations related to
	security and network topology, affecting
	
	their performance.
	
	
	 We have designed a two-tier adaptability component, SWANS, using
	a principled, ontological approach
	
	to ensure both local and global responses to environmental variations.
	Local responses are generated by in-
	
	dividual sensor nodes. At node level, SWANS monitors a set of twenty-one
	low-level parameters (including
	
	those associated with secure WSN establishment) and employs a local
	knowledge base to compute the node’s
	
	logical state. It employs a set of rules determine the most appropriate
	response corresponding to a logical
	
	state. At network level SWANS combines sensor node state information
	with user-defined constraints and
	
	sensor data. It employs a network-level knowledge base to compute
	the network’s logical state and generate a
	
	global response to the observed environmental variation. Experimental
	evaluations show that WSNs employ-
	
	ing SWANS are more secure, live longer and have better connectivity
	than their non-adaptive counterparts.
	
	
	 We also designed a set of three security protocol suites, SONETS,
	that secures a WSN against different
	
	classes of adversaries. P-SONETS is a centralized protocol suite that
	secures WSNs deployed to establish a
	
	perimeter around high value assets against adversaries who seek to
	breach the perimeter and attack the asset.
	
	C-SONETS is a scalable centralized protocol suite containing a novel
	topology discovery and key setup pro-
	
	tocol to thwart adversaries with global presence in the area of interest
	capable of attacking the WSN before,
	
	during and after its formation. D-SONETS is a distributed protocol
	suite that ensures rapid establishment of
	
	a secure WSN for non-critical applications in which adversary presence
	is local. Experimental evaluations of
	
	P-SONETS, C-SONETS and D-SONETS show their feasibility to the associated
	application class and their
	
	ability to thwart adversaries corresponding to each class.},
  file = {avancha2005.pdf:avancha2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.31}
}

@ARTICLE{avancha2003,
  author = {Sasikanth Avancha and Jeffrey Undercoffer and Anupam Joshi and John
	Pinkston},
  title = {Secure sensor networks for perimeter protection},
  journal = {Computer Networks},
  year = {2003},
  volume = {43},
  pages = {421-435},
  number = {4},
  month = {November},
  abstract = {Sensor networks have been identified as being useful in a variety
	of domains to include the battlefield and perimeter defense. We motivate
	the security problems that sensor networks face by developing a scenario
	representative of a large application class where these networks
	would be used in the future. We identify threats to this application
	class and propose a new lightweight security model that operates
	in the base station mode of sensor communication, where the security
	model is mindful of the resource constraints of sensor networks.
	Our application class requires mitigation against traffic analysis,
	hence we do not use any routing mechanisms, relying solely on broadcasts
	of end-to-end encrypted packets. Our model extends the broadcast
	range of the base station model by utilizing nodes adjacent to the
	base station as an intermediary hop. Additionally, our model detects
	and corrects some classes of aberrant node behavior. We have simulated
	our model and present simulation results.},
  file = {avancha2003.pdf:avancha2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{avoine2003,
  author = {Avoine, Gildas and Vaudenay, Serge},
  title = {Fair {E}xchange with {G}uardian {A}ngels},
  booktitle = {The 4th {I}nternational {W}orkshop on {I}nformation {S}ecurity {A}pplications
	- {WISA}},
  year = {2003},
  number = {2908},
  series = {Lecture Notes in Computer Sciences},
  pages = {188--202},
  __markedentry = {[kristjan]},
  abstract = {In this paper we propose a new probabilistic Fair Exchange Protocol
	which requires no central Trusted Third Party. Instead, it relies
	on a virtually distributed and decentralized Trusted Third Party
	which is formalized as a Guardian Angel: a kind of Observer e.g.
	a tamper proof security device. We thus introduce a network model
	with Pirates and Guardian Angels which is well suited for Ad Hoc
	networks. In this setting we reduce the Fair Exchange Problem to
	a Synchronization Problem in which honest parties need to eventually
	decide whether or not a protocol succeeded in a synchronous way through
	a hostile network which does not guaranty that sent messages will
	be eventually received. This problem can be of independent interest
	in order to add reliability of protocol termination in secure channels.},
  affiliation = {EPFL},
  details = {http://infoscience.epfl.ch/record/99464},
  documenturl = {http://infoscience.epfl.ch/getfile.py?recid=99464&mode=best},
  extra-id = {4739; 000189200400015},
  file = {avoine2003.pdf:avoine2003.pdf:PDF},
  keywords = {Fair Exchange; Security Module; Synchronization; Distributed Systems;
	NCCR-MICS; NCCR-MICS/CL3, smart cards, guardian angels, trusted hardware},
  location = {Jeju Island, Korea},
  oai-id = {oai:infoscience.epfl.ch:99464},
  oai-set = {conf; fulltext; fulltext-public},
  review = {Recommended by Sonja Buchegger.
	
	
	Probabilistic fair exchange (w. some prob. both parties get expected
	items or neither does) protocol. Reduce fair exchange problem to
	a synchronization problem by use of tamper proof security devices,
	eg smart cards. Security devices, guardian angles, form a distributed
	trusted third party by means of cryptographic protocols.
	
	
	See refs on utilization of trusted hardware.
	
	
	Discuss (briefly) application to ad-hoc networks.},
  status = {PUBLISHED},
  unit = {LASEC},
  url = {http://www.springer.com/}
}

@TECHREPORT{avoine2003a,
  author = {Avoine, Gildas and Vaudenay, Serge},
  title = {Cryptography with {G}uardian {A}ngels: {B}ringing civilization to
	pirates - {A}bstract},
  institution = {{EFPL}},
  year = {2003},
  note = {Report on a Working Session on Security in Wireless Ad Hoc Networks,
	Levente Buttyan and Jean-Pierre Hubaux (eds.), ACM Mobile Computing
	and Communications Review (MC2R), Vol. 7., pp. 74-94, 2003},
  abstract = {In contrast with traditional cryptographic protocols in which parties
	can have access to common third parties, and where at least one of
	them is assumed to be honest, we propose here a new model which is
	relevant for networks of communication devices with security modules.
	We then focus on the problem of fair exchange in this model. We propose
	a probabilistic protocol which provides arbitrarily low unfairness
	(involving a complexity cost).},
  affiliation = {EPFL},
  details = {http://infoscience.epfl.ch/record/99465},
  documenturl = {http://infoscience.epfl.ch/getfile.py?recid=99465&mode=best},
  file = {avoine2003a.pdf:avoine2003a.pdf:PDF},
  oai-id = {oai:infoscience.epfl.ch:99465},
  oai-set = {fulltext; report; fulltext-public},
  review = {Recommended by Sonja Buchegger.
	
	
	See conference paper by avione from 2009.},
  status = {PUBLISHED},
  unit = {LASEC}
}

@ARTICLE{awerbuch1985,
  author = {Awerbuch, Baruch},
  title = {Complexity of network synchronization},
  journal = {{J. ACM}},
  year = {1985},
  volume = {32},
  pages = {804--823},
  number = {4},
  abstract = {The problem of simulating a synchronous network by an asynchronous
	network is investigated. A new simulation technique, referred to
	as a synchronizer, which is a new, simple methodology for designing
	efficient distributed algorithms in asynchronous networks, is proposed.
	The synchronizer exhibits a trade-off between its communication and
	time complexities, which is proved to be within a constant factor
	of the lower bound.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/4221.4227},
  file = {awerbuch1985.pdf:awerbuch1985.pdf:PDF},
  issn = {0004-5411},
  keywords = {algorithms, synchronizers},
  publisher = {ACM}
}

@INPROCEEDINGS{awerbuch2007,
  author = {Baruch Awerbuch and Christian Scheideler},
  title = {Towards Scalable and Robust Overlay Networks},
  booktitle = {{IPTPS'07}},
  year = {2007},
  abstract = {Every peer-to-peer system is based on some overlay network connecting
	its peers. Many of the overlay network concepts proposed in the scientific
	community are based on the concept of virtual space. These designs
	are usually highly scalable, but they do not guarantee robustness
	against adversarial attacks, especially when considering open peer-to-peer
	systems. In these systems, determined adversaries may start both
	insider and outsider attacks in order to harm the overlay network
	as much as this is possible. We will focus on insider attacks in
	which the adversarial peers in the network perform join-leave attacks,
	and we will consider outsider attacks in which an adversary can perform
	a denial-of-service attack against any of the honest peers in the
	network. Strategies have been proposed that can defend an overlay
	network against even massive join-leave attacks, and strategies are
	also known that can defend an overlay network against limited denial-of-service
	attacks. However, none of these can protect an overlay network against
	combinations of these attacks. We illustrate in this paper why it
	is not easy to design strategies against these attacks and propose
	join and leave protocols for overlay networks based on the concept
	of virtual space that can make them provably robust against these
	attacks without creating too much overhead.},
  keywords = {distributed systems, distributed hash tables, DHTs, adversarial churn,
	join leave attacks},
  owner = {kristjan},
  timestamp = {2009.09.02}
}

@INPROCEEDINGS{awerbuch2006,
  author = {Awerbuch, Baruch and Scheideler, Christian},
  title = {Towards a scalable and robust {DHT}},
  booktitle = {{SPAA} '06: Proceedings of the eighteenth annual {ACM} symposium
	on Parallelism in algorithms and architectures},
  year = {2006},
  pages = {318--327},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The problem of scalable and robust distributed data storage has recently
	attracted a lot of attention. A common approach in the area of peer-to-peer
	systems has been to use a distributed hash table (or DHT). DHTs are
	based on the concept of virtual space. Peers and data items are mapped
	to points in that space, and local-control rules are used to decide,
	based on these virtual locations, how to interconnect the peers and
	how to map the data to the peers.
	
	
	 DHTs are known to be highly scalable and easy to update as peers
	enter and leave the system. It is relatively easy to extend the DHT
	concept so that a constant fraction of faulty peers can be handled
	without any problems, but handling adversarial peers is very challenging.
	The biggest threats appear to be join-leave attacks (i.e., adaptive
	join-leave behavior by the adversarial peers) and attacks on the
	data management level (i.e., adaptive insert and lookup attacks by
	the adversarial peers) against which no provably robust mechanisms
	are known so far. Join-leave attacks, for example, may be used to
	isolate honest peers in the system, and attacks on the data management
	level may be used to create a high load-imbalance, seriously degrading
	the correctness and scalability of the system.
	
	
	 We show, on a high level, that both of these threats can be handled
	in a scalable manner, even if a constant fraction of the peers in
	the system is adversarial, demonstrating that open systems for scalable
	distributed data storage that are robust against even massive adversarial
	behavior are feasible.},
  doi = {http://doi.acm.org/10.1145/1148109.1148163},
  file = {awerbuch2006.pdf:awerbuch2006.pdf:PDF},
  isbn = {1-59593-452-9},
  keywords = {distributed systems, distributed hash tables, DHTs, adversarial churn,
	join leave attacks},
  location = {Cambridge, Massachusetts, USA}
}

@TECHREPORT{axelsson2000,
  author = {Stefan Axelsson},
  title = {Intrusion Detection Systems: A Survey and Taxonomy},
  institution = {Chalmers University of Technology},
  year = {2000},
  file = {axelsson2000.pdf:axelsson2000.pdf:PDF},
  keywords = {networking, intrusion detection, survey}
}

@ONLINE{bacher2008,
  author = {Paul B\"{a}cher and Thorsten Holz and Markus K\"{o}tter and Georg
	Wicherski},
  title = {Know your Enemy: Tracking Botnets},
  url = {http://www.honeynet.org/papers/bots},
  year = {2008},
  abstract = {Honeypots are a well known technique for discovering the tools, tactics,
	and motives of attackers. In this paper we look at a special kind
	of threat: the individuals and organizations who run botnets. A botnet
	is a network of compromised machines that can be remotely controlled
	by an attacker. Due to their immense size (tens of thousands of systems
	can be linked together), they pose a severe threat to the community.
	With the help of honeynets we can observe the people who run botnets
	- a task that is difficult using other techniques. Due to the wealth
	of data logged, it is possible to reconstruct the actions of attackers,
	the tools they use, and study them in detail. In this paper we take
	a closer look at botnets, common attack techniques, and the individuals
	involved.
	
	
	We start with an introduction to botnets and how they work, with examples
	of their uses. We then briefly analyze the three most common bot
	variants used. Next we discuss a technique to observe botnets, allowing
	us to monitor the botnet and observe all commands issued by the attacker.
	We present common behavior we captured, as well as statistics on
	the quantitative information learned through monitoring more than
	one hundred botnets during the last few months. We conclude with
	an overview of lessons learned and point out further research topics
	in the area of botnet-tracking, including a tool called mwcollect2
	that focuses on collecting malware in an automated fashion.},
  keywords = {networking, security, botnets},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{babai1991,
  author = {Babai, L\'{a}szl\'{o} and Fortnow, Lance and Levin, Leonid A. and
	Szegedy, Mario},
  title = {Checking computations in polylogarithmic time},
  booktitle = {{STOC '91}: Proceedings of the twenty-third annual {ACM} symposium
	on Theory of computing},
  year = {1991},
  pages = {21--32},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/103418.103428},
  file = {babai1991.pdf:babai1991.pdf:PDF},
  isbn = {0-89791-397-3},
  location = {New Orleans, Louisiana, United States}
}

@INPROCEEDINGS{backstrom2006,
  author = {Lars Backstrom and Dan Huttenlocher and Jon Kleinberg and Xiangyang
	Lan},
  title = {Group formation in large social networks: membership, growth, and
	evolution},
  booktitle = {KDD '06: Proceedings of the 12th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2006},
  pages = {44--54},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The processes by which communities come together, attract new members,
	and develop over time is a central research issue in the social sciences
	- political movements, professional organizations, and religious
	denominations all provide fundamental examples of such communities.
	In the digital domain, on-line groups are becoming increasingly prominent
	due to the growth of community and social networking sites such as
	MySpace and LiveJournal. However, the challenge of collecting and
	analyzing large-scale time-resolved data on social groups and communities
	has left most basic questions about the evolution of such groups
	largely unresolved: what are the structural features that influence
	whether individuals will join communities, which communities will
	grow rapidly, and how do the overlaps among pairs of communities
	change over time.Here we address these questions using two large
	sources of data: friendship links and community membership on LiveJournal,
	and co-authorship and conference publications in DBLP. Both of these
	datasets provide explicit user-defined communities, where conferences
	serve as proxies for communities in DBLP. We study how the evolution
	of these communities relates to properties such as the structure
	of the underlying social networks. We find that the propensity of
	individuals to join communities, and of communities to grow rapidly,
	depends in subtle ways on the underlying network structure. For example,
	the tendency of an individual to join a community is influenced not
	just by the number of friends he or she has within the community,
	but also crucially by how those friends are connected to one another.
	We use decision-tree techniques to identify the most significant
	structural determinants of these properties. We also develop a novel
	methodology for measuring movement of individuals between communities,
	and show how such movements are closely aligned with changes in the
	topics of interest within the communities.},
  doi = {http://doi.acm.org/10.1145/1150402.1150412},
  file = {backstrom2006.pdf:backstrom2006.pdf:PDF},
  isbn = {1-59593-339-5},
  keywords = {social networks},
  location = {Philadelphia, PA, USA}
}

@ARTICLE{balakrishnan2003,
  author = {Hari Balakrishnan and M. Frans Kaashoek and David Karger and Robert
	Morris and Ion Stoica},
  title = {Looking Up Data in {P2P} Systems},
  journal = {{CACM}},
  year = {2003},
  month = {February},
  file = {balakrishnan2003.pdf:balakrishnan2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.07}
}

@INPROCEEDINGS{balasubramanian2004,
  author = {Chandramouli Balasubramanian and J. J. Garcia-Luna-Aceves},
  title = {Shortest Multipath Routing Using Labeled Distances},
  booktitle = {{IEEE} International Conference on Mobile Ad hoc and Sensor Systems},
  year = {2004},
  abstract = {We present and verify SMLDR (Shortest Multipath Labeled Distance Routing),
	an on-demand loop free multipath routing protocol. It extends Labeled
	Distance Routing (LDR) to the multipath domain and enables loop freedom
	by maintaining the ordering of distance invariants. By modifying
	the route update conditions of LDR and by using the concept of limiting
	distance we demonstrate shortest multipath routing. Further we describe
	the fundamental multipath concepts for on-demand routing protocols
	and elucidate how SMLDR exercises each of these concepts in its routing
	mechanisms. The performance of SMLDR is compared against the performance
	of LDR, AODV and its multipath variant AOMDV. The simulation results
	corroborate the need for shortest multipath routing in terms of higher
	performance for the chosen metrics.},
  file = {balasubramanian2004.pdf:balasubramanian2004.pdf:PDF},
  keywords = {multi-path routing, SMLDR}
}

@INPROCEEDINGS{balfe2005,
  author = {Shane Balfe and Amit D. Lakhani and Kenneth G. Paterson},
  title = {Trusted Computing: Providing Security for Peer-to-Peer Networks},
  booktitle = {P2P '05: Proceedings of the Fifth IEEE International Conference on
	Peer-to-Peer Computing},
  year = {2005},
  pages = {117--124},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {In this paper, we demonstrate the application of Trusted Computing
	to securing Peer-to-Peer (P2P) networks. We identify a central challenge
	in providing many of the security services within these networks,
	namely the absence of stable verifiable peer identities. We employ
	the functionalities provided by Trusted Computing technology to establish
	a pseudonymous authentication scheme for peers and extend this scheme
	to build secure channels between peers for future communications.
	In support of our work, we illustrate how commands from the Trusted
	Computing Group (TCG) specifications can be used to implement our
	approach in P2P networks.},
  doi = {http://dx.doi.org/10.1109/P2P.2005.40},
  file = {:trusted-computing-providing-security.pdf:PDF},
  isbn = {0-7695-2376-5},
  keywords = {networks, trust management, peer-to-peer systems}
}

@INPROCEEDINGS{bar-noy-1987,
  author = {Bar-Noy, Amotz and Dolev, Danny and Dwork, Cynthia and Strong, H.
	Raymond},
  title = {Shifting gears: changing algorithms on the fly to expedite Byzantine
	agreement},
  booktitle = {{PODC '87}: Proceedings of the sixth annual {ACM} Symposium on Principles
	of distributed computing},
  year = {1987},
  pages = {42--51},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/41840.41844},
  isbn = {0-89791-239-4},
  location = {Vancouver, British Columbia, Canada}
}

@ARTICLE{barabasi1999,
  author = {A. L. Barabási and R. Albert},
  title = {Emergence of scaling in random networks},
  journal = {Science},
  year = {1999},
  volume = {286},
  pages = {509 -- 512},
  number = {5439},
  abstract = {Systems as diverse as genetic networks or the world wide web are best
	described as networks with complex topology. A common property of
	many large networks is that the vertex connectivities follow a scale-free
	power-law distribution. This feature is found to be a consequence
	of the two generic mechanisms that networks expand continuously by
	the addition of new vertices, and new vertices attach preferentially
	to already well connected sites. A model based on these two ingredients
	reproduces the observed stationary scalefree distributions, indicating
	that the development of large networks is governed by robust self-organizing
	phenomena that go beyond the particulars of the individual systems.},
  file = {barabasi1999.pdf:barabasi1999.pdf:PDF},
  keywords = {social networks, scaling, modeling}
}

@ARTICLE{barakat2003,
  author = {Chadi Barakat and Patrick Thiran and Gianluca Iannaccone and Christophe
	Diot and Philippe Owezarski},
  title = {Modeling Internet backbone trafﬁc at the ﬂow level},
  journal = {{IEEE} Transactions on Signal Processing - Special Issue on Networking},
  year = {2003},
  volume = {51},
  number = {8},
  month = {August},
  abstract = {Our goal is to design a trafﬁc model for non congested Internet backbone
	links, which is simple enough to be used in network operation, while
	being as general as possible. The proposed solution is to model the
	trafﬁc at the ﬂow level by a Poisson shot-noise process. In our model,
	a ﬂow is a generic notion that must be able to capture the characteristics
	of any kind of data stream. We analyze the accuracy of the model
	with real trafﬁc traces collected on the Sprint IP (Internet Protocol)
	backbone network. Despite its simplicity, our model provides a good
	approximation of the real trafﬁc observed in the backbone and of
	its variation. Finally, we discuss the application of our model to
	network design and dimensioning.},
  file = {barakat2003.pdf:barakat2003.pdf:PDF},
  keywords = {networks, network traffic modeling, network trace analysis},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@INPROCEEDINGS{barbara2001,
  author = {Daniel Barbar\'{a} and Ningning Wu and Sushil Jajodia},
  title = {Detecting Novel Network Intrusions Using Bayes Estimators},
  booktitle = {First {SIAM} Conference on Data mining},
  year = {2001},
  address = {Chicago, IL},
  abstract = {From the ﬁrst appearance of network attacks, the internet worm, to
	the most recent one in which the servers of several famous e-business
	companies were paralyzed for several hours, causing huge ﬁnancial
	losses, network-based attacks have been increasing in frequency and
	severity. As a powerful weapon to protect networks, intrusion detection
	has been gaining a lot of attention.
	
	 Traditionally, intrusion detection techniques are classiﬁed into
	two broad categories: misuse detection and anomaly detection. Misuse
	detection aims to detect well-known attacks as well as slight variations
	of them, by characterizing the rules that govern these attacks. Due
	to its nature, misuse detection has low false alarms but it is unable
	to detect any attacks that lie beyond its knowledge. Anomaly detection
	is designed to capture any deviations from the established proﬁles
	of users and systems normal behavior pattern. Although in principle,
	anomaly detection has the ability to detect new attacks, in practice
	this is far from easy. Anomaly detection has the potential to generate
	too many false alarms, and it is very time consuming and labor expensive
	to sift true intrusions from the false alarms. 
	
	As new network attacks emerge, the need for intrusion detection systems
	to detect novel attacks becomes pressing. As we stated before, this
	is one of the hardest tasks to accomplish, since no knowledge about
	the novel attacks is available. However, if we view the problem from
	another angle, we can ﬁnd a solution. Attacks do something that is
	diﬀerent from normal activities: if we have comprehensive knowledge
	about normal activities and their normal deviations, then all activities
	that are not normal should be suspicious. So the problem becomes
	one of how to derive the knowledge about unknown attacks from the
	existing information of normal activities as well as known attacks.
	
	 In this paper, we propose a method based on a technique called pseudo-Bayes
	estimators to enhance an anomaly detection system’s ability to detect
	new attacks while reducing the false alarm rate as much as possible.
	Our work is based on an anomaly detection system called Audit Data
	Analysis and Mining (ADAM)[3] that we developed at the Center for
	Secure Information Systems of George Mason University. ADAM applies
	mining association rules techniques to look for the abnormal events
	in network traﬃc data, then it uses a classiﬁcation algorithm to
	classify the abnormal events into normal instances and abnormal instances.
	The abnormal instances can be further categorized into attack names
	if ADAM has gained knowledge about the attacks. With the help of
	the classiﬁer, the number of false alarms is greatly reduced because
	the abnormal associations that belong to normal instances will be
	ﬁltered out. However, the normal instances and attacks that the classiﬁer
	is able to recognize are limited to those that appear in the training
	data (due to the innate limitation of all supervised classiﬁcation
	methods).
	
	 To overcome this limitation, we apply the pseudo-Bayes estimators
	method as a means to estimate the prior and posterior probabilities
	of new attacks. Then we construct a Naive Bayes classiﬁer to classify
	the instances into normal instances, known attacks and new attacks.
	One advantage of pseudo-Bayes estimators is that no knowledge about
	new attacks is needed since the estimated prior and posterior probabilities
	of new attacks are derived from the information of normal instances
	and known attacks.},
  file = {sdm01_29.pdf:sdm01_29.pdf:PDF},
  keywords = {networks, security, IDS, intrusion detection},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@ARTICLE{barford-1999,
  author = {Paul Barford and Azer Bestavros and Adam Bradley and Mark Crovella},
  title = {Changes in web client access patterns: Characteristics and caching
	implications},
  journal = {World Wide Web, Special Issue on Characterization and Performance
	Evaluation},
  year = {1999},
  volume = {2},
  pages = {15--28},
  abstract = {Understanding the nature of the workloads and system demands created
	by users of the World Wide Web is crucial to properly designing and
	provisioning Web services. Previous measurements of Web client workloads
	have been shown to exhibit a number of characteristic features; however,
	it is not clear how those features may be changing with time. In
	this study we compare two measurements of Web client workloads separated
	in time by three years, both captured from the same computing facility
	at Boston University. The older dataset, obtained in 1995, is well-known
	in the research literature and has been the basis for a wide variety
	of studies. The newer dataset was captured in 1998 and is comparable
	in size to the older dataset. The new dataset has the drawback that
	the collection of users measured may no longer be representative
	of general Web users; however using it has the advantage that many
	comparisons can be drawn more clearly than would be possible using
	a new, different source of measurement. Our results fall into two
	categories. First we compare the statistical and distributional properties
	of Web requests across the two datasets. This serves to reinforce
	and deepen our understanding of the characteristic statistical properties
	of Web client requests. We find that the kinds of distributions that
	best describe document sizes have not changed between 1995 and 1998,
	although specific values of the distributional parameters are different.
	Second, we explore the question of how the observed differences in
	the properties of Web client requests, particularly the popularity
	and temporal locality properties, affect the potential for Web file
	caching in the network. We find that for the computing facility represented
	by our traces between 1995 and 1998, (1) the benefits of using size-based
	caching policies have diminished; and (2) the potential for caching
	requested files in the network has declined. ii},
  file = {:10.1.1.56.7552.pdf:PDF},
  keywords = {Web measurements, access patterns}
}

@ARTICLE{barford-1998,
  author = {Paul Barford and Mark Crovella},
  title = {Generating representative Web workloads for network and server performance
	evaluation},
  journal = {SIGMETRICS Perform. Eval. Rev.},
  year = {1998},
  volume = {26},
  pages = {151--160},
  number = {1},
  abstract = {One role for workload generation is as a means for understanding how
	servers and networks respond to variation in load. This enables management
	and capacity planning based on current and projected usage. This
	paper applies a number of observations of Web server usage to create
	a realistic Web workload generation tool which mimics a set of real
	users accessing a server. The tool, called Surge (Scalable URL Reference
	Generator) generates references matching empirical measurements of
	1) server file size distribution; 2) request size distribution; 3)
	relative file popularity; 4) embedded file references; 5) temporal
	locality of reference; and 6) idle periods of individual users. This
	paper reviews the essential elements required in the generation of
	a representative Web workload. It also addresses the technical challenges
	to satisfying this large set of simultaneous constraints on the properties
	of the reference stream, the solutions we adopted, and their associated
	accuracy. Finally, we present evidence that Surge exercises servers
	in a manner significantly different from other Web server benchmarks.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/277858.277897},
  file = {:p151-barford.pdf:PDF},
  issn = {0163-5999},
  keywords = {Web measurements, access patterns, modeling},
  publisher = {ACM}
}

@INPROCEEDINGS{barford2002,
  author = {Paul Barford and Jeffery Kline and David Plonka and Amos Ron},
  title = {A Signal Analysis of Network Trafﬁc Anomalies},
  booktitle = {ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP 2002},
  year = {2002},
  abstract = {Identifying anomalies rapidly and accurately is critical to the efﬁcient
	operation of large computer networks. Accurately characterizing important
	classes of anomalies greatly facilitates their identiﬁcation; however,
	the subtleties and complexities of anomalous trafﬁc can easily confound
	this process. In this paper we report results of signal analysis
	of four classes of network trafﬁc anomalies: outages, ﬂash crowds,
	attacks and measurement failures. Data for this study consists of
	IP ﬂow and SNMP measurements collected over a six month period at
	the border router of a large university. Our results show that wavelet
	ﬁlters are quite effective at exposing the details of both ambient
	and anomalous trafﬁc. Speciﬁcally, we show that a pseudo-spline ﬁlter
	tuned at speciﬁc aggregation levels will expose distinct characteristics
	of each class of anomaly. We show that an effective way of exposing
	anomalies is via the detection of a sharp increase in the local variance
	of the ﬁltered data. We evaluate trafﬁc anomaly signals at different
	points within a network based on topological distance from the anomaly
	source or destination. We show that anomalies can be exposed effectively
	even when aggregated with a large amount of additional trafﬁc. We
	also compare the difference between the same trafﬁc anomaly signals
	as seen in SNMP and IP ﬂow data, and show that the more coarse-grained
	SNMP data can also be used to expose anomalies effectively.},
  file = {barford2002.pdf:barford2002.pdf:PDF},
  keywords = {networks, anomaly detection},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@INPROCEEDINGS{barrett2003,
  author = {Barrett, Christopher L. and Eidenbenz, Stephan J. and Kroc, Lukas
	and Marathe, Madhav and Smith, James P.},
  title = {Parametric probabilistic sensor network routing},
  booktitle = {{WSNA} '03: Proceedings of the 2nd {ACM} international conference
	on Wireless sensor networks and applications},
  year = {2003},
  pages = {122--131},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Motivated by realistic sensor network scenarios that have misinformed
	nodes and variable network topologies, we propose a fundamentally
	different approach to routing that combines the best features of
	limited-flooding and information-sensitive path-finding protocols
	into a reliable, low-power method that can make delivery guarantees
	independent of parameter values or information noise levels. We introduce
	Parametric Probabilistic Sensor Network Routing Protocols, a family
	of light-weight and robust multi-path routing protocols for sensor
	networks in which an intermediate sensor decides to forward a message
	with a probability that depends on various parameters, such as the
	distance of the sensor to the destination, the distance of the source
	sensor to the destination, or the number of hops a packet has already
	traveled. We propose two protocol variants of this family and compare
	the new methods to other probabilistic and deterministic protocols,
	namely constant-probability gossiping, uncontrolled flooding, random
	wandering, shortest path routing (and a variation), and a load-spreading
	shortest-path protocol inspired by [Servetto, Barrenechea, 2002].
	We consider sensor networks where a sensor's knowledge of the local
	or global information is uncertain (parametrically noised) due to
	sensor mobility, and investigate the trade-off between robustness
	of the protocol as measured by quality of service (in particular,
	successful delivery rate and delivery lag) and use of resources (total
	network load). Our results show that the multi-path protocols are
	less sensitive to misinformation, and suggest that in the presence
	of noisy data, a limited flooding strategy will actually perform
	better and use fewer resources than an attempted single-path routing
	strategy, with the Parametric Probabilistic Sensor Network Routing
	Protocols outperforming other protocols. Our results also suggest
	that protocols using network information perform better than protocols
	that do not, even in the presence of strong noise.},
  doi = {http://doi.acm.org/10.1145/941350.941368},
  file = {barrett2003.pdf:barrett2003.pdf:PDF},
  isbn = {1-58113-764-8},
  location = {San Diego, CA, USA},
  review = {see with regards to randomized routing -- comparison with constant
	probability gossiping}
}

@INPROCEEDINGS{barry2009,
  author = {Bazara Barry},
  title = {Intrusion Detection with OMNeT++},
  booktitle = {SIMUTOOLS'09},
  year = {2009},
  abstract = {Network simulators serve a variety of purposes. Compared to the cost,
	time, and effort involved in setting up an entire test bed containing
	different types of network devices, network simulators are relatively
	fast and inexpensive. Computer intrusions are occurring almost routinely
	and have become a major issue in our networked society. Every organization
	is faced by the big challenge of selecting an intrusion detection
	system and testing its abilities. Therefore, it is worthwhile to
	investigate the possibility of implementing and thoroughly testing
	intrusion detection systems using network simulators. In this paper,
	we report our experience with implementing and testing intrusion
	detection systems using OMNeT++ simulator. We highlight how OMNeT++
	is harnessed to test and evaluate the intrusion detection system
	in terms of detection accuracy and performance.},
  file = {barry2009.pdf:barry2009.pdf:PDF},
  keywords = {network, security, intrusion detection, modeling, OMNeT++},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@INPROCEEDINGS{barth2008,
  author = {Adam Barth and Collin Jackson and John C. Mitchell},
  title = {Robust defenses for cross-site request forgery},
  booktitle = {CCS '08: Proceedings of the 15th ACM conference on Computer and communications
	security},
  year = {2008},
  pages = {75--88},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Cross-Site Request Forgery (CSRF) is a widely exploited web site vulnerability.
	In this paper, we present a new variation on CSRF attacks, login
	CSRF, in which the attacker forges a cross-site request to the login
	form, logging the victim into the honest web site as the attacker.
	The severity of a login CSRF vulnerability varies by site, but it
	can be as severe as a cross-site scripting vulnerability. We detail
	three major CSRF defense techniques and find shortcomings with each
	technique. Although the HTTP Referer header could provide an effective
	defense, our experimental observation of 283,945 advertisement impressions
	indicates that the header is widely blocked at the network layer
	due to privacy concerns. Our observations do suggest, however, that
	the header can be used today as a reliable CSRF defense over HTTPS,
	making it particularly well-suited for defending against login CSRF.
	For the long term, we propose that browsers implement the Origin
	header, which provides the security benefits of the Referer header
	while responding to privacy concerns.},
  doi = {http://doi.acm.org/10.1145/1455770.1455782},
  file = {p75-barth.pdf:p75-barth.pdf:PDF},
  isbn = {978-1-59593-810-7},
  keywords = {security, XSS},
  location = {Alexandria, Virginia, USA}
}

@INPROCEEDINGS{basagni2001,
  author = {Basagni, Stefano and Herrin, Kris and Bruschi, Danilo and Rosti,
	Emilia},
  title = {Secure pebblenets},
  booktitle = {{MobiHoc '01: Proceedings of the 2nd ACM international symposium
	on Mobile ad hoc networking \& computing}},
  year = {2001},
  pages = {156--163},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We consider the problem of securing communication in large ad hoc
	networks, i.e., wireless networks with no fixed, wired infrastructure
	and with multi-hop routes. Such networks, e.g., networks of sensors,
	are deployed for applications such as microsensing, monitoring and
	control, and for extending the peer-to-peer communication capability
	of smaller group of network users. Because the nodes of these networks,
	which we term pebbles for their very limited size and large number,
	are resource constrained, only symmetric key cryptography is feasible.
	We propose a key management scheme to periodically update the symmetric
	keys used by all pebbles. By combining mobility-adaptive clustering
	and an effective probabilistic selection of the key-generating node,
	the proposed scheme meets the requirements of efficiency, scalability
	and security needed for the survivability of networks of pebbles
	(pebblenets)},
  file = {basagni2001.pdf:basagni2001.pdf:PDF},
  isbn = {1-58113-428-2},
  location = {Long Beach, CA, USA}
}

@TECHREPORT{baset2004,
  author = {Salman A. Baset and Henning Schulzrinne},
  title = {An Analysis of the Skype Peer-to-Peer Internet Telephony Protocol},
  institution = {Computer Science Department, Columbia University},
  year = {2004},
  number = {CUCS-039-04},
  address = {New York, NY},
  abstract = {Skype is a peer-to-peer VoIP client developed by KaZaa in 2003.
	
	Skype claims that it can work almost seamlessly across NATs and
	
	firewalls and has better voice quality than the MSN and Yahoo
	
	IM applications. It encrypts calls end-to-end, and stores user
	
	information in a decentralized fashion. Skype also supports
	
	instant messaging and conferencing.
	
	This report analyzes key Skype functions such as login, NAT and
	
	firewall traversal, call establishment, media transfer, codecs, and
	
	conferencing under three different network setups. Analysis is
	
	performed by careful study of Skype network traffic.},
  file = {:10.1.1.84.2433.pdf:PDF},
  keywords = {networks, protocols}
}

@BOOK{basseville-book-1993,
  title = {Detection of abrupt changes: theory and application},
  publisher = {Prentice-Hall, Inc.},
  year = {1993},
  author = {Basseville, Mich\`{e}le and Nikiforov, Igor V.},
  address = {Upper Saddle River, NJ, USA},
  file = {basseville-book-1993.pdf:basseville-book-1993.pdf:PDF},
  isbn = {0-13-126780-9},
  keywords = {abrupt change detection}
}

@ARTICLE{bawa2007,
  author = {Bawa, Mayank and Gionis, Aristides and Garcia-Molina, Hector and
	Motwani, Rajeev},
  title = {The price of validity in dynamic networks},
  journal = {J. Comput. Syst. Sci.},
  year = {2007},
  volume = {73},
  pages = {245--264},
  number = {3},
  abstract = {Massive-scale self-administered networks like Peer-to-Peer and Sensor
	Networks have data distributed across thousands of participant hosts.
	These networks are highly dynamic with short-lived hosts being the
	norm rather than an exception. In recent years, researchers have
	investigated best-effort algorithms to efficiently process aggregate
	queries (e.g., sum, count, average, minimum and maximum) on these
	networks. Unfortunately, query semantics for best-effort algorithms
	are ill-defined, making it hard to reason about guarantees associated
	with the result returned. In this paper, we specify a correctness
	condition, Single-Site Validity, with respect to which the above
	algorithms are best-effort. We present a class of algorithms that
	guarantee validity in dynamic networks. Experiments on real-life
	and synthetic network topologies validate performance of our algorithms,
	revealing the hitherto unknown price of validity.},
  address = {Orlando, FL, USA},
  doi = {http://dx.doi.org/10.1016/j.jcss.2006.10.007},
  issn = {0022-0000},
  publisher = {Academic Press, Inc.},
  review = {See prev. conference paper bawa2004}
}

@INPROCEEDINGS{bawa2004,
  author = {Mayank Bawa and Aristides Gionis and Hector {Garcia-Molina} and Rajeev
	Motwani},
  title = {The Price of Validity in Dynamic Networks},
  booktitle = {{ACM SIGMOD}},
  year = {2004},
  abstract = {Massive-scale self-administered networks like Peer-to-Peer and Sensor
	Networks have data distributed across thousands of participant hosts.
	These networks are highly dynamic with short-lived hosts being the
	norm rather than an exception. In recent years, researchers have
	investigated best-eﬀort algorithms to eﬃciently process aggregate
	queries (e.g., sum, count, average, minimum and maximum) [6, 13,
	21, 34, 35, 37] on these networks. Unfortunately, query semantics
	for best-eﬀort algorithms are ill-deﬁned, making it hard to reason
	about guarantees associated with the result returned. In this paper,
	we specify a correctness condition, single-site validity, with respect
	to which the above algorithms are best-eﬀort. We present a class
	of algorithms that guarantee validity in dynamic networks. Experiments
	on real-life and synthetic network topologies validate performance
	of our algorithms, revealing the hitherto unknown price of validity.},
  file = {bawa2004.pdf:bawa2004.pdf:PDF},
  owner = {kristjan},
  review = {referenced by nath2008 -- some commonality in methods.
	
	
	
	See subsequent journal version bawa2007
	
	
	Consider crash failures and churn in aggregation networks and address
	the question what are the best possible results (in terms of accuracy)
	that can be achieved in highly dynamic networks. No byzantine failures
	(would be interesting to explore this).
	
	
	Consider the semantics of best effort aggregation and some interesting
	impossibility results.
	
	
	Present a protocol, Wildfire, for aggregation that achieves (in their
	opinion) the best possible semantics for aggregation. 5x messaging
	cost, compared to a best-effort spanning tree protocol. Requires
	duplicate insensitive sketches. Trivial max value protocol. Use FM
	sketches for count and sum.},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{bazzi2005,
  author = {Rida A. Bazzi and Goran Konjevod},
  title = {On the establishment of distinct identities in overlay networks},
  booktitle = {PODC '05: Proceedings of the twenty-fourth annual ACM symposium on
	Principles of distributed computing},
  year = {2005},
  pages = {312--320},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We study ways to restrict or prevent the damage that can be caused
	in a peer-to-peer network by corrupt entities creating multiple pseudonyms.
	We show that it is possible to remotely issue certificates that can
	be used to test the distinctness of identities. To our knowledge,
	this is the first work that shows that remote anonymous certification
	of identity is possible under adversarial conditions. Our certification
	protocols are based on geometric techniques that establish location
	information in a fault-tolerant and distributed fashion. They do
	not rely on a centralized certifying authority or infrastructure
	that has direct knowledge of entities in the system, and work in
	Euclidean or spherical geometry of arbitrary dimension. Our protocols
	tolerate corrupt entities, including corrupt certifiers as well as
	collusion by certification applicants and certifiers. We consider
	both broadcast and point-to-point message passing models.},
  doi = {http://doi.acm.org/10.1145/1073814.1073873},
  file = {bazzi2005.pdf:bazzi2005.pdf:PDF},
  isbn = {1-59593-994-2},
  keywords = {peer-to-peer systems, overlay networks, authentication},
  location = {Las Vegas, NV, USA}
}

@INCOLLECTION{bekara2007,
  author = {Chakib Bekara and Maryline Laurent-maknavicius and Kheira Bekara},
  title = {{SAPC}: A Secure Aggregation Protocol for Cluster-Based Wireless
	Sensor Networks},
  booktitle = {Mobile Ad-Hoc and Sensor Networks},
  publisher = {Springer Berlin / Heidelberg},
  abstract = {To increase the lifespan of wireless sensor networks (WSN) and preserve
	the energy of sensors, data aggregation techniques are usually used.
	Aggregation can be seen as the process by which data sent from sensors
	to the BS are little-by-little processed by some nodes called aggregator
	nodes. Aggregators collect data from surrounding nodes and produce
	a small sized output, thus preventing that all nodes in the network
	send their data to the BS. Security plays a major role in data aggregation
	process, especially that aggregators are more attractive for attackers
	than normal nodes, where compromising few aggregators can significantly
	affect the final result of aggregation. In this paper, we present
	SAPC, a secure aggregation protocol for cluster-based WSN, which
	does not rely on trusted aggregator nodes and thus is immune to aggregators
	compromising. In addition to security performance, SAPC has a low
	transmission overhead.},
  review = {Rather dodgy scheme of using radio overhearing and mutual computation
	and authentication of aggregate to basically make trust in clusterhead
	unneccessary. Depends on all leaves overhearing and computing aggregate,
	all leaves truthfully reporting. Keys shared with clusterhead and
	a majority voting scheme involving trust in CH seem fundamentally
	flawed.
	
	
	Assumes static network and static (or very slow moving) node membership.
	Clusters are formed permanently, clusterhead duties can rotate within
	cluster. Hinges on all nodes within cluster to overhear each others
	transmissions -- seems a dodgy assumption -- connected graph required
	which may not be the most efficient cluster structure. Very basic
	idea of mutual authentication.
	
	
	Very easy DoS attacks by any of cluster members by faking transmission
	failures or corruption.}
}

@INPROCEEDINGS{bellare1998a,
  author = {Bellare, Mihir and Canetti, Ran and Krawczyk, Hugo},
  title = {A modular approach to the design and analysis of authentication and
	key exchange protocols (extended abstract)},
  booktitle = {{STOC} '98: Proceedings of the thirtieth annual ACM symposium on
	Theory of computing},
  year = {1998},
  pages = {419--428},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We prcscnt a general framework for constructing and analyzing authentication
	protocols in realistic models of communication networks. This framework
	provides a sound formalization for the authentication problem and
	suggests simple and attractive design principles for general authentication
	and key exchange protocols. The key element in our appronch io a
	modular treatment of the authentication problem in cryptographic
	protocols; thii applies to the definition of accurity, to the design
	of the protocols, and to their analysis. In particulnr, following
	this modular approach, we show how to systematically transform solutions
	that work in a model of idaalizcd authenticated communications into
	solutions that are secure in the realistic setting of communication
	channels controlled by an active adversary.
	
	
	Using these principles we construct and prove the security of simple
	and practical authentication and key-exchange protocols. In particular,
	we provide a security analysis of aomowell-known key exchange protocols
	(e.g. authenticated Dlfllc-Hcllman key exchange), and of some of
	the techniques underlying the design of several authentication protocols
	that are currently being deployed on a large scale for the Intornot
	Protocol and other applications.},
  doi = {http://doi.acm.org/10.1145/276698.276854},
  file = {bellare1998a.pdf:bellare1998a.pdf:PDF},
  isbn = {0-89791-962-9},
  keywords = {authentication, key exchange, analysis},
  location = {Dallas, Texas, United States}
}

@INPROCEEDINGS{bellare1996,
  author = {Mihir Bellare and Ran Canetti and Hugo Krawczyk},
  title = {Keying hash functions for message authentication},
  year = {1996},
  pages = {1--15},
  publisher = {Springer-Verlag},
  abstract = {The use of cryptographic hash functions like MD5 or SHA for message
	authentication has become a standard approach in many Internet applications
	and protocols. Though very easy to implement, these mechanisms are
	usually based on ad hoc techniques that lack a sound security analysis.
	
	
	 We present new constructions of message authentication schemes based
	on a cryptographic hash function. Our schemes, NMAC and HMAC, are
	proven to be secure as long as the underlying hash function has some
	reasonable cryptographic strengths. Moreover we show, in a quantitative
	way, that the schemes retain almost all the security of the underlying
	hash function. In addition our schemes are efficient and practical.
	Their performance is essentially that of the underlying hash function.
	Moreover they use the hash function (or its compression function)
	as a black box, so that widely available library code or hardware
	can be used to implement them in a simple way, and replaceability
	of the underlying hash function is easily supported.},
  file = {bellare1996.pdf:bellare1996.pdf:PDF},
  keywords = {HMAC, MAC},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{bellare1998,
  author = {Mihir Bellare and Juan A. Garay and Tal Rabin},
  title = {Fast Batch Verification for Modular Exponentiation and Digital Signatures},
  booktitle = {{EUROCRYPT}},
  year = {1998},
  abstract = {Many tasks in cryptography (e.g., digital signature verification)
	call for verification of a basic operation like modular exponentiation
	in some group: given (g, x, y) check that g x = y. This is typically
	done by re-computing g x and checking we get y. We would like to
	do it differently, and faster.
	
	
	 The approach we use is batching. Focusing first on the basic modular
	exponentiation operation, we provide some probabilistic batch verifiers,
	or tests, that verify a sequence of modular exponentiations significantly
	faster than the naive re-computation method. This yields speedups
	for several verification tasks that involve modular exponentiations.
	
	
	 Focusing specifically on digital signatures, we then suggest a weaker
	notion of (batch) verification which we call “screening.” It seems
	useful for many usages of signatures, and has the advantage that
	it can be done very fast; in particular, we show how to screen a
	sequence of RSA signatures at the cost of one RSA verification plus
	hashing.},
  file = {bellare1998.pdf:bellare1998.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.19}
}

@MISC{bellare1999,
  author = {Mihir Bellare and Joe Kiliany and Phillip Rogawayz},
  title = {The Security of the Cipher Block Chaining Message Authentication
	Code},
  year = {1999},
  abstract = {Let F be some block cipher (eg., DES) with block length l. The Cipher
	Block Chaining Message Authentication Code (CBC MAC) speci es that
	an m-block message x = x1 xm be authenticated among parties who share
	a secret key a for the block cipher by tagging x with a pre x of
	ym , where y0 = 0l and yi = Fa (mi yi;1 ) for i = 1 2 : : : m. This
	method is a pervasively used international and U.S. standard. We
	provide its rst formal justi cation, showing the following general
	lemma: cipher block chaining a pseudorandom function yields a pseudorandom
	function. Underlying our results is a technical lemma of independent
	interest, bounding the success probability of a computationally unbounded
	adversary in distinguishing between a random ml-bit to l-bit function
	and the CBC MAC of a random l-bit to l-bit function.},
  file = {bellare1999.pdf:bellare1999.pdf:PDF},
  keywords = {crypto, MAC, message authentication code, CBC-MAC},
  owner = {kristjan},
  timestamp = {2010.06.29}
}

@MISC{bellare2003,
  author = {Mihir Bellare and Daniele Micciancio and Bogdan Warinschi},
  title = {Foundations of Group Signatures: Formal Deﬁnitions, Simpliﬁed Requirements,
	and a Construction Based on General Assumptions},
  month = {May},
  year = {2003},
  abstract = {This paper provides theoretical foundations for the group signature
	primitive. We introduce strong, formal deﬁnitions for the core requirements
	of anonymity and traceability. We then show that these imply the
	large set of sometimes ambiguous existing informal requirements in
	the literature, thereby unifying and simplifying the requirements
	for this primitive. Finally we prove the existence of a construct
	meeting our deﬁnitions based only on the assumption that trapdoor
	permutations exist.},
  file = {bellare2003.pdf:bellare2003.pdf:PDF},
  keywords = {group signatures, crypto},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@MISC{bellare2007,
  author = {Bellare, Mihir and Namprempre, Chanathip},
  title = {Authenticated Encryption: Relations among Notions and Analysis of
	the Generic Composition Paradigm},
  year = {2007},
  __markedentry = {[kristjan]},
  address = {London, UK},
  file = {bellare2007.pdf:bellare2007.pdf:PDF},
  isbn = {3-540-41404-5},
  keywords = {authenticated encryption, cryptography},
  pages = {531--545},
  publisher = {Springer-Verlag},
  review = {Extended abstract available in {ASIACRYPT} '00: Proceedings of the
	6th International Conference on the Theory and Application of Cryptology
	and Information Security. See bellare2000. This is a full version.
	Where published??}
}

@INPROCEEDINGS{bellare2000,
  author = {Mihir Bellare and Chanathip Namprempre},
  title = {Authenticated Encryption: Relations among Notions and Analysis of
	the Generic Composition Paradigm},
  booktitle = {Advances in Cryptology -- {ASIACRYPT} 2000},
  year = {2000},
  __markedentry = {[kristjan]},
  abstract = {We consider two possible notions of authenticity for symmetric encryption
	schemes, namely integrity of plaintexts and integrity of ciphertexts,
	and relate them to the standard notions of privacy for symmetric
	encryption schemes by presenting implications and separations between
	all notions considered. We then analyze the security of authenticated
	encryption schemes designed by “generic composition,” meaning making
	black-box use of a given symmetric encryption scheme and a given
	MAC. Three composition methods are considered, namely Encrypt-and-MAC
	plaintext, MAC-then-encrypt, and Encrypt-then- MAC. For each of these,
	and for each notion of security, we indicate whether or not the resulting
	scheme meets the notion in question assuming the given symmetric
	encryption scheme is secure against chosen-plaintext attack and the
	given MAC is unforgeable under chosen-message attack. We provide
	proofs for the cases where the answer is “yes” and counter-examples
	for the cases where the answer is “no.”},
  file = {bellare2000.pdf:bellare2000.pdf:PDF},
  keywords = {cryptography, authenticated encryption},
  owner = {kristjan},
  review = {This is an older conference version of bellare2007},
  timestamp = {2010.06.10}
}

@INPROCEEDINGS{bellovin1993,
  author = {Steven M. Bellovin and Michael Merritt},
  title = {Augmented Encrypted Key Exchange: a Password-Based Protocol Secure
	Against Dictionary Attacks and Password File Compromise},
  booktitle = {Conf. Computer \& Comm. Security},
  year = {1993},
  abstract = {The encrypted key exchange (EKE) protocol is augmented so that hosts
	do not store cleartext passwords. Consequently, adversaries who obtain
	the one-way encrypted password file may (i) successfully mimic (spoof)
	the host to the user, and (ii) mount dictionary attacks against the
	encrypted passwords, but cannot mimic the user to the host. Moreover,
	the important security properties of EKE are preservedman active
	network attacker obtains insufficient information to mount dictionary
	attacks. Two ways to accomplish this are shown, one using digital
	signatures and one that relies ona family of commutative one-way
	functions.},
  file = {bellovin1993.pdf:bellovin1993.pdf:PDF},
  keywords = {EKE, encrypted key exchange, zero knowledge password proofs},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{bellovin1992,
  author = {Steven M. Bellovin and Michael Merritt},
  title = {Encrypted Key Exchange: Password-Based Protocols Secure Against Dictionary
	Attacks},
  booktitle = {{IEEE S\&P}},
  year = {1992},
  address = {Oakland},
  abstract = {Classical cryptographic protocols based on user-chosen keys allow
	an attacker to mount password-guessing attacks. We introduce a novel
	combination of asymmetric (public-key) and symmetric (secret-key)
	cryptography that allow two parties sharing a common password to
	exchange con dential and authenticated information over an insecure
	network. These protocols are secure against active attacks, and have
	the property that the password is protected against online "dictionary"
	attacks. There are a number of other useful applications as well,
	including secure public telephones.},
  file = {bellovin1992.pdf:bellovin1992.pdf:PDF},
  keywords = {EKE, encrypted key exchange, zero knowledge password proofs},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{ben-david-2008,
  author = {Ben-David, Assaf and Nisan, Noam and Pinkas, Benny},
  title = {{FairplayMP}: a system for secure multi-party computation},
  booktitle = {{CCS '08: Proceedings of the 15th ACM conference on Computer and
	communications security}},
  year = {2008},
  pages = {257--266},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present FairplayMP (for "Fairplay Multi-Party"), a system for secure
	multi-party computation. Secure computation is one of the great achievements
	of modern cryptography, enabling a set of untrusting parties to compute
	any function of their private inputs while revealing nothing but
	the result of the function. In a sense, FairplayMP lets the parties
	run a joint computation that emulates a trusted party which receives
	the inputs from the parties, computes the function, and privately
	informs the parties of their outputs. FairplayMP operates by receiving
	a high-level language description of a function and a configuration
	file describing the participating parties. The system compiles the
	function into a description as a Boolean circuit, and perform a distributed
	evaluation of the circuit while revealing nothing else. FairplayMP
	supplements the Fairplay system [16], which supported secure computation
	between two parties. The underlying protocol of FairplayMP is the
	Beaver-Micali-Rogaway (BMR) protocol which runs in a constant number
	of communication rounds (eight rounds in our implementation). We
	modified the BMR protocol in a novel way and considerably improved
	its performance by using the Ben-Or-Goldwasser-Wigderson (BGW) protocol
	for the purpose of constructing gate tables. We chose to use this
	protocol since we believe that the number of communication rounds
	is a major factor on the overall performance of the protocol. We
	conducted different experiments which measure the effect of different
	parameters on the performance of the system and demonstrate its scalability.
	(We can now tell, for example, that running a second-price auction
	between four bidders, using five computation players, takes about
	8 seconds.)},
  doi = {http://doi.acm.org/10.1145/1455770.1455804},
  file = {ben-david-2008.pdf:ben-david-2008.pdf:PDF},
  isbn = {978-1-59593-810-7},
  location = {Alexandria, Virginia, USA}
}

@INPROCEEDINGS{ben-or-1983,
  author = {Ben-Or, Michael},
  title = {Another advantage of free choice (Extended Abstract): Completely
	asynchronous agreement protocols},
  booktitle = {{PODC} '83: Proceedings of the second annual {ACM} symposium on Principles
	of distributed computing},
  year = {1983},
  pages = {27--30},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Recently, Fischer, Lynch and Paterson [3] proved that no completely
	asynchronous consensus protocol can tolerate even a single unannounced
	process death. We exhibit here a probabilistic solution for this
	problem, which guarantees that as long as a majority of the processes
	continues to operate, a decision will be made (Theorem 1). Our solution
	is completely asynchronous and is rather strong: As in [4], it is
	guaranteed to work with probability 1 even against an adversary scheduler
	who knows all about the system.},
  doi = {http://doi.acm.org/10.1145/800221.806707},
  file = {ben-or-1983.pdf:ben-or-1983.pdf:PDF},
  isbn = {0-89791-110-5},
  location = {Montreal, Quebec, Canada}
}

@INPROCEEDINGS{ben-or-1988,
  author = {Michael Ben-Or and Shafi Goldwasser and Avi Wigdemon},
  title = {Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed
	Computation},
  booktitle = {{STOC}},
  year = {1988},
  file = {ben-or-1988.pdf:ben-or-1988.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.18}
}

@PHDTHESIS{benaloh1987,
  author = {Josh Daniel Cohen Benaloh},
  title = {Verifiable secret-ballot elections},
  school = {Yale University},
  year = {1987},
  address = {New Haven, CT, USA},
  abstract = {Privacy in secret-ballot elections has traditionally been attained
	by using a ballot box or voting booth to disassociate voters from
	ballots. Although such a system might achieve privacy, there is often
	little confidence in the accuracy of the announced tally. This thesis
	describes a practical scheme for conducting secret-ballot elections
	in which the outcome of an election is verifiable by all participants
	and even by non-participating observers. All communications are public,
	yet under a suitable number-theoretic assumption, the privacy of
	votes remains intact. The tools developed here to conduct such elections
	have additional independent applications. Cryptographic capsules
	allow a prover to convince verifiers that either statement A or statement
	B is true without revealing substantial information as to which.
	Secret sharing homomorphisms enable computation on shared (secret)
	data and give a method of distributing shares of a secret such that
	each shareholder can verify the validity of all shares.},
  file = {benaloh1987.ps:benaloh1987.ps:PostScript},
  keywords = {cryptography, homomorphic encryption},
  order_no = {AAI8809191},
  publisher = {Yale University}
}

@MISC{Berners-Lee1998,
  author = {T. Berners-Lee and R. Fielding and L. Masinter},
  title = {{RFC2396: Uniform Resource Identifiers (URI): Generic Syntax}},
  year = {1998},
  address = {United States},
  keywords = {networks;web;RFC},
  owner = {kristjan},
  publisher = {RFC Editor},
  timestamp = {2008.09.19},
  url = {http://www.ietf.org/rfc/rfc2396.txt}
}

@MISC{Berners-Lee-rfc-1738-1994,
  author = {T. Berners-Lee and L. Masinter and M. McCahill},
  title = {{RFC 1738: Uniform Resource Locators (URL)}},
  month = {December},
  year = {1994},
  keywords = {networks;web;RFC},
  owner = {kristjan},
  timestamp = {2009.02.13},
  url = {http://www.ietf.org/rfc/rfc1738.txt}
}

@TECHREPORT{berr-survey-2008,
  author = {{BERR}},
  title = {Information Security Breaches Survey 2008},
  institution = {{Department for Business, Enterprise \& Regulatory Reform (BERR)}},
  year = {2008},
  file = {:BERR_ISBS_2008(sml).pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.01.28}
}

@ARTICLE{bertha2002,
  author = {Istv\'{a}n Zsolt Bertha and Zolt\'{a}n {\'{A}}d\'{a}m Mann},
  title = {Implementing Elliptic Curve Cryptography on {PC} and Smart Card},
  journal = {Periodica Polytechnica Ser. El. Eng.},
  year = {2002},
  volume = {46},
  pages = {47-73},
  abstract = {Elliptic Curve Cryptography (ECC) is a relatively new branch of public
	key cryptography. Its main
	
	advantage is that it can provide the same level of security as RSA
	with significantly shorter keys,
	
	which is beneficial for a smart card based implementation. It is also
	important as a possible alterna-
	
	tive of RSA. This paper presents the authors’ research concerning
	ECC and smart cards.
	
	
	 The authors introduce their ECC prototype implementation that relies
	on Java Card technol-
	
	ogy and is capable of running on smart cards. Test results with various
	cards are attached. It is
	
	also analyzed in what extent algorithms with the complexity of ECC
	can be executed in smart card
	
	environment with limited resources.},
  file = {bertha2002.pdf:bertha2002.pdf:PDF},
  keywords = {Elliptic Curve Cryptography, smart card, Java Card, public key cryptography},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@INCOLLECTION{bertoni2003,
  author = {Guido Bertoni and Luca Breveglieri and Pasqualina Fragneto and Marco
	Macchetti and Stefano Marchesin},
  title = {Efficient Software Implementation of {AES} on 32-Bit Platforms},
  booktitle = {Cryptographic Hardware and Embedded Systems - {CHES 2002}},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  volume = {2523/2003},
  series = {Lecture Notes in Computer Science},
  abstract = {Rijndael is the winner algorithm of the AES contest; therefore it
	should become the most used symmetric-key cryptographic algorithm.
	One important application of this new standard is cryptography on
	smart cards. In this paper we present an optimisation of the Rijndael
	algorithm to speed up execution on 32-bits processors with memory
	constraints, such as those used in smart cards. First a theoretical
	analysis of the Rijndael algorithm and of the proposed optimisation
	is discussed, and then simulation results of the optimised algorithm
	on different processors are presented and compared with other reference
	implementations, as known from the technical literature.},
  file = {bertoni2003.pdf:bertoni2003.pdf:PDF},
  keywords = {cryptography, optimization, implmentation, rijndael, AES},
  owner = {kristjan},
  timestamp = {2010.02.04}
}

@ARTICLE{bhole2005,
  author = {Yogesh Bhole and Adrian Popescu},
  title = {Measurement and Analysis of {HTTP} Traffic},
  journal = {{J. Netw. Syst. Manage.}},
  year = {2005},
  volume = {13},
  pages = {357--371},
  number = {4},
  abstract = {The usage of Internet is rapidly increasing and a large part of the
	Internet traffic is generated by the World Wide Web (WWW) and the
	associated protocol HyperText Transfer Protocol (HTTP). Several important
	parameters that affect the performance of the WWW are bandwidth,
	scalability, and latency. To tackle these parameters and to improve
	the overall performance of the system, it is important to understand
	and to characterize the application level characteristics. This article
	is reporting on the measurement and analysis of HTTP traffic collected
	on the student access network at the Blekinge Institute of Technology
	in Karlskrona, Sweden. The analysis is done on various HTTP traffic
	parameters, e.g., inter-session timings, inter-arrival timings, request
	message sizes, response code, and number of transactions. The reported
	results can be useful for building synthetic workloads for simulation
	and benchmarking purposes.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1007/s10922-005-9000-y},
  file = {bhole2005.pdf:bhole2005.pdf:PDF},
  issn = {1064-7570},
  keywords = {networks, web, measurements},
  publisher = {Plenum Press}
}

@PHDTHESIS{bickson2008,
  author = {Danny Bickson},
  title = {Gaussian Belief Propagation: Theory and Aplication},
  school = {The Hebrew University of Jerusalem},
  year = {2008},
  month = {October},
  abstract = {The canonical problem of solving a system of linear equations arises
	in numerous contexts in information theory, communication theory,
	and related fields. In this contribution, we develop a solution based
	upon Gaussian belief propagation (GaBP) that does not involve direct
	matrix inversion. The iterative nature of our approach allows for
	a distributed message-passing implementation of the solution algorithm.
	In the first part of this thesis, we address the properties of the
	GaBP solver, including convergence, exactness, computational complexity,
	message-passing efficiency and its relation to classical solution
	methods including numerical examples. We further relate to several
	other algorithms and explore their connection to the GaBP algorithm.
	
	In the second part we give three applications to illustrate the applicability
	of the GaBP algorithm to very large computer networks: Peer-to-Peer
	rating, linear detection and distributed computation of support vector
	regression. Using extensive simulations on up to 1,024 CPUs in parallel
	using IBM Bluegene supercomputer we demonstrate the attractiveness
	and applicability of the GaBP algorithm, using real life network
	topologies with up to millions of nodes and hundreds of millions
	of communication links.},
  file = {bickson2008.pdf:bickson2008.pdf:PDF},
  keywords = {belief propagation},
  url = {http://www.citebase.org/abstract?id=oai:arXiv.org:0811.2518}
}

@INPROCEEDINGS{bickson2006,
  author = {Danny Bickson and Danny Dolev and Yair Weiss and Karl Aberer and
	Manfred Hauswirth},
  title = {Indexing Data-Oriented Overlay Networks Using Belief Propagation},
  booktitle = {7th Workshop of distributed algorithms and data structures ({WDAS}
	06)},
  year = {2006},
  abstract = {In this paper we discuss the problem of data-oriented parti-
	
	tioning in large-scale overlay networks, as required by peer-to-
	
	peer databases or by peer-to-peer information retrieval. The goal
	
	is to partition a large set of nodes into k partitions with the ad-
	
	ditional requirement of meeting certain load-balancing constraints
	
	without global knowledge of the network’s parameters, i.e., the de-
	
	sired number of partitions and the partition distribution function
	
	are not known in advance and change dynamically as the network
	
	evolves. This key problem in large-scale decentralized systems has
	
	so far received only very limited attention. The novel contributions
	
	described in the following are (1) the deﬁnition of a distributed
	
	algorithm for local estimation of the partitioning distribution func-
	
	tion, which does not preclude the network’s topology, and (2) a
	
	distributed method for performing the actual partitioning. As ad-
	
	ditional advantages, the algorithms do not require global knowl-
	
	edge and are completely decentralized, thus suitable for Peer-to-
	
	peer networks. Both algorithms are based on the max-product be-
	
	lief propagation algorithm and give exact results on trees, and suf-
	
	ﬁciently accurate approximations on graphs containing cycles. We
	
	show the accuracy of the proposed algorithms in terms of the num-
	
	ber of nodes per partition and the good load balancing of partitions
	
	in the network by simulation. Our algorithms are scalable and the
	
	accuracy of the partitioning improves with larger network sizes.
	
	Having shown the efﬁciency of our proposed algorithms, we dis-
	
	cuss a natural application for our algorithm in the data-oriented
	
	P2P system P-Grid (http://www.p-grid.org/). Using P-Grid’s un-
	
	derlying tree abstraction, we can apply our algorithm recursively
	
	to achieve optimal partitioning results in short times relative to
	the
	
	tree diameter.},
  file = {bickson2006.pdf:bickson2006.pdf:PDF},
  keywords = {belief propagation}
}

@INPROCEEDINGS{bieber1991,
  author = {Pierre Bieber and Fr\'{e}d\'{e}ric Cuppens},
  title = {Computer Security Policies and Deontic Logic},
  booktitle = {First International Workshop on Deontic Logic in Computer Science},
  year = {1991},
  abstract = {With respect to confidentiality, a computer security policy defines
	what infomation stored in a computer users have the permission to
	know. We propose to express these policies with an epistemic and
	deontic logic. In this context, confidentiality is defined by the
	formula $K_{A\phi} \leftarrow R_{A\phi}$ that could be read "if A
	knows phi then A should have permissioin to know phi"". We provide
	a new possible-worlds semantics for the RA operator that depends
	on the security policy to be modeled. Finally, we express within
	our framework three examples of security policies.},
  file = {bieber1991.pdf:bieber1991.pdf:PDF},
  keywords = {Computer security, Confidentiality, Mandatory Access Control, Multi-level
	security, Information flow models, Epistemic logic, Deontic logic.},
  owner = {kristjan},
  timestamp = {2009.08.21}
}

@ARTICLE{binkley2001,
  author = {Binkley, Jim and Trost, William},
  title = {Authenticated ad hoc routing at the link layer for mobile systems},
  journal = {Wirel. Netw.},
  year = {2001},
  volume = {7},
  pages = {139--145},
  number = {2},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1023/A:1016633521987},
  file = {binkley2001.pdf:binkley2001.pdf:PDF},
  issn = {1022-0038},
  publisher = {Kluwer Academic Publishers}
}

@INPROCEEDINGS{birman2002,
  author = {Kenneth P. Birman and Robbert van Renesse},
  title = {Scalable Data Fusion Using Astrolabe},
  booktitle = {Information Fusion},
  year = {2002},
  abstract = {The dramatic growth of computer networks creates both an opportunity
	and a daunting distributed computing problem for users seeking to
	perform data fusion and data mining. The problem is that data often
	resides on large numbers of devices and evolves rapidly. Systems
	that collect data at a single location scale poorly and suffer from
	single-point failures. Astrolabe performs data fusion in real-time,
	creating a virtual system-wide hierarchical database, which evolves
	as the underlying information changes. A scalable aggregation mechanism
	offers a flexible way to perform data mining within the resulting
	virtual database. Astrolabe is secure, robust under a wide range
	of failure and attack scenarios, and imposes low loads even under
	stress.},
  file = {birman2002.pdf:birman2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.03}
}

@ARTICLE{birman2006,
  author = {Kenneth P. Birman and Robbert van Renesse and Werner Vogels},
  title = {Navigating in the Storm: Using Astrolabe to Adaptively Configure
	Web Services and Their Clients},
  journal = {Cluster Computing},
  year = {2006},
  volume = {9},
  pages = {127--139},
  number = {2},
  abstract = {The dramatic growth of distributed computing applications is creating
	both an opportunity and a daunting challenge for users seeking to
	build applications that will play critical roles in their organization.
	Here, we discuss the use of a new system, Astrolabe, to automate
	self-configuration, monitoring, and to control adaptation. Astrolabe
	operates by creating a virtual system-wide hierarchical database,
	which evolves as the underlying information changes. Astrolabe is
	secure, robust under a wide range of failure and attack scenarios,
	and imposes low loads even under stress. To focus the discussion,
	we structure it around a hypothetical Web Services scenario. One
	of the major opportunities created by Astrolabe is to allow Web Services
	client systems to autonomically adapt when a data center becomes
	slow or unreachable.},
  file = {birman2006.pdf:birman2006.pdf:PDF},
  keywords = {astrolabe, network management, adaptive configuration, web services},
  owner = {kristjan},
  timestamp = {2010.05.03}
}

@BOOK{bishop2006,
  title = {Pattern Recognition and Machine Learning},
  publisher = {Springer},
  year = {2006},
  author = {Bishop, Christopher M},
  file = {:bishop-ch8-2006.pdf:PDF},
  keywords = {graphical models, pattern recognition, AI, machine learning},
  owner = {kristjan},
  timestamp = {2009.05.26}
}

@MISC{Bittorrent.org,
  author = {Bittorrent.org},
  title = {Protocol Specification},
  howpublished = {[online] http://www.bittorrent.org/protocol.html},
  date_accessed = {01.02.2007},
  keywords = {networks, protocols, bittorrent},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://www.bittorrent.org/protocol.html}
}

@INPROCEEDINGS{blass2008,
  author = {Bla\ss, Erik-Oliver and Wilke, Joachim and Zitterbart, Martina},
  title = {Relaxed authenticity for data aggregation in wireless sensor networks},
  booktitle = {{SecureComm '08}: Proceedings of the 4th international conference
	on Security and privacy in communication netowrks},
  year = {2008},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {In-network data aggregation allows energy-efficient communication
	within a sensor network. However, such data aggregation introduces
	new security challenges. As sensor nodes are prone to node-compromise,
	a fraction of nodes might act maliciously and forge aggregated data.
	For arbitrary aggregation functions, the verification of authenticity
	of aggregated data, i.e., its correctness, integrity, and origin,
	is impossible. Thus, one can either aggregate data and save energy
	or verify authenticity, not both. We present "ESAWN", a protocol
	that probabilistically relaxes authenticity in the presence of a
	fraction of compromised nodes. This enables a trade-off between probabilistic
	authenticity and probabilistic, energy-saving data aggregation. Besides
	theoretical analysis, we present MICA2-based simulation results.
	They indicate that even for high probabilities of authenticity and
	fraction of compromised nodes, ESAWN is more energy-efficient compared
	to (100%-)secure but non-aggregating communication. For example,
	with a fraction of 20% compromised nodes and 90% authenticity, ESAWN
	saves up to 40% energy.},
  doi = {http://doi.acm.org/10.1145/1460877.1460883},
  file = {blass2008.pdf:blass2008.pdf:PDF},
  isbn = {978-1-60558-241-2},
  location = {Istanbul, Turkey}
}

@INPROCEEDINGS{blass2005,
  author = {Erik-Oliver Bla\ss and Martina Zitterbart},
  title = {Towards Acceptable Public-Key Encryption in Sensor Networks},
  booktitle = {{ACM SIGMIS}},
  year = {2005},
  abstract = {One of the huge problems for security in sensor networks is the lack
	of resources. Based on microcontroller architectures with severe
	limited computing abilities, strong public-key cryptography is commonly
	seen as infeasible on sensor devices. In contrast to this prejudice
	this paper presents an efficient and lightweight implementation of
	public-key cryptography algorithms relying on elliptic curves. The
	code is running on Atmels popular 8Bit ATMEGA128 microcontroller,
	the heart of the MICA2[15] platform. To our knowledge this implementation
	is the first to offer acceptable encryption speed while providing
	adequate security in sensor networks.},
  file = {blass2005.pdf:blass2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@TECHREPORT{blass2005a,
  author = {Erik-Oliver Bla\ss and Martina Zitterbart},
  title = {Efficient Implementation of Elliptic Curve Cryptography for Wireless
	Sensor Networks},
  institution = {Institute of Telematics, University of Karlsruhe},
  year = {2005},
  number = {TM-2005-1},
  abstract = {One of the huge problems for security in sensor networks is the lack
	
	of resources. Typical sensor nodes such as the quite popular MICA
	and MICA2
	
	Motes from UC Berkeley [1] are based on a microcontroller architecture
	with
	
	only a few KBytes of memory and severe limited computing ability.
	Strong public-
	
	key cryptography is therefore commonly seen as infeasible on such
	devices. In
	
	contrast to this prejudice this paper presents an efficient and lightweight
	imple-
	
	mentation of public-key cryptography algorithms relying on elliptic
	curves. The
	
	code is running on Atmels 8Bit ATMEGA128 microcontroller, the heart
	of the
	
	MICA2 platform. The key to our fast implementation is the use of offline
	pre-
	
	computation and handcrafting.},
  file = {blass2005a.pdf:blass2005a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@INCOLLECTION{Black2006,
  author = {John Black and Martin Cochran and Trevor Highland},
  title = {A Study of the {MD5} Attacks: Insights and Improvements},
  booktitle = {Fast Software Encryption (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2006},
  owner = {kristjan},
  timestamp = {2010.03.02}
}

@INPROCEEDINGS{blakley1979,
  author = {G.R. Blakley},
  title = {Safeguarding cryptographic keys},
  booktitle = {{AFIPS NCC}},
  year = {1979},
  volume = {48},
  pages = {313-317},
  address = {Arlington, VA},
  month = {June},
  keywords = {cryptography, secret sharing},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{blesa2007,
  author = {Maria J. Blesa and Christian Blum},
  title = {Finding Edge-disjoint Paths in Networks: An Ant Colony Optimization
	Algorithm},
  journal = {Journal of Mathematical Modelling and Algorithms},
  year = {2007},
  volume = {6},
  pages = {361-391},
  number = {3},
  abstract = {One of the basic operations in communication networks consists in
	establishing routes for connection requests between physically separated
	network nodes. In many situations, either due to technical constraints
	or to quality-of-service and survivability requirements, it is required
	that no two routes interfere with each other. These requirements
	apply in particular to routing and admission control in large-scale,
	high-speed and optical networks. The same requirements also arise
	in a multitude of other applications such as real-time communications,
	vlsi design, scheduling, bin packing, and load balancing. This problem
	can be modeled as a combinatorial optimization problem as follows.
	Given a graph G representing a network topology, and a collection
	T={(s 1,t 1)...(s k ,t k )} of pairs of vertices in G representing
	connection request, the maximum edge-disjoint paths problem is an
	NP-hard problem that consists in determining the maximum number of
	pairs in T that can be routed in G by mutually edge-disjoint s i
	−t i paths. We propose an ant colony optimization (aco) algorithm
	to solve this problem. aco algorithms are approximate algorithms
	that are inspired by the foraging behavior of real ants. The decentralized
	nature of these algorithms makes them suitable for the application
	to problems arising in large-scale environments. First, we propose
	a basic version of our algorithm in order to outline its main features.
	In a subsequent step we propose several extensions of the basic algorithm
	and we conduct an extensive parameter tuning in order to show the
	usefulness of those extensions. In comparison to a multi-start greedy
	approach, our algorithm generates in general solutions of higher
	quality in a shorter amount of time. In particular the run-time behaviour
	of our algorithm is one of its important advantages.},
  file = {blesa2007.pdf:blesa2007.pdf:PDF},
  keywords = {Ant colony optimization, Maximum edge-disjoint paths problem},
  owner = {kristjan},
  timestamp = {2010.05.21}
}

@TECHREPORT{bloedorn2001,
  author = {Eric Bloedorn and Alan D. Christiansen and William Hill and Clement
	Skorupka and Lisa M. Talbot and Jonathan Tivel},
  title = {Data Mining for Network Intrusion Detection: How to Get Started},
  institution = {The {MITRE} Corporation},
  year = {2001},
  abstract = {Recently there has been much interest in applying data mining to computer
	network intrusion detection. For the past two years, MITRE has been
	exploring how to make data mining useful in this context. This paper
	provides lessons learned in this task. Based upon our experiences
	in getting started on this type of project, we suggest data mining
	techniques to consider and types of expertise and infrastructure
	needed. This paper has two intended audiences: network security professionals
	with little background in data mining, and data mining experts with
	little background in network intrusion detection.},
  citeseercitationcount = {0},
  citeseerurl = {http://citeseer.ist.psu.edu/523955.html},
  file = {bloedorn01data.pdf:bloedorn01data.pdf:PDF},
  keywords = {networks, data mining, AI, intrusion detection},
  owner = {kristjan},
  timestamp = {2008.02.26}
}

@INPROCEEDINGS{blom1985,
  author = {Blom, R},
  title = {An optimal class of symmetric key generation systems},
  booktitle = {Proc. of the EUROCRYPT 84 workshop on Advances in cryptology: theory
	and application of cryptographic techniques},
  year = {1985},
  pages = {335--338},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  abstract = {I t is sometimes required t h a t user pairs in a network share secret
	information t o be used f o r
	
	mutual identification or as a key in a cipher system. I f the network
	is large i t becomes
	
	impractical or even impossible t o store all keys securely at the
	users. A natural solution then
	
	is t o supply each user with a relatively small amount of secret data
	from which he can derive
	
	
	 A scheme for this purpose will be presented and we call such a s
	c h e m e a
	
	all his keys.
	
	symmetric key generation system (SKGS). However, as all keys will
	b e generated from a
	
	small amount of data, dependencies between keys will exist. Therefore
	by cooperation, users
	
	in the system might b e able t o decrease their uncertainty about
	keys they should n o t have
	
	access to.},
  file = {blom1985.pdf:blom1985.pdf:PDF},
  isbn = {0-387-16076-0},
  keywords = {symmetric key generation, cryptography, pairwise key establishment},
  location = {Paris, France},
  review = {A system to establish pairwise secret keys efficiently.
	
	
	Based on using a secret line of a secret matrix.}
}

@ARTICLE{Bloom1970,
  author = {Burton H. Bloom},
  title = {Space/Time Trade-offs in Hash Coding with Allowable Errors},
  journal = {Communications of the ACM},
  year = {1970},
  volume = {13},
  pages = {422-426},
  number = {7},
  abstract = {In this paper trade-offs among certain computational factors
	
	in hash coding are analyzed. The paradigm problem con-
	
	sidered is that of testing a series of messages one-by-one
	
	for membership in a given set of messages. Two new hash-
	
	coding methods are examined and compared with a par-
	
	ticular conventional hash-coding method. The computational
	
	factors considered are the size of the hash area (space), the
	
	time required to identify a message as a nonmember of the
	
	given set (reject time), and an allowable error frequency.
	
	
	The new methods are intended to reduce the amount of
	
	space required to contain the hash-coded information from
	
	that associated with conventional methods. The reduction in
	
	space is accomplished by exploiting the possibility that a
	
	small fraction of errors of commission may be tolerable in
	
	some applications, in particular, applications in which a large
	
	amount of data is involved and a core resident hash area is
	
	consequently not feasible using conventional methods.
	
	
	In such applications, it is envisaged that overall performance
	
	could be improved by using a smaller core resident hash area
	
	in conjunction with the new methods and, when necessary, by
	
	using some secondary and perhaps time-consuming test to
	
	"catch" the small fraction of errors associated with the new
	
	methods. An example is discussed which illustrates possible
	
	areas of application for the new methods.
	
	
	Analysis of the paradigm problem demonstrates that al-
	
	lowing a small number of test messages to be falsely identified
	
	as members of the given set will permit a much smaller hash
	
	area to be used without increasing reject time.},
  file = {p422-bloom.pdf:/home/kristjan/articles/p422-bloom.pdf:PDF},
  keywords = {bloom filters},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{blum1988,
  author = {Blum, Manuel and Feldman, Paul and Micali, Silvio},
  title = {Non-interactive zero-knowledge and its applications},
  booktitle = {STOC '88: Proceedings of the twentieth annual ACM symposium on Theory
	of computing},
  year = {1988},
  pages = {103--112},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We show that interaction in any zero-knowledge proof can be replaced
	by sharing a common, short, random string. We use this result to
	construct the first public-key cryptosystem secure against chosen
	ciphertext attack.},
  doi = {http://doi.acm.org/10.1145/62212.62222},
  file = {blum1988.pdf:blum1988.pdf:PDF},
  isbn = {0-89791-264-0},
  keywords = {zero knowledge proofs, security, cryptography},
  location = {Chicago, Illinois, United States}
}

@ARTICLE{blundo1998,
  author = {Blundo, Carlo and De Santis, Alfredo and Vaccaro, Ugo and Herzberg,
	Amir and Kutten, Shay and Yong, Moti},
  title = {Perfectly secure key distribution for dynamic conferences},
  journal = {Inf. Comput.},
  year = {1998},
  volume = {146},
  pages = {1--23},
  number = {1},
  abstract = {In this paper we analyze perfectly secure key distribution schemes
	for dynamic conferences. In this setting, any member of a group of
	t users can compute a common key using only his private initial piece
	of information and the identities of the other t&1 users in the group.
	Keys are secure against coalitions of up to k users; that is, even
	if k users pool together their pieces they cannot compute anything
	about a key of any conference comprised of t other users. First we
	consider a noninteractive model where users compute the common key
	without any interaction. We prove the tight bound on the size of
	each user's piece of information of ( k+t&1 ) times the size of the
	common key. Then, we consider the model t&1 where interaction is
	allowed in the common key computation phase and show a gap between
	the models by exhibiting a one-round interactive scheme in which
	the user's information is only k+t&1 times the size of the common
	key. Finally, we present its adaptation to network topologies with
	neighbourhood constraints and to asymmetric (e.g., client-server)
	communication models.},
  address = {Duluth, MN, USA},
  doi = {http://dx.doi.org/10.1006/inco.1998.2717},
  file = {blundo1998.pdf:blundo1998.pdf:PDF},
  issn = {0890-5401},
  keywords = {pairwise key establishment, symmetric key,, cryptography},
  publisher = {Academic Press, Inc.},
  review = {key establishment via polynomials. See ref by Traynor and by zhu2007.
	
	
	Based on a secret polynomial share.}
}

@MISC{bogetoft2008,
  author = {Peter Bogetoft and Dan Lund Christensen and Ivan Damg and Martin
	Geisler and Thomas Jakobsen and Mikkel Krøigaard and Janus Dam Nielsen
	and Jesper Buus Nielsen and Kurt Nielsen and Jakob Pagter and Michael
	Schwartzbach and Tomas Toft},
  title = {Secure Multiparty Computation Goes Live},
  year = {2008},
  abstract = {In this note, we report on the ﬁrst large-scale and practical application
	of multiparty computation, which took place in January 2008. We also
	report on the novel cryptographic protocols that were used.},
  file = {bogetoft2008.pdf:bogetoft2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@INPROCEEDINGS{bohli2008,
  author = {Bohli, Jens-Matthias and Hessler, Alban and Ugus, Osman and Westhoff,
	Dirk},
  title = {A secure and resilient {WSN} roadside architecture for intelligent
	transport systems},
  booktitle = {{WiSec '08}: Proceedings of the first {ACM} conference on Wireless
	network security},
  year = {2008},
  pages = {161--171},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {We propose a secure and resilient WSN roadside architecture for intelligent
	transport systems which supports the two complementary services accident
	prevention and post-accident investigation. Our WSN security architecture
	is stimulated by the understanding that WSN roadside islands will
	only be rolled-out and used when hardware costs are close to the
	minimum. We provide a purely software based security solution which
	does not rely on costly HW components like road side units (RSU)
	or tamper resistant modules on sensor nodes. We use existing components,
	but also describe protocols that may be of independent interest.},
  doi = {http://doi.acm.org/10.1145/1352533.1352562},
  file = {bohli2008.pdf:bohli2008.pdf:PDF},
  isbn = {978-1-59593-814-5},
  location = {Alexandria, VA, USA}
}

@ARTICLE{bolosky2000,
  author = {William J. Bolosky and John R. Douceur and David Ely and Marvin Theimer},
  title = {Feasibility of a serverless distributed file system deployed on an
	existing set of desktop PCs},
  journal = {{SIGMETRICS} Perform. Eval. Rev.},
  year = {2000},
  volume = {28},
  pages = {34--43},
  number = {1},
  abstract = {We consider an architecture for a serverless distributed file system
	that does not assume mutual trust among the client computers. The
	system provides security, availability, and reliability by distributing
	multiple encrypted replicas of each file among the client machines.
	To assess the feasibility of deploying this system on an existing
	desktop infrastructure, we measure and analyze a large set of client
	machines in a commercial environment. In particular, we measure and
	report results on disk usage and content; file activity; and machine
	uptimes, lifetimes, and loads. We conclude that the measured desktop
	infrastructure would passably support our proposed system, providing
	availability on the order of one unfilled file request per user per
	thousand days.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/345063.339345},
  file = {bolosky2000.pdf:bolosky2000.pdf:PDF},
  issn = {0163-5999},
  keywords = {distributed systems},
  publisher = {ACM},
  review = {See this paper on measurements of properties of p2p systems -- churn
	statistics etc.}
}

@INPROCEEDINGS{boneh2001,
  author = {Boneh, Dan and Franklin, Matthew K.},
  title = {Identity-Based Encryption from the Weil Pairing},
  booktitle = {{CRYPTO} '01: Proceedings of the 21st Annual International Cryptology
	Conference on Advances in Cryptology},
  year = {2001},
  pages = {213--229},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {boneh2001.pdf:boneh2001.pdf:PDF},
  isbn = {3-540-42456-3},
  keywords = {cryptography, public key crypto, identity based cryptography},
  review = {See wikipedia page on identity based crypto. Generally acknowledged
	as being the first ID-based encryption scheme.}
}

@ARTICLE{boneh2003,
  author = {Dan Boneh and Craig Gentry and Ben Lynn and Hovav Shacham},
  title = {A Survey of Two Signature Aggregation Techniques},
  journal = {{CryptoBytes}},
  year = {2003},
  volume = {6},
  pages = {2003},
  __markedentry = {[kristjan]},
  abstract = {We survey two recent signature constructions that support signature
	aggregation: Given n signatures on n distinct messages from n distinct
	users, it is possible to aggregate all these signatures into a single
	signature. This single signature (and all n original messages) will
	convince any verifier that the n users signed the n original messages
	(i.e., for i = 1; : : : ; n user i signed message number i). We survey
	two constructions. The first is based on the short signature scheme
	of Boneh, Lynn, and Shacham and supports general aggregation. The
	second, based on a multisignature scheme of Micali, Ohta, and Reyzin,
	is built from any trapdoor permutation but only supports sequential
	aggregation. Aggregate signatures are useful for reducing the size
	of certificate chains (by aggregating all signatures in the chain)
	and for reducing message size in secure routing protocols such as
	SBGP.},
  file = {boneh2003.pdf:boneh2003.pdf:PDF}
}

@INPROCEEDINGS{boneh2007,
  author = {Dan Boneh and Brent Waters},
  title = {Conjunctive, Subset, and Range Queries on Encrypted Data},
  booktitle = {{TCC}'07},
  year = {2007},
  number = {LNCS 4392, pp. 535-554, 2007},
  pages = {535-554},
  __markedentry = {[kristjan]},
  abstract = {We construct public-key systems that support comparison queries (x
	≥ a) on encrypted
	
	data as well as more general queries such as subset queries (x ∈ S).
	These systems support
	
	arbitrary conjunctive queries (P1 ∧· · ·∧P ) without leaking information
	on individual conjuncts.
	
	In addition, we present a general framework for constructing and analyzing
	public-key systems
	
	supporting queries on encrypted data.},
  file = {boneh2007.pdf:boneh2007.pdf:PDF},
  keywords = {encryption, set query operations, privacy},
  owner = {kristjan},
  review = {set operations on encrypted data},
  timestamp = {2010.05.16}
}

@INPROCEEDINGS{bonneau2006,
  author = {Joseph Bonneau and Ilya Mironov},
  title = {Cache-Collision Timing Attacks Against {AES}},
  booktitle = {Cryptographic Hardware and Embedded Systems -- {CHES} 2006},
  year = {2006},
  pages = {201--215},
  abstract = {This paper describes several novel timing attacks against the common
	table-driven software implementation of the AES cipher. We define
	a general attack strategy using a simplified model of the cache to
	predict timing variation due to cache-collisions in the sequence
	of lookups performed by the encryption. The attacks presented should
	be applicable to most high-speed software AES implementations and
	computing platforms, we have implemented them against OpenSSL v.
	0.9.8.(a) running on Pentium III, Pentium IV Xeon, and UltraSPARC
	III+ machines. The most powerful attack has been shown under optimal
	conditions to reliably recover a full 128-bit AES key with 213 timing
	samples, an improvement of almost four orders of magnitude over the
	best previously published attacks of this type [Ber05]. While the
	task of defending AES against all timing attacks is challenging,
	a small patch can significantly reduce the vulnerability to these
	specific attacks with no performance penalty.},
  file = {bonneau2006.pdf:bonneau2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INCOLLECTION{bonnet2001,
  author = {Philippe Bonnet and Johannes Gehrke and Praveen Seshadri},
  title = {Towards Sensor Database Systems},
  booktitle = {Mobile Data Management (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2001},
  volume = {1987/2001},
  abstract = {Sensor networks are being widely deployed for measurement, detection
	and surveillance applications. In these new applications, users issue
	long-running queries over a combination of stored data and sensor
	data. Most existing applications rely on a centralized system for
	collecting sensor data. These systems lack flexibility because data
	is extracted in a predefined way; also, they do not scale to a large
	number of devices because large volumes of raw data are transferred
	regardless of the queries that are submitted. In our new concept
	of sensor database system, queries dictate which data is extracted
	from the sensors. In this paper, we define the concept of sensor
	databases mixing stored data represented as relations and sensor
	data represented as time series. Each long-running query formulated
	over a sensor database defines a persistent view, which is maintained
	during a given time interval. We also describe the design and implementation
	of the COUGAR sensor database system.},
  file = {bonnet2001.pdf:bonnet2001.pdf:PDF},
  keywords = {sensor networks},
  owner = {kristjan},
  review = {tree based in-network aggregation in a tree-based network (CHECK)},
  timestamp = {2010.01.18}
}

@INPROCEEDINGS{borisov2006,
  author = {Borisov, Nikita},
  title = {Computational Puzzles as Sybil Defenses},
  booktitle = {{P2P} '06: Proceedings of the Sixth {IEEE} International Conference
	on Peer-to-Peer Computing},
  year = {2006},
  pages = {171--176},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {We consider the problem of defending against Sybil attacks using computational
	puzzles. A fundamental difficulty in such defenses is enforcing that
	puzzle solutions not be reused by attackers over time. We propose
	a fully decentralized scheme to enforce this by continually distributing
	locally generated challenges that are then incorporated into the
	puzzle solutions. Our approach consists of an all-to-all broadcast
	of challenges, with a combining function to ensure this can be done
	efficiently. The combining function generates certificates that can
	be used to prove that each node's challenge was delivered to and
	used by each other node, therefore proving the freshness of each
	puzzle. We show how our distribution and verification mechanisms
	can be implemented on top of the the Chord [21] overlay.},
  doi = {http://dx.doi.org/10.1109/P2P.2006.10},
  file = {borisov2006.pdf:borisov2006.pdf:PDF},
  isbn = {0-7695-2679-9},
  keywords = {sybil attack, computational puzzles, DHTs}
}

@INPROCEEDINGS{bortnikov2008,
  author = {Edward Bortnikov and Maxim Gurevich and Idit Keidar and Gabriel Kliot
	and Alexander Shraer},
  title = {Brahms: byzantine resilient random membership sampling},
  booktitle = {{PODC '08}: {Proceedings of the twenty-seventh ACM symposium on Principles
	of distributed computing}},
  year = {2008},
  pages = {145--154},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present Brahms, an algorithm for sampling random nodes in a large
	dynamic system prone to malicious behavior. Brahms stores small membership
	views at each node, and yet overcomes Byzantine attacks by a linear
	portion of the system. Brahms is composed of two components. The
	first one is a resilient gossip-based membership protocol. The second
	one uses a novel memory-efficient approach for uniform sampling from
	a possibly biased stream of ids that traverse the node. We evaluate
	Brahms using rigorous analysis, backed by simulations, which show
	that our theoretical model captures the protocol's essentials. We
	study two representative attacks, and show that with high probability,
	an attacker cannot create a partition between correct nodes. We further
	prove that each node's sample converges to a uniform one over time.
	To our knowledge, no such properties were proven for gossip protocols
	in the past.},
  doi = {http://doi.acm.org/10.1145/1400751.1400772},
  file = {:bortnikov2008-full.pdf:PDF;bortnikov2008.pdf:bortnikov2008.pdf:PDF},
  isbn = {978-1-59593-989-0},
  keywords = {networks,, peer-to-peer systems, byzantine},
  location = {Toronto, Canada},
  review = {Two papers -- a full tech report (?) and a conference paper.
	
	
	Membership sampling in gossip networks.}
}

@ARTICLE{boulis2003,
  author = {Athanassios Boulis and Saurabh Ganeriwal and Mani B. Srivastava},
  title = {Aggregation in sensor networks: an energy-accuracy trade-off},
  journal = {Ad-Hoc Networks},
  year = {2003},
  volume = {1},
  pages = {317 - 331},
  number = {2-3},
  note = {Sensor Network Protocols and Applications},
  abstract = {Wireless ad hoc sensor networks (WASNs) are in need of the study of
	useful applications that will help the researchers view them as distributed
	physically coupled systems, a collective that estimates the physical
	environment, and not just energy-limited ad hoc networks. We develop
	this perspective using a large and interesting class of WASN applications
	called aggregation applications. In particular, we consider the challenging
	periodic aggregation problem where the WASN provides the user with
	periodic estimates of the environment, as opposed to simpler and
	previously studied snapshot aggregation problems. In periodic aggregation
	our approach allows the spatial–temporal correlation among values
	sensed at the various nodes to be exploited towards energy-efficient
	estimation of the aggregated value of interest. Our approach also
	creates a system level energy vs. accuracy knob whereby the more
	the estimation error that the user can tolerate, the less is the
	energy consumed. We present a distributed estimation algorithm that
	can be applied to explore the energy–accuracy subspace for a subclass
	of periodic aggregation problems, and present extensive simulation
	results that validate our approach. The resulting algorithm, apart
	from being more flexible in the energy–accuracy subspace and more
	robust, can also bring considerable energy savings for a typical
	accuracy requirement (fivefold decrease in energy consumption for
	5% estimation error) compared to repeated snapshot aggregations.},
  doi = {DOI: 10.1016/S1570-8705(03)00009-X},
  file = {boulis2003.pdf:boulis2003.pdf:PDF},
  issn = {1570-8705},
  keywords = {Sensor networks, secure aggregation, wireless networks},
  url = {http://www.sciencedirect.com/science/article/B7576-499CSFN-8/2/7bfac29b9ad6bf0e6091dba2cce3efd4}
}

@ARTICLE{bowman1994,
  author = {Bowman, C. Mic and Danzig, Peter B. and Manber, Udi and Schwartz,
	Michael F.},
  title = {Scalable Internet resource discovery: research problems and approaches},
  journal = {{Commun. ACM}},
  year = {1994},
  volume = {37},
  pages = {98--ff.},
  number = {8},
  abstract = {Perhaps use on internet scalability. Bit old. See also bowman1993
	(tech report).},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/179606.179704},
  file = {bowman1994.pdf:bowman1994.pdf:PDF},
  issn = {0001-0782},
  keywords = {internet resource discovery},
  publisher = {ACM}
}

@TECHREPORT{bowman1993,
  author = {C. Mic Bowman and Peter B. Danzig and Michael F. Schwartz},
  title = {Research Problems for Scalable Internet Resource Discovery},
  institution = {University of Colorado, Boulder},
  year = {1993},
  file = {bowman1993.pdf:bowman1993.pdf:PDF},
  keywords = {Internet resource discovery},
  owner = {kristjan},
  review = {Bit old but perhaps use on internet scalability?},
  timestamp = {2010.05.05}
}

@INPROCEEDINGS{boyd1997,
  author = {Colin Boyd},
  title = {Towards extensional goals in authentication protocols},
  booktitle = {{In Proceedings of the 1997 DIMACS Workshop on Design and Formal
	Verification of Security Protocols}},
  year = {1997},
  pages = {9--7},
  abstract = {The importance of clarifying the goals of a cryptographic protocol
	is widely recognised. The majority of authors have addressed intensional
	goals which are concerned with correct operation within the protocol
	itself. Extensional goals are properties independent of the protocol
	and define what the protocol is designed to achieve. This paper reviews
	the previous literature on goals in protocols and classifies them
	as intensional or extensional goals. A hierarchy of extensional protocol
	goals is proposed which includes the major proposed goals for key
	establishment. It is shown how these extensional goals can be exploited
	to motivate design of entity authentication protocols.},
  file = {boyd1997.pdf:boyd1997.pdf:PDF},
  keywords = {cryptography, authentication, protocols},
  owner = {kristjan},
  timestamp = {2009.03.12}
}

@ARTICLE{boyd2006,
  author = {Stephen Boyd and Arpita Ghosh and Balaji Prabhakar and Devavrat Shah},
  title = {Randomized gossip algorithms},
  journal = {IEEE/ACM Trans. Netw.},
  year = {2006},
  volume = {14},
  pages = {2508--2530},
  number = {SI},
  abstract = {Motivated by applications to sensor, peer-to-peer, and ad hoc networks,
	we study distributed algorithms, also known as gossip algorithms,
	for exchanging information and for computing in an arbitrarily connected
	network of nodes. The topology of such networks changes continuously
	as new nodes join and old nodes leave the network. Algorithms for
	such networks need to be robust against changes in topology. Additionally,
	nodes in sensor networks operate under limited computational, communication,
	and energy resources. These constraints have motivated the design
	of "gossip" algorithms: schemes which distribute the computational
	burden and in which a node communicates with a randomly chosen neighbor.We
	analyze the averaging problem under the gossip constraint for an
	arbitrary network graph, and find that the averaging time of a gossip
	algorithm depends on the second largest eigenvalue of a doubly stochastic
	matrix characterizing the algorithm. Designing the fastest gossip
	algorithm corresponds to minimizing this eigenvalue, which is a semidefinite
	program (SDP). In general, SDPs cannot be solved in a distributed
	fashion; however, exploiting problem structure, we propose a distributed
	subgradient method that solves the optimization problem over the
	network.The relation of averaging time to the second largest eigenvalue
	naturally relates it to the mixing time of a random walk with transition
	probabilities derived from the gossip algorithm. We use this connection
	to study the performance and scaling of gossip algorithms on two
	popular networks: Wireless Sensor Networks, which are modeled as
	Geometric Random Graphs, and the Internet graph under the so-called
	Preferential Connectivity (PC) model.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TIT.2006.874516},
  file = {boyd2006.pdf:boyd2006.pdf:PDF},
  issn = {1063-6692},
  keywords = {networks, peer-to-peer systems, gossip algorithms},
  publisher = {IEEE Press},
  review = {See def of fast mixing property here. Used by Yu et al in SybilGuard/SybilLimit
	(?)}
}

@INPROCEEDINGS{boyd2005,
  author = {Stephen Boyd and Arpita Ghosh and Balaji Prabhakar and Devavrat Shah},
  title = {Gossip algorithms: Design, analysis and applications},
  booktitle = {{IEEE INFOCOM}},
  year = {2005},
  pages = {1653--1664},
  abstract = {Motivated by applications to sensor, peer-topeer and ad hoc networks,
	we study distributed asynchronous algorithms, also known as gossip
	algorithms, for computation and information exchange in an arbitrarily
	connected network of nodes. Nodes in such networks operate under
	limited computational, communication and energy resources. These
	constraints naturally give rise to “gossip ” algorithms: schemes
	which distribute the computational burden and in which a node communicates
	with a randomly chosen neighbor. We analyze the averaging problem
	under the gossip constraint for arbitrary network, and find that
	the averaging time of a gossip algorithm depends on the second largest
	eigenvalue of a doubly stochastic matrix characterizing the algorithm.
	Using recent results of Boyd, Diaconis and Xiao (2003), we show that
	minimizing this quantity to design the fastest averaging algorithm
	on the network is a semidefinite program(SDP). In general, SDPs cannot
	be solved distributedly; however, exploiting problem structure, we
	propose a subgradient method that distributedly solves the optimization
	problem over the network. The relation of averaging time to the second
	largest eigenvalue naturally relates it to the mixing time of a random
	walk with transition probabilities that are derived from the gossip
	algorithm. We use this connection to study the performance of gossip
	algorithm on two popular networks: Wireless Sensor Networks, which
	are modeled as Geometric Random Graphs, and the Internet graph under
	the so-called Preferential Connectivity Model.},
  file = {boyd2005.pdf:boyd2005.pdf:PDF}
}

@INPROCEEDINGS{bozdog2003,
  author = {Bozdog, Adrian and {van Renesse}, Robbert and Dumitriu, Dan},
  title = {{SelectCast}: a scalable and self-repairing multicast overlay routing
	facility},
  booktitle = {{SSRS} '03: Proceedings of the 2003 {ACM} workshop on Survivable
	and self-regenerative systems},
  year = {2003},
  pages = {33--42},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper we describe SelectCast, a self-repairing multicast overlay
	routing facility for supporting publish/subscribe applications. Select
	Cast is a peer-to-peer protocol, and leverages Astrolabe, a secure
	distributed information management system. SelectCast uses replication
	to recover quickly from transient failures, as well as Astrolabe's
	aggregation facilities to recover from long-term failures or adapt
	to changes in load or QoS requirements. In order to evaluate the
	scalability and performance of SelectCast, and compare these with
	other multicast facilities, we built a multicast testing facility
	on NetBed. This paper reports latency and load results for SelectCast,
	compared to both native IP multicast and Yoid.},
  doi = {http://doi.acm.org/10.1145/1036921.1036925},
  file = {bozdog2003.pdf:bozdog2003.pdf:PDF},
  isbn = {1-58113-784-2},
  location = {Fairfax, VA}
}

@INPROCEEDINGS{brands1994,
  author = {Brands, Stefan and Chaum, David},
  title = {Distance-bounding protocols},
  booktitle = {{EUROCRYPT '93}: Workshop on the theory and application of cryptographic
	techniques on Advances in cryptology},
  year = {1994},
  pages = {344--359},
  address = {Secaucus, NJ, USA},
  publisher = {Springer-Verlag New York, Inc.},
  abstract = {It is often the case in applications of cryptographic protocols that
	one party would like to determine a practical upper-bound on the
	physical distance to the other party. For instance, when a person
	conducts a cryptographic identification protocol at an entrance to
	a building, the access control computer in the building would like
	to be ensured that the person giving the responses is no more than
	a few meters away.
	
	The “distance bounding” technique we introduce solves this problem
	by timing the delay between sending out a challenge bit and receiving
	back the corresponding response bit. It can be integrated into common
	identification protocols. The technique can also be applied in the
	three-party setting of “wallets with observers” in such a way that
	the intermediary party can prevent the other two from exchanging
	information, or even developing common coinflips.},
  file = {brands1994.pdf:brands1994.pdf:PDF},
  isbn = {3-540-57600-2},
  keywords = {wormhole prevention},
  location = {Lofthus, Norway}
}

@INCOLLECTION{brandt2005,
  author = {Felix Brandt},
  title = {Efficient Cryptographic Protocol Design Based on Distributed {ElGamal}
	Encryption},
  booktitle = {{ICISC}},
  publisher = {Springier},
  year = {2005},
  volume = {3935},
  series = {Lecture Notes in Computer Science},
  abstract = {We propose a set of primitives based on El Gamal encryption that can
	be used to construct eﬃcient multiparty computation protocols for
	certain low-complexity functions. In particular, we show how to privately
	count the number of true Boolean disjunctions of literals and pairwise
	exclusive disjunctions of literals. Applications include eﬃcient
	two-party protocols for computing the Hamming distance of two bitstrings
	and the greater-than function. The resulting protocols only require
	6 rounds of interaction (in the random oracle model) and their communication
	complexity is O(kQ) where k is the length of bit-strings and Q is
	a security parameter. The protocols are secure against active adversaries
	but do not provide fairness. Security relies on the decisional Diﬃe-Hellman
	assumption and error probability is negligible in Q.},
  file = {brandt2005.pdf:brandt2005.pdf:PDF},
  keywords = {ElGamal encryption, crypto protocol design, distributed encryption},
  owner = {kristjan},
  review = {On computationally secure MPC protocol for disjunciton and maximum
	based on el-gamal. Requires fully (?) connected graph. Ref'd by Kreitz
	(?) 
	
	
	See discussion on zero-knowledge proofs in crypto protocol design.
	
	
	Primitives:
	
	* Distributed key generation
	
	* distributed encryption
	
	* random exponentiation.
	
	
	Zero-knowledge proofs with sigma protocols: 
	
	* Proof of knowledge of a discrete logarithm
	
	* proof of equality of two discrete logarithms
	
	* proof that an encrypted value is one out of two values
	
	* verifiable shuffle of k encrypted values.
	
	
	Cryptographic protocols:
	
	* Socialist millionaries protocol -- equality function
	
	* Veto protocol -- conjunction
	
	* Maximum protocol -- compute maximum of private values},
  timestamp = {2010.04.19}
}

@INCOLLECTION{brandt1990,
  author = {J\{o}gen Brandt and Ivan Damg{\aa}rd and Peter Landrock and Torben
	Pedersen},
  title = {Zero-Knowledge Authentication Scheme with Secret Key Exchange},
  booktitle = {Advances in Cryptology -- {CRYPTO}’ 88},
  publisher = {Springer Berlin / Heidelberg},
  year = {1990},
  owner = {kristjan},
  timestamp = {2010.07.07}
}

@ARTICLE{breunig2000,
  author = {Markus M. Breunig and Hans-Peter Kriegel and Raymond T. Ng and J\"{o}rg
	Sander},
  title = {LOF: identifying density-based local outliers},
  journal = {SIGMOD Rec.},
  year = {2000},
  volume = {29},
  pages = {93--104},
  number = {2},
  abstract = {For many KDD applications, such as detecting criminal activities in
	E-commerce, finding the rare instances or the outliers, can be more
	interesting than finding the common patterns. Existing work in outlier
	detection regards being an outlier as a binary property. In this
	paper, we contend that for many scenarios, it is more meaningful
	to assign to each object a degree of being an outlier. This degree
	is called the local outlier factor (LOF) of an object. It is local
	in that the degree depends on how isolated the object is with respect
	to the surrounding neighborhood. We give a detailed formal analysis
	showing that LOF enjoys many desirable properties. Using real-world
	datasets, we demonstrate that LOF can be used to find outliers which
	appear to be meaningful, but can otherwise not be identified with
	existing approaches. Finally, a careful performance evaluation of
	our algorithm confirms we show that our approach of finding local
	outliers can be practical.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/335191.335388},
  file = {p93-breunig.pdf:p93-breunig.pdf:PDF},
  issn = {0163-5808},
  keywords = {anomaly detection, local outlier factor, LOF},
  publisher = {ACM}
}

@INPROCEEDINGS{brickell2004,
  author = {Ernie Brickell and Jan Camenisch and Liqun Chen},
  title = {Direct Anonymous Attestation},
  booktitle = {{CCS'04}},
  year = {2004},
  abstract = {This paper describes the direct anonymous attestation scheme (DAA).
	This scheme was adopted by the Trusted Computing Group (TCG) as the
	method for remote authentication of a hardware module, called Trusted
	Platform Module (TPM), while preserving the privacy of the user of
	the platform that contains the module. DAA can be seen as a group
	signature without the feature that a signature can be opened, i.e.,
	the anonymity is not revocable. Moreover, DAA allows for pseudonyms,
	i.e., for each signature a user (in agreement with the recipient
	of the signature) can decide whether or not the signature should
	be linkable to another signature. DAA furthermore allows for detection
	of “known” keys: if the DAA secret keys are extracted from a TPM
	and published, a veriﬁer can detect that a signature was produced
	using these secret keys. The scheme is provably secure in the random
	oracle model under the strong RSA and the decisional Diﬃe-Hellman
	assumption.},
  file = {brickell2004.pdf:brickell2004.pdf:PDF},
  keywords = {DAA, TCG, TPM, authentication, cryptography, public key crypto},
  owner = {kristjan},
  review = {See http://eprint.iacr.org/2004/205/},
  timestamp = {2010.09.03}
}

@INCOLLECTION{brickell1987,
  author = {E. Brickell and Y. Yacobi},
  title = {On privacy homomorphisms},
  booktitle = {Advances in Cryptology ({EUROCRYPT} ’87)},
  publisher = {Springer},
  year = {1987},
  volume = {304},
  pages = {117-126},
  address = {New York, NY, USA},
  file = {brickell1987.PDF:brickell1987.PDF:PDF},
  keywords = {cryptography, cryptanalysis, privacy homomorphism, homomorphic encryption},
  owner = {kristjan},
  timestamp = {2009.10.19}
}

@MISC{brickell1993,
  author = {Ernest F. Brickell and Dorothy E. Denning and Stephen T. Kent and
	David P. Maher and Walter Tuchman},
  title = {{SKIPJACK} Review. Interim Report. The {SKIPJACK} Algorithm},
  month = {July},
  year = {1993},
  owner = {kristjan},
  timestamp = {2010.09.03},
  url = {http://www.cs.georgetown.edu/~denning/crypto/clipper/SKIPJACK.txt}
}

@INPROCEEDINGS{bridges2000,
  author = {Susan M. Bridges and Rayford B. Vaughn},
  title = {Intrusion Detection via Fuzzy Data Mining},
  booktitle = {Twelfth Annual Canadian Information Technology Security Symposium},
  year = {2000},
  address = {Ottawa, Canada},
  month = {June 19-23},
  file = {canada-00.pdf:canada-00.pdf:PDF},
  keywords = {networks, intrusion detection, data mining, AI},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@INPROCEEDINGS{brin1998,
  author = {S. Brin and L. Page},
  title = {The Anatomy of a Large-Scale Hypertextual Web Search Engine},
  booktitle = {Seventh International World-Wide Web Conference (WWW 1998)},
  year = {1998},
  abstract = {In this paper, we present Google, a prototype of a large-scale search
	engine which makes heavy use of the structure present in hypertext.
	Google is designed to crawl and index the Web efficiently and produce
	much more satisfying search results than existing systems. The prototype
	with a full text and hyperlink database of at least 24 million pages
	is available at http://google.stanford.edu/. To engineer a search
	engine is a challenging task. Search engines index tens to hundreds
	of millions of web pages involving a comparable number of distinct
	terms. They answer tens of millions of queries every day. Despite
	the importance of large-scale search engines on the web, very little
	academic research has been done on them. Furthermore, due to rapid
	advance in technology and web proliferation, creating a web search
	engine today is very different from three years ago. This paper provides
	an in-depth description of our large-scale web search engine -- the
	first such detailed public description we know of to date. Apart
	from the problems of scaling traditional search techniques to data
	of this magnitude, there are new technical challenges involved with
	using the additional information present in hypertext to produce
	better search results. This paper addresses this question of how
	to build a practical large-scale system which can exploit the additional
	information present in hypertext. Also we look at the problem of
	how to effectively deal with uncontrolled hypertext collections where
	anyone can publish anything they want.},
  file = {brin1998.pdf:brin1998.pdf:PDF},
  keywords = {World Wide Web, Search Engines, Information Retrieval, PageRank, Google},
  review = {PageRank},
  url = {http://ilpubs.stanford.edu:8090/361/}
}

@ARTICLE{Broder2003,
  author = {Andrei Broder and Michael Mitzenmacher},
  title = {Network Applications of Bloom Filters: A Survey},
  journal = {Internet Math},
  year = {2003},
  volume = {1},
  pages = {485-509},
  number = {4},
  abstract = {Bloom ﬁlter is a simple space-eﬃcient randomized data structure for
	
	representing a set in order to support membership queries. Bloom ﬁlters
	allow false
	
	positives but the space savings often outweigh this drawback when
	the probability of
	
	an error is controlled. Bloom ﬁlters have been used in database applications
	since the
	
	1970s, but only in recent years have they become popular in the networking
	literature.
	
	The aim of this paper is to survey the ways in which Bloom ﬁlters
	have been used
	
	and modiﬁed in a variety of network problems, with the aim of providing
	a uniﬁed
	
	mathematical and practical framework for understanding them and stimulating
	their
	
	use in future applications.},
  file = {bloomsurvey.pdf:bloomsurvey.pdf:PDF},
  keywords = {networks, bloom filters, survey},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{brugger2004,
  author = {S Terry Brugger},
  title = {Data Mining Methods for Network Intrusion Detection},
  month = {June},
  year = {2004},
  abstract = {Network intrusion detection systems have become a standard component
	in se-
	
	curity infrastructures. Unfortunately, current systems are poor at
	detecting
	
	novel attacks without an unacceptable level of false alarms. We propose
	that
	
	the solution to this problem is the application of an ensemble of
	data mining
	
	techniques which can be applied to network connection data in an oﬄine
	envi-
	
	ronment, augmenting existing real-time sensors. In this paper, we
	expand on
	
	our motivation, particularly with regard to running in an oﬄine environment,
	
	and our interest in multisensor and multimethod correlation. We then
	review
	
	existing systems, from commercial systems, to research based intrusion
	detec-
	
	tion systems. Next we survey the state of the art in the area. Standard
	datasets
	
	and feature extraction turned out to be more important than we had
	initially
	
	anticipated, so each can be found under its own heading. Next, we
	review
	
	the actual data mining methods that have been proposed or implemented.
	We
	
	conclude by summarizing the open problems in this area and proposing
	a new
	
	research project to answer some of these open problems.},
  file = {brugger_dmnid.pdf:brugger_dmnid.pdf:PDF},
  keywords = {networks, intrusion detection, data mining, AI},
  owner = {kristjan},
  timestamp = {2008.02.26}
}

@INPROCEEDINGS{brunel2007,
  author = {Julien Brunel and Fr\'{e}d\'{e}ric Cuppens and Nora Cuppens and Thierry
	Sans and Jean-Paul Bodeveix},
  title = {Security policy compliance with violation management},
  booktitle = {FMSE '07: Proceedings of the 2007 ACM workshop on Formal methods
	in security engineering},
  year = {2007},
  pages = {31--40},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A security policy of an information system is a set of security requirements
	that correspond to permissions, prohibitions and obligations to execute
	some actions when some contextual conditions are satisfied. Traditional
	approaches consider that the information system enforces its associated
	security policy if and only if actions executed in this system are
	permitted by the policy (if the policy is closed) or not prohibited
	(if the policy is open) and every obligatory actions are actually
	executed in the system (no violation of obligations). In this paper,
	we investigate a more sophisticated approach in which an information
	system specification is compliant with its security policy even though
	some security requirements may be violated. Our proposal is to consider
	that this is acceptable when the security policy specifies additional
	requirements that apply in case of violation of other security requirements.
	In this case, we formally define conditions to be satisfied by an
	information system to comply with its security policy. We then present
	a proof-based approach to check if these conditions are enforced.},
  doi = {http://doi.acm.org/10.1145/1314436.1314441},
  file = {brunel2007.pdf:brunel2007.pdf:PDF},
  isbn = {978-1-59593-887-9},
  keywords = {security policies},
  location = {Fairfax, Virginia, USA}
}

@ARTICLE{zarpelao2007,
  author = {Bruno Bogaz Zarpel\, {a}o and Leonardo De Souza Mendes and Mario
	Lemes Proen\c{c}a,Jr.},
  title = {Anomaly Detection Aiming Pro-Active Management of Computer Network
	Based on Digital Signature of Network Segment},
  journal = {J. Netw. Syst. Manage.},
  year = {2007},
  volume = {15},
  pages = {267--283},
  number = {2},
  abstract = {Detecting anomalies accurately is fundamental to rapid diagnosis and
	repair of problems. This paper proposes a novel Anomaly detection
	system based on the comparison of real traffic and DSNS (Digital
	Signature of Network Segment), generated by BLGBA (Baseline for Automatic
	Backbone Management) model, within a hysteresis interval using the
	residual mean and on the correlation of the detected deviations.
	Extensive experimental results on real network servers confirmed
	that our system is able to detect anomalies on the monitored devices,
	avoiding the high false alarms rate.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1007/s10922-007-9064-y},
  file = {zarpelao2007.pdf:zarpelao2007.pdf:PDF},
  issn = {1064-7570},
  keywords = {networks, anomaly detection, intrusion detection, AI},
  publisher = {Plenum Press}
}

@ARTICLE{zarpelao2006,
  author = {Bruno Bogaz Zarpel\,{a}o and Leonardo De Souza Mendes and Mario Lemes
	{Proen\c{c}a, Jr.}},
  title = {Graph-based Correlation of SNMP Objects for Anomaly Detection},
  journal = {{IJCSNS International Journal of Computerscience and Network Scecurity}},
  year = {2006},
  volume = {6},
  pages = {194-202},
  number = {5B},
  month = {May},
  abstract = {Anomaly detection is essential, because it allows a rapid reaction
	
	to the problems and helps assuring performance and security in
	
	computer networks. This paper presents an anomaly detection
	
	system based on: (i) the traffic characterization performed by the
	
	BLGBA model, which is responsible for the DSNS generation;
	
	(ii) an alarm system that compares the DSNS and the real
	
	movement obtained in SNMP objects, sending the alarms to a
	
	correlation system when a behavior deviation is detected; (iii) a
	
	correlation system based on a directed graph which represents
	
	the possible paths of anomaly propagation through the SNMP
	
	objects in a network element. Three years of data collected from
	
	the State University of Londrina network were used to evaluate
	
	this anomaly detection system. The results were encouraging and
	
	confirmed that our system is able to detect anomalies on the
	
	monitored network elements, avoiding the high false alarms rate.},
  file = {zarpelao2006.pdf:zarpelao2006.pdf:PDF},
  keywords = {networks, anomaly detection, AI, intrusion detection, SNMPs},
  owner = {kristjan},
  timestamp = {2009.06.26}
}

@PHDTHESIS{buchegger2004,
  author = {Sonja Buchegger},
  title = {Coping with Misbehavior in Mobile Ad-hoc Networks},
  school = {{\'{E}}cole Polytechnique F\'{e}d\'{e}rale De Lausanne},
  year = {2004},
  month = {February},
  abstract = {In this work, we address the question of how to enable a system to
	operate despite the
	
	presence of misbehavior. Specifically, in a mobile ad-hoc network,
	how can we keep
	
	the network functional for normal nodes when other nodes do not route
	and forward
	
	correctly?
	
	
	Node misbehavior due to selfish or malicious reasons or faulty nodes
	can significantly
	
	degrade the performance of mobile ad-hoc networks. Existing approaches
	such as
	
	economic incentives or secure routing by cryptographic means alleviate
	some of the
	
	problems, but not all. For instance, nodes can still forward packets
	on bogus routes.
	
	We propose a protocol called CONFIDANT (Cooperation Of Nodes — Fairness
	In
	
	Dynamic Ad-hoc NeTworks) to cope with misbehavior. It enables nodes
	to detect
	
	misbehavior by first-hand observation and use of second-hand information
	provided
	
	by other nodes. The view a node has about the behavior of another
	node is captured in
	
	a reputation system, which is used to classify nodes as misbehaving
	or normal. Once
	
	a misbehaving node is detected, it is isolated from the network.
	
	
	Reputation systems can, however, be tricked by the spread of false
	reputation ratings,
	
	be it false accusations or false praise. Simple solutions such as
	exclusively relying
	
	on one’s own direct observations have drawbacks, as they do not make
	use of all the
	
	information available. To solve this problem, we propose a fully distributed
	reputation
	
	system that can cope with false information and effectively use second-hand
	infor-
	
	mation in a safe way. Our approach is based on a modified Bayesian
	estimation and
	
	classification procedure. In our approach, each node maintains a reputation
	rating and
	
	a trust rating about all other nodes it cares about. Reputation ratings
	capture the quality
	
	of the behavior of a node as an actor in the network performing routing
	and forwarding 
	
	tasks. From time to time first-hand reputation information is exchanged
	with others;
	
	using a modified Bayesian approach we designed, second-hand reputation
	informa-
	
	tion is only accepted if it is compatible with the current reputation
	rating. Reputation
	
	ratings are only slightly modified by accepted information. Trust
	ratings capture the
	
	quality of a node as an actor in the reputation system and reflect
	whether the reported
	
	first hand information summaries published by node are likely to be
	true. Trust rat-
	
	ings are updated based on the compatibility of second-hand reputation
	information
	
	with prior reputation ratings. We enable node redemption and prevent
	the sudden ex-
	
	ploitation of good reputation built over time by introducing reputation
	fading. Data is
	
	entirely distributed, the reputation and trust value of a node is
	the collection of ratings
	
	maintained by others.
	
	
	We use simulation to evaluate and demonstrate the performance. We
	found that CON-
	
	FIDANT can keep the network performance high even when up to half
	of the network
	
	population misbehaves. We show that our approach of using second-hand
	information
	
	significantly speeds up the detection of misbehaving nodes while keeping
	the number
	
	of false positives and negatives negligibly low.},
  file = {buchegger2004.pdf:buchegger2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.07}
}

@TECHREPORT{buchegger2003,
  author = {Sonja Buchegger and Jean-Yves {Le Boudec}},
  title = {A Robust Reputation System for Mobile Ad-hoc Networks},
  institution = {EPFL IC},
  year = {2003},
  number = {IC/2003/50},
  abstract = {Reputation systems in mobile ad-hoc networks can be tricked by the
	spreading of false reputation ratings, be it false accusations or
	false praise. Simple solutions such as exclusively relying on one’s
	own direct observations have drawbacks, as they do not make use of
	all the information available. We propose a fully distributed reputation
	system that can cope with false disseminated information. In our
	approach, everyone maintains a reputation rating and a trust rating
	about everyone else that they care about. From time to time ﬁrst-hand
	reputation information is exchanged with others; using a modiﬁed
	Bayesian approach we designed and present in this paper, only second-hand
	reputation information that is not incompatible with the current
	reputation rating is accepted. Thus, reputation ratings are slightly
	modiﬁed by accepted information. Trust ratings are updated based
	on the compatibility of second-hand reputation information with prior
	reputation ratings. Data is entirely distributed: someone’s reputation
	and trust is the collection of ratings maintained by others. We enable
	node redemption and prevent the sudden exploitation of good reputation
	built over time by introducing re-evaluation and reputation fading.
	We present the application of our generic reputation system to the
	context of neighborhood watch in mobile ad-hoc networks, speciﬁcally
	to the CONFIDANT [3] protocol for the detection and isolation of
	nodes exhibiting routing or forwarding misbehavior. We evaluate the
	performance by simulation.},
  file = {buchegger2003.pdf:buchegger2003.pdf:PDF},
  keywords = {reputation and trust management, bayesian statistics, ad-hoc networks,
	CONFIDANT protocol},
  owner = {kristjan},
  review = {Reputation in Ad-Hoc networks. Propose robust reputation mechanisms,
	based on mutual peer observations -- "neighborhood watch" -- to enable
	use of ones own as well as reported information. If only trusting
	reports, the system is vulnerable to false accusations. If only considering
	ones own, the information to make decisions is reduced.
	
	Describe CONFIDANT protocol -- see Buchegger2003 for architecture
	and background.
	
	
	* Reputation rating: represents an opinion formed by a node i about
	the behavior of node j as an actor in the system.
	
	* Truste rating: represents node i's opinion about how honest node
	j is as an actor in the system.
	
	
	Distinquishes between first and second hand information and assigns
	trust ratings accordingly. Ratings used to make decisions about other
	nodes, such as routing decisions.
	
	
	Peers periodically classified as
	
	* Regular/misbehaved
	
	* trustworthy/not trustworthy
	
	Bayesian approach used for updating -- use past history in evaluation.
	
	
	Identity central to reputation: Require identities to be persistent,
	unique and distinct.},
  timestamp = {2010.04.07}
}

@ARTICLE{buchegger2002,
  author = {Sonja Buchegger and Jean-Yves {Le Boudec}},
  title = {Nodes Bearing Grudges: Towards Routing Security, Fairness, and Robustness
	in Mobile Ad Hoc Networks},
  journal = {Euromicro Conference on Parallel, Distributed, and Network-Based
	Processing},
  year = {2002},
  volume = {0},
  pages = {0403},
  abstract = {Devices in mobile ad hoc networks work as network nodes and relay
	packets originated by other nodes. Mobile ad hoc networks can work
	properly only if the participating nodes cooperate in routing and
	forwarding. For individual nodes it might be advantageous not to
	cooperate, though. The new routing protocol extensions presented
	in this paper make it possible to detect and isolate misbehaving
	nodes, thus making it unattractive to deny cooperation. In the presented
	scheme, trust relationships and routing decisions are made based
	on experienced, observed, or reported routing and forwarding behavior
	of other nodes. A hybrid scheme of selective altruism and utilitarianism
	is presented to strengthen mobile ad hoc network protocols in their
	resistance to security attacks, while aiming at keeping network throughput,
	or goodput, high. This paper focuses particularly on the network
	layer, using the Dynamic Source Routing (DSR) protocol as an example.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/EMPDP.2002.994321},
  file = {buchegger2002.pdf:buchegger2002.pdf:PDF},
  issn = {1066-6192},
  keywords = {mobile ad hoc networks, routing, cooperation, robustness, fairness,
	security, distributed systems, reputation systems, DSR, dynamic source
	routing protoco},
  publisher = {IEEE Computer Society},
  review = {Considers reputation mechanisms for enforcing proper routing cooperation
	through peer monitoring of neighbor actions -- "neighborhood watch".
	DSR routing protocol used as an example. Gives architecture for trust
	manager and reputation service for a node. The objective is to establish
	robust mechanisms that reward correct behavior. The paper uses a
	"systems approach": Presenting the concept as a set of clearly defined
	modules, each with specific purpose, and specific interactions.
	
	
	====
	
	
	Mobile ad-hoc networks depend on nodes cooperating. It may however
	be in the best interest of individual nodes to selectively particiapting
	in the protocol (Note: rational behavior). The authors present protocol
	extensions to detect and isolate misbehaving nodes, so denial of
	cooperation will be less attractive. Incentive to NOT participate
	altruistically is for example battery conservation.
	
	
	Issues in mobile ad-hoc networks: authentication, integrity, confidentiality,
	availability, access control, non-reputation (the standard list --
	see Stallings), also cooperation and fairness, confidentiality of
	location and no traffic diversion (routing and forwarding attacks).
	
	
	Thwarting malicious behavior and non-cooperation means punishing (isolating)
	misbehaving nodes. Nodes cut off must however be re-socialized after
	some time to prevent wrongly accused nodes of being excluded for
	eternity.
	
	
	In the protocol,
	
	* Neighborhood watch is employed to observe what happens to other
	nodes. This is done by a monitor component which can watch e.g.\
	intrusions, misuse of cooperation incentives, DoS. This is done by
	listening to the transimissions of neighbors or observing route protocol
	behavior. Content modifications can e.g. be observed by keeping a
	copy and listening to the forwarding transmission (Note: Only in
	case of broadcast media). See the paper for further examples of misbehavior.
	
	* Nodes share information of experienced malicious behavior with friends
	(How are friendship relations established?)
	
	
	A trust management component sends and receives alarm messages based
	on observed behavor. Trust ratings updated accordingly. A mechanism
	similar to PGP trust management is used.
	
	
	Weights of bad behavior -- highest for own experiences, lower for
	observations, reported experiences according to PGP trust.
	
	
	Reputation system: Local ratings and black lists are kept at each
	node. Nodes are blacklisted based on observed behavor. Own observations
	rate highest -- reported less (weighted according to PGP trust rating).
	Timeouts used to allow rehabilitation. Path manager attempts to remove
	paths containing malicious nodes, route around them.
	
	
	Alarm messages are sent by nodes once observed bad behavior exceeds
	a threshold. To prevent bad nodes from abusing this mechanisms, nodes
	evaluate received alarms and rate according to their impression of
	the reporters trust.
	
	
	Authentication prerequisite for the protocol -- one approach is to
	use PGP and a distributed certificaiton authority.
	
	
	The Dynamic Source Routing protocol (DSR) used as an example. An extension
	of the protocol with a list of vulnerabilities (of the original)
	is presented.
	
	
	See reference to Bruce Schneier's Secrets and Lies -- Prevention-only
	strategy works only if the prevention mechanisms are perfect. Otherwise,
	someone will find a way around them. Most attacks and vulnerabilities
	are results of bypassing prevention mechanisms.}
}

@INPROCEEDINGS{buchegger2002a,
  author = {Buchegger, Sonja and {Le Boudec}, Jean-Yves},
  title = {Performance analysis of the {CONFIDANT} protocol},
  booktitle = {{MobiHoc} '02: Proceedings of the 3rd {ACM} international symposium
	on Mobile ad hoc networking \& computing},
  year = {2002},
  pages = {226--236},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Mobile ad-hoc networking works properly only if the participating
	nodes cooperate in routing and forwarding. However,it may be advantageous
	for individual nodes not to cooperate. We propose a protocol, called
	CONFIDANT, for making misbehavior unattractive; it is based on selective
	altruism and utilitarianism. It aims at detecting and isolating misbehaving
	nodes, thus making it unattractive to deny cooperation. Trust relationships
	and routing decisions are based on experienced, observed, or reported
	routing and forwarding behavior of other nodes. The detailed implementation
	of CONFIDANT in this paper assumes that the network layer is based
	on the Dynamic Source Routing (DSR) protocol. We present a performance
	analysis of DSR fortified by CONFIDANT and compare it to regular
	defenseless DSR. It shows that a network with CONFIDANT and up to
	60% of misbehaving nodes behaves almost as well as a benign network,
	in sharp contrast to a defenseless network. All simulations have
	been implemented and performed in GloMoSim.},
  doi = {http://doi.acm.org/10.1145/513800.513828},
  file = {buchegger2002a.pdf:buchegger2002a.pdf:PDF},
  isbn = {1-58113-501-7},
  keywords = {ad-hoc networks, reputation, CONFIDANT protocol, DSR, dynamic source
	routing protocol},
  location = {Lausanne, Switzerland},
  review = {See other papers on CONFIDANT -- buchegger2002 and buchegger2003.
	This paper contributes performance analysis of the protocol: Goodput,
	overhead, utility. Provide simulation results}
}

@INPROCEEDINGS{buchegger2008,
  author = {Sonja Buchegger and Jochen Mundinger and Jean-Yves {Le Boudec}},
  title = {Reputation Systems for Self-Organized Networks: Lessons Learned},
  booktitle = {{IEEE Technology \& Society Magazine}},
  year = {2008},
  abstract = {Self-organized networks such as mobile ad-hoc, Internet-based peer-to-peer,
	wireless mesh and Fourth Generation (4G) Wireless networks depend
	on cooperation of nodes. Reputation systems help nodes decide with
	whom to cooperate and which nodes to avoid. They have been studied
	and applied almost separately in diverse disciplines such as economics,
	computer science and social science, resulting in effort duplication
	and inconsistent terminology. In this paper, we aim at bringing together
	these efforts by outlining features and fundamental questions common
	to reputation systems in general. We derive methodologies to address
	these questions and lessons for both reputation system design and
	research from our own experiences and evaluations by simulation and
	analytical modelling. We argue for using deviation tests, discounting,
	only passing on of first-hand information, secondary response, and
	stressing the importance of identity.},
  file = {buchegger2008.pdf:buchegger2008.pdf:PDF},
  owner = {kristjan},
  review = {A good summary of issues in reputation as well as definition of trust/reputation
	terms.
	
	
	Source which contribute to generation of reputation:
	
	* Keeping track of past experiences -- store sufficient data to make
	decisions
	
	* Incorporating data from different sources -- direct obs always accepted,
	secondary information must be weighed and only that considered likely
	included. Use "confirmation bias".
	
	* Forgetting reputation over time -- discount by a factor so that
	old observations become less important
	
	* Secondary response -- increase sensitivity of nodes that have been
	deemed misbehaving in the past.
	
	
	List questions for reputation systems -- incentives to participate,
	etc.
	
	
	Methodologu to answer fundamental questions. Stocastic formulation,
	discuss system parameters, model for node behavior.
	
	
	Discuss lessons learned, such as using deviation tests to mitigate
	spurious readings. Identity is a critical issue.
	
	
	Liist some of the issues which must be addressed in future reputation
	work, such as coherent terminology and classification
	
	
	Briefly discuss reputation in 4G systems, e.g. 4G address identity,
	taking advantage of an mostly-on central authority.},
  timestamp = {2010.04.07}
}

@INPROCEEDINGS{buchegger2009,
  author = {Sonja Buchegger and Doris Schi{\"{o}}berg and Le Hung Vu and Anwitaman
	Datta},
  title = {{PeerSoN: P2P Social Networking - Early Experiences and Insights}},
  booktitle = {{Proceedings of the Second ACM Workshop on Social Network Systems
	Social Network Systems 2009, co-located with Eurosys 2009}},
  year = {2009},
  address = {N{\"{u}}rnberg, Germany},
  abstract = {To address privacy concerns over Online Social Networks (OSNs), we
	propose a distributed, peer-to-peer approach coupled with encryption.
	Extending the distributed approach by direct data exchange between
	user devices removes the strict connectivity requirements of web-based
	OSNs. In order to verify the feasibility of this approach, we designed
	a two-tiered architecture and protocols that recreate the core features
	of OSNs in a decentralized way. This paper focuses on the description
	of the prototype built for the P2P infrastructure for social networks,
	as a ﬁrst step without the encryption part, and shares early experiences
	from the prototype
	
	and insights gained since ﬁrst outlining the challenges and possibilities
	of decentralized alternatives to OSNs.},
  file = {buchegger2009.pdf:buchegger2009.pdf:PDF}
}

@ARTICLE{burgess2006,
  author = {Mark Burgess},
  title = {Probabilistic anomaly detection in distributed computer networks},
  journal = {Sci. Comput. Program.},
  year = {2006},
  volume = {60},
  pages = {1--26},
  number = {1},
  abstract = {Distributed host-based anomaly detection has not yet proven practical
	due to the excessive computational overhead during training and detection.
	This paper considers an efficient algorithm for detecting resource
	anomalies in event streams with either Poisson or long tailed arrival
	processes. A form of distributed, lazy evaluation is presented, which
	uses a model for human-computer interaction based on two-dimensional
	time and a geometrically declining memory to yield orders of magnitude
	improvements in memory requirements. A three-tiered probabilistic
	method of classifying anomalous behaviour is discussed. This leads
	to a computationally and memory economic means of finding probable
	faults amongst the symptoms of network and system behaviour.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.scico.2005.06.001},
  file = {burgess2006.pdf:burgess2006.pdf:PDF},
  issn = {0167-6423},
  keywords = {networks, distributed systems, anomaly detection, distributed intrusion
	detection},
  publisher = {Elsevier North-Holland, Inc.}
}

@ARTICLE{burgess2002,
  author = {Mark Burgess and H{\aa}rek Haugerud and Sigmund Straumsnes and Trond
	Reitan},
  title = {Measuring system normality},
  journal = {ACM Trans. Comput. Syst.},
  year = {2002},
  volume = {20},
  pages = {125--160},
  number = {2},
  abstract = {A comparative analysis of transaction time-series is made, for light
	to moderately loaded hosts, motivated by the problem of anomaly detection
	in computers. Criteria for measuring the statistical state of hosts
	are examined. Applying a scaling transformation to the measured data,
	it is found that the distribution of fluctuations about the mean
	is closely approximated by a steady-state, maximum-entropy distribution,
	modulated by a periodic variation. The shape of the distribution,
	under these conditions, depends on the dimensionless ratio of the
	daily/weekly periodicity and the correlation length of the data.
	These values are persistent or even invariant. We investigate the
	limits of these conclusions, and how they might be applied in anomaly
	detection.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/507052.507054},
  file = {burgess2002.pdf:burgess2002.pdf:PDF},
  issn = {0734-2071},
  keywords = {networks, anomaly detection, network measurements},
  publisher = {ACM}
}

@ARTICLE{burmester2007,
  author = {Burmester, Mike and Le, Tri Van and Yasinsac, Alec},
  title = {Adaptive gossip protocols: Managing security and redundancy in dense
	ad hoc networks},
  journal = {Ad Hoc Netw.},
  year = {2007},
  volume = {5},
  pages = {313--323},
  number = {3},
  __markedentry = {[kristjan]},
  abstract = {Many ad hoc routing algorithms rely on broadcast flooding for location
	discovery or, more generally, for secure routing applications. Flooding
	is a robust algorithm but because of its extreme redundancy, it is
	impractical in dense networks. Indeed in large wireless networks,
	the use of flooding algorithms may lead to broadcast storms where
	the number of collisions is so large that it causes system failure.
	To prevent broadcast storms, many mechanisms that reduce redundant
	transmissions have been proposed that reduce retransmission overhead
	either deterministically or probabilistically. Gossip is a probabilistic
	algorithm in which packet retransmission is based on the outcome
	of coin tosses. The retransmission probability can be fixed, dynamic
	or adaptive. With dynamic gossip, local information is used to determine
	the retransmission probability. With adaptive gossip, the decision
	to relay is adjusted adaptively based on the outcome of coin tosses,
	the local network structure, and the local response to the flooding
	call. The goal of gossip is to minimize the number of retransmissions,
	while retaining the main benefits of flooding, e.g., universal coverage,
	minimal state retention, and path length preservation. In this paper
	we consider ways to reduce the number of redundant transmissions
	in flooding while guaranteeing security. We present several new gossip
	protocols that exploit local connectivity to adaptively correct propagation
	failures and protect against Byzantine attacks. A main contribution
	of this work is that we introduce a cell-grid approach that allows
	us to analytically prove performance and security protocol properties.
	The last two gossip protocols that we give are fully adaptive, i.e.,
	they automatically correct all faults and guarantee delivery, the
	first such protocols to the best of our knowledge.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2005.11.007},
  file = {burmester2007.pdf:burmester2007.pdf:PDF},
  issn = {1570-8705},
  keywords = {gossip protocol, security, robust gossiping, byzantine fault tolerance},
  publisher = {Elsevier Science Publishers B. V.},
  review = {Consider resiliency of gossip protocols to crash and byzantine failures.
	Present two byzantine resistant protocols. One based on signal direction
	and the other based on geodesic location. Both protocols make quite
	strong assumptions with regards to the aggregation network and node
	capabilities.}
}

@INCOLLECTION{burmester2004,
  author = {Mike Burmester and Tri Van Le and Alec Yasinsac},
  title = {Weathering the Storm: Managing Redundancy and Security in Ad Hoc
	Networks},
  booktitle = {Ad-Hoc, Mobile, and Wireless Networks},
  publisher = {Springer Berlin / Heidelberg},
  year = {2004},
  series = {Lecture Notes in Computer Science},
  __markedentry = {[kristjan]},
  abstract = {Many ad hoc routing algorithms rely on broadcast ﬂooding for location
	discovery or more generally for secure routing applications, particularly
	when dealing with Byzantine threats. Flooding is a robust algorithm
	but, because of its extreme redundancy, it is impractical in dense
	networks. Indeed in large wireless networks, the use of ﬂooding algorithms
	may lead to a broadcast storm in which the number of collisions is
	so large that we get system failure. Further reducing unnecessary
	transmissions greatly improves energy eﬃciency of such networks.
	Several variants have been proposed to reduce the relay overhead
	either deterministically or probabilistically. Gossip is a probabilistic
	algorithm, in which packet relaying is based on the outcome of coin
	tosses. The relay probability can be ﬁxed, dynamic or adaptive. With
	dynamic Gossip, local information (local connectivity) is used. With
	adaptive Gossip, the decision to relay is adjusted adaptively based
	on the outcome of coin tosses, the local network structure and the
	local response to the ﬂooding call. The goal of gossiping is to minimize
	the number of relays, while retaining the main beneﬁts of ﬂooding,
	i.e., eﬀective distance. In this paper we consider ways to reduce
	the number of redundant transmissions in broadcast ﬂooding while
	guaranteeing security. We present several gossip type protocols,
	which exploit local connectivity and adaptively correct local relay
	failures. These use a (geodesic) cell based approach and preserve
	cell-distance. Our last two protocols are non probabilistic and guarantee
	delivery, the ﬁrst such protocols to the best of our knowledge.},
  file = {burmester2004.pdf:burmester2004.pdf:PDF},
  keywords = {Ad hoc networks, secure MANETS, flooding, Gossip, broadcast redundancy,
	broadcast storms, secure routing, robust gossip},
  owner = {kristjan},
  review = {See newer (?) version burmester2007.},
  timestamp = {2010.05.03}
}

@ARTICLE{burrows1990,
  author = {Michael Burrows and Martin Abadi and Roger Needham},
  title = {A logic of authentication},
  journal = {{ACM} Trans. Comput. Syst.},
  year = {1990},
  volume = {8},
  pages = {18--36},
  number = {1},
  abstract = {Authentication protocols are the basis of security in many distributed
	systems, and it is therefore essential to ensure that these protocols
	function correctly. Unfortunately, their design has been extremely
	error prone. Most of the protocols found in the literature contain
	redundancies or security flaws. A simple logic has allowed us to
	describe the beliefs of trustworthy parties involved in authentication
	protocols and the evolution of these beliefs as a consequence of
	communication. We have been able to explain a variety of authentication
	protocols formally, to discover subtleties and errors in them, and
	to suggest improvements. In this paper we present the logic and then
	give the results of our analysis of four published protocols, chosen
	either because of their practical importance or because they serve
	to illustrate our method.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/77648.77649},
  file = {burrows1990.pdf:burrows1990.pdf:PDF},
  issn = {0734-2071},
  keywords = {authentication, formal methods},
  publisher = {ACM}
}

@ARTICLE{buttyan2003,
  author = {Butty\'{a}n, Levente and Hubaux, Jean-Pierre},
  title = {Report on a working session on security in wireless ad hoc networks},
  journal = {{SIGMOBILE} Mob. Comput. Commun. Rev.},
  year = {2003},
  volume = {7},
  pages = {74--94},
  number = {1},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/881978.882002},
  file = {buttyan2003.pdf:buttyan2003.pdf:PDF},
  issn = {1559-1662},
  keywords = {wireless networks, ad-hoc network, sensor network, security, survey},
  publisher = {ACM}
}

@INPROCEEDINGS{buttyan2006,
  author = {Butty\'{a}n, Levente and Schaffer, P\'{e}ter and Vajda, Istv\'{a}n},
  title = {{RANBAR}: {RANSAC}-based resilient aggregation in sensor networks},
  booktitle = {{SASN} '06: Proceedings of the fourth {ACM} workshop on Security
	of ad hoc and sensor networks},
  year = {2006},
  pages = {83--90},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present a novel outlier elimination technique designed for sensor
	networks. This technique is called RANBAR and it is based on the
	RANSAC (RANdom SAmple Consensus) paradigm, which is well-known in
	computer vision and in automated cartography. The RANSAC paradigm
	gives us a hint on how to instantiate a model if there are a lot
	of compromised data elements.However,the paradigm does not specify
	an algorithm and it uses a guess for the number of compromised elements,
	which is not known in general in real life environments. We developed
	the RANBAR algorithm following this paradigm and we eliminated the
	need for the guess. Our RANBAR algorithm is therefore capable to
	handle a high percent of outlier measurement data by leaning on only
	one preassumption,namely that the sample is i.i.d. in the unattacked
	case. We implemented the algorithm in a simulation environment and
	we used it to filter out outlier elements from a sample before an
	aggregation procedure. The aggregation function that we used was
	the average. We show that the algorithm guarantees a small distortion
	on the output of the aggregator even if almost half of the sample
	is compromised. Compared to other resilient aggregation algorithms,
	like the trimmed average and the median, our RANBAR algorithm results
	in smaller distortion, especially for high attack strengths.},
  doi = {http://doi.acm.org/10.1145/1180345.1180356},
  file = {buttyan2006.pdf:buttyan2006.pdf:PDF},
  isbn = {1-59593-554-1},
  keywords = {sensor networks, robustness, outlier elimination, RANBAR, RANSAC,
	model fitting, maximum likelihood estimation, MLE},
  location = {Alexandria, Virginia, USA},
  review = {Based on the random sample consensus (RANBAR) algorithm -- well known
	model fitting algorithm. See fishler1981 for details.
	
	
	This paper is concerned with resilient aggregation. Two ways in which
	sample can be compromised: 1) on way from sensor to base station
	(assume single aggregator) which can be prevented by crypto and 2)
	by affecting individual sensor readings, which cannot be detected
	or prevented by crypto. The latter is what resilient aggregation
	is about. See also wagner2003 on same topic.
	
	
	Single aggregator model as wagner assumes. Random sampling and comparison
	with (theoretical) statistical model used to detect adversarial influence.
	Assume data is iid (that is, in the absence of adversaries).
	
	
	No detection of indiviual corrupted nodes (?) -- purely confidence
	measure for aggregated value. CHECK
	
	
	
	RANSAC -- random sample consensus -- defines a principle for filtering
	non-consistent data from a sample -- fitting a model to experimental
	data.
	
	
	Assumes normally distributed data -- see attacker model discussion.
	However, not limited to iid model (claimed by authors, working on
	correlated data model).
	
	
	Uses maximum likelihood estimation.}
}

@INPROCEEDINGS{buttyan2006a,
  author = {Butty\'{a}n, Levente and Schaffer, P\'{e}ter and Vajda, Istv\'{a}n},
  title = {Resilient Aggregation with Attack Detection in Sensor Networks},
  booktitle = {{PERCOMW} '06: Proceedings of the 4th annual {IEEE} international
	conference on Pervasive Computing and Communications Workshops},
  year = {2006},
  pages = {332},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {In this paper, we propose a new model of resilient data aggregation
	in sensor networks, where the aggregator analyzes the received sensor
	readings and tries to detect unexpected deviations before the aggregation
	function is called. In this model, the adversary does not only want
	to cause maximal distortion in the output of the aggregation function,
	but it also wants to remain undetected. The advantage of this approach
	is that in order to remain undetected, the adversary cannot distort
	the output arbitrarily, but rather the distortion is usually upper
	bounded, even for aggregation functions that were considered to be
	insecure earlier (e.g., the average). We illustrate this through
	an example in this paper.},
  doi = {http://dx.doi.org/10.1109/PERCOMW.2006.119},
  file = {buttyan2006a.pdf:buttyan2006a.pdf:PDF},
  isbn = {0-7695-2520-2},
  review = {Consider resilient aggregation (see Wagner's work). Prerequisite:
	a priori knowledge of the distribution over inputs.
	
	Use sample splitting and a threshold to determine suspicious sample
	sets. If an attack is suspected, the entire set is thrown away. 
	
	
	Single aggregator model. Consider the problem of robust aggregation
	a la Wagner.
	
	
	NOTE: vector for trivial DoS attacks.
	
	
	
	See short note by buttyan2006 -- detection algorithm analyses the
	data before aggregation and tries to detect unexpected deviations
	in received sensor readings. Trimming (one of Wagner's proposals)
	is a special case of this technique. Sample halving used to indicate
	attack if above a threshold. Claim upper bound of distortion achievable
	by a stealthy adversary. Disadvantage: If the algorithm indicates
	attack, the aggregation function is not called -- leads to availability
	attacks.
	
	
	RANBAR paper improves on this by producing an output most of the time
	even when an attack is suspected.}
}

@INPROCEEDINGS{cardenas2008,
  author = {C\'{a}rdenas, Alvaro A. and Amin, Saurabh and Sastry, Shankar},
  title = {Research challenges for the security of control systems},
  booktitle = {{HOTSEC'08}: Proceedings of the 3rd conference on Hot topics in security},
  year = {2008},
  pages = {1--6},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {n this paper we attempt to answer two questions: (1) Why should we
	be interested in the security of control systems? And (2) What are
	the new and fundamentally different requirements and problems for
	the security of control systems? We also propose a new mathematical
	framework to analyze attacks against control systems. Within this
	framework we formulate specific research problems to (1) detect attacks,
	and (2) survive attacks.},
  file = {cardenas2008.pdf:cardenas2008.pdf:PDF},
  keywords = {security, SCADA, control systems},
  location = {San Jose, CA}
}

@MISC{cardenas2006,
  author = {Alvaro A. C\'{a}rdenas and Gelareh Taban and John S. Baras},
  title = {A Unified Framework of Information Assurance for the Design and Analysis
	of Security Algorithms},
  year = {2006},
  abstract = {Most information security algorithms cannot achieve perfect security
	without incurring severe operational costs such as false alarms,
	network congestion, capital investment etc. Operating or designing
	an algorithm with perfect security is therefore not an economically
	rational alternative and thus the question arises of how to find
	the appropriate tradeoff between security and its costs. Although
	several other researchers have recognized that there is a tradeoff,
	there is very little work in formally characterizing it. This paper
	provides the first steps towards a more systematic and general approach
	for cost-effective security management.},
  file = {cardenas2006.pdf:cardenas2006.pdf:PDF},
  owner = {kristjan},
  review = {Gives metrics for cost v.s. security tradeoffs in secure protocols,
	numbers for CPS and some other well known protocols.},
  timestamp = {2010.01.26}
}

@INCOLLECTION{cachin1999,
  author = {Christian Cachin and Silvio Micali and Markus Stadler},
  title = {Computationally Private Information Retrieval with Polylogarithmic
	Communication},
  booktitle = {Advances in Cryptology — {EUROCRYPT ’99}},
  publisher = {Springer},
  year = {1999},
  abstract = {We present a single-database computationally private information retrieval
	scheme with polylogarithmic communication complexity. Our construction
	is based on a new, but reasonable intractability assumption, which
	we call the Φ-Hiding Assumption (ΦHA): essentially the difficulty
	of deciding whether a small prime divides Φ(m), where m is a composite
	integer of unknown factorization.},
  file = {cachin1999.pdf:cachin1999.pdf:PDF},
  keywords = {PIR, private information retrieval},
  owner = {kristjan},
  timestamp = {2009.12.17}
}

@INPROCEEDINGS{cadar2005,
  author = {Cristian Cadar and Dawson Engler},
  title = {{Execution Generated Test Cases: How to Make Systems Code Crash Itself}},
  booktitle = {12th International SPIN Workshop},
  year = {2005},
  address = {San Francisco, CA, USA},
  month = {August 22-24},
  abstract = {This paper presents a technique that uses code to automatically generate
	its own test cases at run-time by using a combination of symbolic
	and concrete (i.e., regular) execution. The input values to a program
	(or software component) provide the standard interface of any testing
	framework with the program it is testing, and generating input values
	that will explore all the \interesting" behavior in the tested program
	remains an important open problem in software testing research. Our
	approach works by turning the problem on its head: we lazily generate,
	from within the program itself, the input values to the program (and
	values derived from input values) as needed. We applied the technique
	to real code and found numerous corner-case errors ranging from simple
	memory over ows and in nite loops to subtle issues in the interpretation
	of language standards.},
  file = {cadar05.pdf:cadar05.pdf:PDF},
  keywords = {computer security},
  owner = {kristjan},
  review = {see also: cadar2005tr (techreport)},
  timestamp = {2008.02.27}
}

@INPROCEEDINGS{calvert2006,
  author = {Calvert, Kenneth L. and Griffioen, James},
  title = {On information hiding and network management},
  booktitle = {INM '06: Proceedings of the 2006 SIGCOMM workshop on Internet network
	management},
  year = {2006},
  pages = {35--40},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {No single administration controls the entire Internet. Instead, competing
	providers work together to enforce of a wide variety of network management
	policies, including policies that limit the flow of management information
	itself. In many cases these policies are designed to keep information
	about the state of the network from "leaking" outside the network.
	In this position paper, we consider the ramifications of such information-hiding
	policies for network management. We discuss mechanisms that might
	be used to enforce such policies, and argue for an open access policy.},
  doi = {http://doi.acm.org/10.1145/1162638.1162644},
  file = {calvert2006.pdf:calvert2006.pdf:PDF},
  isbn = {1-59593-570-3},
  location = {Pisa, Italy}
}

@ARTICLE{cam2006,
  author = {Hasan Cam and Suat Ozdemir and Prashant Nair and Devasenapathy Muthuavinashiappan
	and H. Ozgur Sanli},
  title = {Energy-efficient secure pattern based data aggregation for wireless
	sensor networks},
  journal = {Computer Communications},
  year = {2006},
  volume = {29},
  pages = {446 - 455},
  number = {4},
  note = {Current areas of interest in wireless sensor networks designs},
  abstract = {Data aggregation in wireless sensor networks eliminates redundancy
	to improve bandwidth utilization and energy-efficiency of sensor
	nodes. This paper presents a secure energy-efficient data aggregation
	protocol called ESPDA (Energy-Efficient Secure Pattern based Data
	Aggregation). Unlike conventional data aggregation techniques, ESPDA
	prevents the redundant data transmission from sensor nodes to cluster-heads.
	If sensor nodes sense the same data, ESPDA first puts all but one
	of them into sleep mode and generate pattern codes to represent the
	characteristics of data sensed by sensor nodes. Cluster-heads implement
	data aggregation based on pattern codes and only distinct data in
	encrypted form is transmitted from sensor nodes to the base station
	via cluster-heads. Due to the use of pattern codes, cluster-heads
	do not need to know the sensor data to perform data aggregation,
	which allows sensor nodes to establish secure end-to-end communication
	links with base station. Therefore, there is no need for encryption/decryption
	key distribution between the cluster-heads and sensor nodes. Moreover,
	the use of NOVSF Block-Hopping technique improves the security by
	randomly changing the mapping of data blocks to NOVSF time slots.
	Performance evaluation shows that ESPDA outperforms conventional
	data aggregation methods up to 50% in bandwidth efficiency.},
  doi = {DOI: 10.1016/j.comcom.2004.12.029},
  file = {cam2006.pdf:cam2006.pdf:PDF},
  issn = {0140-3664},
  keywords = {Sensor networks, secure aggregation},
  review = {Pretty weak.
	
	
	Uses pattern codes to aggregate -- the idea is to reduce the amount
	of data transmitted. Equal codes represent equivalent data, so redundant
	items can be eliminated. Only one node in a cluster is requested
	(by clusterhead) to transmit the actual data.
	
	
	Clustered network -- clusterheads chosen dynamically. Pattern codes
	transmitted by cluster members to the CH -- a pattern seed is broadcast
	periodically by the CH to members (encrypted). Pattern comparison
	by CH eliminates redundant readings. CH selects nodes to contribute
	(note: seems to place considerable trust in the CH), removing redundant
	patterns. The nodes in the selected set are requested to transmit
	data (end-to-end encrypted) to the base station -- the nodes not
	selected may be instructed to discard their values.
	
	
	Security protocols:
	
	Fairly basic symmetric key protocols, based on pre-assigned keys.
	Use Blowfish. Base station perioodically broadcasts an encrypted
	sensor key (using shared cluster key) which is used to derive a session
	key for each individual node. Freshness guaranteed by changing encryption
	keys in each session (what exactly is the def of a session?). Same
	key used for MAC -- generally thought to be a bad idea (?). Use CBC-MAC.
	
	
	Security holes: Hinges on the assumption that aggregators choose their
	unique set sensibly, otherwise fairly basic e2e symmetric encryption.
	Additional security by using a NOVSF block hopping technique -- strengthens
	e2e case, but still trust in CH is problematic in my mind. Perhaps
	less of a problem as CH are choosen randomly. 
	
	
	Note: claim blowfish requires less memory than AES but find performance
	to be equivalent.},
  url = {http://www.sciencedirect.com/science/article/B6TYP-4FG885S-2/2/576b379e04905197e83d3121705892a5}
}

@MISC{canetti2005,
  author = {Ran Canetti},
  title = {Universally Composable Security: A New Paradigm for Cryptographic
	Protocols},
  howpublished = {{Cryptology ePrint Archive, Report 2000/067}},
  year = {2005},
  note = {\url{http://eprint.iacr.org/}},
  file = {canetti2005.ps:canetti2005.ps:PostScript},
  keywords = {UC, universal composability, security protocol composition}
}

@ARTICLE{canetti2000,
  author = {Ran Canetti},
  title = {Security and Composition of Multiparty Cryptographic Protocols},
  journal = {Journal of Cryptology},
  year = {2000},
  volume = {13},
  pages = {143-202},
  number = {1},
  file = {canetti2000.pdf:canetti2000.pdf:PDF},
  keywords = {UC, universal composability, security protocol composition},
  owner = {kristjan},
  timestamp = {2010.03.03}
}

@MISC{canetti1998,
  author = {Ran Canetti},
  title = {Security and Composition of Multi-party Cryptographic Protocols},
  howpublished = {Cryptology ePrint Archive, Report 1998/018},
  year = {1998},
  note = {\url{http://eprint.iacr.org/}},
  file = {canetti1998.ps:canetti1998.ps:PostScript},
  keywords = {UC, universal composability, security protocol composition},
  review = {Note: older version of canetti2000}
}

@TECHREPORT{canetti1996,
  author = {Canetti, R. and Friege, U. and Goldreich, O. and Naor, M.},
  title = {Adaptively Secure Multi-party Computation},
  year = {1996},
  address = {Cambridge, MA, USA},
  abstract = {A fundamental problem in designing secure multi-party protocols is
	how to deal with adaptive adversaries (i.e., adversaries that may
	choose the corrupted parties during the course of the computation),
	in a setting where the channels are insecure and secure communication
	is achieved by cryptographic primitives based on computational limitations
	of the adversary. It turns out that the power of an adaptive adversary
	is greatly affected by the amount of information gathered upon the
	corruption of the party. This amount of information models the extent
	to which uncorrupted parties are trusted to carry out instructions
	that cannot be externally verified, such as erasing records of past
	configurations. It has been shown that if the parties are trusted
	to erase such records, then adaptivity secure computation can be
	carried out using known primitives. However, this total trust in
	parties may be unrealistic in many scenarios. An important question,
	open since 1986, is whether adaptively secure multi-party computation
	can be carried out in the "insecure channel" setting, even if no
	party is thoroughly trusted. Our main result is an affirmative resolution
	of this question for the case where even uncorrupted parties may
	deviate from the protocol by keeping record of all past configurations.
	We first propose a novel property of encryption protocols and show
	that if an encryption protocol enjoying this property is used, instead
	of a standard encryption scheme, then known constructions become
	adaptively secure. Next we constructed, based on standard RSA assumption,
	an encryption protocol that enjoys this property. We also consider
	parties that, even when corrupted, may internally deviate from their
	protocols in arbitrary ways, as long as no external test can detect
	faulty behavior. We show that in this case no non-trivial protocol
	can be proven adaptively secure using black-box simulation. This
	holds even if the communication channels are totally secure.},
  file = {canetti1996.pdf:canetti1996.pdf:PDF},
  keywords = {UC, universal composability, security protocol composition},
  publisher = {Massachusetts Institute of Technology},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Amitai%3AMIT-LCS%2F%2FMIT%2FLCS%2FTR-682}
}

@INPROCEEDINGS{canetti1993,
  author = {Canetti, Ran and Rabin, Tal},
  title = {Fast asynchronous Byzantine agreement with optimal resilience},
  booktitle = {{STOC '93: Proceedings of the twenty-fifth annual ACM symposium on
	Theory of computing}},
  year = {1993},
  pages = {42--51},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The Byzantine Agreement problem is one of the most fundamental problems
	in the field of distributed computing. However, despite extensive
	research, a few important questions have remained open.
	
	
	The resilience of a protocol is the maximum number of faults in the
	presence of which the protocol meets its specification. It is known
	that no BA protocol for n players (either synchronous or asynchronous)
	can be [~1-resilient. The only known asynchronous ([~1 - l)-resilient
	BA protocol runs in expected exponential time! A long standing open
	question is whether there exists a fast asynchronous ([:1 – 1)-resilient
	BA protocol.
	
	
	We answer this question in the affirmative. We consider a completely
	asynchronous network of n players, in which every two players are
	connected via a private channel. Furthermore, we let the faulty players
	have unlimited computational power. In this setting, we describe
	an ( [~1 - I)-resilient Byzantine Agreement protocol. With overwhelming
	probability all the non-faulty players complete the execution of
	the protocol. Conditioned on the event that all the non-faulty players
	have completed the execution of the protocol, they do so in constant
	expected time.
	
	
	Our construction employs an ([:1 – I)-resilient Asynchronous Verifiable
	Secret Sharing (AVSS) scheme. No ([:1 – I)-resilient AVSS scheme
	was previously known. Our AVSS scheme employs new asynchronous tools
	which are of independent interest.},
  doi = {http://doi.acm.org/10.1145/167088.167105},
  file = {canetti1993.pdf:canetti1993.pdf:PDF},
  isbn = {0-89791-591-7},
  location = {San Diego, California, United States}
}

@ARTICLE{cao-2004,
  author = {Jin Cao and Cleveland, W.S. and Yuan Gao and Jeffay, K. and Smith,
	F.D. and Weigle, M.},
  title = {Stochastic models for generating synthetic HTTP source traffic},
  journal = {INFOCOM},
  year = {2004},
  volume = {3},
  pages = {1546-1557},
  month = {March},
  abstract = {New source-level models for aggregated HTTP trafﬁc and a design for
	their integration with the TCP transport layer are built and validated
	using two large-scale collections of TCP/IP packet header traces.
	An implementation of the models and the design in the ns network
	simulator can be used to generate web trafﬁc in network simulations.},
  doi = {10.1109/INFCOM.2004.1354568},
  file = {:cao_infocom_2004.pdf:PDF},
  issn = {0743-166X},
  keywords = {IP networks, Web sites, hypermedia, telecommunication traffic, transport
	protocols, IP packet header, TCP transport layer, ns network simulator,
	source-level models, stochastic models, synthetic HTTP source traffic,
	web traffic},
  review = {See also: PackMime-HTTP traffic generator for ns-2}
}

@ARTICLE{cardenas2009,
  author = {Alvaro Cardenas and Tanya Roosta and S. Shankar Sastry},
  title = {Rethinking Security Properties, Threat Models and the Design Space
	in Sensor Networks: A case study in {SCADA} systems},
  journal = {Ad Hoc Networks},
  year = {2009},
  month = {May},
  abstract = {In recent years we have witnessed the emergence and establishment
	of research in sensor network security. The majority of the literature
	has focused on discovering numerous vulnerabilities and attacks against
	sensor networks, along with suggestions for corresponding countermeasures.
	However, there has been little guidance for understanding the holistic
	nature of sensor network security for practical deployments. In this
	paper, we discuss these concerns and propose a taxonomy composed
	of the security properties of the sensor network, the threat model,
	and the security design space. In particular, we try to understand
	the application-layer goals of a sensor network, and provide a guide
	to research challenges that need to be addressed in order to prioritize
	our defenses against threats to application-layer goals.},
  file = {cardenas2009.pdf:cardenas2009.pdf:PDF},
  keywords = {security, SCADA, sensor networks},
  url = {http://chess.eecs.berkeley.edu/pubs/598.html}
}

@INPROCEEDINGS{carmi2007,
  author = {Shai Carmi and Shlomo Havlin and Scott Kirkpatrick and Yuval Shavitt
	and Eran Shir},
  title = {A model of Internet topology using k-shell decomposition},
  booktitle = {{PNAS}},
  year = {2007},
  volume = {104},
  number = {27},
  month = {July},
  abstract = {We study a map of the Internet (at the autonomous systems level),
	by introducing and using the method of k-shell decomposition and
	the methods of percolation theory and fractal geometry, to ﬁnd a
	model for the structure of the Internet. In particular, our analysis
	uses information on the connectivity of the network shells to separate,
	in a unique (no parameters) way, the Internet into three subcomponents:
	(i) a nucleus that is a small ( 100 nodes), very well connected globally
	distributed subgraph; (ii) a fractal subcomponent that is able to
	connect the bulk of the Internet without congesting the nucleus,
	with self-similar properties and critical exponents predicted from
	percolation theory; and (iii) dendrite-like structures, usually isolated
	nodes that are connected to the rest of the network through the nucleus
	only. We show that our method of decomposition is robust and provides
	insight into the underlying structure of the Internet and its functional
	consequences. Our approach of decomposing the network is general
	and also useful when studying other complex networks.},
  file = {PNAS07.pdf:PNAS07.pdf:PDF},
  keywords = {networks, Internet, network measurements and analysis},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@MISC{carrilho-netconf,
  author = {Ntanzi Carrilho and Neco Ventura},
  title = {Distributed Policy-based Network Management with {NETCONF}},
  abstract = {The limitations of the Simple Network Management Protocol are driving
	research for emerging network management technologies which can cope
	with today’s fast growing networks. Considering that XML is a simple
	yet powerful technology for information representation and systems
	integration, and that Policy-based Management is a mechanism which
	allows for the composition of a management system from building blocks
	that can be introduced, modified and withdrawn at any time, without
	interfering with device operation, we present an architecture that
	integrates the XML-based Network Configuration protocol with Policy-based
	Management principles. This results in a distributed system capable
	of autonomous operation guided by management policies.},
  file = {:No 292 - Carrilho.pdf:PDF},
  keywords = {Netconf, Distributed Management, XML-based Management, Policy-based
	Management},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{carrow2007,
  author = {Erwin Louis Carrow},
  title = {{InfoSec} technology management of user space and services through
	security threat gateways},
  booktitle = {InfoSecCD '07: Proceedings of the 4th annual conference on Information
	security curriculum development},
  year = {2007},
  pages = {1--6},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The focus of this paper will demonstrate the need to clearly define
	and segregate various user space environments in the enterprise network
	infrastructure with controls ranging from administrative to technical
	and still provide the various services needed to facilitate the work
	space environment and administrative requirements of an enterprise
	system. Standards assumed are industry practices and associated regulatory
	requirements with implementations as they apply to the various contextual
	applications. This is a high level approach to understanding the
	significance and application of an effective secure network infrastructure.
	The focus is on end user needs and the associated services to support
	those needs. Conceptually user space is a virtual area allocated
	to the end user needs identified with specific services to support
	those needs by creating a virtual playground. To manage risk, the
	concept of creating a "security threat gateway (STG)" isolates and
	secures each user space with its associated services. Emphasis will
	be placed on the functional managerial process and application of
	the STG, safeguarding one user space from another, to facilitate
	the use of the needed services to perform the operational tasks of
	the organization. When user's needs and associated components are
	clearly identified, then it is possible for anyone to use this model
	as a template, to guide them in creating an effective strategy for
	their own network security. This approach is practical in orientation
	and application, focusing on a high level perspective and assumes
	the reader already has a low level technical background for a tactical
	implementation in mitigating risk to the enterprise network infrastructure.},
  doi = {http://doi.acm.org/10.1145/1409908.1409932},
  file = {carrow2007.pdf:carrow2007.pdf:PDF},
  isbn = {978-1-59593-909-8},
  keywords = {networks, network security},
  location = {Kennesaw, Georgia}
}

@INPROCEEDINGS{carrow2007a,
  author = {Erwin Louis Carrow},
  title = {Puppetnets and botnets: information technology vulnerability exploits
	that threaten basic internet use},
  booktitle = {{InfoSecCD} '07: Proceedings of the 4th annual conference on Information
	security curriculum development},
  year = {2007},
  pages = {1--7},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The focus of this paper is to identify dominant trends of information
	security threats to the Internet 2001 to 2007. This paper is intended
	to provide an understanding of the new emphasis of attacks through
	use of robotic networks and how some users and organizations are
	already preparing a response using innovative visualization techniques
	in conjunction with traditional methods. The scope of research will
	focus on basic enterprise level services that are commonly provided
	by various corporations; e.g., e-mail, browser applications, wireless
	and mobile devices, IP telephony, and online banking. The research
	will first review the network infrastructure common to most corporate
	organizations and assume basic enterprise components and functionality
	in response to the current security threats. The second emphasis
	will consider the impact of malware robotic networks (Botnets and
	Puppetnets) on the corporate network infrastructure and how to address
	these threats with new and innovative techniques. This approach is
	pragmatic in application and focuses on assimilation of existing
	data to present a functional rationale of attacks to anticipate and
	prepare for this coming year.},
  doi = {http://doi.acm.org/10.1145/1409908.1409923},
  file = {carrow2007a.pdf:carrow2007a.pdf:PDF},
  isbn = {978-1-59593-909-8},
  keywords = {networks, network security, botnets, puppetnets},
  location = {Kennesaw, Georgia}
}

@INPROCEEDINGS{carzaniga2000,
  author = {Antonio Carzaniga and David S. Rosenblum and Alexander L. Wolf},
  title = {Achieving scalability and expressiveness in an Internet-scale event
	notification service},
  booktitle = {{PODC} '00: Proceedings of the nineteenth annual {ACM} symposium
	on Principles of distributed computing},
  year = {2000},
  pages = {219--227},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper describes the design of SIENA, an Internet-scale event
	notification middleware service for distributed event-based applications
	deployed over wide-area networks. SIENA is responsible for selecting
	the notifications that are of interest to clients (as expressed in
	client subscriptions) and then delivering those notifications to
	the clients via access points. The key design challenge for SIENA
	is maximizing expressiveness in the selection mechanism without sacrificing
	scalability of the delivery mechanism. This paper focuses on those
	aspects of the design of SIENA that fundamentally impact scalability
	and expressiveness. In particular, we describe SIENA's data model
	for notifications, the covering relations that formally define the
	semantics of the data model, the distributed architectures we have
	studied for SIENA's implementation, and the processing strategies
	we developed to exploit the covering relations for optimizing the
	routing of notifications.},
  doi = {http://doi.acm.org/10.1145/343477.343622},
  file = {carzaniga2000.pdf:carzaniga2000.pdf:PDF},
  isbn = {1-58113-183-6},
  location = {Portland, Oregon, United States},
  review = {An event notification service is described, mainly its data model
	and architecture. Publish/subscribe architecture. Limited usefulness.
	Perhaps a bit on internet scalability??}
}

@MISC{rfc_1157_snmp_1990,
  author = {J. Case and M. Fedor and M. Schoffstall and J. Davin},
  title = {{RFC 1157: Simple Network Management Protocol (SNMP)}},
  month = {May},
  year = {1990},
  keywords = {networks, RFC, SNMP},
  owner = {kristjan},
  timestamp = {2009.03.03},
  url = {http://www.faqs.org/rfcs/rfc1157.html}
}

@ARTICLE{castelluccia2004,
  author = {Castelluccia, Claude},
  title = {Cryptographically Generated Addresses for Constrained Devices},
  journal = {Wirel. Pers. Commun.},
  year = {2004},
  volume = {29},
  pages = {221--232},
  number = {3-4},
  abstract = {Cryptographically Generated Addresses (CGAs) have been designed to
	solve the so-called IPv6 Address Ownership problem. The current IETF
	CGA proposal relies on RSA signature. Generating an RSA signature
	is quite expensive and might be prohibitive for small devices with
	limited capacities. For example, a 1024-RSA signature requires approximately
	1536 modular multiplications.
	
	
	In this paper, we propose a new CGA scheme whose verification requires
	fewer than 10 modular multiplications. We achieve this performance
	gain by (1) selecting an efficient signature scheme, namely the small
	prime variation of the Feige-Fiat-Shamir scheme and (2) tuning the
	cryptographic parameters of this signature scheme to the security
	strength of the CGA (i.e. the size of the hash function used to generate
	it).},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1023/B:WIRE.0000047065.81535.84},
  file = {castelluccia2004.pdf:castelluccia2004.pdf:PDF},
  issn = {0929-6212},
  keywords = {cryptographically generated identifiers, signature schemes},
  publisher = {Kluwer Academic Publishers},
  review = {Small cryptographically verifiable identifiers for constrained devices}
}

@ARTICLE{castelluccia2009,
  author = {Castelluccia, Claude and Chan, Aldar C-F. and Mykletun, Einar and
	Tsudik, Gene},
  title = {Efficient and provably secure aggregation of encrypted data in wireless
	sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2009},
  volume = {5},
  pages = {1--36},
  number = {3},
  abstract = {Wireless sensor networks (WSNs) are composed of tiny devices with
	limited computation and battery capacities. For such resource-constrained
	devices, data transmission is a very energy-consuming operation.
	To maximize WSN lifetime, it is essential to minimize the number
	of bits sent and received by each device. One natural approach is
	to aggregate sensor data along the path from sensors to the sink.
	Aggregation is especially challenging if end-to-end privacy between
	sensors and the sink (or aggregate integrity) is required. In this
	article, we propose a simple and provably secure encryption scheme
	that allows efficient additive aggregation of encrypted data. Only
	one modular addition is necessary for ciphertext aggregation. The
	security of the scheme is based on the indistinguishability property
	of a pseudorandom function (PRF), a standard cryptographic primitive.
	We show that aggregation based on this scheme can be used to efficiently
	compute statistical values, such as mean, variance, and standard
	deviation of sensed data, while achieving significant bandwidth savings.
	To protect the integrity of the aggregated data, we construct an
	end-to-end aggregate authentication scheme that is secure against
	outsider-only attacks, also based on the indistinguishability property
	of PRFs.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1525856.1525858},
  file = {castelluccia2009.pdf:castelluccia2009.pdf:PDF},
  issn = {1550-4859},
  owner = {kristjan},
  publisher = {ACM},
  review = {See also castelluccia2005 -- earlier version?
	
	
	See discussion in ozdemir2009. Simple and provably secure homomorphic
	stream cipher using symmetric stream cipher. Problem claimed by ozdemir2009
	that the approach requires a list of contributors. Solution (claimed)
	in a paper by ozdemir from 2008 that apparently only exists in Turkish.
	NOTE: This refers to the earlier conference version.}
}

@INPROCEEDINGS{castelluccia2005,
  author = {Castelluccia, C. and Mykletun, E. and Tsudik, G.},
  title = {Efficient aggregation of encrypted data in wireless sensor networks},
  booktitle = {Mobile and Ubiquitous Systems: Networking and Services, 2005. {MobiQuitous
	2005}. The Second Annual International Conference on},
  year = {2005},
  pages = { 109-117},
  month = {July},
  abstract = {Wireless sensor networks (WSNs) are ad-hoc networks composed of tiny
	devices with limited computation and energy capacities. For such
	devices, data transmission is a very energy-consuming operation.
	It thus becomes essential to the lifetime of a WSN to minimize the
	number of bits sent by each device. One well-known approach is to
	aggregate sensor data (e.g., by adding) along the path from sensors
	to the sink. Aggregation becomes especially challenging if end-to-end
	privacy between sensors and the sink is required. In this paper,
	we propose a simple and provably secure additively homomorphic stream
	cipher that allows efficient aggregation of encrypted data. The new
	cipher only uses modular additions (with very small moduli) and is
	therefore very well suited for CPU-constrained devices. We show that
	aggregation based on this cipher can be used to efficiently compute
	statistical values such as mean, variance and standard deviation
	of sensed data, while achieving significant bandwidth gain.},
  doi = {10.1109/MOBIQUITOUS.2005.25},
  file = {castelluccia2005.pdf:castelluccia2005.pdf:PDF},
  keywords = { ad hoc networks, data privacy, private key cryptography, statistical
	analysis, telecommunication security, wireless sensor networks WSN,
	ad-hoc network, data encryption, data security, data transmission,
	end-to-end privacy, homomorphic stream cipher, minimization, sensor
	data aggregation, statistical value computation, wireless sensor
	network},
  review = {see also castelluccia2009 - a magazine version of this paper?
	
	
	Symmetric homomorphic stream cipher.
	
	
	See discussion in ozdemir2009. Simple and provably secure homomorphic
	stream cipher using symmetric stream cipher. Problem claimed by ozdemir2009
	that the approach requires a list of contributors. Solution (claimed)
	in a paper by ozdemir from 2008 that apparently only exists in Turkish.}
}

@PHDTHESIS{Castro1999,
  author = {Miguel Castro},
  title = {Practical byzantine fault tolerance},
  school = {Massachusetts Institute of Technology},
  year = {1999},
  month = {January},
  abstract = {Our growing reliance on online services accessible on the Internet
	demands highly-available systems that provide correct service without
	interruptions. Byzantine faults such as software bugs, operator mistakes,
	and malicious attacks are the major cause of service interruptions.
	This thesis describes a new replication algorithm, BFT, that can
	be used to build highly-available systems that tolerate Byzantine
	faults. It shows, for the ﬁrst time, how to build Byzantine-fault-tolerant
	systems that can be used in practice to implement real services because
	they do not rely on unrealistic assumptions and they perform well.
	BFT works in asynchronous environments like the Internet, it incorporates
	mechanisms to defend against Byzantine-faulty clients, and it recovers
	replicas proactively. The recovery mechanism allows the algorithm
	to tolerate any number of faults over the lifetime of the system
	provided fewer than 1=3 of the replicas become faulty within a small
	window of vulnerability. The window may increase under a denial-of-service
	attack but the algorithm can detect and respond to such attacks and
	it can also detect when the state of a replica is corrupted by an
	attacker.
	
	 BFT has been implemented as a generic program library with a simple
	interface. The BFT library provides a complete solution to the problem
	of building real services that tolerate Byzantine faults. We used
	the library to implement the ﬁrst Byzantine-fault-tolerant NFS ﬁle
	system, BFS. The BFT library and BFS perform well because the library
	incorporates several important optimizations. The most important
	optimization is the use of symmetric cryptography to authenticate
	messages. Public-key cryptography, which was the major bottleneck
	in previous systems, is used only to exchange the symmetric keys.
	The performance results show that BFS performs 2% faster to 24% slower
	than production implementations of the NFS protocol that are not
	replicated. Therefore, we believe that the BFT library can be used
	to build practical systems that tolerate Byzantine faults.},
  file = {10.1.1.17.7523.pdf:10.1.1.17.7523.pdf:PDF},
  keywords = {fault tolerance, byzantine}
}

@ARTICLE{castro2002,
  author = {Miguel Castro and Peter Druschel and Ayalvadi Ganesh and Antony Rowstron
	and Dan S. Wallach},
  title = {Secure routing for structured peer-to-peer overlay networks},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {2002},
  volume = {36},
  pages = {299--314},
  number = {SI},
  abstract = {Structured peer-to-peer overlay networks provide a substrate for the
	construction of large-scale, decentralized applications, including
	distributed storage, group communication, and content distribution.
	These overlays are highly resilient; they can route messages correctly
	even when a large fraction of the nodes crash or the network partitions.
	But current overlays are not secure; even a small fraction of malicious
	nodes can prevent correct message delivery throughout the overlay.
	This problem is particularly serious in open peer-to-peer systems,
	where many diverse, autonomous parties without preexisting trust
	relationships wish to pool their resources. This paper studies attacks
	aimed at preventing correct message delivery in structured peer-to-peer
	overlays and presents defenses to these attacks. We describe and
	evaluate techniques that allow nodes to join the overlay, to maintain
	routing state, and to forward messages securely in the presence of
	malicious nodes.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/844128.844156},
  file = {castro2002.pdf:castro2002.pdf:PDF},
  issn = {0163-5980},
  keywords = {networks, peer-to-peer systems, security, DHT, distributed hash tables},
  publisher = {ACM}
}

@ARTICLE{castro2002a,
  author = {Castro, Miguel and Liskov, Barbara},
  title = {Practical byzantine fault tolerance and proactive recovery},
  journal = {{ACM Trans. Comput. Syst.}},
  year = {2002},
  volume = {20},
  pages = {398--461},
  number = {4},
  abstract = {Our growing reliance on online services accessible on the Internet
	demands highly available systems that provide correct service without
	interruptions. Software bugs, operator mistakes, and malicious attacks
	are a major cause of service interruptions and they can cause arbitrary
	behavior, that is, Byzantine faults. This article describes a new
	replication algorithm, BFT, that can be used to build highly available
	systems that tolerate Byzantine faults. BFT can be used in practice
	to implement real services: it performs well, it is safe in asynchronous
	environments such as the Internet, it incorporates mechanisms to
	defend against Byzantine-faulty clients, and it recovers replicas
	proactively. The recovery mechanism allows the algorithm to tolerate
	any number of faults over the lifetime of the system provided fewer
	than 1/3 of the replicas become faulty within a small window of vulnerability.
	BFT has been implemented as a generic program library with a simple
	interface. We used the library to implement the first Byzantine-fault-tolerant
	NFS file system, BFS. The BFT library and BFS perform well because
	the library incorporates several important optimizations, the most
	important of which is the use of symmetric cryptography to authenticate
	messages. The performance results show that BFS performs 2&percnt;
	faster to 24&percnt; slower than production implementations of the
	NFS protocol that are not replicated. This supports our claim that
	the BFT library can be used to build practical systems that tolerate
	Byzantine faults.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/571637.571640},
  file = {castro2002a.pdf:castro2002a.pdf:PDF},
  issn = {0734-2071},
  keywords = {distributed systems, byzantine fault tolerance},
  publisher = {ACM}
}

@INPROCEEDINGS{castro1999a,
  author = {Miguel Castro and Barbara Liskov},
  title = {Practical Byzantine Fault Tolerance},
  booktitle = {{OSDI}: Third Symposium on Operating Systems Design and Implementation},
  year = {1999},
  address = {New Orleans, USA},
  month = {February},
  abstract = {This paper describes a new replication algorithm that is able to tolerate
	Byzantine faults. We believe that Byzantine fault-tolerant algorithms
	will be increasingly important in the future because malicious attacks
	and software errors are increasingly common and can cause faulty
	nodes to exhibit arbitrary behavior. Whereas previous algorithms
	assumed a synchronous system or were too slow to be used in practice,
	the algorithm described in this paper is practical: it works in asynchronous
	environments like the Internet and incorporates several important
	optimizations that improve the response time of previous algorithms
	by more than an order of magnitude. We implemented a Byzantine-fault-tolerant
	NFS service using our algorithm and measured its performance. The
	results show that our service is only 3% slower than a standard unreplicated
	NFS.},
  file = {castro1999.pdf:castro1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.01}
}

@INPROCEEDINGS{catrina2008,
  author = {Catrina, O. and Kerschbaum, F.},
  title = {Fostering the Uptake of Secure Multiparty Computation in E-Commerce},
  booktitle = {Availability, Reliability and Security, 2008. ARES 08. Third International
	Conference on},
  year = {2008},
  pages = {693-700},
  month = {March},
  abstract = {Secure multiparty computation (SMC) protocols enable a group of mutually
	distrustful parties to perform a joint computation with private inputs.
	Novel e-commerce applications have emerged that could benefit from
	strong privacy protection, e.g., benchmarking, auctions, and collaborative
	supply chain management and planning. However, the uptake of SMC
	in these applications is still rare. We argue that this is due to
	poor performance, functionality, and scalability, as well as architectures
	that do not meet the needs of e-commerce applications. This paper
	explores SMC approaches and research directions, aiming at providing
	better support for e-commerce applications.},
  doi = {10.1109/ARES.2008.49},
  file = {catrina2008.pdf:catrina2008.pdf:PDF},
  keywords = {data privacy, electronic commerce, protocols, security of datae-commerce,
	privacy protection, secure multiparty computation protocols}
}

@ONLINE{cert-ca-2000-02,
  author = {CERT},
  title = {Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests},
  url = {http://www.cert.org/advisories/CA-2000-02.html},
  year = {2000},
  keywords = {networks, web security, exploits},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{chan2008a,
  author = {Chan, A.C.-F. and Castelluccia, C.},
  title = {On the (Im)possibility of aggregate message authentication codes},
  booktitle = {{ISIT} 2008. {IEEE} International Symposium on Information Theory},
  year = {2008},
  pages = {235-239},
  month = {July},
  __markedentry = {[kristjan]},
  abstract = {In data aggregation, multiple source nodes send their data to a sink
	along a concast tree with aggregation done en route so that the sink
	can obtain the aggregate (which could be the sum, average, etc.)
	of all these data. End-to-end privacy and aggregate integrity are
	the two main goals of secure data aggregation. While the privacy
	goal has been widely studied, providing end-to-end aggregate integrity
	in the presence of possibly compromised aggregating nodes remains
	largely an open problem. Message Authentication Codes (MAC) are commonly
	used to provide end-to-end data integrity in two party settings.
	Natural extensions of MAC for the data aggregation scenario are considered.
	It is shown that a straightforward and intuitive reﬁnement of the
	MAC security model (for the data aggregation setting) is not achievable.
	A weaker security notion is proposed; whether this notion is achievable
	remains unclear.},
  doi = {10.1109/ISIT.2008.4594983},
  file = {chan2008a.pdf:chan2008a.pdf:PDF},
  keywords = {message authentication, source coding, telecommunication security,
	tree codes, trees (mathematics)MAC security model, aggregate message
	authentication codes, concast tree, end-to-end data integrity, end-to-end
	privacy, multiple source nodes, distributed aggregation security,
	signature aggregation}
}

@ARTICLE{chan1998,
  author = {Chan, Danny L. S. and Chanson, Samuel T.},
  title = {Scalability support for multiparty multimedia communications},
  journal = {Multimedia Syst.},
  year = {1998},
  volume = {6},
  pages = {75--87},
  number = {2},
  address = {Secaucus, NJ, USA},
  doi = {http://dx.doi.org/10.1007/s005300050077},
  issn = {0942-4962},
  publisher = {Springer-Verlag New York, Inc.}
}

@PHDTHESIS{chan2009,
  author = {Haowen Chan},
  title = {Authenticated Communication and Computation in Known-Topology Networks
	with a Trusted Authority},
  school = {School of Computer Science, Computer Science Department, Carnegie
	Mellon University},
  year = {2009},
  address = {Pittsburgh, PA 15213, USA},
  month = {September},
  abstract = {We show that two distinguishing properties of sensor networks, i.e.,
	the presence of a trusted base station, and the pre-knowledge of
	the ﬁxed network topology, can yield security protocols that are
	both communication-eﬃcient and highly general. We show new protocols
	for broadcast authentication, credential dissemination and node-to-node
	signatures. For securing in-network distributed computations, we
	show an algorithm for securely computing the sum of sensor readings
	in the network, which we can generalize to tree computations for
	any combination of continuous real-valued functions. Each of these
	primitives involves per-node communication costs that scale logarithmically
	with the number of nodes in the network, do not require public key
	cryptography, and are secure against arbitrary coalitions of malicious
	nodes. The broadcast authentication scheme achieves better properties
	with fewer assumptions than existing work, and the other new protocols
	have no known previous approach that do not require either expensive
	network-wide unicast or public key cryptography.},
  file = {chan2009.pdf:chan2009.pdf:PDF},
  owner = {kristjan},
  review = {\cite{chan2009} is a phd thesis presenting the HT-protocol -- the
	building block of the CPS paper. Also presents further security primitives
	based on the HT protocol -- broadcast authentication, credential
	dissemination and node-to-node signatures.. Considers static networks
	with a known node population and a trusted authority. Earlier work
	is \cite{chan2006} w. regards to the HT protocol.},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{chan2008,
  author = {Chan, Haowen and Perrig, Adrian},
  title = {Efficient security primitives derived from a secure aggregation algorithm},
  booktitle = {{CCS '08}: Proceedings of the 15th {ACM} conference on Computer and
	communications security},
  year = {2008},
  pages = {521--534},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {By functionally decomposing a specific algorithm (the hierarchical
	secure aggregation algorithm of Chan et al. [3] and Frikken et al.
	[7]), we uncover a useful general functionality which we use to generate
	various efficient network security primitives, including: a signature
	scheme ensuring authenticity, integrity and non-repudiation for arbitrary
	node-to-node communications; an efficient broadcast authentication
	algorithm not requiring time synchronization; a scheme for managing
	public keys in a sensor network without requiring any asymmetric
	cryptographic operations to verify the validity of public keys, and
	without requiring nodes to maintain node revocation lists. Each of
	these applications uses the same basic data aggregation primitive
	and thus have O(log n) congestion performance and require only that
	symmetric secret keys are shared between each node and the base station.
	We thus observe the fact that the optimizations developed in the
	application area of secure aggregation can feed back into creating
	more optimized versions of highly general, basic security functions.},
  doi = {http://doi.acm.org/10.1145/1455770.1455836},
  file = {chan2008.pdf:chan2008.pdf:PDF},
  isbn = {978-1-59593-810-7},
  keywords = {Sensor networks, secure aggregation, security primitives},
  location = {Alexandria, Virginia, USA},
  owner = {kristjan},
  review = {references chan2006 and frikken2008. Security primitives described
	are based on elements of those protocols.}
}

@ARTICLE{chan2007,
  author = {Haowen Chan and Adrian Perrig and Bartosz Przydatek and Dawn Song},
  title = {{SIA}: Secure Information Aggregation in Sensor Networks},
  journal = {{Journal of Computer Security}},
  year = {2007},
  volume = {15},
  pages = {69-102},
  number = {1},
  abstract = {In sensor networks, data aggregation is a vital primitive enabling
	efﬁcient data queries. An on-site aggregatordevice collects data
	from sensor nodes and produces a condensed summary which is forwarded
	to the off-site querier, thus reducing the communication cost of
	the query. Since the aggregator is on-site, it is vulnerable to physical
	compromise attacks. A compromised aggregator may report false aggregation
	results. Hence, it is essential that techniques are available to
	allow the querier to verify the integrity of the result returned
	by the aggregator node.
	
	
	 We propose a novel framework for secure information aggregation in
	sensor networks. By constructing efﬁcient random sampling mechanisms
	and interactive proofs, we enable the querier to verify that the
	answer given by the aggregator is a good approximation of the true
	value, even when the aggregator and a fraction of the sensor nodes
	are corrupted. In particular, we present efﬁcient protocols for secure
	computation of the median and average of the measurements, for the
	estimation of the network size, for ﬁnding the minimum and maximum
	sensor reading, and for random sampling and leader election. Our
	protocols require only sublinear communication between the aggregator
	and the user.},
  file = {chan2007.pdf:chan2007.pdf:PDF},
  keywords = {sensor networks, information aggregation, security, approximate interactive
	proofs.},
  owner = {kristjan},
  review = {See older conference publication przydatek2003. Still single aggregator
	model with interactive proofs.},
  timestamp = {2009.12.16}
}

@INPROCEEDINGS{chan2006,
  author = {Haowen Chan and Adrian Perrig and Dawn Song},
  title = {Secure hierarchical in-network aggregation in sensor networks},
  booktitle = {{CCS} '06: Proceedings of the 13th {ACM} conference on Computer and
	communications security},
  year = {2006},
  pages = {278--287},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In-network aggregation is an essential primitive for performing queries
	on sensor network data. However, most aggregation algorithms assume
	that all intermediate nodes are trusted. In contrast, the standard
	threat model in sensor network security assumes that an attacker
	may control a fraction of the nodes, which may misbehave in an arbitrary
	(Byzantine) manner. We present the ﬁrst algorithm for provably secure
	hierarchical in-network data aggregation. Our algorithm is guaranteed
	to detect any manipulation of the aggregate by the adversary beyond
	what is achievable through direct injection of data values at compromised
	nodes. In other words, the adversary can never gain any advantage
	from misrepresenting intermediate aggregation computations. Our algorithm
	incurs only O(Δ log2 n) node congestion, supports arbitrary tree-based
	aggregator topologies and retains its resistance against aggregation
	manipulation in the presence of arbitrary numbers of malicious nodes.
	The main algorithm is based on performing the SUM aggregation securely
	by ﬁrst forcing the adversary to commit to its choice of intermediate
	aggregation results, and then having the sensor nodes independently
	verify that their contributions to the aggregate are correctly incorporated.
	We show how to reduce secure MEDIAN, COUNT, and AVERAGE to this primitive.},
  doi = {http://doi.acm.org/10.1145/1180405.1180440},
  file = {:p278-chan.pdf:PDF},
  isbn = {1-59593-518-5},
  keywords = {networks, peer-to-peer systems, distributed aggregation, security},
  location = {Alexandria, Virginia, USA},
  review = {See brief summary in proposal document on this paper.}
}

@INPROCEEDINGS{chan2003,
  author = {Haowen Chan and Adrian Perrig and Dawn Song},
  title = {Random Key Predistribution Schemes for Sensor Networks},
  booktitle = {{IEEE} Symposium on Security and Privacy},
  year = {2003},
  abstract = {Key establishment in sensor networks is a challenging problem because
	asymmetric key cryptosystems are unsuitable for use in resource constrained
	sensor nodes, and also because the nodes could be physically compromised
	by an adversary. We present three new mechanisms for key establishment
	using the framework of pre-distributing a random set of keys to each
	node. First, in the q-composite keys scheme, we trade off the unlikeliness
	of a large-scale network attack in order to signiﬁcantly strengthen
	random key predistribution’s strength against smaller-scale attacks.
	Second, in the multipath-reinforcement scheme, we show how to strengthen
	the security between any two nodes by leveraging the security of
	other links. Finally, we present the random-pairwise keys scheme,
	which perfectly preserves the secrecy of the rest of the network
	when any node is captured, and also enables node-to-node authentication
	and quorum-based revocation.},
  file = {chan2003.pdf:chan2003.pdf:PDF},
  keywords = {cryptography, key distribution, sensor networks},
  owner = {kristjan},
  review = {Referenced by traynor -- key establishment via encrypted broadcast.},
  timestamp = {2010.01.20}
}

@ARTICLE{chander2004,
  author = {Ajay Chander and Drew Dean and John Mitchell},
  title = {A Distributed High Assurance Reference Monitor},
  journal = {Lecture Notes in Computer Science},
  year = {2004},
  volume = {3225/2004},
  pages = {231-244},
  month = {September},
  abstract = {We present DHARMA, a distributed high assurance reference monitor
	that is generated mechanically by the formal methods tool PVS from
	a veriﬁed speciﬁcation of its key algorithms. DHARMA supports policies
	that allow delegation of access rights, as well as structured, distributed
	names. To test DHARMA, we use it as the core reference monitor behind
	a web server that serves ﬁles over SSL connections. Our measurements
	show that formally veriﬁed high assurance access control systems
	are practical.},
  file = {isc04.pdf:isc04.pdf:PDF},
  keywords = {reference monitor, formal methods},
  owner = {kristjan},
  timestamp = {2008.03.10}
}

@ARTICLE{chander2004a,
  author = {Ajay Chander and Drew Dean and John C. Mitchell},
  title = {Reconstructing Trust Management},
  journal = {Journal of Computer Security},
  year = {2004},
  volume = {12},
  pages = {131-164},
  number = {1},
  abstract = {We present a trust management kernel that clearly separates authorization
	and structured distributed naming. Given an access request and supporting
	credentials, the kernel determines whether the request is authorized.
	
	We prove soundness and completeness of the authorization system without
	names and prove that naming is orthogonal to authorization in a precisesense.
	The orthogonality theorem gives us simple soundness and completeness
	proofs for the entire kernel. The kernel is formally veriﬁed in PVS,
	allowing for the automatic generation of a veriﬁed implementation
	of a reference monitor. By separating naming and authorization primitives,
	we arrive at a compositional model and avoid concepts such as “speaks-for”
	that have led to anomalies in logical characterizations of other
	trust management systems.},
  file = {chander2004a.pdf:chander2004a.pdf:PDF},
  keywords = {security, trust management, reference monitor},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@TECHREPORT{chandola2009,
  author = {Varun Chandola and Arindam Banerjee and Vipin Kumar},
  title = {Anomaly Detection : A Survey},
  institution = {University of Minnesota. Department of Computer Science and Engineering.},
  year = {2009},
  number = {TR 07-017},
  month = {August},
  abstract = {Anomaly detection is an important problem that has been researched
	within diverse research areas and application domains. Many anomaly
	detection techniques have been specifically developed for certain
	application domains, while others are more generic. This survey tries
	to provide a structured and comprehensive overview of the research
	on anomaly detection. We have grouped existing techniques into different
	categories based on the underlying approach adopted by each technique.
	For each category we have identified key assumptions, which are used
	by the techniques to differentiate between normal and anomalous behavior.
	When applying a given technique to a particular domain, these assumptions
	can be used as guidelines to assess the effectiveness of the technique
	in that domain. For each category, we provide a basic anomaly detection
	technique, and then show how the different existing techniques in
	that category are variants of the basic technique. This template
	provides an easier and succinct understanding of the techniques belonging
	to each category. Further, for each category, we identify the advantages
	and disadvantages of the techniques in that category. We also provide
	a discussion on the computational complexity of the techniques since
	it is an important issue in real application domains. We hope that
	this survey will provide a better understanding of the different
	directions in which research has been done on this topic, and how
	techniques developed in one area can be applied in domains for which
	they were not intended to begin with.},
  file = {chandola2009.pdf:chandola2009.pdf:PDF},
  keywords = {networks, anomaly detection, survey},
  owner = {kristjan},
  timestamp = {2009.06.18}
}

@INPROCEEDINGS{channakeshava2009,
  author = {Karthik Channakeshava and Deepti Chafekar and Keith Bisset and Anil
	Vullikanti and Madhav Marathe},
  title = {EpiNet: A Simulation Framework to Study the Spread of Malware},
  booktitle = {SIMUTOOLS'09},
  year = {2009},
  abstract = {We describe a modeling framework to study the spread of malware over
	realistic wireless networks. We develop (i) methods for generating
	synthetic, yet realistic wireless networks using activity-based models
	of urban population mobility, and (ii) an interaction-based simulation
	framework to study the dynamics of worm propagation over wireless
	networks. We use the prototype framework to study how Bluetooth worms
	spread over realistic wireless networks. This required developing
	an abstract model of the Bluetooth worm and its within-host behavior.
	
	 As an illustration of the applicability of our framework, and the
	utility of activity-based models, we compare the dynamics of Bluetooth
	worm epidemics over realistic wireless networks and networks generated
	using random waypoint mobility models. We show that realistic wireless
	networks exhibit very different structural properties. Importantly,
	these differences have signiﬁcant qualitative effect on spatial as
	well as temporal dynamics of worm propagation. Our results also demonstrate
	the importance of early detection to control the epidemic.},
  file = {channakeshava2009.pdf:channakeshava2009.pdf:PDF},
  keywords = {networks, wireless networks, simulation, security, worm propagation,
	bluetooth},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@INPROCEEDINGS{chatterjea2003,
  author = {Supriyo Chatterjea and Paul Havinga},
  title = {A Dynamic Data Aggregation Scheme for Wireless Sensor Networks},
  booktitle = {Proceedings of the Program for Research on Integrated Systems and
	Circuits},
  year = {2003},
  address = {Veldhoven, The Netherlands},
  abstract = {Wireless sensor networks are formed of tiny, energy-constrained sensor
	nodes that could be mobile and may be deployed in unfamiliar environments
	in large numbers. Considering these unique characteristics, our network
	architecture is modelled around a data-centric approach that allows
	us to make use of in-network processing and data aggregation which
	in turn helps to maximize network lifetime. This paper suggests methods
	to improve network efficiency by combining Directed Diffusion [2]
	with clustering and by introducing a more elaborate data aggregation
	scheme. Our data aggregation scheme allows nodes to process data
	collected from sensors and subsequently aggregate the data even in
	completely unfamiliar environments by including entire query definitions
	within interest messages. We also describe certain novel design features
	such as interest transformation, layered data aggregation and dynamic
	data aggregation points all of which would improve overall system
	performance.},
  file = {chatterjea2003.pdf:chatterjea2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.12}
}

@INPROCEEDINGS{chaum1988,
  author = {David Chaum and Claude Crepeau and Ivan Damgard},
  title = {Multi-party Unconditionally Secure Protocols},
  booktitle = {STOC},
  year = {1988},
  abstract = {Assume n participants P 1,P 2, . . . , Pn share the
	
	knowledge of a multivariable function F and that they
	
	want to publicly compute z =F (x 1,x 2, . . . , xn ), where xi
	
	is a secret input provided by Pi . The difﬁculty is to
	
	simultaneously provide the secrecy of each xi and to
	
	guarantee the correctness of the common result z . Such a
	
	task has been accomplished in [GMW] under the
	
	assumption that trapdoor permutations exist. The result we
	
	propose in this extended abstract is that, under the
	
	assumption that each pair of participants can communicate
	
	secretly, any reasonable function can be computed if at least
	
	2n
	
	___ of the participants are honest and this is proved without
	
	3
	
	any cryptographic assumption. Our result is based on a
	
	non-cryptographic veriﬁable secret sharing protocol that we
	
	also introduce in this paper.},
  file = {chaum1988.pdf:chaum1988.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.18}
}

@INPROCEEDINGS{chaum1991,
  author = {Chaum, David and Van Heyst, Eug\`{e}ne},
  title = {Group signatures},
  booktitle = {{EUROCRYPT}'91: Proceedings of the 10th annual international conference
	on Theory and application of cryptographic techniques},
  year = {1991},
  pages = {257--265},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {In this paper we present a new type of signature for a group of persons,
	called a group signature, which has the following properties: (i)
	only members of the group can sign messages; (ii) the receiver can
	verify that it is a valid group signature, but cannot discover which
	group member made it; (iii) if necessary, the signature can be "opened",
	so that the person who signed the message is revealed.
	
	
	The group signatures are a "generalization" of the credential/ membership
	authentication schemes, in which one person proves that he belongs
	to a certain group.
	
	
	We present four schemes that satisfy the properties above. Not all
	these schemes arc based on the same cryptographic assumption. In
	some of the schemes a trusted centre is only needed during the setup;
	and in other schemes, each pason can create the group he belongs
	to.},
  file = {chaum1991.pdf:chaum1991.pdf:PDF},
  isbn = {3-540-54620-0},
  keywords = {crypto, signature schemes, group signatures},
  location = {Brighton, UK}
}

@INPROCEEDINGS{chen2002,
  author = {Benjie Chen and Kyle Jamieson and Hari Balakrishnan and Robert Morris},
  title = {Span: An Energy-Efficient Coordination Algorithm for Topology Maintenance
	in Ad Hoc Wireless Networks},
  booktitle = {{ACM Wireless Networks Journal}},
  year = {2002},
  pages = {85--96},
  abstract = {This paper presents Span, a power saving technique for multi-hop ad
	hoc wireless networks that reduces energy consumption without significantly
	diminishing the capacity or connectivity of the network. Span builds
	on the observation that when a region of a shared-channel wireless
	network has a sufficient density of nodes, only a small number of
	them need be on at any time to forward traffic for active connections.},
  file = {chen2002.pdf:chen2002.pdf:PDF}
}

@INPROCEEDINGS{chen2005,
  author = {Chen, Jen-Yeu and Pandurangan, Gopal and Xu, Dongyan},
  title = {Robust computation of aggregates in wireless sensor networks: distributed
	randomized algorithms and analysis},
  booktitle = {{IPSN} '05: Proceedings of the 4th international symposium on Information
	processing in sensor networks},
  year = {2005},
  pages = {46},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  abstract = {A wireless sensor network consists of a large number of small, resource-constrained
	devices and usually operates in hostile environments that are prone
	to link and node failures. Computing aggregates such as average,
	minimum, maximum and sum is fundamental to various primitive functions
	of a sensor network like system monitoring, data querying, and collaborative
	information processing. In this paper we present and analyze a suite
	of randomized distributed algorithms to efficiently and robustly
	compute aggregates. Our Distributed Random Grouping (DRG) algorithm
	is simple and natural and uses probabilistic grouping to progressively
	converge to the aggregate value. DRG is local and randomized and
	is naturally robust against dynamic topology changes from link/node
	failures. Although our algorithm is natural and simple, it is nontrivial
	to show that it converges to the correct aggregate value and to bound
	the time needed for convergence. Our analysis uses the eigen-structure
	of the underlying graph in a novel way to show convergence and to
	bound the running time of our algorithms. We also present simulation
	results of our algorithm and compare its performance to various other
	known distributed algorithms. Simulations show that DRG needs much
	less transmissions than other distributed localized schemes, namely
	gossip and broadcast flooding.},
  file = {chen2005.pdf:chen2005.pdf:PDF},
  isbn = {0-7803-9202-7},
  location = {Los Angeles, California}
}

@INPROCEEDINGS{cheng2005,
  author = {Alice Cheng and Eric Friedman},
  title = {Sybilproof reputation mechanisms},
  booktitle = {{P2PECON '05: Proceedings of the 2005 ACM SIGCOMM workshop on Economics
	of peer-to-peer systems}},
  year = {2005},
  pages = {128--132},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Due to the open, anonymous nature of many P2P networks, new identities
	- or sybils - may be created cheaply and in large numbers. Given
	a reputation system, a peer may attempt to falsely raise its reputation
	by creating fake links between its sybils. Many existing reputation
	mechanisms are not resistant to these types of strategies.
	
	 Using a static graph formulation of reputation, we attempt to formalize
	the notion of sybilproofness. We show that there is no symmetric
	sybilproof reputation function. For nonsymmetric reputations, following
	the notion of reputation propagation along paths, we give a general
	asymmetric reputation function based on ﬂow and give conditions for
	sybilproofness.},
  doi = {http://doi.acm.org/10.1145/1080192.1080202},
  file = {p128-cheng.pdf:p128-cheng.pdf:PDF},
  isbn = {1-59593-026-4},
  keywords = {networks, peer-to-peer systems, security, sybil attack, reputation},
  location = {Philadelphia, Pennsylvania, USA}
}

@INPROCEEDINGS{cheng2006,
  author = {Hongju Cheng and Qin Liu and Xiaohua Jia},
  title = {Heuristic algorithms for real-time data aggregation in wireless sensor
	networks},
  booktitle = {{IWCMC} '06: Proceedings of the 2006 international conference on
	Wireless communications and mobile computing},
  year = {2006},
  pages = {1123--1128},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In sensor networks, energy efficiency is crucial to achieving satisfactory
	network life. Using the strategy of data aggregation and the technology
	of smart radio with adjustable transmission power, energy can be
	saved significantly. In this work we model the real-time requirement
	in sensor networks as two constraints with the data aggregation tree:
	node degree bounded and tree height bounded. We state with energy
	model as the FIRST ORDER RADIO MODEL [4], the maximum node degree
	of the MST for any graph in a plane is six, and it can be transformed
	into a MST with maximum node degree as five. Then, we propose three
	heuristic algorithms to build a MST with hop and degree constraints,
	namely Node-First Heuristic (NFH), Tree-First Heuristic (TFH), and
	Hop-Bounded Heuristic (HBH). Simulation results reveal that they
	are all suitable to solve the real-time data aggregation problem
	and the performance of NFH is the best.},
  doi = {http://doi.acm.org/10.1145/1143549.1143774},
  file = {cheng2006.pdf:cheng2006.pdf:PDF},
  isbn = {1-59593-306-9},
  keywords = {networks, peer-to-peer systems, distributed aggregation, power efficiency},
  location = {Vancouver, British Columbia, Canada}
}

@INPROCEEDINGS{cheng2004,
  author = {Yu-chung Cheng and Urs Hölzle and Neal Cardwell and Stefan Savage
	and Geoffrey M. Voelker},
  title = {Monkey See, Monkey Do: A Tool for TCP Tracing and Replaying},
  booktitle = {In {USENIX} Annual Technical Conference},
  year = {2004},
  pages = {87--98},
  abstract = {The performance of popular Internet Web services is governed by a
	complex combination of server behavior, network characteristics and
	client workload -- all interacting through the actions of the underlying
	transport control protocol (TCP). Consequently, even small changes
	to TCP or to the network infrastructure can have significant impact
	on end-to-end performance, yet at the same time it is challenging
	for service administrators to predict what that impact will be. In
	this paper we describe the implementation of a tool called Monkey
	that is designed to help address such questions. Monkey collects
	live TCP trace data near a server, distills key aspects of each connection
	(e.g., network delay, bottleneck bandwidth, server delays, etc.)
	and then is able to faithfully replay the client workload in a new
	setting. Using Monkey, one can easily evaluate the effects of different
	network implementations or protocol optimizations in a controlled
	fashion, without the limitations of synthetic workloads or the lack
	of reproducibility of live user traffic. Using realistic network
	traces from the Google search site, we show that Monkey is able to
	replay traces with a high degree of accuracy and can be used to predict
	the impact of changes to the TCP stack.},
  file = {cheng2004.pdf:cheng2004.pdf:PDF},
  keywords = {networks, network measurements, trace collection and replaying}
}

@ARTICLE{cheon2006,
  author = {Cheon, Jung Hee and Kim, Woo-Hwan and Nam, Hyun Soo},
  title = {Known-plaintext cryptanalysis of the Domingo-Ferrer algebraic privacy
	homomorphism scheme},
  journal = {Inf. Process. Lett.},
  year = {2006},
  volume = {97},
  pages = {118--123},
  number = {3},
  abstract = {We propose cryptanalysis of the First Domingo-Ferrer's algebraic privacy
	homomorphism ε: Zn → (Zp × Zq)d where n = pq. We show that the scheme
	can be broken by (d + 1) known plaintexts in O(d3 log2 n) time. Even
	when the modulus n is kept secret, it can be broken by 2(d + 1) known
	plaintexts in O(d4 log dn + d3 log2 n + ε(m)) time with overwhelming
	probability.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.ipl.2005.09.016},
  file = {cheon2006.pdf:cheon2006.pdf:PDF},
  issn = {0020-0190},
  keywords = {cryptography, cryptanalysis, privacy homomorphism, homomorphic encryption,
	domingo-ferrer PH},
  publisher = {Elsevier North-Holland, Inc.}
}

@MISC{chess2007,
  author = {Brian Chess and Yekaterina Tsipenyuk O'Neil and Jacob West},
  title = {Javascript Hijacking},
  howpublished = {[whitepaper] Fortify Software, http://www.fortifysoftware.com/servlet/downloads/public/JavaScript\_Hijacking.pdf},
  month = {March 2007},
  year = {2007},
  file = {JavaScript_Hijacking.pdf:JavaScript_Hijacking.pdf:PDF},
  keywords = {security, exploits},
  owner = {kristjan},
  timestamp = {2008.04.09},
  url = {http://www.fortifysoftware.com/servlet/downloads/public/JavaScript_Hijacking.pdf}
}

@INPROCEEDINGS{cheswick2000,
  author = {Bill Cheswick and Hal Burch and Steve Branigan},
  title = {Mapping and Visualizing the Internet},
  booktitle = {{USENIX} Annual Technical Conference},
  abstract = {We have been collecting and recording routing paths from a test host
	to each of over 90,000 registered networks on the Internet since
	August 1998. The resulting database contains interesting routing
	and reachability information, and is available to the public for
	research purposes. The daily scans cover approximately a tenth of
	the networks on the Internet, with a full scan run roughly once a
	month. We have also been collecting Lucent's intranet data, and applied
	these tools to understanding its size and connectivity. We have also
	detecting the loss of power to routers in Yugoslavia as the result
	of NATO bombing.
	
	A simulated spring-force algorithm lays out the graphs that results
	from these databases. This algorithm is well known, but has never
	been applied to such a large problem. The Internet graph, with around
	88,000 nodes and 100,000 edges, is much larger than those previously
	considered tractable by the data visualization community. The resulting
	Internet layouts are pleasant, though rather cluttered. On smaller
	networks, like Lucent's intranet, the layouts present the data in
	a useful way. For the Internet data, we have tried plotting a minimum
	distance spanning tree; by throwing away edges, the remaining graph
	can be made more accessible. Once a layout is chosen, it can be colored
	in various ways to show network-relevant data, such as IP address,
	domain information, location, ISPs, location of rewalls, etc. This
	paper expands and updates the description of the project given in
	[2].},
  file = {cheswick2000.pdf:cheswick2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@MISC{chien_yahooligans_2006,
  author = {Eric Chien},
  title = {Malicious Yahooligans},
  howpublished = {http://www.symantec.com/avcenter/reference/malicious.yahooligans.pdf},
  year = {2006},
  abstract = {On June 11, 2006 we received reports of a worm propagating via email.
	That in itself was nothing special, but what was more interesting
	was the fact that this worm appeared to propagate only through Yahoo!
	Mail email accounts.
	
	Once we obtained a sample, it became clear that this threat wasn’t
	any ordinary email worm, but was the first webmail worm, later named
	JS.Yamanner@m. In the past, we have seen email worms that sent themselves
	via Outlook and those that communicated with SMTP servers directly,
	but we hadn’t seen an email worm that actually harnessed a webmail
	interface. JS.Yamanner@m utilized Yahoo! Mail’s webmail interface
	both to collect email addresses and to send itself to other users.},
  file = {malicious.yahooligans.pdf:malicious.yahooligans.pdf:PDF},
  keywords = {viruses, web applications, worm propagation, yahoo mail},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://www.symantec.com/avcenter/reference/malicious.yahooligans.pdf}
}

@INPROCEEDINGS{choi1999,
  author = {K.-K. Choi and J. O. Limb},
  title = {A behavioral model of web traffic},
  booktitle = {{ICNP}},
  year = {1999},
  abstract = {The growing importance of Web traffic on the Internet makes it important
	that we have accurate traffic models in order to plan and provision.
	In this paper we present a Web traffic model designed to assist in
	the evaluation and engineering of shared communications networks.
	Because the model is behavioral we can extrapolate the model to assess
	the effect of changes in protocols, the network or user behavior.
	The increasing complexity of Web traffic has required that we base
	our model on the notion of a Web-request, rather a Web page. A Web-request
	results in the retrieval of information that might consist of one
	or more Web pages. The parameters of our model are derived from an
	extensive trace of Web traffic. Web requests are identified by analyzing
	not just the TCP header in the trace but also the HTTP headers. The
	effect of Web caching is incorporated into the model. The model is
	evaluated by comparing independent statistics from the model and
	from the trace. The reasons for differences between the model and
	the traces are given.},
  file = {choi1999.pdf:choi1999.pdf:PDF},
  keywords = {networks, simulation and modeling, web traffic model, behavioral modeling,
	request based modeling},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@ARTICLE{chong2003,
  author = {Chee-Yee Chong and Srikanta P. Kumar},
  title = {Sensor Networks: Evolution, Opportunities,
	
	and Challenges},
  journal = {Proceedings of the {IEEE}},
  year = {2003},
  volume = {91},
  number = {8},
  month = {August},
  abstract = {Wireless microsensor networks have been identified as one of the most
	important technologies for the 21st century. This paper traces the
	history of research in sensor networks over the past three decades,
	including two important programs of the Defense Advanced Research
	Projects Agency (DARPA) spanning this period: the Distributed Sensor
	Networks (DSN) and the Sensor Information Technology (SensIT) programs.
	Technology trends that impact the development of sensor networks
	are reviewed, and new applications such as infrastructure security,
	habitat monitoring, and traffic control are presented. Technical
	challenges in sensor network development include network discovery,
	control and routing, collaborative signal and information processing,
	tasking and querying, and security. The paper concludes by presenting
	some recent research results in sensor network algorithms, including
	localized algorithms and directed diffusion, distributed tracking
	in wireless ad hoc networks, and distributed classification using
	local agents.},
  file = {chong2003.pdf:chong2003.pdf:PDF},
  owner = {kristjan},
  review = {Very highly referenced (invited paper).},
  timestamp = {2010.01.17}
}

@ARTICLE{chor1993,
  author = {Benny Chor and Eyal Kushilevitz},
  title = {A Communication-Privacy Tradeoff for Modular Addition},
  journal = {Information Processing Letters},
  year = {1993},
  volume = {45},
  pages = {205--210},
  abstract = {In this note we consider the following problem: A set of n parties,
	each holding an input value x i 2 f0; 1; : : : ; m \Gamma 1g, wishes
	to distributively compute the sum of their input values modulo the
	integer m, (i.e, P n i=1 x i mod m). The parties wish to compute
	this sum t--privately. That is, in a way that no coalition of size
	at most t can infer any additional information, other than what follows
	from their input values and the computed sum. We present an oblivious
	protocol which computes the sum t--privately, using n \Delta d(t
	+ 1)=2e messages. This protocol requires fewer messages than the
	known private protocols for modular addition. Then, we show that
	this protocol is in a sense optimal, by proving a tight lower bound
	of dn \Delta (t + 1)=2e messages for any oblivious protocol that
	computes the sum t--privately.},
  file = {chor1993.pdf:chor1993.pdf:PDF},
  keywords = {private computation, message complexity, modular sum.},
  review = {Protocol for privately computing summation. Information-theoretic
	guarantees. Requires fully (?) connected graph.}
}

@ARTICLE{chor1998,
  author = {Benny Chor and Eyal Kushilevitz and Oded Goldreich and Madhu Sudan},
  title = {Private Information Retrieval},
  journal = {{J. ACM}},
  year = {1998},
  volume = {45},
  pages = {965-981},
  number = {6},
  abstract = {Publicly accessible databases are an indispensable resource for retrieving
	up-to-date
	
	information. But they also pose a significant risk to the privacy
	of the user, since a curious database
	
	operator can follow the user’s queries and infer what the user is
	after. Indeed, in cases where the
	
	users’ intentions are to be kept secret, users are often cautious
	about accessing the database. It can be
	
	shown that when accessing a single database, to completely guarantee
	the privacy of the user, the
	
	whole database should be down-loaded; namely n bits should be communicated
	(where n is the
	
	number of bits in the database).
	
	
	In this work, we investigate whether by replicating the database,
	more efficient solutions to the
	
	private retrieval problem can be obtained. We describe schemes that
	enable a user to access k
	
	replicated copies of a database (k Ն 2) and privately retrieve information
	stored in the database. This
	
	means that each individual server (holding a replicated copy of the
	database) gets no information on
	
	the identity of the item retrieved by the user. Our schemes use the
	replication to gain substantial
	
	saving. In particular, we present a two-server scheme with communication
	complexity O(n 1/3 ).},
  file = {chor1998.pdf:chor1998.pdf:PDF},
  keywords = {PIR, private information retrieval},
  owner = {kristjan},
  timestamp = {2009.12.17}
}

@INPROCEEDINGS{chou2004,
  author = {Neil Chou and Robert Ledesma and Yuka Teraguchi and John C. Mitchell},
  title = {Client-side defense against web-based identity theft},
  booktitle = {11th Annual {Network and Distributed Systems Security Symposium}
	({NDSS} '04)},
  year = {2004},
  abstract = {Web spooﬁng is a signiﬁcant problem involving fraudulent email and
	web sites that trick unsuspecting users into revealing private information.
	We discuss some aspects of common attacks and propose a framework
	for client-side defense: a browser plug-in that examines web pages
	and warns the user when requests for data may be part of a spoof
	attack. While the plug-in, SpoofGuard, has been tested using actual
	sites obtained through government agencies concerned about the problem,
	we expect that web spooﬁng and other forms of identity theft will
	be continuing problems in coming years.},
  file = {:Chou.pdf:PDF},
  keywords = {web applications, security, browser protection, SpoofGuard, web spoofing,
	identity theft},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@ARTICLE{christiansen2001,
  author = {Mikkel Christiansen and Kevin Jeffay and David Ott and F. Donelson
	Smith},
  title = {Tuning RED for Web traffic},
  journal = {{IEEE/ACM Trans. Netw.}},
  year = {2001},
  volume = {9},
  pages = {249--264},
  number = {3},
  abstract = {We study the effects of RED on the performance of Web browsing with
	a novel aspect of our work being the use of a user-centric measure
	of performance: response time for HTTP request-response pairs. We
	empirically evaluate RED across a range of parameter settings and
	offered loads. Our results show that: 1) contrary to expectations,
	compared to a FIFO queue, RED has a minimal effect on HTTP response
	times for offered loads up to 90% of link capacity; 2) response times
	at loads in this range are not substantially affected by RED parameters;
	3) between 90% and 100% load, RED can be carefully tuned to yield
	performance somewhat superior to FIFO, however, response times are
	quite sensitive to the actual RED parameter values selected; and
	4) in such heavily congested networks, RED parameters that provide
	the best link utilization produce power response times. We conclude
	that for links carrying only Web traffic, RED queue management appears
	to provide no clear advantage over tail-drop FIFO for end-user response
	times.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/90.929849},
  file = {christiansen2001.pdf:christiansen2001.pdf:PDF},
  issn = {1063-6692},
  publisher = {IEEE Press}
}

@ARTICLE{chun2007,
  author = {Chun, Byung-Gon and Maniatis, Petros and Shenker, Scott and Kubiatowicz,
	John},
  title = {Attested append-only memory: making adversaries stick to their word},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {2007},
  volume = {41},
  pages = {189--204},
  number = {6},
  abstract = {Researchers have made great strides in improving the fault tolerance
	of both centralized and replicated systems against arbitrary (Byzantine)
	faults. However, there are hard limits to how much can be done with
	entirely untrusted components; for example, replicated state machines
	cannot tolerate more than a third of their replica population being
	Byzantine. In this paper, we investigate how minimal trusted abstractions
	can push through these hard limits in practical ways. We propose
	Attested Append-Only Memory (A2M), a trusted system facility that
	is small, easy to implement and easy to verify formally. A2M provides
	the programming abstraction of a trusted log, which leads to protocol
	designs immune to equivocation -- the ability of a faulty host to
	lie in different ways to different clients or servers -- which is
	a common source of Byzantine headaches. Using A2M, we improve upon
	the state of the art in Byzantine-fault tolerant replicated state
	machines, producing A2M-enabled protocols (variants of Castro and
	Liskov's PBFT) that remain correct (linearizable) and keep making
	progress (live) even when half the replicas are faulty, in contrast
	to the previous upper bound. We also present an A2M-enabled single-server
	shared storage protocol that guarantees linearizability despite server
	faults. We implement A2M and our protocols, evaluate them experimentally
	through micro- and macro-benchmarks, and argue that the improved
	fault tolerance is cost-effective for a broad range of uses, opening
	up new avenues for practical, more reliable services.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1323293.1294280},
  file = {chun2007.pdf:chun2007.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM},
  review = {The authors explore the effects of adding a trusted log to byzantine
	fault tolerance systems. The result is that byzantine fault tolerance
	can be achieved with a 2f+1 majority as the ability to equivocate
	-- provide conflicting responses to requests -- is removed by the
	log. The work is presented (at least in the talk) in the context
	of replicated servers -- the application considered in Castro's PBFT
	work.
	
	
	See their adversarial formulation: Faulty app v.s. faulty operator
	notion. Tolerance dependent on the implementation -- integrated trusted
	hardware being the strongest.}
}

@INPROCEEDINGS{chun2004,
  author = {Brent N. Chun and Andy Bavier},
  title = {Decentralized Trust Management and Accountability in Federated Systems},
  booktitle = {37th Hawaii International Conference on System Sciences},
  year = {2004},
  file = {chun2004.pdf:chun2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.07}
}

@ARTICLE{claessens2002,
  author = {Joris Claessens and Bart Preneel and Joos Vandewalle},
  title = {A Tangled World Wide Web of Security Issues},
  journal = {First Monday},
  year = {2002},
  volume = {7},
  number = {3},
  month = {March},
  abstract = {The World Wide Web (WWW) was initially intended as a means to share
	distributed information amongst individuals. Now the WWW has become
	the preferred environment for a multitude of e-services: e-commerce,
	e-banking, e-voting, e-government, etc. Security for these applications
	is an important enabler. This article gives a thorough overview of
	the different security issues regarding the WWW, and provides insight
	in the current state-of-the-art and evolution of the proposed and
	deployed solutions.},
  file = {Web_Security_Issues.pdf:Web_Security_Issues.pdf:PDF},
  keywords = {web, security, survey},
  owner = {kristjan},
  timestamp = {2008.09.08}
}

@MISC{rfc3954_cisco_netflow_2004,
  author = {B. Claise},
  title = {{RFC3954: Cisco Systems NetFlow Services Export Version 9}},
  howpublished = {http://www.faqs.org/rfcs/rfc3954.html},
  year = {2004},
  abstract = {This document specifies the data export format for version 9 of Cisco
	Systems' NetFlow services, for use by implementations on the network
	elements and/or matching collector programs. The version 9 export
	format uses templates to provide access to observations of IP packet
	flows in a flexible and extensible manner. A template defines a collection
	of fields, with corresponding descriptions of structure and semantics.},
  keywords = {networks, network monitoring, tools, NetFlow},
  owner = {kristjan},
  timestamp = {2008.03.03},
  url = {http://www.faqs.org/rfcs/rfc3954.html}
}

@MISC{clark2009,
  author = {David D. Clark},
  title = {Toward the design of a Future Internet},
  month = {July, 8},
  year = {2009},
  file = {clark2009.pdf:clark2009.pdf:PDF},
  keywords = {future internet, internet scalability, internet research},
  owner = {kristjan},
  review = {Interesting notes on the future internet. A collection of discussion
	points and proposals rather than any concrete technological proposals.
	Use on internet scalability?},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{clark2003,
  author = {David D. Clark and Craig Partridge and J. Christopher Ramming and
	John T. Wroclawski},
  title = {A knowledge plane for the internet},
  booktitle = {{SIGCOMM} '03: Proceedings of the 2003 conference on Applications,
	technologies, architectures, and protocols for computer communications},
  year = {2003},
  pages = {3--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We propose a new objective for network research: to build a fundamentally
	different sort of network that can assemble itself given high level
	instructions, reassemble itself as requirements change, automatically
	discover when something goes wrong, and automatically fix a detected
	problem or explain why it cannot do so. We further argue that to
	achieve this goal, it is not sufficient to improve incrementally
	on the techniques and algorithms we know today. Instead, we propose
	a new construct, the Knowledge Plane, a pervasive system within the
	network that builds and maintains high-level models of what the network
	is supposed to do, in order to provide services and advice to other
	elements of the network. The knowledge plane is novel in its reliance
	on the tools of AI and cognitive systems. We argue that cognitive
	techniques, rather than traditional algorithmic approaches, are best
	suited to meeting the uncertainties and complexity of our objective.},
  doi = {http://doi.acm.org/10.1145/863955.863957},
  file = {p3-clark.pdf:p3-clark.pdf:PDF},
  isbn = {1-58113-735-4},
  keywords = {networks, knowledge plane, AI, pervasive systems, cognitive technigues},
  location = {Karlsruhe, Germany}
}

@INPROCEEDINGS{clement2009,
  author = {A. Clement and E. Wong and L. Alvisi and M. Dahlin and M. Marchetti},
  title = {Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults},
  booktitle = {{USENIX} Symposium on Networked Systems Design and Implementation},
  year = {2009},
  month = {April 22–24},
  owner = {kristjan},
  timestamp = {2010.04.26}
}

@INPROCEEDINGS{cocks2001,
  author = {Cliﬀord Cocks},
  title = {An Identity Based Encryption Scheme based on Quadratic Residues},
  booktitle = {8th {IMA} International Conference on Cryptography and Coding},
  year = {2001},
  abstract = {We present a novel public key cryptosystem in which the public key
	of a subscriber can be chosen to be a publicly known value, such
	as his identity. We discuss the security of the proposed scheme,
	and show that this is related to the diﬃculty of solving the quadratic
	residuosity problem},
  file = {cocks2001.pdf:cocks2001.pdf:PDF},
  keywords = {public key cryptography, identity-based cryptography},
  owner = {kristjan},
  timestamp = {2010.05.16}
}

@MISC{cohen2001,
  author = {Bram Cohen and Ben Laurie},
  title = {{AES}-hash},
  month = {May},
  year = {2001},
  file = {:aeshash.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{cohen2004,
  author = {Ira Cohen and Jeffery S. Chase},
  title = {Correlating instrumentation data to system states: A building block
	for automated diagnosis and control},
  booktitle = {OSDI},
  year = {2004},
  abstract = {This paper studies the use of statistical induction techniques as
	a basis for automated performance diagnosis and performance management.
	The goal of the work is to develop and evaluate tools for ofﬂine
	and online analysis
	
	of system metrics gathered from instrumentation in Internet server
	platforms. We use a promising class of probabilistic models (Tree-Augmented
	Bayesian Networks or TANs) to identify combinations of system-level
	metrics and threshold values that correlate with high-level performance
	states—compliance with Service Level Objectives (SLOs) for average-case
	response time—in a three-tier Web service under a variety of conditions.
	
	 Experimental results from a testbed show that TAN models involving
	small subsets of metrics capture patterns of performance behavior
	in a way that is accurate and yields insights into the causes of
	observed performance effects. TANs are extremely efﬁcient to represent
	and evaluate, and they have interpretability properties that make
	them excellent candidates for automated diagnosis and control. We
	explore the use of TAN models for ofﬂine forensic diagnosis, and
	in a limited online setting for performance forecasting with stable
	workloads.},
  file = {slic_osdi2004.pdf:slic_osdi2004.pdf:PDF},
  keywords = {networks, network management, performance analysis, bayesian networks,
	tree-augmented bayesian networks, TAN, AI},
  owner = {kristjan},
  review = {Tree-augmented Bayesian networks (TANs) used to identify combinations
	of system-level metrics that correspond to Service Level Objectives
	(SLOs).
	
	TANs are shown to be effective for automated diagnosis and control.
	
	
	TAN: Imposes a tree-structured dependence graph on a naive Bayesian
	network. The resulting structure is a Markov tree.
	
	
	Statistical learning techniques attractive for self-managing systems
	because they build system models with no a priori knowledge
	
	of system structure or workload characteristics. Paper shows that
	TANs are powerful enough to capture the performance behaviour of
	a three tier web service. Demonstrate value in sifting through instrumentation
	data to zero in on the most relevant metrics.
	
	
	Goal of this work: Automate analysis of instrumentation data from
	network services in order to forecast, diagnose and repair failure
	conditions. End result is
	
	a classifier. Approach is based on classification rather than anomaly
	detection. The model is trained with observations of SLO violations
	as well as normal behaviour.
	
	Supervised learning used. The problem of pattern classificaton is
	transformed to one of statistical fitting of a probabilistic model.},
  timestamp = {2008.02.25}
}

@ARTICLE{considine2009,
  author = {Considine, Jeffrey and Hadjieleftheriou, Marios and Li, Feifei and
	Byers, John and Kollios, George},
  title = {Robust approximate aggregation in sensor data management systems},
  journal = {{ACM Trans. Database Syst.}},
  year = {2009},
  volume = {34},
  pages = {1--35},
  number = {1},
  abstract = {In the emerging area of sensor-based systems, a signiﬁcant challenge
	is to develop scalable, fault-tolerant methods to extract useful
	information from the data the sensors collect. An approach to this
	data management problem is the use of sensor database systems, which
	allow users to perform aggregation queries such as MIN, COUNT, and
	AVG on the readings of a sensor network. In addition, more advanced
	queries such as frequency counting and quantile estimation can be
	supported. Due to energy limitations in sensor-based networks, centralized
	data collection is generally impractical, so most systems use in-network
	aggregation to reduce network trafﬁc. However, even these aggregation
	strategies remain bandwidth-intensive when combined with the fault-tolerant,
	multi-path routing methods often used in these environments. To avoid
	this expense, we investigate the use of approximate in-network aggregation
	using small sketches. We present duplicate-insensitive sketching
	techniques that can be implemented efﬁciently on small sensor devices
	with limited hardware support and we analyze both their performance
	and accuracy. Finally, we present an experimental evaluation that
	validates the effectiveness of our methods.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1508857.1508863},
  file = {considine2009.pdf:considine2009.pdf:PDF},
  issn = {0362-5915},
  publisher = {ACM}
}

@INPROCEEDINGS{considine2004,
  author = {Jeffrey Considine and Feifei Li and George Kollios and John Byers},
  title = {Approximate aggregation techniques for sensor databases},
  booktitle = {{ICDE}},
  year = {2004},
  pages = {449--460},
  abstract = {In the emerging area of sensor-based systems, a significant challenge
	is to develop scalable, fault-tolerant methods to extract useful
	information from the data the sensors collect. An approach to this
	data management problem is the use of sensor database systems, exemplified
	by TinyDB and Cougar, which allow users to perform aggregation queries
	such as MIN, COUNT and AVG on a sensor network. Due to power and
	range constraints, centralized approaches are generally impractical,
	so most systems use in-network aggregation to reduce network traffic.
	Also, aggregation strategies must provide fault-tolerance to address
	the issues of packet loss and node failures inherent in such a system.
	An unfortunate consequence of standard methods is that they typically
	introduce duplicate values, which must be accounted for to compute
	aggregates correctly. Another consequence of loss in the network
	is that exact aggregation is not possible in general. With this in
	mind, we investigate the use of approximate in-network aggregation
	using small sketches. Our contributions are as follows: 1) we generalize
	well known duplicateinsensitive sketches for approximating COUNT
	to handle SUM (and by extension, AVG and other aggregates), 2) we
	present and analyze methods for using sketches to produce accurate
	results with low communication and computation overhead (even on
	low-powered CPUs with little storage and no floating point operations),
	and 3) we present an extensive experimental validation of our methods.},
  file = {considine2004.pdf:considine2004.pdf:PDF},
  review = {see also nath2008}
}

@ARTICLE{conti2009,
  author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei,
	Alessandro},
  title = {Distributed data source verification in wireless sensor networks},
  journal = {Inf. Fusion},
  year = {2009},
  volume = {10},
  pages = {342--353},
  number = {4},
  __markedentry = {[kristjan]},
  abstract = {In-network data aggregation is favorable for wireless sensor networks
	(WSNs): It allows in-network data processing while reducing the network
	traffic and hence saving the sensors energy. However, due to the
	distributed and unattended nature of WSNs, several attacks aiming
	at compromising the authenticity of the collected data could be perpetrated.
	For example, an adversary could capture a node to create clones of
	the captured one. These clones disseminated through the network could
	provide malicious data to the aggregating node, thus poisoning/disrupting
	the aggregation process. In this paper we address the problem of
	detecting cloned nodes; a requirement to be fulfilled to provide
	authenticity of the data fusion process. First, we analyze the desirable
	properties a distributed clone detection protocol should meet. Specifically:
	It should avoid having a single point of failure; the load should
	be totally distributed across the nodes in the network; the position
	of the clones in the network should not influence the detection probability.
	We then show that current solutions do not meet the exposed requirements.
	Next, we propose the Information Fusion Based Clone Detection Protocol
	(ICD). ICD is a probabilistic, completely distributed protocol that
	efficiently detects clones. ICD combines two cryptographic mechanisms:
	The pseudo-random key pre-distribution, usually employed to secure
	node pairwise communications, with a sparing use of asymmetric crypto
	primitives. We show that ICD matches all the requirements above mentioned
	and compare its performance with current solutions in the literature;
	experimental results show that ICD has better performance than existing
	solutions for all the cost parameters considered: Number of messages
	sent, per sensor storage requirement, and signature verification.
	These savings allow to increase the network operating lifetime. Finally,
	note that ICD protocol could be used as an independent layer by any
	data aggregation mechanism.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.inffus.2009.01.002},
  file = {conti2009.pdf:conti2009.pdf:PDF},
  issn = {1566-2535},
  keywords = {sensor network, distributed clone detection, node clone attack},
  publisher = {Elsevier Science Publishers B. V.},
  review = {The paper considers cloning of captured sensor nodes. Countermeasures
	proposed.}
}

@INPROCEEDINGS{cooke2005,
  author = {Evan Cooke and Farnam Jahanian and Danny McPherson},
  title = {The Zombie roundup: understanding, detecting, and disrupting botnets},
  booktitle = {{SRUTI'05}: Proceedings of the Steps to Reducing Unwanted Traffic
	on the Internet on Steps to Reducing Unwanted Traffic on the Internet
	Workshop},
  year = {2005},
  pages = {6--6},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {Global Internet threats are undergoing a profound transformation from
	attacks designed solely to disable infrastructure to those that also
	target people and organizations. Behind these new attacks is a large
	pool of compromised hosts sitting in homes, schools, businesses,
	and governments around the world. These systems are infected with
	a bot that communicates with a bot controller and other bots to form
	what is commonly referred to as a zombie army or botnet. Botnets
	are a very real and quickly evolving problem that is still not well
	understood or studied. In this paper we outline the origins and structure
	of bots and botnets and use data from the operator community, the
	Internet Motion Sensor project, and a honeypot experiment to illustrate
	the botnet problem today. We then study the effectiveness of detecting
	botnets by directly monitoring IRC communication or other command
	and control activity and show a more comprehensive approach is required.
	We conclude by describing a system to detect botnets that utilize
	advanced command and control systems by correlating secondary detection
	data from multiple sources.},
  file = {:cooke2005.pdf:PDF},
  keywords = {networks, security, botnets},
  location = {Cambridge, MA}
}

@INPROCEEDINGS{cooke2006,
  author = {Evan Cooke and Richard Mortier and Austin Donnelly and Paul Barham
	and Rebecca Isaacs},
  title = {{Reclaiming Network-wide Visibility Using Ubiquitous Endsystem Monitors}},
  booktitle = {{USENIX} 2006},
  year = {2006},
  abstract = {Network-centric tools like NetFlow and security systems like IDSes
	provide essential data about the availability, reliability, and security
	of network devices and applications. However, the increased use of
	encryption and tunnelling has reduced the visibility of monitoring
	applications into packet headers and payloads (e.g. 93% of trafﬁc
	on our enterprise network is IPSec encapsulated). The result is the
	inability to collect the required information using network-only
	measurements. To regain the lost visibility we propose that measurement
	systems must themselves apply the end-to-end principle: only endsystems
	can correctly attach semantics to trafﬁc they send and receive. We
	present such an end-to-end monitoring platform that ubiquitously
	records per-ﬂow data and then we show that this approach is feasible
	and practical using data from our enterprise network.},
  file = {usenix06-anemone.pdf:usenix06-anemone.pdf:PDF},
  keywords = {networks, network management, end-system monitoring, end-to-end monitoring},
  owner = {kristjan},
  project = {phd},
  review = {(see also mortier2005)
	
	
	Network centric tools like NetFlow \cite{rfc3954_cisco_netflow_2004}
	and security systems like IDSes (?!) provide information about availability,
	reliability and security of network devices and applications. The
	increased use of encryption and tunneling has decreased the visibility
	of these network monitoring applications into packet headers and
	payloads. The result is inability to collect the required information
	using network-only measurements. The authors propose that the measurement
	systems must apply the end-to-end principle, since only end-systems
	can correctly attach semantics to traffic they send and receive.
	This work presents an end-to-end monitoring platform to ubiquitously
	record per-flow data. Continuous monitoring platforms subject to
	ongoing research - see e.g.\ \cite{iannaccone2004,moore2003}. However,
	these approaches assume direct access to packet headers and payloads.
	This is a problem, given the widespread use of encryption and tunneling.
	Further, many services are provided over dynamically allocated ports
	so collecting packets at upstream routers may no longer be sufficient
	to diagnose downstream applications.
	
	
	The authors propose an approach which provides an end-to-end view
	of the system. Fine grained auditing capability thus retained without
	restricting the ability to deploy essential security mechanisms.
	
	
	Each end system runs a small daemon which logs network activity. A
	summary is prepared by each device. A network operator or management
	application can qurey some or all endsystems, asking questions about
	availability, reachability and performance of network resourcecs
	and servers in the network.
	
	
	Projects using end-system agents to monitor network behaviour are
	e.g.\ \cite{online_dimes_project} (see \cite {carmi2007} for applications
	of DIMES), \cite{online_neti_at_home} (see \cite{simpson2006} on
	application of NETI@home) and Anemone \cite{mortimer2005}. Ubiqutous
	end-system network monitoring more alike in-network monitoring like
	NetFlow \cite{rfc3954_cisco_netflow_2004}. 
	
	
	End-system monitoring restores lost visibility and can provide better
	context since only the end systems can associate traffic to specific
	applications.
	
	
	Further study: See refs on distributed databases for network management
	applicatons, e.g.\ \cite{huebsch2003,yalagandula2004}.co},
  timestamp = {2008.02.07}
}

@INPROCEEDINGS{corral2003,
  author = {Joel Corral and Geraldine Texier and Laurent Toutain},
  title = {End-to-End Active Measurement Architecture in {IP} Networks ({SATURNE})},
  booktitle = {{PAM2003 - A workshop on Passive and Active Measurements}},
  year = {2003},
  pages = {3--4},
  abstract = {Performance measurement is an important issue in IP Networks for both
	ISPs and final users. Active measurement represents an efficient
	mean of evaluation and an alternative to the important infrastructure
	investment needed for passive measurement. Nowadays, the increasing
	complexity of routing mechanisms and the evolution of transport protocols
	leads to unawareness on the effective routes in the network; the
	symmetry of the paths followed by the packets can no longer be assumed.
	For this reason, the one-way metrics experience a remarkable development,
	introducing new requirements, like the synchronization of the points
	of measurement.},
  file = {corral2003.pdf:corral2003.pdf:PDF}
}

@INPROCEEDINGS{costa_vigilante_2005,
  author = {Manuel Costa and Jon Crowcroft and Miguel Castro and Antony Rowstron
	and Lidong Zhou and Lintao Zhang and Paul Barham},
  title = {Vigilante: end-to-end containment of internet worms},
  booktitle = {SOSP '05: Proceedings of the twentieth ACM symposium on Operating
	systems principles},
  year = {2005},
  pages = {133--147},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Worm containment must be automatic because worms can spread too fast
	for humans to respond. Recent work has proposed network-level techniques
	to automate worm containment; these techniques have limitations because
	there is no information about the vulnerabilities exploited by worms
	at the network level. We propose Vigilante, a new end-to-end approach
	to contain worms automatically that addresses these limitations.
	Vigilante relies on collaborative worm detection at end hosts, but
	does not require hosts to trust each other. Hosts run instrumented
	software to detect worms and broadcast self-certifying alerts (SCAs)
	upon worm detection. SCAs are proofs of vulnerability that can be
	inexpensively veriﬁed by any vulnerable host. When hosts receive
	an SCA, they generate ﬁlters that block infection by analysing the
	SCA-guided execution of the vulnerable software. We show that Vigilante
	can automatically contain fast-spreading worms that exploit unknown
	vulnerabilities without blocking innocuous traﬃc.},
  doi = {http://doi.acm.org/10.1145/1095810.1095824},
  file = {VigilanteSOSP.pdf:VigilanteSOSP.pdf:PDF},
  isbn = {1-59593-079-5},
  keywords = {networks, security, worms, worm containment, end-to-end monitoring,
	collaborative worm detection},
  location = {Brighton, United Kingdom}
}

@ARTICLE{coull2009,
  author = {Scott E. Coull and Boleslaw K. Szymanski},
  title = {On the development of an internetwork-centric defense for scanning
	worms},
  journal = {Computers \& Security},
  year = {2009},
  volume = {In Press, Corrected Proof},
  pages = {-},
  abstract = {Studies of worm outbreaks have found that the speed of worm propagation
	makes manual intervention ineffective. Consequently, many automated
	containment mechanisms have been proposed to contain worm outbreaks
	before they grow out of control. These containment systems, however,
	only provide protection for hosts within networks that implement
	them. Such a containment strategy requires complete participation
	to protect all vulnerable hosts. Moreover, collaborative containment
	systems, where participants share alert data, face a tension between
	resilience to false alerts and quick reaction to worm outbreaks.
	
	
	This paper suggests an alternative approach where an autonomous system
	in an internetwork, such as the Internet, protects not only its local
	hosts, but also all hosts that route traffic through it, which we
	call internetwork-centric containment. Additionally, we propose a
	novel reputation-based alerting mechanism to provide fast dissemination
	of infection information while maintaining the fairness of the system.
	Through simulation studies, we show that the combination of internetwork-centric
	containment and reputation-based alerting is able to contain an extremely
	virulent worm with relatively little participation in the containment
	system. In comparison to other collaborative containment systems,
	ours provides better protection against worm outbreaks and resilience
	to false alerts.},
  doi = {DOI: 10.1016/j.cose.2009.07.003},
  file = {coull2009.pdf:coull2009.pdf:PDF},
  issn = {0167-4048},
  keywords = {Network security, security, reputation, worms, malware protection,
	worm containment, collaborative network defense},
  url = {http://www.sciencedirect.com/science/article/B6V8G-4WTHS2K-1/2/acad4121033fb44b5493d134371b1696}
}

@INPROCEEDINGS{cowling2006,
  author = {Cowling, James and Myers, Daniel and Liskov, Barbara and Rodrigues,
	Rodrigo and Shrira, Liuba},
  title = {HQ replication: a hybrid quorum protocol for byzantine fault tolerance},
  booktitle = {{OSDI '06: Proceedings of the 7th symposium on Operating systems
	design and implementation}},
  year = {2006},
  pages = {177--190},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {There are currently two approaches to providing Byzantine-fault-tolerant
	state machine replication: a replica-based approach, e.g., BFT, that
	uses communication between replicas to agree on a proposed ordering
	of requests, and a quorum-based approach, such as Q/U, in which clients
	contact replicas directly to optimistically execute operations. Both
	approaches have shortcomings: the quadratic cost of inter-replica
	communication is un-necessary when there is no contention, and Q/U
	requires a large number of replicas and performs poorly under contention.
	
	
	We present HQ, a hybrid Byzantine-fault-tolerant state machine replication
	protocol that overcomes these problems. HQ employs a lightweight
	quorum-based protocol when there is no contention, but uses BFT to
	resolve contention when it arises. Furthermore, HQ uses only 3f +
	1 replicas to tolerate f faults, providing optimal resilience to
	node failures.
	
	
	We implemented a prototype of HQ, and we compare its performance to
	BFT and Q/U analytically and experimentally. Additionally, in this
	work we use a new implementation of BFT designed to scale as the
	number of faults increases. Our results show that both HQ and our
	new implementation of BFT scale as f increases; additionally our
	hybrid approach of using BFT to handle contention works well.},
  file = {cowling2006.pdf:cowling2006.pdf:PDF},
  isbn = {1-931971-47-1},
  location = {Seattle, Washington}
}

@INPROCEEDINGS{cramer2000,
  author = {Ronald Cramer and Ivan Damg{\aa}rd and Stefan Dziembowski},
  title = {On the Complexity of Verifiable Secret Sharing and Multiparty Computation},
  booktitle = {Proceedings of the 32nd {ACM} Symposium on Theory of Computing ({STOC}
	’00)},
  year = {2000},
  pages = {325--334},
  publisher = {ACM Press},
  abstract = {We first study the problem of doing Verifiable Secret Sharing (VSS)
	information theoretically secure for a general access structure.
	We do it in the model where private channels between players and
	a broadcast channel is given, and where an active, adaptive adversary
	can corrupt any set of players not in the access structure. In particular,
	we consider the complexity of protocols for this problem, as a function
	of the access structure and the number of players. For all access
	structures where VSS is possible at all, we show that, up to a polynomial
	time black-box reduction, the complexity of adaptively secure VSS
	is the same as that of ordinary secret sharing (SS), where security
	is only required against a passive, static adversary. Previously,
	such a connection was only known for linear secret sharing and VSS
	schemes. We then show an impossibility result indicating that a similar
	equivalence does not hold for Multiparty Computation (MPC): we show
	that even if protocols are given blac...},
  file = {cramer2000.pdf:cramer2000.pdf:PDF}
}

@INCOLLECTION{cramer1997,
  author = {Ronald Cramer and Rosario Gennaro and Berry Schoenmakers},
  title = {A Secure and Optimally Efficient Multi-Authority Election Scheme},
  booktitle = {Avances in Cryptology (EUROCRYPT ’97)},
  publisher = {Springer},
  year = {1997},
  volume = {1233},
  pages = {103–118},
  address = {New York, NY, USA},
  abstract = {In this paper we present a new multi-authority secret-ballot election
	scheme that guarantees privacy, universal verifiability, and robustness.
	It is the first scheme for which the performance is optimal in the
	sense that time and communication complexity is minimal both for
	the individual voters and the authorities. An interesting property
	of the scheme is that the time and communication complexity for the
	voter is independent of the number of authorities. A voter simply
	posts a single encrypted message accompanied by a compact proof that
	it contains a valid vote. Our result is complementary to the result
	by Cramer, Franklin, Schoenmakers, and Yung in the sense that in
	their scheme the work for voters is linear in the number of authorities
	but can be instantiated to yield information-theoretic privacy, while
	in our scheme the voter's effort is independent of the number of
	authorities but always provides computational privacy-protection.
	We will also point out that the majority ...},
  file = {cramer1997.pdf:cramer1997.pdf:PDF}
}

@MISC{crockford2007,
  author = {Douglas Crockford},
  title = {JSON and Browser Security},
  howpublished = {[online] http://yuiblog.com/blog/2007/04/10/json-and-browser-security/},
  month = {April 10},
  year = {2007},
  keywords = {web, security, browser vulnerabilities, JSON, browser security model},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://yuiblog.com/blog/2007/04/10/json-and-browser-security/}
}

@ARTICLE{crovella-1997,
  author = {Crovella, M.E. and Bestavros, A.},
  title = {Self-similarity in World Wide Web traffic: evidence and possible
	causes},
  journal = {Networking, IEEE/ACM Transactions on},
  year = {1997},
  volume = {5},
  pages = {835-846},
  number = {6},
  month = {Dec},
  abstract = {The notion of self-similarity has been shown to apply to wide-area
	and local-area network traffic. We show evidence that the subset
	of network traffic that is due to World Wide Web (WWW) transfers
	can show characteristics that are consistent with self-similarity,
	and we present a hypothesized explanation for that self-similarity.
	Using a set of traces of actual user executions of NCSA Mosaic, we
	examine the dependence structure of WWW traffic. First, we show evidence
	that WWW traffic exhibits behavior that is consistent with self-similar
	traffic models. Then we show that the self-similarity in such traffic
	can be explained based on the underlying distributions of WWW document
	sizes, the effects of caching and user preference in file transfer,
	the effect of user “think time”, and the superimposition of many
	such transfers in a local-area network. To do this, we rely on empirically
	measured distributions both from client traces and from data independently
	collected at WWW servers},
  doi = {10.1109/90.650143},
  file = {:crovella-1997.pdf:PDF},
  issn = {1063-6692},
  keywords = {Internet, performance evaluation, statistical analysis, WWW document
	size distribution, traffic analysis, client traces, empirically measured
	distributions, self-similar traffic models, self-similarity, user
	preference, user think time}
}

@TECHREPORT{cunha-1995,
  author = {Carlos Cunha and Azer Bestavros and Mark Crovella},
  title = {Characteristics of {WWW} Client-based Traces},
  institution = {Boston University},
  year = {1995},
  number = {BU-CS-95-010},
  address = {Boston, MA, USA},
  abstract = {The explosion of WWW traffic necessitates an accurate picture of WWW
	use, and in particular requires a good understanding of client requests
	for WWW documents. To address this need, we have collected traces
	of actual executions of NCSA Mosaic, reflecting over half a million
	user requests for WWW documents. In this paper we present a descriptive
	statistical summary of the traces we collected, which identifies
	a number of trends and reference patterns in WWW use. In particular,
	we show that many characteristics of WWW use can be modelled using
	power-law distributions, including the distribution of document sizes,
	the popularity of documents as a function of size, the distribution
	of user requests for documents, and the number of references to documents
	as a function of their overall rank in popularity (Zipf''s law).
	In addition, we show how the power-law distributions derived from
	our traces can be used to guide system designers interested in caching
	WWW documents. --- Our client-based traces are available via FTP
	from http://www.cs.bu.edu/techreports/1995-010-www-client-traces.tar.gz
	http://www.cs.bu.edu/techreports/1995-010-www-client-traces.a.tar.gz},
  file = {:10.1.1.36.1313.pdf:PDF},
  keywords = {networks, web, traffic analysis, www traces, statistical analysis,
	modeling, power-law distributions, zipf-distributions, www caching},
  publisher = {Boston University},
  source = {View on NCSTRL}
}

@ARTICLE{dabek2001,
  author = {Frank Dabek and M. Frans Kaashoek and David Karger and Robert Morris
	and Ion Stoica},
  title = {Wide-area cooperative storage with {CFS}},
  journal = {SIGOPS Oper. Syst. Rev.},
  year = {2001},
  volume = {35},
  pages = {202--215},
  number = {5},
  abstract = {The Cooperative File System (CFS) is a new peer-to-peer read-only
	storage system that provides provable guarantees for the efficiency,
	robustness, and load-balance of file storage and retrieval. CFS does
	this with a completely decentralized architecture that can scale
	to large systems. CFS servers provide a distributed hash table (DHash)
	for block storage. CFS clients interpret DHash blocks as a file system.
	DHash distributes and caches blocks at a fine granulaxity to achieve
	load balance, uses replication for robustness, and decreases latency
	with server selection. DHash finds blocks using the Chord location
	protocol, which operates in time logarithmic in
	
	the number of servers.
	
	CFS is implemented using the SFS file system toolkit and runs on Linux,
	OpenBSD, and FreeBSD. Experience on a globally deployed prototype
	shows that CFS delivers data to clients as fast as FTP. Controlled
	tests show that CFS is scalable: with 4,096 servers, looking up a
	block of data involves contacting only seven servers. The tests also
	demonstrate nearly perfect robustness and unimpaired performance
	even when as many as half the servers fail.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/502059.502054},
  file = {dabek2001.pdf:dabek2001.pdf:PDF},
  issn = {0163-5980},
  keywords = {networks, peer-to-peer systems, distributed hash tables, DHT, CFS},
  publisher = {ACM},
  review = {CFS and CHORD}
}

@INPROCEEDINGS{daemen1997,
  author = {Daemen, Joan and Knudsen, Lars R. and Rijmen, Vincent},
  title = {The Block Cipher Square},
  booktitle = {{FSE} '97: Proceedings of the 4th International Workshop on Fast
	Software Encryption},
  year = {1997},
  pages = {149--165},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {daemen1997.pdf:daemen1997.pdf:PDF},
  isbn = {3-540-63247-6}
}

@INPROCEEDINGS{daemen2002,
  author = {Joan Daemen and Vincent Rijmen},
  title = {Security of a Wide Trail Design},
  booktitle = {{INDOCRYPT}},
  year = {2002},
  file = {daemen2002.pdf:daemen2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.02}
}

@INCOLLECTION{daemen2001,
  author = {Joan Daemen and Vincent Rijmen},
  title = {The Wide Trail Design Strategy},
  booktitle = {Cryptography and Coding},
  publisher = {Springer Berlin / Heidelberg},
  year = {2001},
  volume = {2260/2001},
  series = {Lecture Notes in Computer Science},
  file = {daemen2001.pdf:daemen2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.02}
}

@INPROCEEDINGS{daemen2000,
  author = {Daemen, Joan and Rijmen, Vincent},
  title = {The Block Cipher {Rijndael}},
  booktitle = {{CARDIS} '98: Proceedings of the The International Conference on
	Smart Card Research and Applications},
  year = {2000},
  pages = {277--284},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {daemen2000.pdf:daemen2000.pdf:PDF},
  isbn = {3-540-67923-5},
  keywords = {security, encryption, symmetric key cryptography, AES. Rijndael}
}

@MISC{daemen1999,
  author = {Joan Daemen and Vincent Rijmen},
  title = {{AES} Proposal: {Rijndael}},
  month = {March},
  year = {1999},
  abstract = {In this paper we present the block cipher Rijndael, which is one of
	the fifteen candidate algorithms for the Advanced Encryption Standard
	(AES). We show that the cipher can be implemented very efficiently
	on Smart Cards.},
  file = {daemen1999.pdf:daemen1999.pdf:PDF},
  keywords = {security, encryption, symmetric key cryptography, AES, Rijndael},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{dam2005,
  author = {Mads Dam and Rolf Stadler},
  title = {A generic protocol for network state aggregation},
  booktitle = {{RVK} 05},
  year = {2005},
  address = {Link{\"o}ping, Sweden},
  month = jun,
  abstract = {Aggregation functions, which compute global parameters, such as the
	sum, minimum or average of local device variables, are needed for
	many network monitoring and management tasks. As networks grow larger
	and become more dynamic, it is crucial to compute these functions
	in a scalable and robust manner. To this end, we have developed GAP
	(Generic Aggregation Protocol), a novel protocol that computes aggregates
	of device variables for network management purposes. GAP supports
	continuous estimation of aggregates in a network where local state
	variables and the network graph may change. Aggregates are computed
	in a decentralized way using an aggregation tree. We have performed
	a functional evaluation of GAP in a simulation environment and have
	identified configuration choices that potentially allow us to control
	the performance characteristics of the protocol.},
  file = {GAP-RVK2005.pdf:GAP-RVK2005.pdf:PDF},
  keywords = {networks, network management, distributed aggregation, protocols,
	GAP}
}

@INPROCEEDINGS{damgaard1989,
  author = {Damg{\aa}rd, Ivan},
  title = {A Design Principle for Hash Functions},
  booktitle = {{CRYPTO} '89: Proceedings of the 9th Annual International Cryptology
	Conference on Advances in Cryptology},
  year = {1989},
  pages = {416--427},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {damgaard1989.PDF:damgaard1989.PDF:PDF},
  isbn = {3-540-97317-6}
}

@INPROCEEDINGS{damgaard2006,
  author = {Ivan Damg{\aa}rd and Yuval Ishai},
  title = {Scalable Secure Multiparty Computation},
  booktitle = {{Advances in Cryptology - CRYPTO 2006}},
  year = {2006},
  abstract = {We present the first general protocol for secure multiparty computation
	which is scalable, in the sense that the amortized work per player
	does not grow, and in some natural settings even vanishes, with the
	number of players. Our protocol is secure against an active adversary
	which may adaptively corrupt up to some constant fraction of the
	players. The protocol can be implemented in a constant number rounds
	assuming the existence of a “computationally simple” pseudorandom
	generator, or in a small non-constant number of rounds assuming an
	arbitrary pseudorandom generator.},
  file = {damgaard2006.pdf:damgaard2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.09}
}

@INPROCEEDINGS{damgaard2008,
  author = {Damg{\aa}rd, Ivan and Ishai, Yuval and Kroigaard, Mikkel and Nielsen,
	Jesper Buus and Smith, Adam},
  title = {Scalable Multiparty Computation with Nearly Optimal Work and Resilience},
  booktitle = {{CRYPTO 2008}: Proceedings of the 28th Annual conference on Cryptology},
  year = {2008},
  pages = {241--261},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {We present the first general protocol for secure multiparty computation
	in which the total amount of work required by n players to compute
	a function f grows only polylogarithmically with n (ignoring an additive
	term that depends on n but not on the complexity of f). Moreover,
	the protocol is also nearly optimal in terms of resilience, providing
	computational security against an active, adaptive adversary corrupting
	a (1/2 ¿ ¿) fraction of the players, for an arbitrary ¿> 0.},
  doi = {http://dx.doi.org/10.1007/978-3-540-85174-5_14},
  file = {damgaard2008.pdf:damgaard2008.pdf:PDF},
  isbn = {978-3-540-85173-8},
  location = {Santa Barbara, CA, USA}
}

@INPROCEEDINGS{damgaard2007,
  author = {Ivan Damg{\aa}rd and Jesper Buus Nielsen},
  title = {Scalable and Unconditionally Secure Multiparty Computation},
  booktitle = {{Advances in Cryptology - CRYPTO 2007}},
  year = {2007},
  abstract = {We present a multiparty computation protocol that is unconditionally
	secure against adaptive and active adversaries, with communication
	complexity $\mathcal{O}(\mathcal{C} n) k + \mathcal{O}(D n^2) k +
	{\rm poly}(n \kappa)$ , where $\mathcal{C}$ is the number of gates
	in the circuit, n is the number of parties, k is the bit-length of
	the elements of the field over which the computation is carried out,
	D is the multiplicative depth of the circuit, and κ is the security
	parameter. The corruption threshold is t < n/3. For passive security
	the corruption threshold is t < n/2 and the communication complexity
	is $\mathcal{O}(n \mathcal{C}) k$ . These are the first unconditionally
	secure protocols where the part of the communication complexity that
	depends on the circuit size is linear in n. We also present a protocol
	with threshold t < n/2 and complexity $\mathcal{O}(\mathcal{C} n)
	k + {\rm poly}(n \kappa)$ based on a complexity assumption which,
	however, only has to hold during the execution of the protocol –
	that is, the protocol has so called everlasting security.},
  file = {damgaard2007.pdf:damgaard2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.09}
}

@INPROCEEDINGS{damiani2002,
  author = {Ernesto Damiani and De Capitani {di Vimercati} and Stefano Paraboschi
	and Pierangela Samarati and Fabio Violante},
  title = {A reputation-based approach for choosing reliable resources in peer-to-peer
	networks},
  booktitle = {CCS '02: Proceedings of the 9th ACM conference on Computer and communications
	security},
  year = {2002},
  pages = {207--216},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Peer-to-peer (P2P) applications have seen an enormous success, and
	recently introduced P2P services have reached tens of millions of
	users. A feature that significantly contributes to the success of
	many P2P applications is user anonymity. However, anonymity opens
	the door to possible misuses and abuses, exploiting the P2P network
	as a way to spread tampered with resources, including Trojan Horses,
	viruses, and spam. To address this problem we propose a self-regulating
	system where the P2P network is used to implement a robust reputation
	mechanism. Reputation sharing is realized through a distributed polling
	algorithm by which resource requestors can assess the reliability
	of a resource offered by a participant before initiating the download.
	This way, spreading of malicious contents will be reduced and eventually
	blocked. Our approach can be straightforwardly piggybacked on existing
	P2P protocols and requires modest modifications to current implementations.},
  doi = {http://doi.acm.org/10.1145/586110.586138},
  file = {:p207-damiani.pdf:PDF},
  isbn = {1-58113-612-9},
  keywords = {networks, peer-to-peer systems, security, reputation systems},
  location = {Washington, DC, USA}
}

@INPROCEEDINGS{danezis2005,
  author = {Danezis, G. and Lesniewski-Laas, C. and Kaashoek, F. and Anderson,
	R.},
  title = {Sybil-resistant {DHT} routing},
  booktitle = {European Symp. Research in Computer Security (ESORICS 2005)},
  year = {2005},
  pages = {305--318},
  address = {Milan, Italy},
  month = {September},
  abstract = {Distributed Hash Tables (DHTs) are very eﬃcient distributed systems
	for routing, but at the same time vulnerable to disruptive nodes.
	Designers of such systems want them used in open networks, where
	an adversary can perform a sybil attack by introducing a large number
	of corrupt nodes in the network, considerably degrading its performance.
	We introduce a routing strategy that alleviates some of the eﬀects
	of such an attack by making sure that lookups are performed using
	a diverse set of nodes. This ensures that at least some of the nodes
	queried are good, and hence the search makes forward progress. This
	strategy makes use of latent social information present in the introduction
	graph of the network.},
  file = {danezis2005.pdf:danezis2005.pdf:PDF},
  keywords = {networks, peer-to-peer systems, distributed hash tables, DHTs, security,
	sybil attack, social networks},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@TECHREPORT{danezis2008,
  author = {George Danezis and Prateek Mittal},
  title = {{SybilInfer}: Detecting Sybil Nodes using Social Networks},
  institution = {Microsoft Research},
  year = {2008},
  number = {MSR-TR-2009-6},
  abstract = {SybilInfer is an algorithm for labelling nodes in a social network
	as honest users or Sybils controlled by an adversary. At the heart
	of SybilInfer lies a probabilistic model of honest social networks,
	and an inference engine that returns potential regions of dishonest
	nodes. The Bayesian inference approach to Sybil detection comes with
	the advantage label has an assigned probability, indicating its degree
	of certainty. We prove through analytical results as well as experiments
	on simulated and real-world network topologies that, given standard
	constraints on the adversary, SybilInfer is secure, in that it successfully
	distinguishes between honest and dishonest nodes and is not susceptible
	to manipulation by the adversary. Furthermore, our results show that
	SybilInfer outperforms state of the art algorithms, both in being
	more widely applicable, as well as providing vastly more accurate
	results.},
  file = {danezis2008.pdf:danezis2008.pdf:PDF},
  keywords = {sybil defense, social network},
  owner = {kristjan},
  timestamp = {2010.05.02}
}

@INCOLLECTION{datta2006,
  author = {Anupam Datta and Ante Derek and John C. Mitchell and Ajith Ramanathan
	and Andre Scedrov},
  title = {Games and the Impossibility of Realizable Ideal Functionality},
  booktitle = {Theory of Cryptography},
  publisher = {Springer Berlin / Heidelberg},
  year = {2006},
  volume = {3876/2006},
  series = {Lecture Notes in Computer Science},
  abstract = {A cryptographic primitive or a security mechanism can be specified
	in a variety of ways, such as a condition involving a game against
	an attacker, construction of an ideal functionality, or a list of
	properties that must hold in the face of attack. While game conditions
	are widely used, an ideal functionality is appealing because a mechanism
	that is indistinguishable from an ideal functionality is therefore
	guaranteed secure in any larger system that uses it. We relate ideal
	functionalities to games by defining the set of ideal functionalities
	associated with a game condition and show that under this definition,
	which reflects accepted use and known examples, bit commitment, a
	form of group signatures, and some other cryptographic concepts do
	not have any realizable ideal functionality.},
  file = {datta2006.pdf:datta2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.14}
}

@ARTICLE{datta2003,
  author = {Anindya Datta and Kaushik Dutta and Helen Thomas and Debra VanderMeer},
  title = {{World Wide Wait}: {A Study of Internet Scalability and Cache-Based
	Approaches to Alleviate It}},
  journal = {{Manage. Sci.}},
  year = {2003},
  volume = {49},
  pages = {1425--1444},
  number = {10},
  abstract = {The Internet is growing rapidly in terms of both use and infrastructure.
	Unfortunately, demand is outpacing the capacity of the infrastructure,
	as evidenced by unacceptably long response times. To support current
	load and further growth, we must address this problem. Several caching
	strategies have been proposed in the literature; many have been implemented
	to improve the quality of service on the Web. In this paper, we identify
	the main causes of delay on the Web, and provide a review of the
	various caching strategies employed to mitigate these delays. We
	also survey the application of Operations Research/Management Science
	(OR/MS) techniques to caching on the Web. Finally, we identify several
	open OR/MS research problems related to Web caching.},
  address = {Institute for Operations Research and the Management Sciences (INFORMS),
	Linthicum, Maryland, USA},
  doi = {http://dx.doi.org/10.1287/mnsc.49.10.1425.17312},
  file = {datta2003.pdf:datta2003.pdf:PDF},
  issn = {0025-1909},
  keywords = {internet scalability, caching strategies},
  publisher = {INFORMS},
  review = {Scalability problems of the Internet in very general terms, references
	DDoS and flash crowds. Proposed solution in terms of caching.}
}

@MISC{datta2005,
  author = {Anupam Datta and Ajith Ramanathan and Ante Derek and Andre Scedrov
	and John C. Mitchell},
  title = {The Impossibility of Realizable Ideal Functionality},
  year = {2005},
  file = {datta2005.pdf:datta2005.pdf:PDF}
}

@INPROCEEDINGS{davison2001,
  author = {Brian D. Davison},
  title = {{HTTP} Simulator Validation Using Real Measurements: A Case Study},
  booktitle = {MASCOTS '01: Proceedings of the Ninth International Symposium in
	Modeling, Analysis and Simulation of Computer and Telecommunication
	Systems},
  year = {2001},
  pages = {389},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Simulation is a common technique used by Web researchers and provides
	many benefits. Verification and validation of a simulator are essential
	if the results of those simulations are to be believed. Unfortunately,
	even limited validation of simulators has been uncommon in the Web
	caching community. In contrast, this paper argues for the validity
	of a new network and caching simulator by extensively comparing simulated
	results to both small- and large-scale real-world HTTP traffic. In
	addition, we describe some of the preparation needed to use a large,
	well-known trace of Web usage.},
  file = {davison2001.pdf:davison2001.pdf:PDF},
  keywords = {web, HTTP, simulation, web measurements}
}

@INPROCEEDINGS{de-canniere-2006,
  author = {Christophe {De Canniere} and Christian Rechberger},
  title = {Finding {SHA-1} Characteristics: General Results and Applications},
  booktitle = {ASIACRYPT},
  year = {2006},
  owner = {kristjan},
  timestamp = {2010.03.02}
}

@INPROCEEDINGS{decristofaro2009,
  author = {{De Cristofaro}, Emiliano and Bohli, Jens-Matthias and Westhoff,
	Dirk},
  title = {{FAIR}: fuzzy-based aggregation providing in-network resilience for
	real-time wireless sensor networks},
  booktitle = {{WiSec '09}: Proceedings of the second {ACM} conference on Wireless
	network security},
  year = {2009},
  pages = {253--260},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {This work introduces FAIR, a novel framework for <u>F</u>uzzy-based
	Aggregation providing In-network Resilience for Wireless Sensor Networks
	(WSN). FAIR addresses the possibility of malicious aggregator nodes
	manipulating data. It provides data-integrity based on a trust level
	of the WSN response and it tolerates link or node failures. Compared
	to available solutions, it offers a general aggregation model and
	makes the trust level visible to the querier. We classify the proposed
	approach as complementary to protocols ensuring resilience against
	sensor leaf nodes providing faulty data. Thanks to our flexible resilient
	framework and due to the use of Fuzzy Inference Schemes, we achieve
	promising results within a short design cycle.},
  doi = {http://doi.acm.org/10.1145/1514274.1514309},
  file = {decristofaro2009.pdf:decristofaro2009.pdf:PDF},
  isbn = {978-1-60558-460-7},
  location = {Zurich, Switzerland},
  review = {considers in-network aggregation security -- integrity objectives.}
}

@ARTICLE{de2003,
  author = {De, Swades and Qiao, Chunming and Wu, Hongyi},
  title = {Meshed multipath routing with selective forwarding: an efficient
	strategy in wireless sensor networks},
  journal = {Comput. Netw.},
  year = {2003},
  volume = {43},
  pages = {481--497},
  number = {4},
  abstract = {Due to limited functionalities and potentially large number of sensors,
	existing routing strategies proposed for mobile ad hoc networks are
	not directly applicable to wireless sensor networks. In this paper,
	we present a meshed multipath routing (M-MPR) protocol with selective
	forwarding (SF) of packets and end-to-end forward error correction
	(FEC) coding. We also describe a meshed multipath searching scheme
	suitable for sensor networks, which has a reduced signaling overhead
	and nodal database. Our performance evaluations show that (1) M-MPR
	achieves a much improved throughput over conventional disjoint multipath
	routing with comparable power consumption and receiver complexity;
	(2) to successfully route a message using FEC coding, selective forwarding
	(SF) consumes much less network resources, such as channel bandwidth
	and battery power, than packet replication (or limited flooding).},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S1389-1286(03)00355-4},
  file = {de2003.pdf:de2003.pdf:PDF},
  issn = {1389-1286},
  publisher = {Elsevier North-Holland, Inc.}
}

@PHDTHESIS{dean1999phd,
  author = {Richard Drews Dean},
  title = {Formal Aspects of Mobile Code Security},
  school = {Princeton University},
  year = {1999},
  file = {dean1999phd.pdf:dean1999phd.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@ARTICLE{debar1999,
  author = {Herv\'{e} Debar and Marc Dacier and Andreas Wespi},
  title = {Towards a taxonomy of intrusion-detection systems},
  journal = {Computer Networks},
  year = {1999},
  volume = {31},
  pages = {805–822},
  abstract = {Intrusion-detection systems aim at detecting attacks against computer
	systems and networks, or against information systems in general,
	as it is difficult to provide provably secure information systems
	and maintain them in such a secure state for their entire lifetime
	and for every utilization. Sometimes, legacy or operational constraints
	do not even allow a fully secure information system to be realized
	at all. Therefore, the task of intrusion-detection systems is to
	monitor the usage of such systems and to detect the apparition of
	insecure states. They detect attempts and active misuse by legitimate
	users of the information systems or external parties to abuse their
	privileges or exploit security vulnerabilities. In this paper, we
	introduce a taxonomy of intrusion-detection systems that highlights
	the various aspects of this area. This taxonomy defines families
	of ntrusion-detection systems according to their properties. It is
	illustrated by numerous examples from past and current projects.},
  file = {debar1999.pdf:debar1999.pdf:PDF},
  keywords = {networks, network security, intrusion detection, taxonomy, survey},
  owner = {kristjan},
  timestamp = {2009.08.24}
}

@INCOLLECTION{deligiannakis2004,
  author = {Antonios Deligiannakis and Yannis Kotidis and Nick Roussopoulos},
  title = {Hierarchical In-Network Data Aggregation with Quality Guarantees},
  booktitle = {Advances in Database Technology - {EDBT} 2004},
  publisher = {Springer Berlin / Heidelberg},
  year = {2004},
  pages = {577-578},
  __markedentry = {[kristjan]},
  abstract = {Earlier work has demonstrated the effectiveness of in-network data
	aggregation in order to minimize the amount of messages exchanged
	during continuous queries in large sensor networks. The key idea
	is to build an aggregation tree, in which parent nodes aggregate
	the values received from their children. Nevertheless, for large
	sensor networks with severe energy constraints the reduction obtained
	through the aggregation tree might not be sufficient. In this paper
	we extend prior work on in-network data aggregation to support approximate
	evaluation of queries to further reduce the number of exchanged messages
	among the nodes and extend the longevity of the network. A key ingredient
	to our framework is the notion of the residual mode of operation
	that is used to eliminate messages from sibling nodes when their
	cumulative change is small. We introduce a new algorithm, based on
	potential gains, which adaptively redistributes the error thresholds
	to those nodes that benefit the most and tries to minimize the total
	number of transmitted messages in the network. Our experiments demonstrate
	that our techniques significantly outperform previous approaches
	and reduce the network traffic by exploiting the super-imposed tree
	hierarchy.},
  file = {deligiannakis2004.pdf:deligiannakis2004.pdf:PDF},
  keywords = {networks, wireless, sensor networks, distributed aggregation, in-network
	aggregation, quality guarantees},
  owner = {kristjan},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{demers1987,
  author = {Alan Demers and Dan Greene and Carl Hauser and Wes Irish and John
	Larson and Scott Shenker and Howard Sturgis and Dan Swinehart and
	Doug Terry},
  title = {Epidemic algorithms for replicated database maintenance},
  booktitle = {{PODC '87: Proceedings of the sixth annual ACM Symposium on Principles
	of distributed computing}},
  year = {1987},
  pages = {1--12},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {When a database is replicated at many sites, maintaining mutual consistency
	among the sites in the fac:e of updates is a significant problem.
	This paper describes several randomized algorithms for distribut.ing
	updates and driving the replicas toward consistency. The algorithnns
	are very simple and require few guarantees from the underlying communications
	system, yet they ensure t.hat the effect of every update is eventually
	reflected in all replicas. The cost and performance of the algorithms
	are tuned by choosing appropriate distributions in the randoinization
	step.
	
	The algorithms are closely analogous to epidemics and the epidemiology
	literature aids in understanding their behavior. One algorithm has
	been implemented in the Clearinghouse servers of the Xerox Corporate
	Internet, solving long-standing problems of high traffic and database
	inconsistency.},
  doi = {http://doi.acm.org/10.1145/41840.41841},
  file = {demers1987.pdf:demers1987.pdf:PDF},
  isbn = {0-89791-239-4},
  keywords = {databases, database replication, epidemic, epidemiology, randomized
	algorithms},
  location = {Vancouver, British Columbia, Canada},
  review = {referenced by van_renesse_2003 on uses of gossiping or epidemic aggregation.}
}

@ARTICLE{deng2006,
  author = {Jing Deng and Richard Han and Shivakant Mishra},
  title = {{INSENS}: Intrusion-tolerant routing for wireless sensor networks},
  journal = {{Computer Communications}},
  year = {2006},
  volume = {29},
  pages = {216 - 230},
  number = {2},
  note = {Dependable Wireless Sensor Networks},
  abstract = {This paper describes an INtrusion-tolerant routing protocol for wireless
	SEnsor NetworkS (INSENS). INSENS securely and efficiently constructs
	tree-structured routing for wireless sensor networks (WSNs). The
	key objective of an INSENS network is to tolerate damage caused by
	an intruder who has compromised deployed sensor nodes and is intent
	on injecting, modifying, or blocking packets. To limit or localize
	the damage caused by such an intruder, INSENS incorporates distributed
	lightweight security mechanisms, including efficient one-way hash
	chains and nested keyed message authentication codes that defend
	against wormhole attacks, as well as multipath routing. Adapting
	to WSN characteristics, the design of INSENS also pushes complexity
	away from resource-poor sensor nodes towards resource-rich base stations.
	An enhanced single-phase version of INSENS scales to large networks,
	integrates bidirectional verification to defend against rushing attacks,
	accommodates multipath routing to multiple base stations, enables
	secure joining/leaving, and incorporates a novel pairwise key setup
	scheme based on transitory global keys that is more resilient than
	LEAP. Simulation results are presented to demonstrate and assess
	the tolerance of INSENS to various attacks launched by an adversary.
	A prototype implementation of INSENS over a network of MICA2 motes
	is presented to evaluate the cost incurred.},
  doi = {DOI: 10.1016/j.comcom.2005.05.018},
  file = {deng2006.pdf:deng2006.pdf:PDF},
  issn = {0140-3664},
  keywords = {Sensor network, Security, Intrusion tolerance, Fault tolerance, Secure
	routing, ISENS},
  review = {referenced by perrig2004 on resiliency against node capture by multiple
	routes.},
  url = {http://www.sciencedirect.com/science/article/B6TYP-4GKW5V8-3/2/7a0b8d97a038370076a0b6f0654deb8a}
}

@ARTICLE{deng2006a,
  author = {Deng, Jing and Han, Richard and Mishra, Shivakant},
  title = {Limiting {DoS} attacks during multihop data delivery in wireless
	sensor networks},
  journal = {Int. J. Secur. Netw.},
  year = {2006},
  volume = {1},
  pages = {167--178},
  number = {3/4},
  abstract = {Denial of Service (DoS) attacks can be easily launched in Wireless
	Sensor Networks (WSNs). Due to their resource constraints, namely
	limited energy, memory and bandwidth, WSNs are especially vulnerable
	to DoS attacks. This paper addresses a particular class of DoS attacks
	that overwhelm resources along a multihop data delivery path. Since
	WSNs are typically tree-structured, then a DoS attack on a path will
	be especially effective in denying routing service to an entire branch
	of sensor nodes, not just the nodes along the path. This paper proposes
	a solution using one-way hash chains to protect end-to-end multihop
	communications in WSNs against such Path-based DoS (PDoS) attacks.
	The proposed solution is lightweight, tolerates bursty packet losses
	and can easily be implemented in modern WSNs. This paper reports
	on performance measured from a prototype implementation.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJSN.2006.011776},
  file = {deng2006a.pdf:deng2006a.pdf:PDF},
  issn = {1747-8405},
  keywords = {sensor networks, security, DoS attack},
  publisher = {Inderscience Publishers}
}

@INPROCEEDINGS{deng2005,
  author = {Deng, Jing and Han, Richard and Mishra, Shivakant},
  title = {Defending against path-based {DoS} attacks in wireless sensor networks},
  booktitle = {{SASN} '05: Proceedings of the 3rd {ACM} workshop on Security of
	ad hoc and sensor networks},
  year = {2005},
  pages = {89--96},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Denial of service (DoS) attacks can cause serious damage in resource-constrained,
	wireless sensor networks (WSNs). This paper addresses an especially
	damaging form of DoS attack, called PDoS (Path-based Denial of Service).
	In a PDoS attack, an adversary overwhelms sensor nodes a long distance
	away by flooding a multi-hop end-to-end communication path with either
	replayed packets or injected spurious packets. This paper proposes
	a solution using one-way hash chains to protect end-to-end communications
	in WSNs against PDoS attacks. The proposed solution is lightweight,
	tolerates bursty packet losses, and can easily be implemented in
	modern WSNs. The paper reports on performance measured from a prototype
	implementation.},
  doi = {http://doi.acm.org/10.1145/1102219.1102235},
  file = {deng2005.pdf:deng2005.pdf:PDF},
  isbn = {1-59593-227-5},
  keywords = {sensor network, DoS},
  location = {Alexandria, VA, USA}
}

@INCOLLECTION{deng2003,
  author = {Jing Deng and Richard Han and Shivakant Mishra},
  title = {A Performance Evaluation of Intrusion-Tolerant Routing in Wireless
	Sensor Networks},
  booktitle = {Information Processing in Sensor Networks. Lecture Notes in Computer
	Science.},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  volume = {2634/2003},
  abstract = {This paper evaluates the performance of INSENS, an INtrusion-tolerant
	routing protocol for wireless SEnsor Networks. Security in sensor
	networks is important in battlefield monitoring and home security
	applications to prevent intruders from eavesdropping, from tampering
	with sensor data, and from launching denial-of-service (DOS) attacks
	against the entire network. The resilience of INSENS’s multipath
	performance against various forms of communication-based attacks
	by intruders is evaluated in simulation. Within the context of INSENS,
	the paper evaluates implementations on the motes of the RC5 and AES
	encryption standards, an RC5-based scheme to generate message authentication
	codes (MACs), and an RC5-based generation of one-way sequence numbers.},
  file = {deng2003.pdf:deng2003.pdf:PDF},
  keywords = {multipath routing, resilience, sensor networks, intrusion detection},
  owner = {kristjan},
  timestamp = {2009.09.01}
}

@INPROCEEDINGS{deng2003a,
  author = {Deng, Jing and Han, Richard and Mishra, Shivakant},
  title = {Security support for in-network processing in Wireless Sensor Networks},
  booktitle = {{SASN} '03: Proceedings of the 1st {ACM} workshop on Security of
	ad hoc and sensor networks},
  year = {2003},
  pages = {83--93},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {The benefits of in-network processing for wireless sensor networks
	include improved scalability, prolonged lifetime, and increased versatility.
	This paper addresses the challenges associated with securing in-network
	processing within WSNs, and proposes a collection of mechanisms for
	delegating trust to aggregators that are not initially trusted by
	individual sensor nodes. Security mechanisms are proposed to address
	the downstream requirement that sensor nodes authenticate commands
	disseminated from parent aggregators. Conversely, security mechanisms
	are also proposed to address the upstream requirement that aggregators
	authenticate data produced by sensors before aggregating. Simulation
	results in ns2 of the proposed mechanisms for secure in-network processing
	are presented, as well as implementation on a mote testbed.},
  doi = {http://doi.acm.org/10.1145/986858.986870},
  file = {deng2003a.pdf:deng2003a.pdf:PDF},
  isbn = {1-58113-783-4},
  keywords = {sensor network},
  location = {Fairfax, Virginia},
  review = {Referenced by roosta2006 on securing in-network aggregation. Also
	referenced by zhu2007.}
}

@ARTICLE{denning1987,
  author = {D.E. Denning},
  title = {An Intrusion-Detection Model},
  journal = {IEEE Transactions on Software Engineering},
  year = {1987},
  volume = {13},
  pages = {222-232},
  number = {2},
  abstract = {A model of a real-time intrusion-detection expert system capable of
	detecting break-ins, penetrations, and other forms of computer abuse
	is described. The model is based on the hypothesis that security
	violations can be detected by monitoring a system's audit records
	for abnormal patterns of system usage. The model includes profiles
	for representing the behavior of subjects with respect to objects
	in terms of metrics and statistical models, and rules for acquiring
	knowledge about this behavior from audit records and for detecting
	anomalous behavior. The model is independent of any particular system,
	application environment, system vulnerability, or type of intrusion,
	thereby providing a framework for a general-purpose intrusion-detection
	expert system.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.1987.232894},
  file = {denning1987.pdf:denning1987.pdf:PDF},
  issn = {0098-5589},
  keywords = {networking, security, intrusion detection},
  publisher = {IEEE Computer Society}
}

@ARTICLE{denning1981,
  author = {Denning, Dorothy E. and Sacco, Giovanni Maria},
  title = {Timestamps in key distribution protocols},
  journal = {Commun. {ACM}},
  year = {1981},
  volume = {24},
  pages = {533--536},
  number = {8},
  abstract = {The distribution of keys in a computer network using single key or
	public key encryption is discussed. We consider the possibility that
	communication keys may be compromised, and show that key distribution
	protocols with timestamps prevent replays of compromised keys. The
	timestamps have the additional benefit of replacing a two-step handshake.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/358722.358740},
  file = {denning1981.pdf:denning1981.pdf:PDF},
  issn = {0001-0782},
  keywords = {cryptography, key exchange, Needham-Schroeder},
  publisher = {ACM}
}

@INPROCEEDINGS{deshpande2004,
  author = {Deshpande, Amol and Guestrin, Carlos and Madden, Samuel R. and Hellerstein,
	Joseph M. and Hong, Wei},
  title = {Model-driven data acquisition in sensor networks},
  booktitle = {{VLDB} '04: Proceedings of the Thirtieth international conference
	on Very large data bases},
  year = {2004},
  pages = {588--599},
  publisher = {VLDB Endowment},
  abstract = {Declarative queries are proving to be an attractive paradigm for ineracting
	with networks of wireless sensors. The metaphor that "the sensornet
	is a database" is problematic, however, because sensors do not exhaustively
	represent the data in the real world. In order to map the raw sensor
	readings onto physical reality, a model of that reality is required
	to complement the readings. In this paper, we enrich interactive
	sensor querying with statistical modeling techniques. We demonstrate
	that such models can help provide answers that are both more meaningful,
	and, by introducing approximations with probabilistic confidences,
	significantly more efficient to compute in both time and energy.
	Utilizing the combination of a model and live data acquisition raises
	the challenging optimization problem of selecting the best sensor
	readings to acquire, balancing the increase in the confidence of
	our answer against the communication and data acquisition costs in
	the network. We describe an exponential time algorithm for finding
	the optimal solution to this optimization problem, and a polynomial-time
	heuristic for identifying solutions that perform well in practice.
	We evaluate our approach on several real-world sensor-network data
	sets, taking into account the real measured data and communication
	quality, demonstrating that our model-based approach provides a high-fidelity
	representation of the real phenomena and leads to significant performance
	gains versus traditional data acquisition techniques.},
  file = {deshpande2004.pdf:deshpande2004.pdf:PDF},
  isbn = {0-12-088469-0},
  keywords = {model driven aggregation, sensor networks},
  location = {Toronto, Canada},
  review = {Model driven data acquisition: A statistical model is used to "enrich"
	the real measured data in a sensor network. The authors claim this
	is beneficial due to reduced traffic.
	
	How about security and sensitivity to sudden changes??}
}

@INPROCEEDINGS{deshpande2003,
  author = {Deshpande, Amol and Nath, Suman and Gibbons, Phillip B. and Seshan,
	Srinivasan},
  title = {Cache-and-query for wide area sensor databases},
  booktitle = {{SIGMOD '03}: Proceedings of the 2003 {ACM} {SIGMOD} international
	conference on Management of data},
  year = {2003},
  pages = {503--514},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Webcams, microphones, pressure gauges and other sensors provide exciting
	new opportunities for querying and monitoring the physical world.
	In this paper we focus on querying wide area sensor databases, containing
	(XML) data derived from sensors spread over tens to thousands of
	miles. We present the first scalable system for executing XPATH queries
	on such databases. The system maintains the logical view of the data
	as a single XML document, while physically the data is fragmented
	across any number of host nodes. For scalability, sensor data is
	stored close to the sensors, but can be cached elsewhere as dictated
	by the queries. Our design enables self starting distributed queries
	that jump directly to the lowest common ancestor of the query result,
	dramatically reducing query response times. We present a novel query-evaluate
	gather technique (using XSLT) for detecting (1) which data in a local
	database fragment is part of the query result, and (2) how to gather
	the missing parts. We define partitioning and cache invariants that
	ensure that even partial matches on cached data are exploited and
	that correct answers are returned, despite our dynamic query-driven
	caching. Experimental results demonstrate that our techniques dramatically
	increase query throughputs and decrease query response times in wide
	area sensor databases.},
  doi = {http://doi.acm.org/10.1145/872757.872818},
  file = {deshpande2003.pdf:deshpande2003.pdf:PDF},
  isbn = {1-58113-634-X},
  location = {San Diego, California}
}

@INPROCEEDINGS{dewan2004,
  author = {Prashant Dewan},
  title = {Peer-to-peer reputations},
  booktitle = {18th International Parallel and Distributed Processing Symposium},
  year = {2004},
  month = {April},
  abstract = {Peer-to-peer (P2P) networks are designed with an assumption that the
	nodes in a P2P network will cooperate each other. In the absence
	of any common goals shared by the nodes of a P2P network, external
	motivation to cooperate and be trustworthy is required. Digital Reputations
	can be used to inject trust among the autonomous nodes of a network
	and motivate the nodes to contribute resources. This paper summarizes
	a self-certiﬁcation scheme for the identiﬁcation of peers using digital
	certiﬁcates similar to SDSI certiﬁcates, techniques to mitigate the
	problem of a consortium of liars’ and an elicitation-storage protocol
	for procuring and storing recommendations.},
  file = {:dewan2004.pdf:PDF},
  keywords = {networks, peer-to-peer systems, security, reputation management, self
	certification},
  owner = {kristjan},
  timestamp = {2009.02.17}
}

@ARTICLE{di-lucca-2004,
  author = {Di Lucca, G.A. and Fasolino, A.R. and Mastoianni, M. and Tramontana,
	P.},
  title = {Identifying cross site scripting vulnerabilities in Web applications},
  journal = {Web Site Evolution, 2004. WSE 2004. Proceedings. Sixth IEEE International
	Workshop on},
  year = {2004},
  pages = { 71-80},
  month = {Sept.},
  abstract = {Cross Site Scripting (XSS) is a vulnerability of a Web Application
	that is essentially caused by the failure of the application to check
	up on user input before returning it to the client's web browser.
	Without an adequate validation, user input may include malicious
	code that may be sent to other clients and unexpectedly executed
	by their browsers, thus causing a security attack.
	
	Techniques to prevent this type of attacks require that all application
	input must be checked up and filtered, encoded, or validated before
	sending them to any user. In order to discover the XSS vulnerabilities
	in a Web application, traditional source code analysis techniques
	can be exploited. In this paper, in order to assess the XSS vulnerability
	of a Web application, an approach that combines static and dynamic
	analysis of the Web application is presented. Static analysis based
	criteria have been defined to detect potential vulnerabilities in
	the server pages of a Web application, while a process of dynamic
	analysis has been proposed in order to detect actual vulnerabilities.
	Some case studies have been carried out, giving encouraging results.},
  doi = {10.1109/WSE.2004.10013},
  file = {lucca-xss.pdf:lucca-xss.pdf:PDF},
  issn = {1550-4441 },
  keywords = {web applications, security, XSS, browser security, static analysis,
	dynamic analysis},
  project = {phd}
}

@ARTICLE{di-pietro-2006,
  author = {Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
  title = {Energy efficient node-to-node authentication and communication confidentiality
	in wireless sensor networks},
  journal = {Wirel. Netw.},
  year = {2006},
  volume = {12},
  pages = {709--721},
  number = {6},
  __markedentry = {[kristjan]},
  abstract = {A distributed Wireless Sensor Network (WSN) is a collection of low-end
	devices with wireless message exchange capabilities. Due to the scarcity
	of hardware resources, the lack of network infrastructures, and the
	threats to security, implementing secure pair-wise communications
	among any pair of sensors is a challenging problem in distributed
	WSNs. In particular, memory and energy consumption as well as resilience
	to sensor physical compromise are the most stringent requirements.
	In this paper, we introduce a new threat model to communications
	confidentiality in WSNs, the smart attacker model. Under this new,
	more realistic model, the security features of previously proposed
	schemes decrease drastically. We then describe a novel pseudo-random
	key pre-deployment strategy ESP that combines all the following properties:
	(a) it supports an energy-efficient key discovery phase requiring
	no communications; (b) it provides node to node authentication; (c)
	it is highly resistant to the smart attacker. We provide both asymptotic
	results and extensive simulations of the schemes that are being proposed.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11276-006-6530-5},
  file = {di-pietro-2006.pdf:di-pietro-2006.pdf:PDF},
  issn = {1022-0038},
  publisher = {Kluwer Academic Publishers},
  review = {See on key exchange using only knowledge of node id's.}
}

@ARTICLE{di-pietro-2009,
  author = {Roberto {Di Pietro} and Pietro Michiardi and Refik Molva},
  title = {Confidentiality and integrity for data aggregation in {WSN} using
	peer monitoring},
  journal = {Security and Communication Networks},
  year = {2009},
  volume = {2},
  pages = {181--194},
  abstract = {Hop-by-hop data aggregation is a very important technique used to
	reduce the communication overhead and energy expenditure of sensor
	nodes during the process of data collection in a wireless sensor
	network (WSN). However, the unattended nature of WSNs calls for data
	aggregation techniques to be secure. Indeed, sensor nodes can be
	compromised to mislead the base station (BS) by injecting bogus data
	into the network during both forwarding and aggregation of data.
	Moreover, data aggregation might increase the risk of confidentiality
	violations: If sensors close to the BS are corrupted, an adversary
	could easily access to the results of the ‘in network’ computation
	performed by the WSN. Further, nodes can also fail due to random
	and non-malicious causes (e.g., battery exhaustion), hence availability
	should be considered as well.
	
	
	In this paper we tackle the above issues that affect data aggregation
	techniques by proposing a mechanism that: (i) provides both confidentiality
	and integrity of the aggregated data so that for any compromised
	sensor in the WSN the information acquired could only reveal the
	readings performed by a small, constant number of neighboring sensors
	of the compromised one; (ii) detects bogus data injection attempts;
	(iii) provides high resilience to sensor failures. Our protocol is
	based on the concept of delayed aggregation and peer monitoring and
	requires local interactions only. Hence, it is highly scalable and
	introduces small overhead; detailed analysis supports our findings.},
  file = {di-pietro-2009.pdf:di-pietro-2009.pdf:PDF},
  owner = {kristjan},
  review = {NOTE: Use as ref for security overlay. See their monitoring nodes
	and associated protocols. Some refs on set cover for distribution
	of monitoring nodes.
	
	
	See short discussion in albath2009. 
	
	
	Delayed aggregation, peer monitoring. Consider confidentiality and
	integrity of aggregation. Uses homomorphic crypto, similar to castelluccia,
	based on a symmetric key. RC4 used to generate stream, based on secret
	key and unique message identifier.
	
	
	contributions: 1) potocol for secure aggregation, based on a homomorphic
	crypto scheme and 2) local peer monitoring algorithm to detect injection
	of false data.
	
	
	Adversarial model: Passive (eavesdropping) as well as active (injeciton
	of bogus data) but stealthy. Oblivious adversary - random distribution
	for selection of next compromised node (memoryless process).
	
	
	Use a tree-based aggregation network. A certain number of sensors
	are selected as peer monitoring nodes (some mechanism for this selection
	assumed). Purpose of sensors: detect subversive activity to compromise
	the integrity of the sensed data. Use inherent overhearing properties
	of the wireless medium.
	
	
	Core aggregation idea: An aggregator does not compute the mean on
	its own reading, but only of the contributing values (one level down).
	Delayed aggregation, similar to Hu&Evans. Purpose not completely
	clear at this time, but enables the checking by monitoring nodes.
	
	
	Peer monitoring nodes either use direct observations (overhearing)
	or request aggregation nodes to relay observations (with some added
	security measures). Peer monitoring nodes raise alarms if inconsistencies
	are detected or if expected relayed observations are not received.},
  timestamp = {2010.01.26}
}

@MISC{dickinson2010,
  author = {Boonsri Dickinson},
  title = {With 'smart dust' a trillion sensors scattered around the globe},
  howpublished = {{Science Scope}},
  month = {May},
  year = {2010},
  owner = {kristjan},
  timestamp = {2010.05.20},
  url = {http://www.smartplanet.com/technology/blog/science-scope/building-a-real-world-web-with-smart-dust/1673/}
}

@MISC{diffie1992,
  author = {Whitfield Diffie and Paul C. {van Oorschot} and Michael J. Wiener},
  title = {Authentication and Authenticated Key Exchanges},
  month = {March},
  year = {1992},
  abstract = {We discuss two-party mutual authentication protocols providing authenticated
	key exchange, focusing on those using asymmetric techniques. A simple,
	efficient protocol referred to as the station-to-station (STS) protocol
	is introduced, examined in detail, and considered in relation to
	existing protocols. The definition of a secure protocol is considered,
	and desirable characteristics of secure protocols are discussed.},
  file = {diffie1992.pdf:diffie1992.pdf:PDF},
  keywords = {STS protocol, cryptography, authentication, key exchange},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@ARTICLE{dilman2002,
  author = {D. M. Dilman and Raz},
  title = {Efficient reactive monitoring},
  journal = {Selected Areas in Communications, IEEE Journal on},
  year = {2002},
  volume = {20},
  pages = {668-676},
  number = {4},
  month = {May},
  abstract = {Networks are monitored in order to ensure that the system operates
	within desirable parameters. The increasing complexity of networks
	and services provided by them increases this need for monitoring.
	Monitoring consists of measuring properties of the network, and of
	inferring an aggregate predicate from these measurements. Conducting
	such monitoring introduces traffic overhead that may reduce the overall
	effective throughput. This paper studies ways to minimize the monitoring
	communication overhead in IP networks. We develop and analyze several
	monitoring algorithms that achieve significant reduction in the management
	overhead while maintaining the functionality. The main idea is to
	combine global polling with local event driven reporting. The amount
	of traffic saving depends on the statistical characterization of
	the monitored data. We indicate the specific statistical factors
	that affect the saving and show how to choose the right algorithm
	for the type, of monitored data. In particular, our results show
	that for Internet traffic our algorithms can save more than 90% of
	the monitoring traffic},
  doi = {10.1109/JSAC.2002.1003034},
  file = {dilman2002.pdf:dilman2002.pdf:PDF},
  issn = {0733-8716},
  keywords = {networks, network management, network monitoring, monitoring overhead
	reduction}
}

@INPROCEEDINGS{dimakis2006,
  author = {A.~G.~Dimakis and A.~D.~Sarwate and M.~Wainwright},
  title = {Geographic Gossip: Efficient Aggregation for Sensor Networks},
  booktitle = {5th International Symposium on Information Processing in Sensor\
	Networks ({IPSN} 2006)},
  year = {2006},
  address = {Nashville, TN},
  month = {April},
  file = {dimakis2006.pdf:dimakis2006.pdf:PDF},
  keywords = {sensor networks, in-network aggregation, gossiping}
}

@MISC{dimitriou2006a,
  author = {Dimitriou and Foteinakis},
  title = {Secure and efficient in-network processing for sensor networks},
  __markedentry = {[kristjan]},
  abstract = {In this work we present a protocol that can be applied in wireless
	sensor networks in order to provide secure and authenticated in-network
	processing. Our protocol utilizes aggregator nodes which are responsible
	for data aggregation and command dissemination. The proposed protocol
	is simple and scalable and exhibits resiliency against node capture
	and replication as compromised nodes cannot be used to populate and
	eventually take over the network. It also allows for dynamic addition
	of new nodes and eviction of compromised ones by requiring minimum
	involvement of the base station. Finally, it is designed so that
	the majority of the sensors have to store only two keys plus a hash
	value, minimizing the storage capacity needed for the protocol to
	operate.},
  file = {dimitriou2006a.pdf:dimitriou2006a.pdf:PDF},
  owner = {kristjan},
  review = {Referenced by roosta2006 on securing in-network aggregation.},
  timestamp = {2010.01.26}
}

@INCOLLECTION{dimitriou2006,
  author = {Tassos Dimitriou and Ioannis Krontiris},
  title = {Secure In-Network Processing in Sensor Networks},
  booktitle = {Security in Sensor Networks},
  publisher = {CRC Press},
  year = {2006},
  editor = {Yang Xiao},
  __markedentry = {[kristjan]},
  abstract = {In-network processing in large-scale sensor networks has been shown
	to improve scalability, eliminate information redundancy and increase
	the lifetime of the network. In this chapter we address the challenge
	of securing in-network processing, both for aggregating sensor node’s
	measurements and disseminating commands from the aggregators to individual
	sensor nodes. We present the key mechanisms for establishing a secure
	communication channel between sensor nodes and aggregators and show
	how scalability and resiliency against diﬀerent type of attacks can
	be achieved. We also present how requirements such as dynamically
	adding new nodes in the network and harmonious existence with other
	security protocols of the network can be met. Finally we elaborate
	on resilient aggregation under corrupted measurements and the proposed
	solutions.},
  file = {dimitriou2006.pdf:dimitriou2006.pdf:PDF},
  owner = {kristjan},
  review = {see as primer on securing in-network aggregation.},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{ding2005,
  author = {M. Ding and D. Chen and K. Xing and X. Cheng},
  title = {Localized fault-tolerant event boundary detection in sensor networks},
  booktitle = {24th Annual Joint Conference of the {IEEE} Computer and Communications
	Socities {(INFOCOM)}},
  year = {2005},
  abstract = {This paper targets the identiﬁcation of faulty sensors and detection
	of the reach of events in sensor networks with faulty sensors. Typical
	applications include the detection of the transportation front line
	of a contamination and the diagnosis of network health. We propose
	and analyze two novel algorithms for faulty sensor identiﬁcation
	and fault-tolerant event boundary detection. These algorithms are
	purely localized and thus scale well to large sensor networks. Their
	computational overhead is low, since only simple numerical operations
	are involved. Simulation results indicate that these algorithms can
	clearly detect the event boundary and can identify faulty sensors
	with a high accuracy and a low false alarm rate when as many as 20%
	sensors become faulty.
	
	
	 Our work is exploratory in that the proposed algorithms can accept
	any kind of scalar values as inputs, a dramatic improvement over
	existing works that take only 0/1 decision predicates. Therefore,
	our algorithms are generic. They can be applied as long as the “events”
	can be modelled by numerical numbers. Though designed for sensor
	networks, our algorithms can be applied to the outlier detection
	and regional data analysis in spatial data mining.},
  file = {ding2005.pdf:ding2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{dingledine2004,
  author = {Roger Dingledine and Nick Mathewson and Paul Syverson},
  title = {{Tor: The Second-Generation Onion Router}},
  booktitle = {{13th USENIX Security Symposium}},
  year = {2004},
  month = {August},
  abstract = {We present Tor, a circuit-based low-latency anonymous communication
	service. This second-generation Onion Routing system addresses limitations
	in the original design by adding perfect forward secrecy, congestion
	control, directory servers, integrity checking, conﬁgurable exit
	policies, and a practical design for location-hidden services via
	rendezvous points. Tor works on the real-world Internet, requires
	no special privileges or kernel modiﬁcations, requires little synchronization
	or coordination between nodes, and provides a reasonable tradeoff
	between anonymity, usability, and efﬁciency. We brieﬂy describe our
	experiences with an international network
	
	of more than 30 nodes. We close with a list of open problems in anonymous
	communication.},
  file = {:tor-design.pdf:PDF},
  keywords = {networks, anonymity, onion routing, Tor},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@MISC{dojo_toolkit,
  author = {{DoJo Foundation}},
  title = {{DoJo. The JavaScript Toolkit}},
  howpublished = {http://dojotoolkit.org/},
  keywords = {web, framework, software, JavaScript},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://dojotoolkit.org/}
}

@MISC{dokas,
  author = {Paul Dokas and Levent Ertoz and Vipin Kumar and Aleksandar Lazarevic
	and Jaideep Srivastava and Pang-Nig Tan},
  title = {Data Mining for Network Intrusion Detection},
  owner = {kristjan},
  timestamp = {2008.02.26}
}

@INPROCEEDINGS{dolev1991,
  author = {Dolev, Danny and Dwork, Cynthia and Naor, Moni},
  title = {Non-malleable cryptography},
  booktitle = {{STOC} '91: Proceedings of the twenty-third annual {ACM} symposium
	on Theory of computing},
  year = {1991},
  pages = {542--552},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/103418.103474},
  file = {dolev1991.pdf:dolev1991.pdf:PDF},
  isbn = {0-89791-397-3},
  keywords = {cryptography, non-malleable,},
  location = {New Orleans, Louisiana, United States}
}

@ARTICLE{dolev1983,
  author = {Dolev, D. and Strong, H.R.},
  title = {Authenticated algorithms for Byzantine agreement.},
  journal = {Siam J. Comput.},
  year = {1983},
  volume = {12},
  pages = {656-666},
  number = {4},
  abstract = {Reaching agreement in a distributed system in the presence of faulty
	processors is a central issue for reliable computer systems. Using
	an authentication protocol, one can limit the undetected behavior
	of faulty processors to a simple failure to relay messages to all
	intended targets. In this paper, the authors show that, in spite
	of such an ability to limit faulty behavior, and no matter what message
	types or protocols are allowed, reaching (Byzantine) agreement requires
	at least t + 1 phases or rounds of information exchange, where t
	is an upper bound on the number of faulty processors.},
  file = {dolev1983.pdf:dolev1983.pdf:PDF},
  keywords = {byzantine agreement, fault tolerance},
  owner = {kristjan},
  timestamp = {2009.11.08}
}

@ARTICLE{dolev1993,
  author = {Shlomi Dolev and Amos Israeli and Shlomo Moran},
  title = {Self-stabilization of dynamic systems assuming only read/write atomicity},
  journal = {Distrib. Comput.},
  year = {1993},
  volume = {7},
  pages = {3--16},
  number = {1},
  abstract = {Three self-stabilizing protocols for distributed systems in the shared
	memory model are presented. The ﬁrst protocol is a mutual exclusion
	protocol for tree structured systems. The second protocol is a spanning
	tree protocol for systems with any connected communication graph.
	The third protocol is a self stabilizing protocol for mutual exclusion,
	for systems with a general (connected) communication graph. This
	last protocol is obtained by combining the previous two protocols.
	The combination employs a simple technique called fair protocol combination,
	which is enabled by both the self-stability and by the ﬂexibility
	of dynamic protocols. The presented protocols improve upon previous
	protocols in two ways: First, it is assumed that the only atomic
	operations are either read or write to the shared memory. Second,
	our protocols work for any connected network and even for dynamic
	networks, in which the topology of the network may change during
	the execution.},
  address = {London, UK},
  doi = {http://dx.doi.org/10.1007/BF02278851},
  file = {:dim92.pdf:PDF},
  issn = {0178-2770},
  owner = {kristjan},
  publisher = {Springer-Verlag},
  timestamp = {2008.12.05}
}

@INPROCEEDINGS{domingo-ferrer-2002,
  author = {Domingo-Ferrer, Josep},
  title = {A Provably Secure Additive and Multiplicative Privacy Homomorphism},
  booktitle = {{ISC '02}: Proceedings of the 5th International Conference on Information
	Security},
  year = {2002},
  pages = {471--483},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {Privacy homomorphisms (PHs) are encryption transformations mapping
	a set of operations on cleartext to another set of operations on
	ciphertext. If addition is one of the ciphertext operations, then
	it has been shown that a PH is insecure against a chosen-cleartext
	attack. Thus, a PH allowing full arithmetic on encrypted data can
	be at best secure against known-cleartext attacks. We present one
	such PH (none was known so far) which can be proven secure against
	known-cleartext attacks, as long as the ciphertext space is much
	larger than the cleartext space. Some applications to delegation
	of sensitive computing and data and to e-gambling are briefly outlined.},
  isbn = {3-540-44270-7},
  review = {Symmetric key homomorphic cryptosystem.
	
	
	The first (?) proposed algebraic (additive and multiplicative) cryptosystem.
	
	Broken -- see cryptanalysis by e.g. \shortcite{cheon2006}.
	
	
	Believe fully algebraic cryptosystems are still a open issue.}
}

@INPROCEEDINGS{Douceur2002,
  author = {John R. Douceur},
  title = {{The Sybil Attack}},
  booktitle = {{IPTPS} '01: Revised Papers from the First International Workshop
	on Peer-to-Peer Systems},
  year = {2002},
  pages = {251--260},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {Large-scale peer-to-peer systems face security threats from faulty
	or hostile remote computing elements. To resist these threats, many
	such systems employ redundancy. However, if a single faulty entity
	can present multiple identities, it can control a substantial fraction
	of the system, thereby undermining this redundancy. One approach
	to preventing these “Sybil attacks” is to have a trusted agency certify
	identities. This paper shows that, without a logically centralized
	authority, Sybil attacks are always possible except under extreme
	and unrealistic assumptions of resource parity and coordination among
	entities.},
  file = {101.pdf:101.pdf:PDF},
  isbn = {3-540-44179-4}
}

@CONFERENCE{Drytkiewicz2003,
  author = {Witold Drytkiewicz and Steffen Sroka and Vlado Handziski and Andreas
	K\"{o}pke and Holger Karl},
  title = {A Mobility Framework for OMNeT++},
  booktitle = {3rd International OMNeT++ Workshop},
  year = {2003},
  address = {Department of Telecommunications, Budapest, Hungary},
  month = {Jan},
  file = {drytkiewicz03mobility.pdf:/home/kristjan/articles/drytkiewicz03mobility.pdf:PDF},
  howpublished = {3rd International OMNeT++ Workshop},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/drytkiewicz03mobility.html}
}

@INPROCEEDINGS{du2001,
  author = {Du, Wenliang and Atallah, Mikhail J.},
  title = {Secure multi-party computation problems and their applications: a
	review and open problems},
  booktitle = {{NSPW} '01: Proceedings of the 2001 workshop on New security paradigms},
  year = {2001},
  pages = {13--22},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {The growth of the Internet has triggered tremendous opportunities
	for cooperative computation, where people are jointly conducting
	computation tasks based on the private inputs they each supplies.
	These computations could occur between mutually untrusted parties,
	or even between competitors. For example, customers might send to
	a remote database queries that contain private information; two competing
	financial organizations might jointly invest in a project that must
	satisfy both organizations' private and valuable constraints, and
	so on. Today, to conduct such computations, one entity must usually
	know the inputs from all the participants; however if nobody can
	be trusted enough to know all the inputs, privacy will become a primary
	concern.This problem is referred to as Secure Multi-party Computation
	Problem (SMC) in the literature. Research in the SMC area has been
	focusing on only a limited set of specific SMC problems, while privacy
	concerned cooperative computations call for SMC studies in a variety
	of computation domains. Before we can study the problems, we need
	to identify and define the specific SMC problems for those computation
	domains. We have developed a framework to facilitate this problem-discovery
	task. Based on our framework, we have identified and defined a number
	of new SMC problems for a spectrum of computation domains. Those
	problems include privacy-preserving database query, privacy-preserving
	scientific computations, privacy-preserving intrusion detection,
	privacy-preserving statistical analysis, privacy-preserving geometric
	computations, and privacy-preserving data mining.The goal of this
	paper is not only to present our results, but also to serve as a
	guideline so other people can identify useful SMC problems in their
	own computation domains.},
  doi = {http://doi.acm.org/10.1145/508171.508174},
  file = {du2001.pdf:du2001.pdf:PDF},
  isbn = {1-58113-457-6},
  keywords = {secure multi-party computation, MPC, SMC},
  location = {Cloudcroft, New Mexico}
}

@INPROCEEDINGS{du2003,
  author = {Wenliang Du and Jing Deng and Yunghsiang S. Han and Pramod Varshney},
  title = {A Witness-Based Approach for Data Fusion Assurance in Wireless Sensor
	Networks},
  booktitle = {{In Proceedings of the IEEE Global Telecommunications Conference}},
  year = {2003},
  pages = {1435--1439},
  abstract = {In wireless sensor networks, sensor nodes are spread randomly over
	the coverage area to collect information of interest. Data fusion
	is used to process these collected information before they are sent
	to the base station, the observer of the sensor network. We study
	the security of the data fusion process in this work. In particular,
	we propose a witness-based solution to assure the validation of the
	data sent from data fusion nodes to the base station. We also present
	the theoretical analysis for the overhead associated with the mechanism,
	which indicates that even in an extremely harsh environment the overhead
	is low for the proposed mechanism.},
  file = {du2003.pdf:du2003.pdf:PDF}
}

@ARTICLE{du2005,
  author = {Du, Wenliang and Deng, Jing and Han, Yunghsiang S. and Varshney,
	Pramod K. and Katz, Jonathan and Khalili, Aram},
  title = {A pairwise key predistribution scheme for wireless sensor networks},
  journal = {{ACM Trans. Inf. Syst. Secur.}},
  year = {2005},
  volume = {8},
  pages = {228--258},
  number = {2},
  abstract = {To achieve security in wireless sensor networks, it is important to
	be able to encrypt and authenticate messages sent between sensor
	nodes. Before doing so, keys for performing encryption and authentication
	must be agreed upon by the communicating parties. Due to resource
	constraints, however, achieving key agreement in wireless sensor
	networks is nontrivial. Many key agreement schemes used in general
	networks, such as Diffie-Hellman and other public-key based schemes,
	are not suitable for wireless sensor networks due to the limited
	computational abilities of the sensor nodes. Predistribution of secret
	keys for all pairs of nodes is not viable due to the large amount
	of memory this requires when the network size is large.In this paper,
	we provide a framework in which to study the security of key predistribution
	schemes, propose a new key predistribution scheme which substantially
	improves the resilience of the network compared to previous schemes,
	and give an in-depth analysis of our scheme in terms of network resilience
	and associated overhead. Our scheme exhibits a nice threshold property:
	when the number of compromised nodes is less than the threshold,
	the probability that communications between any additional nodes
	are compromised is close to zero. This desirable property lowers
	the initial payoff of smaller-scale network breaches to an adversary,
	and makes it necessary for the adversary to attack a large fraction
	of the network before it can achieve any significant gain.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1065545.1065548},
  file = {du2005.pdf:du2005.pdf:PDF},
  issn = {1094-9224},
  keywords = {cryptography, key management, sensor networks},
  publisher = {ACM}
}

@ARTICLE{Du2008,
  author = {Xiaojiang Du and Hsiao-Hwa Chen},
  title = {Security in wireless sensor networks},
  journal = {{IEEE} Wireless Communications},
  year = {2008},
  volume = {15},
  pages = {60--66},
  number = {4},
  abstract = {Recent advances in electronics and wireless communication technologies
	have enabled the development of large-scale wireless sensor networks
	that consist of many low-power, low-cost, and small-size sensor nodes.
	Sensor networks hold the promise of facilitating large-scale and
	real-time data processing in complex environments. Security is critical
	for many sensor network applications, such as military target tracking
	and security monitoring. To provide security and privacy to small
	sensor nodes is challenging, due to the limited capabilities of sensor
	nodes in terms of computation, communication, memory/storage, and
	energy supply. In this article we survey the state of the art in
	research on sensor network security.},
  file = {du2008.pdf:du2008.pdf:PDF},
  keywords = {sensor networks, wireless networking, security, survey},
  owner = {kristjan},
  review = {An ok review of wireless SN security. Brief and accessible. Very SN
	specific. B/B+.
	
	
	Discuss challenges in aggregation NW: end-to-end SSL-like authenticity,
	integrity and confidentiality challenging because of the in-network
	aggregation.
	
	
	Discuss key management. Refs on public key crypto on 8-bit CPUs. \cite{gura2004}.
	
	Secure time synchronization, secure location discovery (limited interest).
	
	Very briefly on secure routing -- salient point: secure MANET routing
	protocols not designed for aggregation but for delivery of individual
	packets.},
  timestamp = {2010.01.17}
}

@MISC{dua2009,
  author = {Akshay Dua and Wen Hu and Nirupama Bulusu},
  title = {Demo Abstract: A Trusted Platform Based Framework for Participatory
	Sensing},
  year = {2009},
  abstract = {“Participatory sensing” is an exciting new paradigm where people voluntarily
	sense their local environment and share this data using mobile phones
	and the Internet. It can revolutionize applications such as intelligent
	transportation, public health and social networking. However, a major
	concern is the amount of trust that can be placed in the shared data.
	We address this concern in our demonstration by using a Trusted Platform
	Module (TPM) in conjunction with a smart phone. The TPM is responsible
	for attesting the application on the phone to assure remote entities
	that the application has not been tampered with. To the best of our
	knowledge, this is the ﬁrst demonstration of application attestation
	on a smart phone employing a TPM.},
  file = {dua2009.pdf:dua2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{duan2008,
  author = {Yitao Duan and John Canny},
  title = {Practical Private Computation and Zero-Knowledge Tools for Privacy-Preserving
	Distributed Data Mining},
  booktitle = {{SDM}},
  year = {2008},
  pages = {265-276},
  organization = {{SIAM}},
  file = {duan2008.pdf:duan2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.16}
}

@MISC{dworakowski2002,
  author = {Wojciech Dworakowski},
  title = {Why is a firewall alone not enough? What are {IDSes} and why are
	they worth having?},
  howpublished = {http://www.windowsecurity.com/articles},
  year = {2002},
  owner = {kristjan},
  timestamp = {2008.03.03},
  url = {http://www.windowsecurity.com/articles/Why_is_a_firewall_alone_not_enough_What_are_IDSes_and_why_are_they_worth_having.html}
}

@ARTICLE{dwork2004,
  author = {Dwork, Cynthia and Naor, Moni and Sahai, Amit},
  title = {Concurrent zero-knowledge},
  journal = {{J. ACM}},
  year = {2004},
  volume = {51},
  pages = {851--898},
  number = {6},
  abstract = {Concurrent executions of a zero-knowledge protocol by a single prover
	(with one or more verifiers) may leak information and may not be
	zero-knowledge in toto. In this article, we study the problem of
	maintaining zero-knowledge.We introduce the notion of an (α, β) timing
	constraint: for any two processors P1 and P2, if P1 measures α elapsed
	time on its local clock and P2 measures β elapsed time on its local
	clock, and P2 starts after P1 does, then P2 will finish after P1
	does. We show that if the adversary is constrained by an (α, β) assumption
	then there exist four-round almost concurrent zero-knowledge interactive
	proofs and perfect concurrent zero-knowledge arguments for every
	language in NP. We also address the more specific problem of Deniable
	Authentication, for which we propose several particularly efficient
	solutions. Deniable Authentication is of independent interest, even
	in the sequential case; our concurrent solutions yield sequential
	solutions without recourse to timing, that is, in the standard model.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1039488.1039489},
  file = {dwork2004.pdf:dwork2004.pdf:PDF},
  issn = {0004-5411},
  keywords = {zero knowledge proofs, cryptography, security},
  publisher = {ACM}
}

@MISC{dworkin2010,
  author = {Morris Dworkin},
  title = {{NIST} Special Publication 800-38A (Draft Addendum): Recommendation
	for Block Cipher Modes of Operation: Three Variants of Ciphertext
	Stealing for {CBC} Mode},
  month = {June},
  year = {2010},
  file = {:nist-sp-800-38A-draft-addendum.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@MISC{dworkin2007,
  author = {Morris Dworkin},
  title = {{NIST} Special Publication 800-38D: Recommendation for Block Cipher
	Modes of Operation: Galois/Counter Mode ({GCM}) and {GMAC}},
  month = {November},
  year = {2007},
  file = {:SP-800-38D.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.02}
}

@MISC{dworkin2005,
  author = {Morris Dworkin},
  title = {{NIST} Special Publication 800-38B: Cipher Modes of Operation: The
	{CMAC} Mode for Authentication},
  month = {May},
  year = {2005},
  file = {:SP_800-38B.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.02}
}

@MISC{dworkin2004,
  author = {Morris Dworkin},
  title = {{NIST} Special Publication 800-38C: Recommendation for Block Cipher
	Modes of Operation: The {CCM} Mode for Authentication and Confidentiality},
  month = {May},
  year = {2004},
  file = {:SP800-38C_updated-July20_2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.02}
}

@MISC{dworkin2001,
  author = {Morris Dworkin},
  title = {{NIST} Special Publication 800-38A: Recommendation for Block Cipher
	Modes of Operation: Methods and Techniques},
  month = {December},
  year = {2001},
  file = {:sp800-38a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@MISC{Eastlake2001sha1,
  author = {{Eastlake, 3rd}, D. and Jones, P.},
  title = {{RFC} 3174: {US Secure Hash Algorithm 1 (SHA1)}},
  year = {2001},
  abstract = {The purpose of this document is to make the SHA-1 (Secure Hash Algorithm
	1) hash algorithm conveniently available to the Internet community.
	The United States of America has adopted the SHA-1 hash algorithm
	described herein as a Federal Information Processing Standard. Most
	of the text herein was taken by the authors from FIPS 180-1. Only
	the C code implementation is "original".},
  address = {United States},
  publisher = {RFC Editor},
  url = {http://www.faqs.org/rfcs/rfc3174.html}
}

@MISC{ecma_262_1999,
  author = {{ECMA Standardizing Information and Communication Systems}},
  title = {{Standard ECMA-262: ECMAScript Language Specification}},
  month = {December},
  year = {1999},
  file = {Ecma-262.pdf:Ecma-262.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.18},
  url = {http://www.ecma-international.org/publications/standards/Ecma-262.htm}
}

@INPROCEEDINGS{el-gamal-1985,
  author = {El Gamal, Taher},
  title = {A public key cryptosystem and a signature scheme based on discrete
	logarithms},
  booktitle = {Proceedings of {CRYPTO} '84 on Advances in cryptology},
  year = {1985},
  pages = {10--18},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  file = {el-gamal-1985.pdf:el-gamal-1985.pdf:PDF},
  isbn = {0-387-15658-5},
  keywords = {cryptography, homomorphic encryption},
  location = {Santa Barbara, California, United States}
}

@ARTICLE{elgamal1985a,
  author = {El Gamal, Taher},
  title = {A public key cryptosystem and a signature scheme based on discrete
	logarithms},
  journal = {{IEEE} Transactions of Information Theory},
  year = {1985},
  volume = {31},
  pages = {10--18},
  number = {4},
  month = {July},
  abstract = {A new signature scheme is proposed, together with an implementation
	of the Diffie-Hellman key distribution scheme that achieves a public
	key cryptosystem. The security of both systems relies on the difficulty
	of computing discrete logarithms over finite fields.},
  address = {New York, NY, USA},
  booktitle = {{CRYPTO 84} -- Advances in cryptology},
  file = {elgamal1985.pdf:elgamal1985.pdf:PDF},
  isbn = {0-387-15658-5},
  location = {Santa Barbara, California, United States},
  publisher = {Springer-Verlag New York, Inc.}
}

@INPROCEEDINGS{el-zarki-2002,
  author = {Magda {El Zarki} and Sharad Mehrotra and Gene Tsudik and Nalini Venkatasubramanian},
  title = {Security Issues in a Future Vehicular Network},
  booktitle = {European Wireless, 2002},
  year = {2002},
  abstract = {In this paper we present a novel infrastructure for vehicular communication
	on highways (DAHNI) and propose some potential applications aimed
	at assisting drivers. Certain unique features of the envisaged infrastructure
	and applications result in equally unique and interesting security
	challenges. We discuss these challenges and outline some possible
	solutions.},
  file = {:el-zarki-2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.18}
}

@MISC{endler-2002,
  author = {David Endler},
  title = {The Evolution of Cross-Site Scripting Attacks},
  file = {endler_XSS.pdf:endler_XSS.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14}
}

@ARTICLE{ergun2000,
  author = {Funda Erg\"{u}n and Sampath Kannan and S. Ravi Kumar},
  title = {Spot-checkers},
  journal = {J. of Computer and System Sciences},
  year = {2000},
  file = {ergun2000.ps:ergun2000.ps:PostScript},
  owner = {kristjan},
  timestamp = {2010.04.08}
}

@ARTICLE{ergun2004,
  author = {Funda Erg\"{u}n and Ravi Kumar and Ronitt Rubinfeld},
  title = {Fast approximate probabilistically checkable proofs},
  journal = {Information and Computation},
  year = {2004},
  volume = {189},
  pages = {135 - 159},
  number = {2},
  abstract = {We investigate the question of when a verifier, with the aid of a
	proof, can reliably compute a function faster than it can without
	the proof. The proof system model that we use is based on a variant
	of the Probabilistically Checkable Proofs (PCP) model, in which a
	verifier can ascertain the correctness of the proof by looking at
	very few locations in the proof. However, known results in the PCP
	model require that the verifier spend time linear in the size of
	the input in order to determine where to query the proof. In this
	work, we focus on the case when it is enough for the verifier to
	know that the answer is close to correct, and develop an approximate
	PCP model. We construct approximate PCPs for several optimization
	problems, in which the total running time of the verifier is significantly
	less than the size of the input. For example, we give polylogarithmic
	time approximate PCPs for showing the existence of a large cut, or
	a large matching in a graph, and a small bin packing. In the process,
	we develop a set of tools for use in constructing these proof systems.},
  doi = {DOI: 10.1016/j.ic.2003.09.005},
  file = {ergun2004.pdf:ergun2004.pdf:PDF},
  issn = {0890-5401},
  keywords = {Property testing, Proof-assisted property testing, Probabilistically
	checkable proofs, Sub-linear time algorithms, Optimization problems},
  url = {http://www.sciencedirect.com/science/article/B6WGK-4B8P46B-1/2/744297f9b88c9309cea5a82116e4cf77}
}

@INPROCEEDINGS{ergun1999,
  author = {Erg\"{u}n, Funda and Kumar, Ravi and Rubinfeld, Ronitt},
  title = {Fast approximate {PCPs}},
  booktitle = {{STOC '99}: Proceedings of the thirty-first annual {ACM} symposium
	on Theory of computing},
  year = {1999},
  pages = {41--50},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/301250.301267},
  file = {ergun1999.pdf:ergun1999.pdf:PDF},
  isbn = {1-58113-067-8},
  keywords = {probabilistic checkable proofs, PCP, interactive proofs},
  location = {Atlanta, Georgia, United States}
}

@PHDTHESIS{erlingsson2004phd,
  author = {{\'{U}}lfar Erlingsson},
  title = {The inlined reference monitor approach to security policy enforcement},
  year = {2004},
  address = {Ithaca, NY, USA},
  note = {Adviser-Fred B. Schneider},
  abstract = {Embedding security enforcement code into applications is an alternative
	to traditional security mechanisms. This dissertation supports the
	thesis that such Inlined Reference Monitors, or IRMs, offer many
	advantages and are a practical option in modern systems. IRMs enable
	flexible general-purpose enforcement of security policies, and they
	are especially well suited for extensible systems and other non-traditional
	platforms. IRMs can exhibit similar, or even better, performance
	than previous approaches and can help increase assurance by contributing
	little to the size of a trusted computing base. Moreover, IRMs' agility
	in distributed settings allows for their cost-effective and trustworthy
	deployment in many scenarios.
	
	
	In this dissertation, IRM implementations are derived from formal
	automatabased specifications of security policies. Then, an IRM toolkit
	for Java is described in detail. This Java IRM toolkit uses an imperative
	policy language that allows a security policy, in combination with
	the details of its enforcement, to be given in a single complete
	specification. Various example policies, including the stack-inspection
	policy of Java, illustrate the approach. These examples shed light
	on practical issues in policy specification, the support needed from
	an IRM toolkit, and the advantages of the IRM approach.},
  file = {:erlingsson-phdthesis.pdf:PDF},
  order_no = {AAI3114521},
  publisher = {Cornell University}
}

@INPROCEEDINGS{erlingsson2007,
  author = {{\'{U}}lfar Erlingsson and Benjamin Livshits and Yinglian Xie},
  title = {{End-to-end Web Application Security}},
  booktitle = {{Proceedings of the 11th Workshop on Hot Topics in Operating Systems
	(HotOS'07)}},
  year = {2007},
  address = {San Diego, CA},
  month = {May},
  abstract = {Web applications are important, ubiquitous distributed systems whose
	current security relies primarily on server-side mechanisms. This
	paper makes the end-to-end argument that the client and server must
	collaborate
	
	to achieve security goals, to eliminate common security exploits,
	and to secure the emerging class of rich, cross-domain Web applications
	referred to as Web 2.0. In order to support end-to-end security,
	Web clients
	
	must be enhanced. We introduce Mutation-Event Transforms: an easy-to-use
	client-side mechanism that can enforce even ﬁne-grained, application-speciﬁc
	security policies, and whose implementation requires only
	
	straightforward changes to existing Web browsers. We give numerous
	examples of attractive, new security policies that demonstrate the
	advantages of end-to-end Web application security and of our proposed
	mechanism.},
  file = {e2ewebappsec.pdf:e2ewebappsec.pdf:PDF},
  owner = {kristjan},
  review = {*See also [[erlingsson2007a]]*
	
	
	Makes an end-to-end argument for web application security - that the
	server and
	
	client must collaborate to achieve security goals of Web 2.0 applications.
	A client side mechansim - 
	
	mutation-event transforms (MET) is introduced. Web application development
	has to date focused on 
	
	server side security enforcement (in fact current advice is that web
	browsers cannot be trusted 
	
	under any circumstances \cite{crockford2007}).
	
	
	Browsers are assumed to enforce a \textit{Same Origin} security policy
	\cite{o_wi_same_origin_policy}
	
	as a measure to prevent \textit{cross-site scripting} \cite{o_wi_cross_site_scripting}.
	
	
	$<script>$ tags are however exempt from this restriction and are thus
	widely used to create 
	
	mashup applications
	
	which need to provide interoperability between code provided by distinct
	sites within the same
	
	browser session.
	
	%
	
	Server side enforcement is particularily difficult to enforce for
	mashups, since none of the 
	
	web servers involved in providing such an application have a complete
	end application view; the
	
	final HTML is rendered by the AJAX application running in the users
	browser just before viewing.
	
	
	METs are JavaScript functions provided by the web servers specifying
	the applicable security policies.
	
	These functions are invoked on web page modifications - a MET can
	transform a mutation (including 
	
	the code and data on a web page) before it takes place.
	
	%
	
	\footnote{Mutation events are proposed in \cite{pixley2000} as events
	caused by any event that
	
	modifies the DOM structure. Two events are defined for the $<script>$
	tag: 1) when a node is
	
	inserted into the DOM and 2) when the node is populated.}
	
	%
	
	METs are callbacks which are called on a mutation event. Very flexible
	security policies can be set
	
	using this mechanism. 
	
	%
	
	A server sets the security policies which are enforced in the browser
	- hence the end-to-end argument.
	
	
	For further study:
	
	See also IRMs in [[erlingsson2000irm]] and [[erlingsson2004phd]].
	See also [[yu2007]]. 
	
	Distributed reference monitoring - check out [[gasser1989]] and [[chander2004]]
	
	See also SDSI [[rivest1996]].},
  timestamp = {2008.02.14}
}

@INPROCEEDINGS{erlingsson2007a,
  author = {{\'{U}}lfar Erlingsson and Benjamin Livshits and Yinglian Xie},
  title = {Mutation-Event Transforms: A Flexible Client-side Foundation for
	End-to-end Web 2.0 Security},
  booktitle = {{W2SP: Web 2.0 Security \& Privacy}},
  year = {2007},
  address = {Oakland, CA},
  month = {May},
  abstract = {It is our position that to reliably achieve Web application security
	goals, the server and the client must collaborate to enforce security
	policies. Such end-to-end security enforcement is particularly important
	in order to fully re-
	
	alize the promise of rich, cross-domain Web 2.0 applications. However,
	this improved security requires that Web clients be enhanced, and
	those enhancements must both be straightforward to implement and
	offer multiple,
	
	attractive beneﬁts if they are to be adopted by popular Web browsers.
	We propose Mutation-Event Transforms, or METs, as a simple, ﬂexible
	client-side mechanism for security policy enforcement. METs have
	the appealing
	
	property that simple policies are easy to specify and enforce; yet,
	METs are ﬂexible enough to enforce even ﬁne-grained, application-speciﬁc
	security policies.},
  file = {paper-215-z_7682.pdf:paper-215-z_7682.pdf:PDF},
  owner = {kristjan},
  review = {See erlingsson2007 - End-to-end web application security.},
  timestamp = {2008.02.19}
}

@INPROCEEDINGS{erlingsson2000irm,
  author = {{\'{U}}lfar Erlingsson and Fred B. Schneider},
  title = {{IRM} Enforcement of Java Stack Inspection},
  booktitle = {{IEEE} Symposium on Security and Privacy},
  year = {2000},
  pages = {246-255},
  file = {2000-1786.ps:2000-1786.ps:PDF},
  url = {citeseer.ist.psu.edu/erlingsson00irm.html}
}

@TECHREPORT{erlingsson2003,
  author = {Úlfar Erlingsson},
  title = {The Inlined Reference Monitor Approach to Security Policy Enforcement},
  institution = {Cornell University},
  year = {2003},
  number = {TR-2003-1916},
  month = {December},
  abstract = {Embedding security enforcement code into applications is an alternative
	to tradi-
	
	tional security mechanisms. This dissertation supports the thesis
	that such Inlined
	
	Reference Monitors, or IRMs, oﬀer many advantages and are a practical
	option
	
	in modern systems. IRMs enable ﬂexible general-purpose enforcement
	of security
	
	policies, and they are especially well suited for extensible systems
	and other non-
	
	traditional platforms. IRMs can exhibit similar, or even better, performance
	than
	
	previous approaches and can help increase assurance by contributing
	little to the
	
	size of a trusted computing base. Moreover, IRMs’ agility in distributed
	settings
	
	allows for their cost-eﬀective and trustworthy deployment in many
	scenarios.
	
	 In this dissertation, IRM implementations are derived from formal
	automata-
	
	based speciﬁcations of security policies. Then, an IRM toolkit for
	Java is described
	
	in detail. This Java IRM toolkit uses an imperative policy language
	that allows
	
	a security policy, in combination with the details of its enforcement,
	to be given
	
	in a single complete speciﬁcation. Various example policies, including
	the stack-
	
	inspection policy of Java, illustrate the approach. These examples
	shed light on
	
	practical issues in policy speciﬁcation, the support needed from an
	IRM toolkit,
	
	and the advantages of the IRM approach.},
  file = {TR2003-1916.pdf:TR2003-1916.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.08.28}
}

@INPROCEEDINGS{ertaul2007,
  author = {Levent Ertaul and Vaidehi},
  title = {Computing Aggregation Function Minimum/Maximum using Homomorphic
	Encryption Schemes in Wireless Sensor Networks {(WSNs)}},
  booktitle = {{ICWN}},
  year = {2007},
  __markedentry = {[kristjan]},
  abstract = {Data aggregation in wireless sensor networks (WSN) helps eliminate
	information redundancy and increase the lifetime of the network.
	When homomorphic encryption is used for data aggregation, end-to-end
	encryption is achieved and aggregation function like average or minimum/maximum
	can be computed on the encrypted data. Aggregation functions like
	minimum/maximum rely on comparison operation. But, it has been shown
	that any homomorphic encryption is insecure against ciphertext only
	attacks if they support comparison operation. The order preserving
	encryption scheme (OPES) has been suggested for WSNs, for secure
	comparison of encrypted data at the aggregator node in WSNs. But,
	the computational cost at the sensor nodes in WSNs by using OPES
	is huge. This paper provides an alternative for OPES when used to
	calculate aggregation function minimum/maximum. In this paper we
	briefly describe some homomorphic encryption schemes and show how
	the sensed data is encrypted by using these homomorphic encryption
	schemes. we show how aggregation function minimum/maximum can be
	computed at the aggregator node in WSNs by performing addition operation
	and not comparison operation on the data encrypted with homomorphic
	encryption schemes. We also show how our scheme helps eliminate the
	encryption cost at the sensor node in WSNs.},
  file = {ertaul2007.pdf:ertaul2007.pdf:PDF},
  keywords = {sensor network, aggregation network, homomorphic crypto, min max functions},
  owner = {kristjan},
  timestamp = {2010.05.20}
}

@INPROCEEDINGS{eschenauer2002,
  author = {Laurent Eschenauer and Virgil D. Gligor},
  title = {A key-management scheme for distributed sensor networks},
  booktitle = {{CCS '02: Proceedings of the 9th ACM conference on Computer and communications
	security}},
  year = {2002},
  pages = {41--47},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Distributed Sensor Networks (DSNs) are ad-hoc mobile networks that
	include sensor nodes with limited computation and communication capabilities.
	DSNs are dynamic in the sense that they allow addition and deletion
	of sensor nodes after deployment to grow the network or replace failing
	and unreliable nodes. DSNs may be deployed in hostile areas where
	communication is monitored and nodes are subject to capture and surreptitious
	use by an adversary. Hence DSNs require cryptographic protection
	of communications, sensor-capture detection, key revocation and sensor
	disabling. In this paper, we present a key-management scheme designed
	to satisfy both operational and security requirements of DSNs. The
	scheme includes selective distribution and revocation of keys to
	sensor nodes as well as node re-keying without substantial computation
	and communication capabilities. It relies on probabilistic key sharing
	among the nodes of a random graph and uses simple protocols for shared-key
	discovery and path-key establishment, and for key revocation, re-keying,
	and incremental addition of nodes. The security and network connectivity
	characteristics supported by the key-management scheme are discussed
	and simulation experiments presented.},
  doi = {http://doi.acm.org/10.1145/586110.586117},
  file = {eschenauer2002.pdf:eschenauer2002.pdf:PDF},
  isbn = {1-58113-612-9},
  keywords = {key establishment, key management, sensor networks},
  location = {Washington, DC, USA},
  review = {referenced by perrig2004. Random key predistribution. Referenced by
	Traynor -- key establishment using encrypted broadcast.}
}

@INPROCEEDINGS{eskin00anomaly,
  author = {Eleazar Eskin},
  title = {{Anomaly Detection over Noisy Data using Learned Probability Distributions}},
  booktitle = {{Proc. 17th International Conf. on Machine Learning}},
  year = {2000},
  pages = {255--262},
  publisher = {Morgan Kaufmann, San Francisco, {CA}},
  abstract = {Traditional anomaly detection techniques focus on detecting anomalies
	in new data after training on normal (or clean) data. In this paper
	we present a technique for detecting anomalies without training on
	normal data. We present a method for detecting anomalies within a
	data set that contains a large number of normal elements and relatively
	few anomalies. We present a mixture model for explaining the presence
	of anomalies in the data. Motivated by the model, the approach uses
	machine learning techniques to estimate a probability distribution
	over the data and applies a statistical test to detect the anomalies.
	The anomaly detection technique is applied to intrusion detection
	by examining intrusions manifested as anomalies in UNIX system call
	traces.},
  file = {eskin00anomaly.pdf:eskin00anomaly.pdf:PDF},
  url = {citeseer.ist.psu.edu/eskin00anomaly.html}
}

@ARTICLE{eskin2001,
  author = {Eleazar Eskin and Salvatore J. Stolfo and Wenke Lee},
  title = {Modeling System Calls for Intrusion Detection with Dynamic Window
	Sizes},
  journal = {discex},
  year = {2001},
  volume = {01},
  pages = {0165},
  abstract = {We extend prior research on system call anomaly detection modeling
	methods for intrusion detection by incorporating dynamic window sizes.
	The window size is the length of the subsequence of a system call
	trace which is used as the basic unit for modeling program or process
	behavior. In this work we incorporate dynamic window sizes and show
	marked improvements in anomaly detection. We present two methods
	for estimating the optimal window size based on the available training
	data. The first method is an entropy modeling method which determines
	the optimal single window size for the data. The second method is
	a probability modeling method that takes into account context dependent
	window sizes. A context dependent window size model is motivated
	by the way that system calls are generated by processes. Sparse Markov
	transducers (SMTs) are used to compute the context dependent window
	size model. We show over actual system call traces that the entropy
	modeling methods lead to the optimal single window size. We also
	show that context dependent window sizes outperform traditional system
	call modeling methods.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/DISCEX.2001.932213},
  file = {Modeling-System-Calls-for-IDS.pdf:Modeling-System-Calls-for-IDS.pdf:PDF},
  isbn = {0-7695-1212-7},
  publisher = {IEEE Computer Society}
}

@ARTICLE{esteves-tapiador-2004,
  author = {Juan M. Estevez-Tapiador and Pedro Garcia-Teodoro and Jesus E. Diaz-Verdejo},
  title = {Anomaly detection methods in wired networks: a survey and taxonomy},
  journal = {Computer Communications},
  year = {2004},
  volume = {27},
  pages = {1569-1584},
  number = {16},
  month = {October},
  owner = {kristjan},
  timestamp = {2008.02.20},
  url = {http://www.sciencedirect.com/science/article/B6TYP-4CYPVT7-2/2/e6da080f61251cf8277912b4e4377a91}
}

@INPROCEEDINGS{estrin1999,
  author = {Estrin, Deborah and Govindan, Ramesh and Heidemann, John and Kumar,
	Satish},
  title = {Next century challenges: scalable coordination in sensor networks},
  booktitle = {{MobiCom '99}: Proceedings of the 5th annual {ACM/IEEE} international
	conference on Mobile computing and networking},
  year = {1999},
  pages = {263--270},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/313451.313556},
  file = {estrin1999.pdf:estrin1999.pdf:PDF},
  isbn = {1-58113-142-9},
  location = {Seattle, Washington, United States}
}

@MISC{europol-htc-2007,
  author = {{Europol}},
  title = {High Tech Crimes Within The {EU}: Old Crimes New Tools, New Crimes
	New Tools. Threat Assessment 2007.},
  month = {August},
  year = {2007},
  note = {Document number 247781},
  file = {:HTCThreatAssessment2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.01.28}
}

@INPROCEEDINGS{eyal2009,
  author = {Ittay Eyal and Idit Keidar and Raphael Rom},
  title = {Distributed Clustering for Robust Aggregation in Large Networks},
  booktitle = {{HotDep}},
  year = {2009},
  abstract = {We present a scalable protocol for robust data aggregation in a large,
	error-prone network. The protocol aggregates the multidimensional
	distribution of any number of data samples (sensor reads) and removes
	data errors using constant size synopses, by clustering samples and
	detecting outliers. Initial simulations show that the protocol achieves
	robustness to both crashes and data errors.},
  file = {eyal2009.pdf:eyal2009.pdf:PDF},
  keywords = {gossip protocol, anomaly deteciton, outlier detection, synopsis diffusion},
  owner = {kristjan},
  review = {Present a distributed outlier detection algorithm based on clustering
	of anomalies. Gossiping with constant size synopsis -- "normal" data
	is progressively compressed, while outliers are grouped. Allows more
	sophisticated aggregates such as 1/3 of network is at 99% cpu and
	rest is idle -- may represent DDoS attacks. Gossiping based on ideas
	from Kempe and Nath on mass conservation (problematic) and synopsis
	diffusion.
	
	
	Objective: Detect outliers by grouping data. No detection of compromised
	nodes. Crash failure model only.
	
	
	Clustering here in the sens of grouping of measurements -- not construction
	or utilization of clustered network, In contrast, the authors use
	a gossip protocol, allowing each node to view the approximate global
	state.},
  timestamp = {2010.05.22}
}

@BOOK{fagin2003,
  title = {Reasoning About Knowledge},
  publisher = {The MIT Press},
  year = {2003},
  author = {Ronald Fagin and Joseph Y. Halpern and Yoram Moses and Moshe Y. Vardi},
  owner = {kristjan},
  timestamp = {2009.08.20}
}

@INPROCEEDINGS{faloutsos1999,
  author = {Michalis Faloutsos and Petros Faloutsos and Christos Faloutsos},
  title = {On power-law relationships of the Internet topology},
  booktitle = {{SIGCOMM '99}: Proceedings of the conference on Applications, technologies,
	architectures, and protocols for computer communication},
  year = {1999},
  pages = {251--262},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Despite the apparent randomness of the Internet, we discover some
	surprisingly simple power-laws of the Internet topology. These power-laws
	hold for three snapshots of the Internet, between November 1997 and
	December 1998, despite a 45% growth of its size during that period.
	We show that our power-laws fit the real data very well resulting
	in correlation coefficients of 96% or higher.Our observations provide
	a novel perspective of the structure of the Internet. The power-laws
	describe concisely skewed distributions of graph properties such
	as the node outdegree. In addition, these power-laws can be used
	to estimate important parameters such as the average neighborhood
	size, and facilitate the design and the performance analysis of protocols.
	Furthermore, we can use them to generate and select realistic topologies
	for simulation purposes.},
  doi = {http://doi.acm.org/10.1145/316188.316229},
  file = {faloutsos1999.pdf:faloutsos1999.pdf:PDF},
  isbn = {1-58113-135-6},
  location = {Cambridge, Massachusetts, United States}
}

@ARTICLE{fasolo2007,
  author = {Fasolo, E. and Rossi, M. and Widmer, J. and Zorzi, M.},
  title = {In-network aggregation techniques for wireless sensor networks: a
	survey},
  journal = {Wireless Communications, {IEEE}},
  year = {2007},
  volume = {14},
  pages = {70-87},
  number = {2},
  month = {April },
  abstract = {In this article we provide a comprehensive review of the existing
	literature on techniques and protocols for in-network aggregation
	in wireless sensor networks. We first define suitable criteria to
	classify existing solutions, and then describe them by separately
	addressing the different layers of the protocol stack while highlighting
	the role of a cross-layer design approach, which is likely to be
	needed for optimal performance. Throughout the article we identify
	and discuss open issues, and propose directions for future research
	in the area.},
  doi = {10.1109/MWC.2007.358967},
  file = {fasolo2007.pdf:fasolo2007.pdf:PDF},
  issn = {1536-1284},
  keywords = {protocols, wireless sensor networkscross-layer design, in-network
	aggregation techniques, wireless sensor networks},
  review = {A fairly good survey of distributed aggregation in sensor networks.
	Considers structured SNs -- trees, multipath. 
	
	
	Interesting discussion on distributed source coding -- Leave for later.}
}

@INPROCEEDINGS{feige1990,
  author = {Feige, U. and Shamir, A.},
  title = {Witness indistinguishable and witness hiding protocols},
  booktitle = {{STOC} '90: Proceedings of the twenty-second annual ACM symposium
	on Theory of computing},
  year = {1990},
  pages = {416--426},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A two p a r t y protocol in which p a r t y A uses one of several
	secret witnesses to an NP assertion is witness indistinguishable
	if p a r t y B cannot tell which witness A is actually using. The
	protocol is witness hiding if by the end of the protocol B cannot
	compute any new witness which he did not know before the protocol
	began. Witness hiding is a natural security requirement, and can
	replace zero knowledge in m a n y cryptographic protocols.
	
	 We prove two central results: 1. Unlike zero knowledge protocols,
	witness indistinguishablity is preserved under arbitrary composition
	of protocols, including parallel execution. 2. If a statement has
	at least two independent witnesses, then any witness indistinguishable
	protocol for this statement is also witness hiding.
	
	 Using these results, we show how to overcome some of the difficulties
	associated with cryptographic schemes based on zero knowledge protocols.
	In particular, we show how to parallelize identification protocols
	without loss of security, how to construct bounded round zero knowledge
	arguments for any NP s t a t e m e n t under the sole assumption
	that oneway functions exist, and how to use the Bellare-Goldwasser
	signature scheme to sign polynomially m a n y messages in a completely
	memoryless way.},
  doi = {http://doi.acm.org/10.1145/100216.100272},
  file = {feige1990.pdf:feige1990.pdf:PDF},
  isbn = {0-89791-361-2},
  keywords = {witness indistinguishable protocol, security, cryptography},
  location = {Baltimore, Maryland, United States}
}

@INPROCEEDINGS{feldman2004,
  author = {Michal Feldman and Kevin Lai and Ion Stoica and John Chuang},
  title = {Robust incentive techniques for peer-to-peer networks},
  booktitle = {EC '04: Proceedings of the 5th ACM conference on Electronic commerce},
  year = {2004},
  pages = {102--111},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Lack of cooperation (free riding) is one of the key problems that
	confronts today's P2P systems. What makes this problem particularly
	difficult is the unique set of challenges that P2P systems pose:
	large populations, high turnover, a symmetry of interest, collusion,
	zero-cost identities, and traitors. To tackle these challenges we
	model the P2P system using the Generalized Prisoner's Dilemma (GPD),and
	propose the Reciprocative decision function as the basis of a family
	of incentives techniques. These techniques are fullydistributed and
	include: discriminating server selection, maxflow-based subjective
	reputation, and adaptive stranger policies. Through simulation, we
	show that these techniques can drive a system of strategic users
	to nearly optimal levels of cooperation.},
  doi = {http://doi.acm.org/10.1145/988772.988788},
  file = {feldman2004.pdf:feldman2004.pdf:PDF},
  isbn = {1-58113-711-0},
  location = {New York, NY, USA}
}

@INPROCEEDINGS{feldman1988,
  author = {Feldman, Paul and Micali, Silvio},
  title = {Optimal algorithms for Byzantine agreement},
  booktitle = {{STOC} '88: Proceedings of the twentieth annual {ACM} symposium on
	Theory of computing},
  year = {1988},
  pages = {148--161},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We exhibit randomized Byzantine agreement (BA) algorithms achieving
	optimal running time and fault tolerance against all types of adversaries
	ever considered in the literature. Our BA algorithms do not require
	trusted parties, preprocessing, or non-constructive arguments. Given
	private communication lines, we show that n processors can reach
	BA in expected constant time in a syncronous network if any < n/3
	faults occur in an asynchronous network if any < n/4 faults occur
	For both synchronous and asynchronous networks whose lines do not
	guarantee private communication, we may use cryptography to obtain
	algorithms optimal both in fault tolerance and running time against
	computationally bounded adversaries. (Thus, in this setting, we tolerate
	up to n/3 faults even in an asynchronous network.)},
  doi = {http://doi.acm.org/10.1145/62212.62225},
  file = {feldman1988.pdf:feldman1988.pdf:PDF},
  isbn = {0-89791-264-0},
  location = {Chicago, Illinois, United States}
}

@INPROCEEDINGS{felt2008,
  author = {Adrienne Felt and David Evans},
  title = {Privacy Protection for Social Networking Platforms},
  booktitle = {Workshop on Web 2.0 Security and Privacy},
  year = {2008},
  address = {Oakland, CA},
  month = {May},
  abstract = {Social networking platforms integrate third-party con-
	
	tent into social networking sites and give third-party
	
	developers access to user data. These open interfaces
	
	enable popular site enhancements but pose serious pri-
	
	vacy risks by exposing user data to third-party devel-
	
	opers. We address the privacy risks associated with so-
	
	cial networking APIs by presenting a privacy-by-proxy
	
	design for a privacy-preserving API. Our design is mo-
	
	tivated by an analysis of the data needs and uses of
	
	Facebook applications. We studied 150 popular Face-
	
	book applications and found that nearly all applica-
	
	tions could maintain their functionality using a limited
	
	interface that only provides access to an anonymized
	
	social graph and placeholders for user data. Since the
	
	platform host can control the third party applications’
	
	output, privacy-by-proxy can be accomplished by us-
	
	ing new tags and data transformations without major
	
	changes to either the platform architecture or applica-
	
	tions.},
  file = {felt2008.pdf:felt2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.25}
}

@INPROCEEDINGS{felten1997,
  author = {Edward W. Felten and Dirk Balfanz and Drew Dean and Dan S. Wallach},
  title = {Web Spoofing: An Internet Con Game},
  booktitle = {20th National Information Systems Security Conference},
  year = {1997},
  address = {Baltimore, Maryland},
  month = {October},
  abstract = {This paper describes an Internet security attack that could endanger
	the privacy of World Wide Web users and the integrity of their data.
	The attack can be carried out on today's systems, endangering users
	of the most common Web browsers, including Netscape Navigator and
	Microsoft Internet Explorer. Web spoofing allows an attacker to create
	a "shadow copy" of the entire World Wide Web. Accesses to the shadow
	Web are funneled through the attacker's machine, allowing the attacker
	to monitor all of the victim's activities including any passwords
	or account numbers the victim enters. The attacker can also cause
	false or misleading data to be sent to Web servers in the victim's
	name, or to the victim in the name of any Web server. In short, the
	attacker observes and controls everything the victim does on the
	Web. We have implemented a demonstration version of this attack.},
  file = {felten_spoofing.pdf:felten_spoofing.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.08}
}

@INPROCEEDINGS{felten2000,
  author = {Edward W. Felten and Michael A. Schneider},
  title = {Timing attacks on Web privacy},
  booktitle = {CCS '00: Proceedings of the 7th ACM conference on Computer and communications
	security},
  year = {2000},
  pages = {25--32},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We describe a class of attacks that can compromise the privacy of
	
	users’ Web-browsing histories. The attacks allow a malicious Web
	
	site to determine whether or not the user has recently visited some
	
	other, unrelated Web page. The malicious page can determine this
	
	information by measuring the time the user’s browser requires to
	
	perform certain operations. Since browsers perform various forms
	
	of caching, the time required for operations depends on the user’s
	
	browsing history; this paper shows that the resulting time variations
	
	convey enough information to compromise users’ privacy. This at-
	
	tack method also allows other types of information gathering by
	
	Web sites, such as a more invasive form of Web “cookies”. The
	
	attacks we describe can be carried out without the victim’s knowl-
	
	edge, and most “anonymous browsing” tools fail to prevent them.
	
	Other simple countermeasures also fail to prevent these attacks. We
	
	describe a way of reengineering browsers to prevent most of them.},
  doi = {http://doi.acm.org/10.1145/352600.352606},
  file = {:p25-felten.pdf:PDF},
  isbn = {1-58113-203-4},
  location = {Athens, Greece}
}

@INPROCEEDINGS{feng2008,
  author = {Taiming Feng and Chuang Wang and Wensheng Zhang and Lu Ruan},
  title = {Confidentiality Protection for Distributed Sensor Data Aggregation},
  booktitle = {{IEEE INFOCOM}. The 27th Conference on Computer Communications},
  year = {2008},
  pages = {56-60},
  month = {April},
  abstract = {Efficiency and security are two basic requirements for sensor network
	design. However, these requirements could be sharply contrary to
	each other in some scenarios. For example, in- network data aggregation
	can significantly reduce communication overhead and thus has been
	adopted widely as a means to improve network efficiency; however,
	the adoption of in-network data aggregation may prevent data from
	being encrypted since it is a prerequisite for aggregation that data
	be accessible during forwarding. In this paper, we address this dilemma
	by proposing a family of secret perturbation-based schemes that can
	protect sensor data confidentiality without disrupting additive data
	aggregation. Extensive simulations are also conducted to evaluate
	the proposed schemes. The results show that our schemes provide confidentiality
	protection for both raw and aggregated data items with an overhead
	lower than that of existing related schemes.},
  doi = {10.1109/INFOCOM.2008.20},
  file = {feng2008.pdf:feng2008.pdf:PDF},
  issn = {0743-166X},
  keywords = {telecommunication security, wireless sensor networksconfidentiality
	protection, distributed sensor data aggregation, network security,
	secret perturbation-based scheme, wireless sensor network},
  owner = {kristjan}
}

@MISC{fielding_rfc2616_1999,
  author = {R. Fielding and J. Gettys and J. Mogul and H. Frystyk and L. Masinter
	and P. Leach and T. Berners-Lee},
  title = {RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1},
  month = {June},
  year = {1999},
  owner = {kristjan},
  timestamp = {2009.02.27},
  url = {http://www.w3.org/Protocols/rfc2616/rfc2616.html}
}

@MISC{fips-197-2001,
  author = {{FIPS}},
  title = {{Federal Information Processing Standards Publication 107. Announcing
	the Advanced Encryption Standard (AES)}},
  howpublished = {[online] \url{http://www.csrc.nist.gov/publications/fips/fips197/fips-197.pdf}},
  month = {November},
  year = {2001},
  owner = {kristjan},
  timestamp = {2010.03.15},
  url = {http://www.csrc.nist.gov/publications/fips/fips197/fips-197.pdf}
}

@TECHREPORT{fischer2000,
  author = {Michael J. Fischer},
  title = {The Consensus Problem in Unreliable Distributed Systems (A Brief
	Survey)},
  institution = {Yale University},
  year = {2000},
  number = {YALEU/DCS/TR-273},
  address = {New Haven, Conneticut},
  abstract = {Agreement problems involve a system of processes, some of which may
	be faulty. A fundamental problem of fault-tolerant distributed computing
	is for the reliable processes to reach a consensus. We survey the
	considerable literature on this problem that has developed over the
	past few years and give an informal overview of the major theoretical
	results in the area.},
  file = {fischer2000.pdf:fischer2000.pdf:PDF}
}

@ARTICLE{fischer1985,
  author = {Fischer, Michael J. and Lynch, Nancy A. and Paterson, Michael S.},
  title = {Impossibility of distributed consensus with one faulty process},
  journal = {{J. ACM}},
  year = {1985},
  volume = {32},
  pages = {374--382},
  number = {2},
  abstract = {The consensus problem involves an asynchronous system of processes,
	some of which may be unreliable. The problem is for the reliable
	processes to agree on a binary value. In this paper, it is shown
	that every protocol for this problem has the possibility of nontermination,
	even with only one faulty process. By way of contrast, solutions
	are known for the synchronous case, the “Byzantine Generals” problem.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/3149.214121},
  file = {fischer1985.pdf:fischer1985.pdf:PDF},
  issn = {0004-5411},
  publisher = {ACM},
  review = {The FLP impossibility proof.}
}

@ARTICLE{fischler1981,
  author = {Fischler, Martin A. and Bolles, Robert C.},
  title = {Random sample consensus: a paradigm for model fitting with applications
	to image analysis and automated cartography},
  journal = {{Commun. ACM}},
  year = {1981},
  volume = {24},
  pages = {381--395},
  number = {6},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model
	to experimental data is introduced. RANSAC is capable of interpreting/smoothing
	data containing a significant percentage of gross errors, and is
	thus ideally suited for applications in automated image analysis
	where interpretation is based on the data provided by error-prone
	feature detectors. A major portion of this paper describes the application
	of RANSAC to the Location Determination Problem (LDP): Given an image
	depicting a set of landmarks with known locations, determine that
	point in space from which the image was obtained. In response to
	a RANSAC requirement, new results are derived on the minimum number
	of landmarks needed to obtain a solution, and algorithms are presented
	for computing these minimum-landmark solutions in closed form. These
	results provide the basis for an automatic system that can solve
	the LDP under difficult viewing},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/358669.358692},
  file = {fischler1981.pdf:fischler1981.pdf:PDF},
  issn = {0001-0782},
  keywords = {Random sample consensus, RANBAR, model fitting},
  publisher = {ACM},
  review = {See RANBAR paper -- buttyan2006 -- for an application of this method.
	Used there to remove outliers in dataset to improve robustness.}
}

@ARTICLE{flajolet1985,
  author = {Philippe Flajolet and G. Nigel Martin},
  title = {Probabilistic counting algorithms for data base applications},
  journal = {J. Comput. Syst. Sci.},
  year = {1985},
  volume = {31},
  pages = {182--209},
  number = {2},
  address = {Orlando, FL, USA},
  doi = {http://dx.doi.org/10.1016/0022-0000(85)90041-8},
  issn = {0022-0000},
  publisher = {Academic Press, Inc.}
}

@ARTICLE{flaxman2008,
  author = {Abraham D. Flaxman},
  title = {Expansion and Lack Thereof in Randomly Perturbed Graphs},
  year = {2008},
  pages = {24--35},
  abstract = {This paper studies the expansion properties of randomly perturbed
	graphs. These graphs are formed by, for example, adding a random
	$1{\text{-out}}$ or very sparse Erdős-Rényi graph to an arbitrary
	connected graph.
	
	
	The central results show that there exists a constant ¿ such that
	when any connected n-vertex base graph $\bar{G}$ is perturbed by
	adding a random 1-out then, with high probability, the resulting
	graph has $e(S,\bar S) \geq \delta |S|$ for all S ¿ V with $|S| \leq
	\frac34 n$. When $\bar{G}$ is perturbed by adding a random Erdős-Rényi
	graph, $\mathbb{G}_{n,\epsilon/n}$, the expansion of the perturbed
	graph depends on the structure of the base graph. A necessary condition
	for the base graph is given under which the resulting graph is an
	expander with high probability.
	
	
	The proof techniques are also applied to study rapid mixing in the
	small worlds graphs described by Watts and Strogatz in [Nature 292
	(1998), 440---442] and by Kleinberg in [Proc. of 32nd ACM Symposium
	on Theory of Computing (2000), 163---170]. Analysis of Kleinberg's
	model shows that the graph stops being an expander exactly at the
	point where a decentralized algorithm is effective in constructing
	a short path.
	
	
	The proofs of expansion rely on a way of summing over subsets of vertices
	which allows an argument based on the First Moment Method to succeed.},
  address = {Berlin, Heidelberg},
  book = {Algorithms and Models for the Web-Graph: Fourth International Workshop,
	WAW 2006, Banff, Canada, November 30 - December 1, 2006. Revised
	Papers},
  doi = {http://dx.doi.org/10.1007/978-3-540-78808-9_3},
  file = {:TR-2006-118.pdf:PDF},
  isbn = {978-3-540-78807-2},
  publisher = {Springer-Verlag}
}

@ARTICLE{floyd2001,
  author = {Sally Floyd and Vern Paxson},
  title = {Difficulties in simulating the internet},
  journal = {{IEEE/ACM Trans. Netw.}},
  year = {2001},
  volume = {9},
  pages = {392--403},
  number = {4},
  abstract = {Simulating how the global Internet behaves is an immensely challenging
	undertaking because of the network's great heterogeneity and rapid
	change. The heterogeneity ranges from the individual links that carry
	the network's traffic, to the protocols that interoperate over the
	links, the "mix" of different applications used at a site, and the
	levels of congestion seen on different links. We discuss two key
	strategies for developing meaningful simulations in the face of these
	difficulties: searching for invariants and judiciously exploring
	the simulation parameter space. We finish with a brief look at a
	collaborative effort within the research community to develop a common
	network simulator.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/90.944338},
  file = {floyd2001.pdf:floyd2001.pdf:PDF},
  issn = {1063-6692},
  keywords = {networks, modeling, simulation, network simulator},
  publisher = {IEEE Press}
}

@BOOK{fogie2007xss,
  title = {{XSS Attacks: Cross Site Scripting Exploits and Defense}},
  publisher = {Syngress},
  year = {2007},
  author = {Seth Fogie and Jeremiah Grossman and Robert Hansen and Anton Rager
	and Petko D. Petkov},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://www.syngress.com/catalog/?pid=4360}
}

@ARTICLE{fontaine2007,
  author = {Caroline Fontaine and Fabien Galand},
  title = {A Survey of Homomorphic Encryption for Nonspecialists},
  journal = {{EURASIP} Journal on Information Security},
  year = {2007},
  volume = {2007},
  abstract = {Processing encrypted signals requires special properties of the underlying
	encryption scheme. A possible choice is the use of homomorphic encryption.
	In this paper, we propose a selection of the most important available
	solutions, discussing their properties and limitations.},
  file = {fontaine2007.pdf:fontaine2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.09}
}

@INPROCEEDINGS{ford2005,
  author = {Bryan Ford},
  title = {Peer-to-peer communication across network address translators},
  booktitle = {{USENIX} Annual Technical Conference},
  year = {2005},
  pages = {179--192},
  abstract = {J’fais des trous, des petits trous... toujours des petits trous- S.
	Gainsbourg Network Address Translation (NAT) causes well-known difficulties
	for peer-to-peer (P2P) communication, since the peers involved may
	not be reachable at any globally valid IP address. Several NAT traversal
	techniques are known, but their documentation is slim, and data about
	their robustness or relative merits is slimmer. This paper documents
	and analyzes one of the simplest but most robust and practical NAT
	traversal techniques, commonly known as “hole punching. ” Hole punching
	is moderately well-understood for UDP communication, but we show
	how it can be reliably used to set up peer-to-peer TCP streams as
	well. After gathering data on the reliability of this technique on
	a wide variety of deployed NATs, we find that about 82 % of the NATs
	tested support hole punching for UDP, and about 64 % support hole
	punching for TCP streams. As NAT vendors become increasingly conscious
	of the needs of important P2P applications such as Voice over IP
	and online gaming protocols, support for hole punching is likely
	to increase in the future.},
  file = {:10.1.1.59.6799.pdf:PDF},
  keywords = {networks, network operation, NAT, NAT traversal, hole punching}
}

@ARTICLE{forrest1996,
  author = {Stephanie Forrest and Steven A. Hofmeyr and Anil Somayaji and Thomas
	A. Longstaff},
  title = {A Sense of Self for Unix Processes},
  journal = {sp},
  year = {1996},
  volume = {00},
  pages = {0120},
  abstract = {A method for anomaly detection is introduced in which “normal” is
	deﬁned by short-range correlations in a process’ system calls. Initial
	experiments suggest that the deﬁnition is stable during normal behavior
	for standard UNIX programs. Further, it is able to detect several
	common intrusions involving sendmail and lpr. This work is part of
	a research program aimed at building computer security systems that
	incorporate the mechanisms and algorithms used by natural immune
	systems.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SECPRI.1996.502675},
  file = {ieee-sp-96-unix.pdf:ieee-sp-96-unix.pdf:PDF},
  issn = {1540-7993},
  publisher = {IEEE Computer Society}
}

@INCOLLECTION{fouladgar2006,
  author = {Sepideh Fouladgar and Bastien Mainaud and Khaled Masmoudi and Hossam
	Afifi},
  title = {{Tiny 3-TLS}: A Trust Delegation Protocol for Wireless Sensor Networks},
  booktitle = {Security and Privacy in Ad-Hoc and Sensor Networks},
  publisher = {Springer Berlin/Heidelberg},
  year = {2006},
  volume = {4357/2006},
  series = {Lecture Notes in Computer Science},
  abstract = {Adapting security protocols to wireless sensor networks architectures
	is a challenging research field because of their specific constraints.
	Actually, sensors are computationally weak devices, unable to perform
	heavy cryptographic operations like classical asymmetric algorithms
	(RSA, Diffie-Hellman). In this paper, we introduce Tiny 3-TLS, an
	extension and adaptation of TLS handshake sub-protocol that allows
	establishing secure communications between sensing nodes and remote
	monitoring terminals. Our protocol aims at guaranteeing the integrity
	and confidentiality of communications between sensors and distant
	terminals, after having established mutual authentication between
	the two parties. In order to achieve these security goals without
	putting too much burden on sensing devices, Tiny 3-TLS rely on an
	intermediate node, the sink node. Depending on the trustworthiness
	of this sink node and on the applications, we propose two versions
	of our proposition. Besides, we provide a formal validation of the
	protocol’s security goals achievement and an evaluation of its computation
	and delay performances.},
  file = {fouladgar2006.pdf:fouladgar2006.pdf:PDF},
  keywords = {sensor networks, security},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{fouque2000,
  author = {Pierre-alain Fouque and David Pointcheval and École Normale Supérieure
	Département},
  title = {Threshold Cryptosystems Secure against Chosen-Ciphertext Attacks},
  booktitle = {In Proc. of Asiacrypt},
  year = {2000},
  pages = {351--368},
  publisher = {SpringerVerlag},
  __markedentry = {[kristjan]},
  abstract = {Semantic security against chosen-ciphertext attacks (IND-CCA) is widely
	believed as the correct security level for public-key encryption
	scheme. On the other hand, it is often dangerous to give to only
	one people the power of decryption. Therefore, threshold cryptosystems
	aimed at distributing the decryption ability. However, only two efficient
	such schemes have been proposed so far for achieving IND-CCA. Both
	are El Gamal-like schemes and thus are based on the same intractability
	assumption, namely the Decisional Diffie-Hellman problem. In this
	article we rehabilitate the twin-encryption paradigm proposed by
	Naor and Yung to present generic conversions from a large family
	of (threshold) IND-CPA scheme into a (threshold) IND-CCA one in the
	random oracle model. An efficient instantiation is also proposed,
	which is based on the Paillier cryptosystem. This new construction
	provides the first example of threshold cryptosystem secure against
	chosen-ciphertext attacks based on the factorization problem. Moreover,
	this construction provides a scheme where the “homomorphic properties
	” of the original scheme still hold. This is rather cumbersome because
	homomorphic cryptosystems are known to be malleable and therefore
	not to be CCA secure. However, we do not build a “homomorphic cryptosystem”,
	but just keep the homomorphic properties.},
  file = {fouque2000.pdf:fouque2000.pdf:PDF},
  keywords = {cryptosystem, homomorphic, non-malleable, IND-CCA}
}

@INPROCEEDINGS{fraleigh2001,
  author = {Chuck Fraleigh and Christophe Diot and Bryan Lyles and Sue Moon Philippe
	Owezarski and Dina Papagiannaki and Fouad Tobagi},
  title = {Design and Deployment of a Passive Monitoring Infrastructure},
  booktitle = {In Passive and Active Measurement Workshop},
  year = {2001},
  pages = {2001},
  abstract = {This paper presents the architecture of a passive monitoring system
	installed within the Sprint IP backbone network. This system differs
	from other packet monitoring systems in that it collects packet-level
	traces from multiple links within the network and provides the capability
	to correlate the data using highly accurate GPS timestamps. After
	a thorough description of the monitoring systems, we demonstrate
	the system's capabilities and the diversity of the results that can
	be obtained from the collected data. These results include workload
	characterization, packet size analysis, and packet delay incurred
	through a single backbone router. We conclude with lessons learned
	from the development of the monitoring infrastructure and present
	future research goals.},
  file = {fraleigh2001.pdf:fraleigh2001.pdf:PDF}
}

@INPROCEEDINGS{Francis1999,
  author = {P. Francis and S. Jamin and C. Jin and Y. Jin and D. Raz and Y. Shavitt
	and L. Zhang},
  title = {An Architecture for a Global Internet Host Distance Estimation Service},
  booktitle = {In Proceedings of {IEEE INFOCOM}},
  year = {1999},
  pages = {210--217},
  abstract = {There is an increasing need to quickly and efﬁciently learn network
	distances, in terms of metrics such as latency or bandwidth, between
	Internet hosts. For example, Internet content providers often place
	data and server mirrors throughout the Internet to improve access
	latency for clients, and it is necessary to direct clients to the
	nearst mirrors based on some distance metric in order to realize
	the beneﬁt of mirrors. We suggest a scalable Internet-wide architecture,
	called IDMaps, which measures and disseminates distance information
	on the global Internet. Higher-level services can collect such distance
	information to build a virtual distance map of the Internet and estimate
	the distance between any pair of IP addresses. We present our solutions
	to the measurement server placement and distance map construction
	problems in IDMaps. We show that IDMaps can indeed provide useful
	distance estimations to applications such as nearest mirror selection.},
  file = {:10.1.1.28.8826.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.12.05}
}

@INPROCEEDINGS{franklin1995,
  author = {Matthew Franklin and Moti Yung},
  title = {Secure Hypergraphs: Privacy from Partial Broadcast},
  booktitle = {In Proceedings of the Twenty-Seventh Annual {ACM} Symposium on the
	Theory of Computing},
  year = {1995},
  pages = {36--44},
  publisher = {ACM Press},
  abstract = {A \partial broadcast channel" enables one processor to send the same
	message|simultaneously and privately to a xed subset of processors.
	Suppose that a collection of processors are connected by an arbitrary
	network of partial broadcast channels (a hypergraph). We initiate
	the study of necessary and su cient conditions, complexity bounds,
	and protocols for individual processors to exchange private messages
	across this network. Private message exchange, in turn, enables the
	realization of general secure computation primitives. The model (motivated
	by various environments such as multicast network architectures and
	group communication in distributed systems) is an intermediate setting
	between the private channels model and the full information model,
	both of which have been investigated extensively in the last few
	years. We assume an all-powerful adversary (i.e., the information
	theoretic notion of security), and our techniques are combinatorial.
	Both the possibility and the polynomial-time feasibility of private
	message exchange are investigated.},
  file = {franklin1995.pdf:franklin1995.pdf:PDF}
}

@MISC{Frederick2004,
  author = {Frederick Ducatelle, Gianni Di Caro and Luca Maria Gambardella},
  title = {Ant Agents for Hybrid Multipath Routing in Mobile Ad-Hoc Networks},
  year = {2004},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{freedman2002,
  author = {Michael J. Freedman and Robert Morris},
  title = {Tarzan: A peer-to-peer anonymizing network layer},
  booktitle = {In Proceedings of the 9th ACM Conference on Computer and Communications
	Security (CCS 2002)},
  year = {2002},
  abstract = {Tarzan is a peer-to-peer anonymous IP network overlay. Because it
	provides IP service, Tarzan is general-purpose and transparent to
	applications. Organized as a decentralized peer-to-peer overlay,
	Tarzan is fault-tolerant, highly scalable, and easy to manage. Tarzan
	achieves its anonymity with layered encryption and multi-hop routing,
	much like a Chaumian mix. A message initiator chooses a path of peers
	pseudo-randomly through a restricted topology in a way that adversaries
	cannot easily inﬂuence. Cover trafﬁc prevents a global observer from
	using trafﬁc analysis to identify an initiator. Protocols toward
	unbiased peer-selection offer new directions for distributing trust
	among untrusted entities. Tarzan provides anonymity to either clients
	or servers, without requiring that both participate. In both cases,
	Tarzan uses a network address translator (NAT) to bridge between
	Tarzan hosts and oblivious Internet hosts. Measurements show that
	Tarzan imposes minimal overhead over a corresponding non-anonymous
	overlay route.},
  file = {10.1.1.19.9397.pdf:10.1.1.19.9397.pdf:PDF}
}

@ARTICLE{freeman1979,
  author = {Linton C. Freeman},
  title = {Centrality in Social Networks. Conceptual Clarification},
  journal = {Social Networks},
  year = {1979},
  volume = {1},
  pages = {215-239},
  abstract = {The intuitive background for measures of structural centrality in
	social
	
	networks is reviewed aPzd existing measures are evaluated in terms
	of their
	
	consistency with intuitions and their interpretability.
	
	 Three distinct intuitive conceptions of centrality are uncovered
	and
	
	existing measures are refined to embody these conceptions. Three measures
	
	are developed for each concept, one absolute and one relative measure
	of the
	
	centrality of positions in a network and one relenting the degree
	of centrali-
	
	zation of the entire network. The implications of these measures for
	the
	
	experimental study of small groups is examined.},
  file = {freeman1979.pdf:freeman1979.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.22}
}

@ARTICLE{freeman1977,
  author = {Linton C. Freeman},
  title = {A Set of Measures of Centrality Based on Betweenness},
  journal = {Sociometry},
  year = {1977},
  volume = {40},
  pages = {35-41},
  number = {1},
  month = {March},
  abstract = {A Family of new measures of point and graph centrality based on early
	intuitions of Bavelas (1948) is introduced. These measures define
	centrality in terms of the degree to which a point falls on the shortest
	path between others and therefore has a potential for control of
	communication. They may be used to index centrality in any large
	or small network of symmetrical relations, whether connected or unconnected.},
  owner = {kristjan},
  timestamp = {2009.04.22},
  url = {http://www.jstor.org/pss/3033543}
}

@ARTICLE{frey1999,
  author = {Gerhard Frey and Michael M\"{u}ller and Hans-Georg R\"{u}ck},
  title = {The Tate Pairing and the Discrete Logarithm Applied to Elliptic Curve
	Cryptosystems},
  journal = {{IEEE} Transactions on Information Theory},
  year = {1999},
  volume = {45},
  pages = {1717-1719},
  number = {5},
  file = {frey1999.pdf:frey1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@ARTICLE{friedman2007,
  author = {Roy Friedman and Daniela Gavidia and Luis Rodrigues and Aline Carneiro
	Viana and Spyros Voulgaris},
  title = {Gossiping on {MANETs}: the beauty and the beast},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {2007},
  volume = {41},
  pages = {67--74},
  number = {5},
  abstract = {Gossip protocols have emerged as a powerful technique for implementing
	highly scalable and robust services, such as information dissemination
	and aggregation. The fact that gossip protocols require very little
	or no structure to operate makes them particularly appealing to apply
	in dynamic systems, where topology changes are common (for instance,
	due to frequent faults or high churn rates). Therefore, gossip protocols
	seem particularly well fit to operate in wireless self-organizing
	networks. Unfortunately, these networks have a number of characteristics
	that impede the deployment of gossip protocols designed for wired
	networks. In this work we identify the inherent differences in communication
	between wired and wireless networks and their impact on the design
	and implementation of gossip protocols. In particular, our comparison
	includes drawing a distinction between the gossiping primitives suitable
	for each of these environments. In the context of this analysis,
	we conclude by presenting a list of open research questions.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1317379.1317390},
  file = {friedman2007.pdf:friedman2007.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM}
}

@INPROCEEDINGS{frikken2008,
  author = {Frikken, Keith B. and Dougherty,IV, Joseph A.},
  title = {An efficient integrity-preserving scheme for hierarchical sensor
	aggregation},
  booktitle = {{WiSec '08}: Proceedings of the first {ACM} conference on Wireless
	network security},
  year = {2008},
  pages = {68--76},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Sensor networks have proven to be useful in many application domains.
	Having the sensor nodes aggregate their results inside the network
	before sending the results to a base station has been shown to increase
	the lifetime of the network. However, sensor networks that are deployed
	in hostile environments need aggregation protocols that protect the
	integrity of the result. Recently, Chan et al. [3] introduced such
	a scheme that requires O(Δlog2n) communication per node, where Δ$
	is the degree of the aggregation tree for the network and n is the
	number of nodes in the network. In this paper, we introduce modifications
	of this approach that reduce the maximum communication per node to
	O(Δlog n).},
  doi = {http://doi.acm.org/10.1145/1352533.1352546},
  file = {frikken2008.pdf:frikken2008.pdf:PDF},
  isbn = {978-1-59593-814-5},
  location = {Alexandria, VA, USA}
}

@ARTICLE{fu2002,
  author = {Kevin Fu and M. Frans Kaashoek and David Mazi\`{e}res},
  title = {Fast and secure distributed read-only file system},
  journal = {ACM Trans. Comput. Syst.},
  year = {2002},
  volume = {20},
  pages = {1--24},
  number = {1},
  abstract = {Internet users increasingly rely on publicly available data for everything
	from software installation to investment decisions. Unfortunately,
	the vast majority of public content on the Internet comes with no
	integrity or authenticity guarantees. This paper presents the self-certifying
	read-only ﬁle system, a content distribution system providing secure,
	scalable access to public, read-only data.
	
	 The read-only ﬁle system makes the security of published content
	independent from that of the distribution infrastructure. In a secure
	area (perhaps off-line), a publisher creates a digitally signed database
	out of a ﬁle system’s contents. The publisher then replicates the
	database on untrusted content-distribution servers, allowing for
	high availability.
	
	 The read-only ﬁle system avoids performing any cryptographic operations
	on servers and keeps the overhead of cryptography low on clients,
	allowing servers to scale to a large number of clients. Measurements
	of an implementation show that an individual server running on a
	550-Mhz Pentium III with FreeBSD can support 1,012 connections per
	second and 300 concurrent clients compiling a large software package.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/505452.505453},
  file = {fu2002.pdf:fu2002.pdf:PDF},
  issn = {0734-2071},
  publisher = {ACM},
  review = {referenced by sit2002 on self certifying path names to ensure authenticity
	of data in DHTs.}
}

@MISC{fultz,
  author = {Neal Fultz},
  title = {Distributed attacks as security games},
  abstract = {Due to the development of easy-to-use software, distributed denial
	of service attacks have gone from theoretical weapons to being in
	the hands of criminals in less than twenty years. This paper analyzes
	the threat of DDoS attacks by developing a two-sided multiplayer
	model of security in which attackers attempt to deny service and
	defenders attempt to protect against attacks. Key ﬁndings include
	the existence of protection and non-attack Nash equilibria among
	diﬀerent conﬁgurations of contribution functions and numbers of players,
	and validation of this model against infection data. I ﬁnd that strategic
	attackers launch attacks only if protection will not occur. Therefore,
	the threat of protection can be enough to deter an attacker, but
	as the number of attackers grows, this equilibrium becomes increasingly
	unstable.},
  file = {:nfultz.pdf:PDF},
  keywords = {networks, security, attacks, DDoS, game theory, Nash equilibria},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{galbraith2002,
  author = {Galbraith, Steven D. and Harrison, Keith and Soldera, David},
  title = {Implementing the Tate Pairing},
  booktitle = {{ANTS-V}: Proceedings of the 5th International Symposium on Algorithmic
	Number Theory},
  year = {2002},
  pages = {324--337},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {galbraith2002.pdf:galbraith2002.pdf:PDF},
  isbn = {3-540-43863-7}
}

@INPROCEEDINGS{gamer2009,
  author = {Thomas Gamer and Cristoph Mayer},
  title = {Large-scale Evaluation of Distributed Attack Detection},
  booktitle = {{2nd OMNeT++ Workshop}},
  year = {2009},
  file = {gamer2009.pdf:gamer2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@INPROCEEDINGS{gamer2008,
  author = {Thomas Gamer and Michael Scharf},
  title = {Realistic Simulation Environments for {IP}-based Networks},
  booktitle = {{1st OMNeT++ Workshop}},
  year = {2008},
  month = {March},
  note = {ReaSE},
  abstract = {During development of new protocols and systems researchers in most
	cases use simulations for evaluation of their product, especially
	in the area of communication networks. The quality of the simulation
	environment, however, signiﬁcantly inﬂuences the quality of a product’s
	evaluation. Therefore, simulation environments as realistic as possible
	are necessary in order to get reliable results. In this paper we
	present ReaSE, a tool for creation of such realistic environments.
	It considers multiple aspects: topology generation – on AS level
	as well as on router level –, traﬃc patterns, and attack traﬃc. Furthermore,
	ReaSE is based on current state of the art solutions.},
  file = {rease_omnet2008.pdf:rease_omnet2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{ganeriwal2008,
  author = {Saurabh Ganeriwal and Laura K. Balzano and Mani B. Srivastava},
  title = {Reputation-based framework for high integrity sensor networks},
  year = {2008},
  volume = {4},
  number = {3},
  pages = {1--37},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Sensor network technology promises a vast increase in automatic data
	collection capabilities through efficient deployment of tiny sensing
	devices. The technology will allow users to measure phenomena of
	interest at unprecedented spatial and temporal densities. However,
	as with almost every data-driven technology, the many benefits come
	with a significant challenge in data reliability. If wireless sensor
	networks are really going to provide data for the scientific community,
	citizen-driven activism, or organizations which test that companies
	are upholding environmental laws, then an important question arises:
	How can a user trust the accuracy of information provided by the
	sensor network&quest; Data integrity is vulnerable to both node and
	system failures. In data collection systems, faults are indicators
	that sensor nodes are not providing useful information. In data fusion
	systems the consequences are more dire; the final outcome is easily
	affected by corrupted sensor measurements, and the problems are no
	longer visibly obvious.
	
	
	In this article, we investigate a generalized and unified approach
	for providing information about the data accuracy in sensor networks.
	Our approach is to allow the sensor nodes to develop a community
	of trust. We propose a framework where each sensor node maintains
	reputation metrics which both represent past behavior of other nodes
	and are used as an inherent aspect in predicting their future behavior.
	We employ a Bayesian formulation, specifically a beta reputation
	system, for the algorithm steps of reputation representation, updates,
	integration and trust evolution. This framework is available as a
	middleware service on motes and has been ported to two sensor network
	operating systems, TinyOS and SOS. We evaluate the efficacy of this
	framework using multiple contexts: (1) a lab-scale test bed of Mica2
	motes, (2) Avrora simulations, and (3) real data sets collected from
	sensor network deployments in James Reserve.},
  doi = {http://doi.acm.org/10.1145/1362542.1362546},
  file = {ganeriwal2008.pdf:ganeriwal2008.pdf:PDF},
  issn = {1550-4859},
  journal = {ACM Trans. Sen. Netw.}
}

@MISC{ganeriwal2008a,
  author = {Saurabh Ganeriwal and Srivaths Ravi and Anand Raghunathan},
  title = {Trusted Platform based Key Establishment \& Management for Sensor
	Networks},
  year = {2008},
  abstract = {Trusted computing is emerging as a promising approach to addressing
	security concerns in traditional computing systems (PCs, workstations,
	servers, etc). A critical component in this approach is a Trusted
	Platform Module (TPM), a hardware component that is added to the
	system in order to enable functions such as attestation, platform
	integrity measurement, reporting, and protected storage. In this
	work, we investigate how the concepts of trusted computing can be
	applied to sensor networks. In the sensor network domain, cost and
	size constraints make it difficult to equip each battery-powered
	sensor node with a TPM. Therefore, we explore a tiered network architecture
	wherein only a small number of sensor nodes are equipped with TPMs;
	the rest are not assumed to have any security hardware or tamper-resistance
	capabilities.},
  file = {ganeriwal2008a.pdf:ganeriwal2008a.pdf:PDF},
  keywords = {sensor networks, TPM, trusted platform},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@ARTICLE{ganesan2001,
  author = {Deepak Ganesan and Ramesh Govindan and Scott Shenker and Deborah
	Estrin},
  title = {Highly-resilient, energy-efficient multipath routing in wireless
	sensor networks},
  journal = {SIGMOBILE Mob. Comput. Commun. Rev.},
  year = {2001},
  volume = {5},
  pages = {11--25},
  number = {4},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/509506.509514},
  file = {ganesan2001.pdf:ganesan2001.pdf:PDF},
  issn = {1559-1662},
  publisher = {ACM}
}

@TECHREPORT{ganesan2002,
  author = {Deepak Ganesan and Bhaskar Krishnamachari and Alec Woo and David
	Culler and Deborah Estrin and Stephen Wicker},
  title = {An Empirical Study of Epidemic Algorithms in Large Scale Multihop
	Wireless Networks},
  institution = {Intel Research},
  year = {2002},
  number = {IRB-TR-02-003},
  file = {ganesan2002.pdf:ganesan2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.01}
}

@ARTICLE{garay1998,
  author = {Juan A. Garay and Yoram Moses},
  title = {Fully Polynomial Byzantine Agreement for n > 3t Processors in t+1
	Rounds},
  journal = {{SICOMP: SIAM Journal on Computing}},
  year = {1998},
  volume = {27},
  abstract = {This paper presents a polynomial-time protocol for reaching Byzantine
	agreement in t + 1 rounds whenever n ? 3t, where n is the number
	of processors and t is an a priori upper bound on the number of failures.
	This resolves an open problem presented by Pease, Shostak and Lamport
	in 1980. An early-stopping variant of this protocol is also presented,
	reaching agreement in a number of rounds that is proportional to
	the number of processors that actually fail.},
  file = {garay1998.pdf:garay1998.pdf:PDF},
  url = {citeseer.ist.psu.edu/garay98fully.html}
}

@ARTICLE{garofalakis2007,
  author = {Garofalakis, M. and Hellerstein, J.M. and Maniatis, P.},
  title = {Proof Sketches: Verifiable In-Network Aggregation},
  journal = {{IEEE} 23rd International Conference on Data Engineering {ICDE 2007}},
  year = {2007},
  pages = {996-1005},
  month = {April},
  abstract = {Recent work on distributed, in-network aggregation assumes a benign
	population of participants. Unfortunately, modern distributed systems
	are plagued by malicious participants. In this paper we present a
	ﬁrst step towards veriﬁable yet efﬁcient distributed, in-network
	aggregation in adversarial settings. We describe a general framework
	and threat model for the problem and then present proof sketches,
	a compact veriﬁcation mechanism that combines cryptographic signatures
	and Flajolet-Martin sketches to guarantee acceptable aggregation
	error bounds with high probability. We derive proof sketches for
	count aggregates and extend them for random sampling, which can be
	used to provide veriﬁable approximations for a broad class of data-analysis
	queries, e.g., quantiles and heavy hitters. Finally, we evaluate
	the practical use of proof sketches, and observe that adversaries
	can often be reduced to much smaller violations in practice than
	our worst-case bounds suggest.},
  doi = {10.1109/ICDE.2007.368958},
  file = {:Garofalakis2007.pdf:PDF},
  keywords = {cryptography, digital signatures, distributed processing, formal verification,
	query processing, Flajolet-Martin sketches, compact verification,
	cryptographic signatures, data analysis queries, distributed systems,
	distributedaggregation, proof sketches, verifiable in-network aggregation,
	worst-case bounds, FM sketches},
  review = {Flajolet-martin sketches augmented with authentication manifests AM-FM
	sketches (cryptographis signatures over data captured by the sketch).
	Silent omissions of values are countered by a separate counting proof
	sketch on the compliment of the of the query predicate -- this works
	if the size of the population is approximately known.
	
	
	AM-FM sketches are inflation free -- 1 bits are authenticated by aggregators
	which turn them on (single signature per bit). Deflation -- turning
	1 bits into 0 bits -- can be prevented by multi-path routing (FM
	sketches are duplicate insensitive). Redundancy removes the advantage
	of individual adversaries in the tree. Compliment aggregates (assuming
	knowledge of the number of nodes in the population) are used to secure
	the aggregate without having to make assumptions about the graph
	structure. 
	
	
	Veriable random sampling is supported, in addition to count.
	
	
	Problems -- considerable size of authentication manifest. Limited
	applicability -- count and sampling of scalar values. Public key
	signatures may be problem for resource constrained nodes.
	
	
	Safe cheating strategy is discussed -- considerable error may be injected
	without detection -- see nath2009.}
}

@ONLINE{garret2005,
  author = {Jesse James Garret},
  title = {{Ajax: A New Approach to Web Applications}},
  url = {http://adaptivepath.com/ideas/essays/archives/000385.php},
  year = {2005},
  howpublished = {[online] http://adaptivepath.com/ideas/essays/ archives/000385.php},
  month = {February},
  owner = {kristjan},
  timestamp = {2008.02.15}
}

@INPROCEEDINGS{gasser1989,
  author = {Morrie Gasser and Andy Goldstein and Charlie Kaufman and Butler Lampson},
  title = {The Digital Distributed System Security Architecture},
  booktitle = {Proc. 12th {NIST}-{NCSC} National Computer Security Conference},
  year = {1989},
  pages = {305--319},
  abstract = {The Digital Distributed System Security Architecture is a comprehensive
	specification for security in a distributed system that employs state-of-the-art
	concepts to address the needs of both commercial and government environments.
	The architecture covers user and system authentication, mandatory
	and discretionary security, secure initialization and loading, and
	delegation in a general-purpose computing environment of heterogeneous
	systems where there are no central authorities, no global trust,
	and no central controls. The architecture prescribes a framework
	for all applications and operating systems currently available or
	to be developed. Because the distributed system is an open OSI environment,
	where functional interoperability only requires compliance with selected
	protocols needed by a given application, the architecture must be
	designed to securely support systems that do not implement or use
	any of the security services, while providing extensive additional
	security capabilities for those systems that choose to implement
	the architecture.},
  file = {gasser1989.pdf:gasser1989.pdf:PDF},
  url = {citeseer.ist.psu.edu/gasser89digital.html}
}

@TECHREPORT{gaudry2000,
  author = {Gaudry, P. and Hess, F. and Smart, Nigel P.},
  title = {Constructive and Destructive Facets of Weil Descent on Elliptic Curves},
  institution = {HP Labs},
  year = {2000},
  number = {HPL-2000-10},
  file = {gaudry2000.pdf:gaudry2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@MISC{gauravaram2009,
  author = {Praveen Gauravaram and Lars R. Knudsen and Krystian Matusiewicz and
	Florian Mendel and Christian Rechberger and Martin Schl\"{a}ffer
	and S{\o}ren S. Thomsen},
  title = {Gr{\o}stl -- a {SHA-3} candidate},
  month = {September},
  year = {2009},
  note = {Addendum published after second round selection},
  file = {gauravaram2009.pdf:gauravaram2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@MISC{gauravaram2008,
  author = {Praveen Gauravaram and Lars R. Knudsen and Krystian Matusiewicz and
	Florian Mendel and Christian Rechberger and Martin Schl\"{a}ffer
	and S{\o}ren S. Thomsen},
  title = {Gr{\o}stl -- a {SHA-3} candidate},
  month = {October},
  year = {2008},
  file = {gauravaram2008.pdf:gauravaram2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{geambasu2009,
  author = {Roxana Geambasu and Tadayoshi Kohno and Amit A. Levy and Henry M.
	Levy},
  title = {Vanish: Increasing Data Privacy with Self-Destructing Data},
  booktitle = {18th {USENIX} Security Symposium},
  year = {2009},
  abstract = {Today’s technical and legal landscape presents formidable challenges
	to personal data privacy. First, our increasing reliance on Web services
	causes personal data to be cached, copied, and archived by third
	parties, often without our knowledge or control. Second, the disclosure
	of private data has become commonplace due to carelessness, theft,
	or legal actions. Our research seeks to protect the privacy of past,
	archived data — such as copies of emails maintained by an email provider
	— against accidental, malicious, and legal attacks. Speciﬁcally,
	we wish to ensure that all copies of certain data become unreadable
	after a userspeciﬁed time, without any speciﬁc action on the part
	of a user, and even if an attacker obtains both a cached copy of
	that data and the user’s cryptographic keys and passwords.
	
	
	This paper presents Vanish, a system that meets this challenge through
	a novel integration of cryptographic techniques with global-scale,
	P2P, distributed hash tables (DHTs). We implemented a proof-of-concept
	Vanish prototype to use both the million-plus-node Vuze BitTorrent
	DHT and the restricted-membership OpenDHT. We evaluate experimentally
	and analytically the functionality, security, and performance properties
	of Vanish, demonstrating that it is practical to use and meets the
	privacy-preserving goals described above. We also describe two applications
	that we prototyped on Vanish: a Firefox plugin for Gmail and other
	Web sites and a Vanishing File application.},
  file = {geambasu2009.pdf:geambasu2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{gentry2009,
  author = {Gentry, Craig},
  title = {Fully homomorphic encryption using ideal lattices},
  booktitle = {{STOC} '09: Proceedings of the 41st annual {ACM} symposium on Theory
	of computing},
  year = {2009},
  pages = {169--178},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We propose a fully homomorphic encryption scheme -- i.e., a scheme
	that allows one to evaluate circuits over encrypted data without
	being able to decrypt. Our solution comes in three steps. First,
	we provide a general result -- that, to construct an encryption scheme
	that permits evaluation of arbitrary circuits, it suffices to construct
	an encryption scheme that can evaluate (slightly augmented versions
	of) its own decryption circuit; we call a scheme that can evaluate
	its (augmented) decryption circuit bootstrappable.
	
	
	Next, we describe a public key encryption scheme using ideal lattices
	that is almost bootstrappable.
	
	
	Lattice-based cryptosystems typically have decryption algorithms with
	low circuit complexity, often dominated by an inner product computation
	that is in NC1. Also, ideal lattices provide both additive and multiplicative
	homomorphisms (modulo a public-key ideal in a polynomial ring that
	is represented as a lattice), as needed to evaluate general circuits.
	
	
	Unfortunately, our initial scheme is not quite bootstrappable -- i.e.,
	the depth that the scheme can correctly evaluate can be logarithmic
	in the lattice dimension, just like the depth of the decryption circuit,
	but the latter is greater than the former. In the final step, we
	show how to modify the scheme to reduce the depth of the decryption
	circuit, and thereby obtain a bootstrappable encryption scheme, without
	reducing the depth that the scheme can evaluate. Abstractly, we accomplish
	this by enabling the encrypter to start the decryption process, leaving
	less work for the decrypter, much like the server leaves less work
	for the decrypter in a server-aided cryptosystem.},
  doi = {http://doi.acm.org/10.1145/1536414.1536440},
  file = {gentry2009.pdf:gentry2009.pdf:PDF},
  isbn = {978-1-60558-506-2},
  keywords = {computer security, cryptography, homomorphic encryption, fully homomorphic
	cryptosystem},
  location = {Bethesda, MD, USA}
}

@INPROCEEDINGS{Gerber2003,
  author = {Alexandre Gerber and Joseph Houle and Han Nguyen and Matthew Roughan
	and Subhabrata Sen},
  title = {{P2P}, the Gorilla in the Cable},
  booktitle = {{National Cable \& Telecommunications Association (NCTA)}},
  year = {2003},
  abstract = {There is considerable interest in Peer-to-
	
	peer (P2P) traffic because of its remarkable
	
	increase over the last few years. By analyzing
	
	flow measurements at the regional
	
	aggregation points of several cable operators,
	
	we are able to study its properties. It has
	
	become a large part of broadband traffic and
	
	its characteristics are different from older
	
	applications, such as the Web. It is a stable
	
	balanced traffic: the peak to valley ratio
	
	during a day is around 2 and the
	
	Inbound/Outbound traffic balance is close to
	
	one. Although P2P protocols are based on a
	
	distributed architecture, they don’t show
	
	strong signs of geographical locality. A cable
	
	subscriber is not much more likely to
	
	download a file from a close region than from
	
	a far region.
	
	
	 It is clear that most of the traffic is
	
	generated by heavy hitters who abuse P2P
	
	(and other) applications, whereas most of the
	
	subscribers only use their broadband
	
	connections to browse the web, exchange e-
	
	mails or chat. However it is not easy to
	
	directly block or limit P2P traffic, because
	
	theses applications adapt themselves to their
	
	environment: the users develop ways of
	
	eluding the traffic blocks. The traffic that
	
	could be once identified with five port
	
	numbers is now spread over thousands of
	
	TCP ports, pushing port based identification
	
	to its limits. More complex methods to identify
	
	P2P traffic are not a long-term solution, the
	
	cable industry should opt for a a “pay for
	
	what you use” model like the other utilities.},
  file = {nguyen03pp.pdf:nguyen03pp.pdf:PDF},
  owner = {kristjan},
  text = {A. Gerber, J. Houle, H. Nguyen, M. Roughan, and S. Sen. P2P The Gorilla
	in the Cable. In National Cable \& Telecommunications Association(NCTA)
	2003.},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{Gerla1999,
  author = {Mario Gerla and Ken Tang and Rajive Bagrodia},
  title = {TCP Performance in Wireless Multi-hop Networks},
  booktitle = {Proceedings of {IEEE WMCSA'99}},
  year = {1999},
  address = {New Orleans, LA},
  month = {February},
  file = {gerla99tcp.pdf:gerla99tcp.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://citeseer.ist.psu.edu/gerla99tcp.html}
}

@PHDTHESIS{ghodsi2006,
  author = {Ali Ghodsi},
  title = {{D}istributed $k$-ary {S}ystem: {A}lgorithms for Distributed Hash
	Tables},
  school = {{KTH} -- Royal Institute of Technology},
  year = {2006},
  type = {{PhD} Dissertation},
  address = {Stockholm, Sweden},
  month = oct,
  abstract = {This dissertation presents algorithms for data structures called distributed
	
	 hash tables (DHT) or structured overlay networks, which are used
	to build
	
	 scalable self-managing distributed systems. The provided algorithms
	
	guarantee lookup consistency in the presence of dynamism: they guarantee
	con-
	
	sistent lookup results in the presence of nodes joining and leaving.
	Similarly, the
	
	algorithms guarantee that routing never fails while nodes join and
	leave. Previ-
	
	ous algorithms for lookup consistency either suffer from starvation,
	do not work
	
	in the presence of failures, or lack proof of correctness.
	
	
	 Several group communication algorithms for structured overlay networks
	
	are presented. We provide an overlay broadcast algorithm, which unlike
	previ-
	
	ous algorithms avoids redundant messages, reaching all nodes in O(log
	n) time,
	
	while using O(n) messages, where n is the number of nodes in the system.
	The
	
	broadcast algorithm is used to build overlay multicast.
	
	
	 We introduce bulk operation, which enables a node to efficiently
	make multi-
	
	ple lookups or send a message to all nodes in a specified set of identifiers.
	The
	
	algorithm ensures that all specified nodes are reached in O(log n)
	time, sending
	
	maximum O(log n) messages per node, regardless of the input size of
	the bulk
	
	operation. Moreover, the algorithm avoids sending redundant messages.
	Previ-
	
	ous approaches required multiple lookups, which consume more messages
	and
	
	can render the initiator a bottleneck. Our algorithms are used in
	DHT-based
	
	storage systems, where nodes can do thousands of lookups to fetch
	large files.
	
	We use the bulk operation algorithm to construct a pseudo-reliable
	broadcast
	
	algorithm. Bulk operations can also be used to implement efficient
	range queries.
	
	
	 Finally, we describe a novel way to place replicas in a DHT, called
	symmetric
	
	replication, that enables parallel recursive lookups. Parallel lookups
	are known
	
	to reduce latencies. However, costly iterative lookups have previously
	been used
	
	to do parallel lookups. Moreover, joins or leaves only require exchanging
	O(1)
	
	messages, while other schemes require at least log( f ) messages for
	a replication
	
	degree of f .
	
	
	 The algorithms have been implemented in a middleware called the Dis-
	
	tributed k-ary System (DKS), which is briefly described.},
  file = {ghodsi2006.pdf:ghodsi2006.pdf:PDF},
  keywords = {distributed hash tables, structured overlay networks, distributed
	algorithms, distributed systems, group communication, replication}
}

@INPROCEEDINGS{ghosh99,
  author = {Anup K. Ghosh and Aaron Schwartzbard},
  title = {A study in using neural networks for anomaly and misuse detection},
  booktitle = {{SSYM'99: Proceedings of the 8th conference on USENIX Security Symposium}},
  year = {1999},
  pages = {12--12},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  file = {p12-ghosh.pdf:p12-ghosh.pdf:PDF},
  location = {Washington, D.C.}
}

@ARTICLE{gibbons2003,
  author = {Phillip B. Gibbons and Brad Karp and Yan Ke and Suman Nath and Srinivasan
	Seshan},
  title = {IrisNet: An Architecture for a Worldwide Sensor Web},
  journal = {IEEE Pervasive Computing},
  year = {2003},
  volume = {2},
  pages = {22--33},
  number = {4},
  abstract = {Today's common computing hardware Internet-connected desktop PCs and
	inexpensive, commodity off-the-shelf sensors such as Webcams is an
	ideal platform for a worldwide sensor web. In a worldwide sensor
	web, users can query, as a single unit, vast quantities of data from
	thousands or even millions of widely distributed, heterogeneous sensors.
	Users can also actuate sensors and adapt sensor-feed processing in
	reaction to sensed data in real time.IrisNet is a software infrastructure
	that aims to provide the missing software components for realizing
	a worldwide sensor web. It supports many features that simplify the
	task of creating sensor web services that are feature-rich, widely-distributed,
	high performance, highly scalable, adapt well to usage patterns,
	and robust against failures. Three services from different application
	domains currently use IrisNet.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/MPRV.2003.1251166},
  file = {gibbons2003.pdf:gibbons2003.pdf:PDF},
  issn = {1536-1268},
  publisher = {IEEE Educational Activities Department}
}

@INPROCEEDINGS{Girao2005,
  author = {Joao Girao and Dirk Westhoff},
  title = {{CDA}: Concealed data aggregation for reverse multicast traffic in
	wireless sensor networks},
  booktitle = {In {IEEE} International Conference on Communications ({ICC}’05),
	Seoul, Korea},
  year = {2005},
  abstract = {End-to-end encryption for wireless sensor networks is a challenging
	problem. To save the overall energy resources of the network it is
	agreed that sensed data need to be consolidated and aggregated on
	their way to the final destination. We present an approach that (1)
	conceals sensed data end-to-end, by (2) still providing efficient
	in-network data aggregation. The aggregating intermediate nodes are
	not required to operate on the sensed plaintext data. We apply a
	particular class of encryption transformation and exemplarily discuss
	the approach on the basis of two aggregation functions. We use actual
	implementation to show that the approach is feasible and flexible
	and frequently even more energy efficient than hop-by-hop encryption.},
  file = {Girao2005.pdf:Girao2005.pdf:PDF}
}

@ARTICLE{girao2007,
  author = {Girao, Joao and Westhoff, Dirk and Mykletun, Einar and Araki, Toshinori},
  title = {{TinyPEDS}: Tiny persistent encrypted data storage in asynchronous
	wireless sensor networks},
  journal = {Ad Hoc Netw.},
  year = {2007},
  volume = {5},
  pages = {1073--1089},
  number = {7},
  abstract = {In wireless sensor networks there is a need to securely store monitored
	data in a distributed way whenever it is either not desired or simply
	not possible to transmit regional volatile information to an authorised
	recipient in real-time. In particular, for wireless sensor network
	applications with an asynchronous character, the wireless sensor
	network itself needs to store the monitored data. Since nodes may
	disappear over time, a replicated and read-protected, but yet space-
	and energy-efficient, data storage is mandatory. In this work we
	provide and analyse an approach for a tiny Persistent Encrypted Data
	Storage (tinyPEDS) of the environmental fingerprint for asynchronous
	wireless sensor networks. Even if parts of the network are exhausted,
	restoring rules ensure that, with a high probability, environmental
	information from past is still available.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2006.05.004},
  file = {girao2007.pdf:girao2007.pdf:PDF},
  issn = {1570-8705},
  keywords = {crypto, homomorphic crypto, persistent storage, sensor network},
  publisher = {Elsevier Science Publishers B. V.}
}

@ARTICLE{girvan2002,
  author = {Girvan, M. and Newman, M.E.J.},
  title = {Community strucure in social and biological networks},
  journal = {Proc. of the National Academy of Sciences},
  year = {2002},
  volume = {99},
  number = {12},
  abstract = {A number of recent studies have focused on the statistical properties
	of networked systems such as social networks and the Worldwide Web.
	Researchers have concentrated particularly on a few properties that
	seem to be common to many networks: the small-world property, power-law
	degree distributions, and network transitivity. In this article,
	we highlight another property that is found in many networks, the
	property of community structure,
	
	in which network nodes are joined together in tightly knit groups,
	between which there are only looser connections. We propose a method
	for detecting such communities, built around the idea of using centrality
	indices to ﬁnd community boundaries. We test our method on computer-generated
	and real-world graphs whose community structure is already known
	and ﬁnd that the method detects this known structure with high sensitivity
	and reliability. We also apply the method to two networks whose community
	structure is not well known—a collaboration network and a food web—and
	ﬁnd that it detects signiﬁcant and informative community divisions
	in both cases.},
  file = {girvan2002.pdf:girvan2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.01}
}

@MISC{gladman2001,
  author = {Brian Gladman},
  title = {A Specification for Rijndael, the AES Algorithm},
  month = {March},
  year = {2001},
  file = {gladman2001.pdf:gladman2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.02.12}
}

@ARTICLE{glasgow1992,
  author = {Janice Glasgow and Glenn Macewen and Prakash Panangaden},
  title = {A logic for reasoning about security},
  journal = {{ACM Trans. Comput. Syst.}},
  year = {1992},
  volume = {10},
  pages = {226--264},
  number = {3},
  abstract = {A formal framework called Security Logic (SL) is developed for specifying
	and reasoning about security policies and for verifying that system
	designs adhere to such policies. Included in this modal logic framework
	are definitions of knowledge, permission, and obligation. Permission
	is used to specify secrecy policies and obligation to specify integrity
	policies. The combination of policies is addressed and examples based
	on policies from the current literature are given.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/146937.146940},
  file = {glasgow1992.pdf:glasgow1992.pdf:PDF},
  issn = {0734-2071},
  publisher = {ACM}
}

@INPROCEEDINGS{Glass1997,
  author = {Gideon Glass and Pei Cao},
  title = {Adaptive Page Replacement Based on Memory Reference Behaviour},
  booktitle = {In Proceedings of ACM SIGMETRICS 1997 - Measurement and Modeling
	of Computer Systems},
  year = {1997},
  pages = {115-126},
  month = {June},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/glass97adaptive.html}
}

@ARTICLE{golbeck2007,
  author = {Golbeck},
  title = {The Dynamics of Web-based Social Networks: Membership, Relationships,
	and Change},
  journal = {First Monday},
  year = {2007},
  abstract = {Social networks on the web are growing dramatically in size and number.
	The huge popularity of sites like MySpace, Facebook, and others has
	drawn in hundreds of millions of users, and the attention of scientists
	and the media. The public accessibility of web-based social networks
	offers great promise for researchers interested in studying the behavior
	of users and how to integrate social information into applications.
	However, to do that effectively, it is necessary to understand how
	networks grow and change. Over a two-year period we have collected
	data on every social network we could identify, and we also gathered
	daily information on thirteen networks over a forty-seven day period.
	In this article, we present the ﬁrst comprehensive survey of web-based
	social networks, followed by an analysis of membership and relationship
	dynamics within them. From our analysis of these data, we present
	several conclusions on how users behave in social networks, and what
	network features correlate with that behavior.},
  file = {golbeck2007.pdf:golbeck2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@ARTICLE{golbeck2006,
  author = {Jennifer Golbeck and James Hendler},
  title = {Inferring binary trust relationships in Web-based social networks},
  journal = {ACM Trans. Interet Technol.},
  year = {2006},
  volume = {6},
  pages = {497--529},
  number = {4},
  abstract = {The growth of Web-based social networking and the properties of those
	networks have created great potential for producing intelligent software
	that integrates a user’s social network and preferences. Our research
	looks particularly at assigning trust in Web-based social networks
	and investigates how trust information can be mined and integrated
	into applications. This article introduces a deﬁnition of trust suitable
	for use in Web-based social networks with a discussion of the properties
	that will inﬂuence its use in computation. We then present two algorithms
	for inferring trust relationships between individuals that are not
	directly connected in the network. Both algorithms are shown theoretically
	and through simulation to produce calculated trust values that are
	highly accurate.. We then present TrustMail, a prototype email client
	that uses variations on these algorithms to score email messages
	in the user’s inbox based on the user’s participation and ratings
	in a trust network.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1183463.1183470},
  file = {golbeck2006.pdf:golbeck2006.pdf:PDF},
  issn = {1533-5399},
  publisher = {ACM}
}

@BOOK{goldreich2002mpcbook,
  title = {Secure Multi-Party Computation},
  year = {2002},
  author = {Oded Goldreich},
  month = {October},
  note = {Final (incomplete) Draft, Version 1.4},
  file = {goldreich2002mpcbook.pdf:goldreich2002mpcbook.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.04}
}

@INPROCEEDINGS{goldreich1996,
  author = {Oded Goldreich},
  title = {Probabilistic Proof Systems (A Survey)},
  booktitle = {Symposium on Theoretical Aspects of Computer Science},
  year = {1996},
  abstract = {Various types of probabilistic proof systems have played a central
	role in the de-
	
	velopment of computer science in the last decade. In this exposition,
	we concentrate
	
	on three such proof systems — interactive proofs, zero-knowledge proofs,
	and prob-
	
	abilistic checkable proofs — stressing the essential role of randomness
	in each of
	
	them.},
  file = {goldreich1996.pdf:goldreich1996.pdf:PDF}
}

@ARTICLE{goldreich1994,
  author = {Goldreich, Oded},
  title = {A taxonomy of proof systems (part 2)},
  journal = {{SIGACT} News},
  year = {1994},
  volume = {25},
  pages = {22--30},
  number = {1},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/181773.181775},
  file = {goldreich1994.pdf:goldreich1994.pdf:PDF},
  issn = {0163-5700},
  keywords = {interactive proofs, zero-knowledge proofs, probabilistically checkable
	proofs, PCP, IP},
  publisher = {ACM}
}

@ARTICLE{goldreich1993,
  author = {Goldreich, Oded},
  title = {A taxonomy of proof systems (part 1)},
  journal = {{SIGACT} News},
  year = {1993},
  volume = {24},
  pages = {2--13},
  number = {4},
  abstract = {Several alternative formulations of the concept of an efficient proof
	system are nowadays coexisting in our field. These systems include
	the classical formulation of NP, interactive proof systems (giving
	rise to the class IP)computationally-sound proof systems, and probabilistically
	checkable proofs (PCP) which are closely related to multi-prover
	interactive proofs (MIP). Although these notions are sometimes introduced
	using the same generic phrases, they are actually very different
	in motivation, applications and expressive power. The main objective
	of this essay is to try to clarify these differences.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/164996.165000},
  file = {goldreich1993.pdf:goldreich1993.pdf:PDF},
  issn = {0163-5700},
  keywords = {interactive proofs, zero-knowledge proofs, probabilistically checkable
	proofs, PCP, IP},
  publisher = {ACM}
}

@ARTICLE{goldreich1991,
  author = {Goldreich, Oded and Micali, Silvio and Wigderson, Avi},
  title = {Proofs that yield nothing but their validity or all languages in
	NP have zero-knowledge proof systems},
  journal = {{J. ACM}},
  year = {1991},
  volume = {38},
  pages = {690--728},
  number = {3},
  abstract = {In this paper the generality and wide applicability of Zero-knowledge
	proofs, a notion introduced by Goldwasser, Micali, and Rackoff is
	demonstrated. These are probabilistic and interactive proofs that,
	for the members of a language, efficiently demonstrate membership
	in the language without conveying any additional knowledge. All previously
	known zero-knowledge proofs were only for number-theoretic languages
	in NP fl CONP.
	
	 Under the assumption that secure encryption functions exist or by
	using “physical means for hiding information, ‘‘ it is shown that
	all languages in NP have zero-knowledge proofs. Loosely speaking,
	it is possible to demonstrate that a CNF formula is satisfiable without
	revealing any other property of the formula, in particular, without
	yielding neither a satis@ing assignment nor properties such as whether
	there is a satisfying assignment in which xl = X3 etc.
	
	 It is also demonstrated that zero-knowledge proofs exist “outside
	the domain of cryptography and number theory. ” Using no assumptions.
	it is shown that both graph isomorphism and graph nonisomorphism
	have zero-knowledge interactive proofs. The mere existence of an
	interactive proof for graph nonisomorphism is interesting, since
	graph nonisomorphism is not known to be in NP and hence no efficient
	proofs were known before for demonstrating that two graphs are not
	isomorphic.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/116825.116852},
  file = {goldreich1991.pdf:goldreich1991.pdf:PDF},
  issn = {0004-5411},
  keywords = {zero knowledge proofs, NP-complete, cryptography, security},
  publisher = {ACM}
}

@INPROCEEDINGS{goldreich1987,
  author = {Goldreich, O. and Micali, S. and Wigderson, A.},
  title = {How to play ANY mental game},
  booktitle = {STOC '87: Proceedings of the nineteenth annual ACM symposium on Theory
	of computing},
  year = {1987},
  pages = {218--229},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present a polynomial-time algorithm that, given as a input the
	description of a game with incomplete information and any number
	of players, produces a protocol for playing the game that leaks no
	partial information, provided the majority of the players is honest.
	Our algorithm automatically solves all the multi-party protocol problems
	addressed in complexity-based cryptography during the last 10 years.
	It actually is a completeness theorem for the class of distributed
	protocols with honest majority. Such completeness theorem is optimal
	in the sense that, if the majority of the players is not honest,
	some protocol problems have no efficient solution [C].},
  doi = {http://doi.acm.org/10.1145/28395.28420},
  file = {goldreich1987.pdf:goldreich1987.pdf:PDF},
  isbn = {0-89791-221-7},
  keywords = {security, cryptography, MPC},
  location = {New York, New York, United States}
}

@ARTICLE{goldszmidt98,
  author = {G. Goldszmidt and Y. Yemini},
  title = {Delegated agents for network management},
  journal = {IEEE Communications Magazine},
  year = {1998},
  volume = {36},
  pages = {66-70},
  number = {3},
  month = {Mar},
  abstract = {Current network management depends on centralized monitoring, analysis,
	and control by operations staff who must manipu-
	
	late detailed and often obscure element instrumentation. This complex
	and labor-intensive
	
	management paradigm has been stretched t o its limits by the scale
	and complexity of
	
	emerging networks. This article describes the use of delegated agents
	t o distribute and
	
	automate management functions. With delegated agents, management intelligence
	can be
	
	dynamically embedded in elements and domains so that networked systems
	can be pro-
	
	grammed t o be self-managed.},
  doi = {10.1109/35.663329},
  file = {goldszmidt98.pdf:goldszmidt98.pdf:PDF},
  issn = {0163-6804},
  keywords = {distributed processing, protocols, software agents, telecommunication
	computing, telecommunication control, telecommunication network managementcentralized
	analysis, centralized control, centralized monitoring, delegated
	agents, distributed technology, labor-intensive management, management
	functions automation, management intelligence, management protocols,
	network management, networked systems, operations staff, programming
	languages, self-managed systems, software applications}
}

@INPROCEEDINGS{goldwasser1997,
  author = {Goldwasser, Shafi},
  title = {Multi party computations: past and present},
  booktitle = {{PODC} '97: Proceedings of the sixteenth annual ACM symposium on
	Principles of distributed computing},
  year = {1997},
  pages = {1--6},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/259380.259405},
  file = {goldwasser1997.pdf:goldwasser1997.pdf:PDF},
  isbn = {0-89791-952-1},
  keywords = {MPC, multi-party computation},
  location = {Santa Barbara, California, United States}
}

@ARTICLE{goldwasser1984,
  author = {Shafi Goldwasser and Silvio Micali},
  title = {Probabilistic Encryption},
  journal = {Journal of Computer and Systems Sciences},
  year = {1984},
  volume = {28},
  pages = {270-299},
  number = {2},
  file = {goldwasser1984.pdf:goldwasser1984.pdf:PDF},
  keywords = {cryptography, probabilistic encryption},
  owner = {kristjan},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{goldwasser1982,
  author = {Goldwasser, Shafi and Micali, Silvio},
  title = {Probabilistic encryption \& how to play mental poker keeping secret
	all partial information},
  booktitle = {{STOC} '82: Proceedings of the fourteenth annual {ACM} symposium
	on Theory of computing},
  year = {1982},
  pages = {365--377},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper proposes an Encryption Scheme that possess the following
	property : An adversary, who knows the encryption algorithm and is
	given the cyphertext, cannot obtain any information about the clear-text.
	Any implementation of a Public Key Cryptosystem, as proposed by Diffie
	and Hellman in [8], should possess this property. Our Encryption
	Scheme follows the ideas in the number theoretic implementations
	of a Public Key Cryptosystem due to Rivest, Shamir and Adleman [13],
	and Rabin [12].},
  doi = {http://doi.acm.org/10.1145/800070.802212},
  file = {goldwasser1982.pdf:goldwasser1982.pdf:PDF},
  isbn = {0-89791-070-2},
  keywords = {cryptography, probabilistic encryption},
  location = {San Francisco, California, United States}
}

@ARTICLE{goldwasser1989,
  author = {Goldwasser, S. and Micali, S. and Rackoff, C.},
  title = {The knowledge complexity of interactive proof systems (Extended abstract)},
  journal = {{SIAM J. Comput.}},
  year = {1989},
  volume = {18},
  pages = {186--208},
  number = {1},
  address = {Philadelphia, PA, USA},
  doi = {http://dx.doi.org/10.1137/0218012},
  file = {goldwasser1989.pdf:goldwasser1989.pdf:PDF},
  issn = {0097-5397},
  keywords = {zero knowledge proofs, security, cryptography},
  publisher = {Society for Industrial and Applied Mathematics}
}

@INPROCEEDINGS{golle2002,
  author = {Philippe Golle and Stanislaw Jarecki and Ilya Mironov},
  title = {Cryptographic Primitives Enforcing Communication and Storage Complexity},
  booktitle = {{In Financial Cryptography (FC 2002)}},
  year = {2002},
  pages = {120--135},
  publisher = {Springer},
  abstract = {We introduce a new type of cryptographic primitives which enforce
	high communication or storage complexity. To evaluate these primitives
	on a random input, one has to engage in a protocol of high communication
	complexity, or one has to use a lot of storage. Therefore, the ability
	to compute these primitives constitutes a certain “proof of work,”
	since the computing party is forced to contribute a lot of its communication
	or storage resources to this task. Such primitives can be used in
	applications which deal with non-malicious but selfishly resource-maximizing
	parties. For example, they can be useful in constructing peer-to-peer
	systems which are robust against so called “free riders.” In this
	paper we define two such primitives, a communication-enforcing signature
	and a storage-enforcing commitment scheme, and we give constructions
	for both.},
  file = {golle2002.pdf:golle2002.pdf:PDF},
  review = {Proof of work approach. To check later.}
}

@ARTICLE{grabowski2008,
  author = {Darren Grabowski},
  title = {Global Network Pandemic - The Silent Threat},
  journal = {Global Telecommunications Conference, 2008. IEEE GLOBECOM 2008. IEEE},
  year = {2008},
  pages = {1-5},
  month = {30 2008-Dec. 4},
  doi = {10.1109/GLOCOM.2008.ECP.1064},
  file = {:Grabowski_Global_Network_Pandemic.pdf:PDF},
  issn = {1930-529X},
  keywords = {Internet, computer network management, security of dataInternet, botnets,
	global network pandemic, zombie computer},
  owner = {kristjan},
  timestamp = {2009.02.24}
}

@INPROCEEDINGS{graham1971,
  author = {G. Scott Graham and Peter J. Denning},
  title = {Protection -- Principles and practice},
  booktitle = {{AFIPS '71 (Fall): Proceedings of the November 16-18, 1971, fall
	joint computer conference}},
  year = {1971},
  pages = {417--429},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1478873.1478928},
  file = {:p417-graham.pdf:PDF},
  location = {Las Vegas, Nevada}
}

@INPROCEEDINGS{gray1978,
  author = {Gray, Jim},
  title = {Notes on Data Base Operating Systems},
  booktitle = {Operating Systems, An Advanced Course},
  year = {1978},
  pages = {393--481},
  address = {London, UK},
  publisher = {Springer-Verlag},
  isbn = {3-540-08755-9},
  review = {The two generals paradox defined and given an impossibility proof.}
}

@INPROCEEDINGS{greenwald2004,
  author = {Greenwald, Michael B. and Khanna, Sanjeev},
  title = {Power-conserving computation of order-statistics over sensor networks},
  booktitle = {{PODS} '04: Proceedings of the twenty-third {ACM SIGMOD-SIGACT-SIGART}
	symposium on Principles of database systems},
  year = {2004},
  pages = {275--285},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We study the problem of power-conserving computation of order statistics
	in sensor networks. Significant power-reducing optimizations have
	been devised for computing simple aggregate queries such as COUNT,
	AVERAGE, or MAX over sensor networks. In contrast, aggregate queries
	such as MEDIAN have seen little progress over the brute force approach
	of forwarding all data to a central server. Moreover, battery life
	of current sensors seems largely determined by communication costs
	--- therefore we aim to minimize the number of bytes transmitted.
	Unoptimized aggregate queries typically impose extremely high power
	consumption on a subset of sensors located near the server. Metrics
	such as total communication cost underestimate the penalty of such
	imbalance: network lifetime may be dominated by the worst-case replacement
	time for depleted batteries.In this paper, we design the first algorithms
	for computing order-statistics such that power consumption is balanced
	across the entire network. Our first main result is a distributed
	algorithm to compute an ε-approximate quantile summary of the sensor
	data such that each sensor transmits only O(log2 n/ε) data values,
	irrespective of the network topology, an improvement over the current
	worst-case behavior of Ω(n). Second, we show an improved result when
	the height, h, of the network is significantly smaller than n. Our
	third result is that we can exactly compute any order statistic (e.g.,
	median) in a distributed manner such that each sensor needs to transmit
	O(log3 n) values.Further, we design the aggregates used by our algorithms
	to be decomposable. An aggregate Q over a set S is decomposable if
	there exists a function, f, such that for all S = S1 ∪ S2, Q(S) =
	f(Q(S1), Q(S2)). We can thus directly apply existing optimizations
	to decomposable aggregates that increase error-resilience and reduce
	communication cost.Finally, we validate our results empirically,
	through simulation. When we compute the median exactly, we show that,
	even for moderate size networks, the worst communication cost for
	any single node is several times smaller than the corresponding cost
	in prior median algorithms. We show similar cost reductions when
	computing approximate order-statistic summaries with guaranteed precision.
	In all cases, our total communication cost over the entire network
	is smaller than or equal to the total cost of prior algorithms.},
  doi = {http://doi.acm.org/10.1145/1055558.1055597},
  file = {greenwald2004.pdf:greenwald2004.pdf:PDF},
  isbn = {158113858X},
  location = {Paris, France}
}

@ONLINE{grimes2009,
  author = {Roger A. Grimes},
  title = {This Internet fix is no pipe dream},
  url = {http://weblog.infoworld.com/securityadviser/archives/2009/02/call_me_a_dream.html},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.03.10}
}

@INPROCEEDINGS{grizzard2005,
  author = {Julian B. Grizzard and Charles Robert {Simpson, Jr.} and Sven Krasser
	and Henry L. Owen and George F. Riley},
  title = {Flow Based Observations from {NETI@home} and Honeynet Data},
  booktitle = {Proceedings from the sixth IEEE Systems, Man and Cybernetics Information
	Assurance Workshop},
  year = {2005},
  pages = {244--251},
  month = {June},
  abstract = {We conduct a ﬂow based comparison of honeynet traﬃc,
	
	representing malicious traﬃc, and NETI@home traﬃc, rep-
	
	resenting typical end user traﬃc. We present a cumulative
	
	distribution function of the number of packets for a TCP
	
	ﬂow and learn that a large portion of these ﬂows in both
	
	datasets are failed and potentially malicious connection at-
	
	tempts. Next, we look at a histogram of TCP port activity
	
	over large time scales to gain insight into port scanning and
	
	worm activity. One key observation is that new worms can
	
	linger on for more than a year after the initial release date.
	
	Finally, we look at activity relative to the IP address space
	
	and observe that the sources of malicious traﬃc are spread
	
	across the allocated range.},
  file = {:neti-honey.pdf:PDF},
  isbn = {0-7803-9290-6},
  keywords = {NETI@home
	
	end-to-end monitoring},
  project = {phd}
}

@ARTICLE{grosky2007,
  author = {Grosky, W.I. and Kansal, A. and Nath, S. and Jie Liu and Feng Zhao},
  title = {{SenseWeb}: An Infrastructure for Shared Sensing},
  journal = {{IEEE} Multimedia},
  year = {2007},
  volume = {14},
  pages = {8 -13},
  number = {4},
  month = {oct.-dec. },
  abstract = {Peer-produced systems can achieve what might be infeasible for stand-alone
	systems developed by a single entity. The SenseWeb's goal is to enable
	these kinds of capabilities. Using SenseWeb, applications can initiate
	and access sensor data streams from shared sensors across the entire
	Internet. The SenseWeb infrastructure helps ensure optimal sensor
	selection for each application and efficient sharing of sensor streams
	among multiple applications.},
  doi = {10.1109/MMUL.2007.82},
  file = {grosky2007.pdf:grosky2007.pdf:PDF},
  issn = {1070-986X},
  keywords = {Internet;SenseWeb infrastructure;optimal sensor selection;peer-produced
	systems;sensor data streams;shared sensing;shared sensors;stand-alone
	systems;Internet;distributed sensors;peer-to-peer computing;}
}

@ARTICLE{Grossglauser2002,
  author = {M. Grossglauser and D. Tse},
  title = {Mobility increases the capacity of ad hoc wireless networks},
  journal = {IEEE/ACM Transactions on Networking},
  year = {2002},
  volume = {10},
  pages = {477-486},
  number = {4},
  month = {August},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{grossman2007,
  author = {Jeremiah Grossman},
  title = {Hacking Intranet Websites from the Outside (Take 2).},
  month = {July},
  file = {bh-usa-07-grossman-WP.pdf:bh-usa-07-grossman-WP.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{grossman06,
  author = {Jeremiah Grossman},
  title = {I know if you’re logged-in, anywhere},
  howpublished = {[0nline] http://jeremiahgrossman.blogspot.com/2006/12/i-know-if-youre-logged-in-anywhere.html},
  month = {December},
  year = {2006},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://jeremiahgrossman.blogspot.com/2006/12/i-know-if-youre-logged-in-anywhere.html}
}

@MISC{grossman2006,
  author = {Jeremiah Grossman},
  title = {Cross-site scripting worms and viruses.
	
	The impending threat and the best defense},
  howpublished = {[online] www.whitehatsec.com/downloads/WHXSSThreats.pdf},
  month = {April},
  year = {2006},
  file = {WHXSSThreats.pdf:WHXSSThreats.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {www.whitehatsec.com/downloads/WHXSSThreats.pdf}
}

@INPROCEEDINGS{gueron2008,
  author = {Shay Gueron and Michael E. Kounavis},
  title = {Vortex: A New Family of One-Way Hash Functions Based on {AES} Rounds
	and Carry-Less Multiplication},
  booktitle = {{ISC}},
  year = {2008},
  abstract = {We present Vortex a new family of one way hash functions that can
	produce message digests of 256 bits. The main idea behind the design
	of these hash functions is that we use well known algorithms that
	can support very fast diffusion in a small number of steps. We also
	balance the cryptographic strength that comes from iterating block
	cipher rounds with SBox substitution and diffusion (like Whirlpool)
	against the need to have a lightweight implementation with as small
	number of rounds as possible. We use only 3 AES rounds but with a
	stronger key schedule. Our goal is not to protect a secret symmetric
	key but to support perfect mixing of the bits of the input into the
	hash value. Three AES rounds are followed by our variant of Galois
	Field multiplication. This achieves cross-mixing between 128-bit
	sets. We present a set of qualitative arguments why we believe Vortex
	is secure.},
  file = {gueron2008.pdf:gueron2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{guillou1988,
  author = {Guillou, L. C. and Quisquater, J.-J.},
  title = {A practical zero-knowledge protocol fitted to security microprocessor
	minimizing both transmission and memory},
  booktitle = {Lecture Notes in Computer Science on Advances in Cryptology-EUROCRYPT'88},
  year = {1988},
  pages = {123--128},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  file = {guillou1988.pdf:guillou1988.pdf:PDF},
  isbn = {0-387-50251-3},
  keywords = {zero-knowledge proof, authentication algoritm, identification, crypto},
  location = {Davos, Switzerland}
}

@INPROCEEDINGS{guimaraes2005,
  author = {Guimaraes, Germano and Souto, Eduardo and Sadok, Djamel and Kelner,
	Judith},
  title = {Evaluation of Security Mechanisms in Wireless Sensor Networks},
  booktitle = {{ICW} '05: Proceedings of the 2005 Systems Communications},
  year = {2005},
  pages = {428--433},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Ad hoc and wireless sensor networks have recently emerged as successful
	technologies in a number of application domains. The need to build
	security services into them remains however a considerable challenge
	as the hardware used often shows serious processing and energy limitations.
	This work evaluates the impact of a number of security mechanisms
	on sensor nodes and the network as a whole. Hence a number of actual
	measurements were undertaken in a real sensor platform in order to
	accurately establish energy consumption for various encryption algorithms
	as well the baseline scenario obtained when none of these is used.
	Measurements have shown that integrity code length added to application
	messages using some cryptography algorithms and MAC (Message Authentication
	Code) is acceptable for a sensor node with 128 KB of ROM memory and
	4 KB of RAM (MICA2). We also were able to check that power consumption
	of the encryption process does not in itself cause representative
	impact, since it is in the micro-joules range.},
  doi = {http://dx.doi.org/10.1109/ICW.2005.47},
  file = {guimaraes2005.pdf:guimaraes2005.pdf:PDF},
  isbn = {0-7695-2422-2},
  keywords = {sensor network, security, encryption, power consumption},
  review = {Evaluates the practicality of encryption on resource constrained sensor
	nodes.}
}

@INPROCEEDINGS{gummadi2003,
  author = {Krishna P. Gummadi and Richard J. Dunn and Stefan Saroiu and Steven
	D. Gribble and Henry M. Levy and John Zahorjan},
  title = {Measurement, modeling, and analysis of a peer-to-peer file-sharing
	workload},
  booktitle = {SOSP '03: Proceedings of the nineteenth ACM symposium on Operating
	systems principles},
  year = {2003},
  pages = {314--329},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/945445.945475},
  file = {p314-gummadi.pdf:p314-gummadi.pdf:PDF},
  isbn = {1-58113-757-5},
  location = {Bolton Landing, NY, USA}
}

@ARTICLE{guo1999,
  author = {Y. Guo and T. Akatsuka and Y. Hiranaka},
  title = {Hierarchical Network Management Based on Extended {SNMP}},
  journal = {Transactions of the Institute of Electrical Engineers of Japan},
  year = {1999},
  volume = {119C},
  pages = {404-412},
  number = {3},
  abstract = {In this paper, we present an analysis of the problems involved in
	both centralized and distributed network management architectures
	and present a scheme of Hierarchical Network Management based on
	Extended SNMP as our solution. The status field in SNMP PDU Format
	is newly defined so that various management policies can be encapsulated
	into the SNMP PDU and sent from main manager to sub manager. The
	management task, which achieves concrete management activities on
	side of the sub manage, is created and executed according to management
	policy. One of the advantages of the proposed method is distribution
	of all monitoring tasks and data processing tasks to each sub manager
	so that the load of main manager and the traffic of management information
	on the backbone network can be significantly decreased. In addition,
	it is possible to obtain high-level management result from the sub
	manager directly by using free-designed management policy. The management
	framework is easy to implement on all versions of SNMP and makes
	the management system more flexible and scalable. Implementation
	examples are also given.},
  owner = {kristjan},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{gupta2003,
  author = {Gaurav Gupta and Mohamed Younis},
  title = {Fault-Tolerant Clustering of Wireless Sensor Networks},
  booktitle = {{WCNC'03}: {IEEE} Wireless Communications and Networking},
  year = {2003},
  abstract = {During the past few years distributed wireless sensor networks have
	been the focus of considerable research for both military and civil
	applications. Sensors are generally constrained in on-board energy
	supply therefore efficient management of the network is crucial to
	extend the life of the system. Sensors’ energy cannot support long
	haul communication to reach a remote command site, thus they require
	multi-tier architecture to forward data. An efficient way to enhance
	the lifetime of the system is to partition the network into distinct
	clusters with a high-energy node called gateway as cluster-head.
	Failures are inevitable in sensor networks due to the inhospitable
	environment and unattended deployment. However, failures in higher
	level of hierarchy e.g. cluster-head cause more damage to the system
	because they also limit accessibility to the nodes that are under
	their supervision. In this paper we propose an efficient mechanism
	to recover sensors from a failed cluster. Our approach avoids a full-scale
	re-clustering and does not require deployment of redundant gateways.},
  file = {gupta2003.pdf:gupta2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{gupta2001,
  author = {Indranil Gupta and Robbert {van Renesse} and Kenneth P. Birman},
  title = {Scalable Fault-Tolerant Aggregation in Large Process Groups},
  booktitle = {Dependable Systems and Networks},
  year = {2001},
  pages = {433-442},
  abstract = {This paper discusses fault-tolerant, scalable solutions to the problem
	of accurately and scalably calculating global aggregate functions
	in large process groups communicating over unreliable networks. These
	groups could represent sensors or processes communicating over a
	network that is either ﬁxed (eg., the Internet) or dynamic (eg.,
	multihop ad-hoc). Group members are prone to failures. The ability
	to evaluate global aggregate properties (eg., the average of sensor
	temperature readings) is important for higher-level coordination
	activities in such large groups. We ﬁrst deﬁne the setting and problem,
	laying down metrics to evaluate different algorithms for the same.
	We discuss why the usual approaches to solve this problem are unviable
	and unscalable over an unreliable network prone to message delivery
	failures and crash failures. We then propose a technique to impose
	an abstract hierarchy on such large groups, describing how this hierarchy
	can be made to mirror the network topology. We discuss several alternatives
	to use this technique to solve the global aggregate function evaluation
	problem. Finally, we present a protocol based on gossiping that uses
	this hierarchical technique. We present mathematical analysis and
	performance results to validate the robustness, efﬁciency and accuracy
	of the Hierarchical Gossiping algorithm.},
  file = {gupta2001.pdf:gupta2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.03}
}

@MISC{gura2004,
  author = {Nils Gura and Arun Patel and Arvinderpal Wander and Hans Eberle and
	Sheueling Chang Shantz},
  title = {Comparing Elliptic Curve Cryptography and RSA on 8-bit {CPUs}},
  year = {2004},
  abstract = {Strong public-key cryptography is often considered to be too
	
	computationally expensive for small devices if not accelerated by
	crypto-
	
	graphic hardware. We revisited this statement and implemented elliptic
	
	curve point multiplication for 160-bit, 192-bit, and 224-bit NIST/SECG
	
	curves over GF(p) and RSA-1024 and RSA-2048 on two 8-bit micro-
	
	controllers. To accelerate multiple-precision multiplication, we propose
	a
	
	new algorithm to reduce the number of memory accesses.
	
	
	Implementation and analysis led to three observations: 1. Public-key
	
	cryptography is viable on small devices without hardware acceleration.
	
	On an Atmel ATmega128 at 8 MHz we measured 0.81s for 160-bit ECC
	
	point multiplication and 0.43s for a RSA-1024 operation with exponent
	
	e = 216 + 1. 2. The relative performance advantage of ECC point multi-
	
	plication over RSA modular exponentiation increases with the decrease
	
	in processor word size and the increase in key size. 3. Elliptic curves
	
	over fields using pseudo-Mersenne primes as standardized by NIST and
	
	SECG allow for high performance implementations and show no perfor-
	
	mance disadvantage over optimal extension fields or prime fields selected
	
	specifically for a particular processor architecture.},
  file = {gura2004.pdf:gura2004.pdf:PDF},
  keywords = {elliptic curve cryptography, EC, RSA},
  owner = {kristjan},
  review = {Ref'd by du2008 on public key crypto on small devices.},
  timestamp = {2010.04.12}
}

@MISC{gutterman2006,
  author = {Zvi Gutterman and Benny Pinkas and Tzachy Reinman},
  title = {Analysis of the Linux Random Number Generator},
  month = {March},
  year = {2006},
  abstract = {Linux is the most popular open source project. The Linux random number
	generator is part of the kernel of all
	
	Linux distributions and is based on generating randomness from entropy
	of operating system events. The output of
	
	this generator is used for almost every security protocol, including
	TLS/SSL key generation, choosing TCP sequence
	
	numbers, and file system and email encryption. Although the generator
	is part of an open source project, its source
	
	code (about 2500 lines of code) is poorly documented, and patched
	with hundreds of code patches.
	
	
	 We used dynamic and static reverse engineering to learn the operation
	of this generator. This paper presents a
	
	description of the underlying algorithms and exposes several security
	vulnerabilities. In particular, we show an attack
	
	on the forward security of the generator which enables an adversary
	who exposes the state of the generator to compute
	
	previous states and outputs. In addition we present a few cryptographic
	flaws in the design of the generator, as well
	
	as measurements of the actual entropy collected by it, and a critical
	analysis of the use of the generator in Linux
	
	distributions on disk-less devices.},
  file = {gutterman2006.pdf:gutterman2006.pdf:PDF},
  keywords = {linux random number generation, vulnerabilities},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{gyongyi2004,
  author = {Zolt\'{a}n Gy\"{o}ngyi and Hector Garcia-Molina and Jan Pedersen},
  title = {Combating web spam with trustrank},
  booktitle = {VLDB '04: Proceedings of the Thirtieth international conference on
	Very large data bases},
  year = {2004},
  pages = {576--587},
  publisher = {VLDB Endowment},
  abstract = {Web spam pages use various techniques to achieve higher-than-deserved
	rankings in a search engine's results. While human experts can identify
	spam, it is too expensive to manually evaluate a large number of
	pages. Instead, we propose techniques to semi-automatically separate
	reputable, good pages from spam. We first select a small set of seed
	pages to be evaluated by an expert. Once we manually identify the
	reputable seed pages, we use the link structure of the web to discover
	other pages that are likely to be good. In this paper we discuss
	possible ways to implement the seed selection and the discovery of
	good pages. We present results of experiments run on the World Wide
	Web indexed by AltaVista and evaluate the performance of our techniques.
	Our results show that we can effectively filter out spam from a significant
	fraction of the web, based on a good seed set of less than 200 sites.},
  file = {gyongyi2004.pdf:gyongyi2004.pdf:PDF},
  isbn = {0-12-088469-0},
  location = {Toronto, Canada},
  review = {TrustRank}
}

@ARTICLE{hadida2009,
  author = {Rachid Hadida and Mehmet Hakan Karaata},
  title = {An adaptive stabilizing algorithm for finding all disjoint paths
	in anonymous mesh networks},
  journal = {Comput. Commun.},
  year = {2009},
  volume = {32},
  pages = {858-866},
  month = {5},
  abstract = {In this paper, we present an adaptive stabilizing algorithm for finding
	all disjoint paths in anonymous mesh networks. Given two distinct
	nodes s and t of a network, the all disjoint paths problem is to
	identify all disjoint paths from s to t. Since our algorithm is stabilizing,
	it does not require initialization and withstands transient faults.
	In addition, the proposed algorithm adapts to topology changes in
	the form of process/link crashes and additions, i.e., upon a topology
	change, it finds all available paths from s to t. The space complexity
	of our algorithm is 4×d states for the source process s, one state
	for the target process, 120×d states for other processes, where d
	is the diameter of the communication network. The time complexity
	of the proposed algorithm is O(d) rounds. The proposed algorithm
	has a wide range of applications in ensuring reliability and security
	of sensor, mobile and fixed communication networks.},
  file = {hadida2009.pdf:hadida2009.pdf:PDF},
  keywords = {Disjoint paths; Distributed systems; Fault-tolerance; Mesh networks;
	Stabilization},
  owner = {kristjan},
  timestamp = {2010.05.21}
}

@ARTICLE{hadim2006,
  author = {Salem Hadim and Nader Mohamed},
  title = {Middleware: Middleware Challenges and Approaches for Wireless Sensor
	Networks},
  journal = {{IEEE} Distributed Systems Online},
  year = {2006},
  volume = {7},
  number = {7},
  month = {March},
  abstract = {Due to many advantages over traditional networks, in recent years,
	wireless sensor networks have offered a spectrum of new applications.
	A middleware layer bridging the gap between applications and low-level
	constructs is a novel approach to resolve many of the open issues
	and drastically enhance application development on such networks.
	This survey shows the current state of the research in this domain
	by presenting and discussing the most representative WSN middleware.
	The authors concentrate on discovering similarities and differences
	among these approaches by making state-of-the-art classifications,
	and providing a framework for evaluation and appropriateness.},
  file = {hadim2006.pdf:hadim2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@ARTICLE{haeberlen2007,
  author = {Haeberlen, Andreas and Kouznetsov, Petr and Druschel, Peter},
  title = {{PeerReview}: Practical Accountability for Distributed Systems},
  journal = {{SIGOPS} Oper. Syst. Rev.},
  year = {2007},
  volume = {41},
  pages = {175--188},
  number = {6},
  abstract = {We describe PeerReview, a system that provides accountability in distributed
	systems. PeerReview ensures that Byzantine faults whose effects are
	observed by a correct node are eventually detected and irrefutably
	linked to a faulty node. At the same time, PeerReview ensures that
	a correct node can always defend itself against false accusations.
	These guarantees are particularly important for systems that span
	multiple administrative domains, which may not trust each other.PeerReview
	works by maintaining a secure record of the messages sent and received
	by each node. The record isused to automatically detect when a node's
	behavior deviates from that of a given reference implementation,
	thus exposing faulty nodes. PeerReview is widely applicable: it only
	requires that a correct node's actions are deterministic, that nodes
	can sign messages, and that each node is periodically checked by
	a correct node. We demonstrate that PeerReview is practical by applying
	it to three different types of distributed systems: a network filesystem,
	a peer-to-peer system, and an overlay multicast system.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1323293.1294279},
  file = {haeberlen2007.pdf:haeberlen2007.pdf:PDF},
  issn = {0163-5980},
  keywords = {accountability systems},
  publisher = {ACM}
}

@INPROCEEDINGS{hagberg2008,
  author = {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
  title = {Exploring network structure, dynamics, and function using {NetworkX}},
  booktitle = {Proceedings of the 7th Python in Science Conference (SciPy2008)},
  year = {2008},
  pages = {11--15},
  address = {Pasadena, CA USA},
  month = Aug,
  abstract = {NetworkX is a Python language package for exploration and analysis
	of networks and network algorithms. The core package provides data
	structures for representing many types of networks, or graphs, including
	simple graphs, directed graphs, and graphs with parallel edges and
	self-loops. The nodes in NetworkX graphs can be any (hashable) Python
	object and edges can contain arbitrary data; this flexibility makes
	NetworkX ideal for representing networks found in many different
	scientific fields.
	
	
	In addition to the basic data structures many graph algorithms are
	implemented for calculating network properties and structure measures:
	shortest paths, betweenness centrality, clustering, and degree distribution
	and many more. NetworkX can read and write various graph formats
	for easy exchange with existing data, and provides generators for
	many classic graphs and popular graph models, such as the Erdos-Renyi,
	Small World, and Barabasi-Albert models.
	
	
	The ease-of-use and flexibility of the Python programming language
	together with connection to the SciPy tools make NetworkX a powerful
	tool for scientific computations. We discuss some of our recent work
	studying synchronization of coupled oscillators to demonstrate how
	NetworkX enables research in the field of computational networks.},
  editors = {G\"{a}el Varoquaux, Travis Vaught, and Jarrod Millman},
  file = {hagberg2008.pdf:hagberg2008.pdf:PDF},
  urlpdf = {http://math.lanl.gov/~hagberg/Papers/hagberg-2008-exploring.pdf}
}

@INPROCEEDINGS{haghani2007,
  author = {Haghani, Parisa and Papadimitratos, Panos and Poturalski, Marcin
	and Aberer, Karl and Hubaux, Jean-Pierre},
  title = {Efficient and Robust Secure Aggregation for Sensor Networks},
  booktitle = {{NPSEC '07}: Proceedings of the 2007 3rd {IEEE} Workshop on Secure
	Network Protocols},
  year = {2007},
  pages = {1--6},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Wireless Sensor Networks (WSNs) rely on in-network aggregation for
	efficiency, however, this comes at a price: A single adversary can
	severely influence the outcome by contributing an arbitrary partial
	aggregate value. Secure in-network aggregation can detect such manipulation
	[2]. But as long as such faults persist, no aggregation result can
	be obtained. In contrast, the collection of individual sensor node
	values is robust and solves the problem of availability, yet in an
	inefficient way. Our work seeks to bridge this gap in secure data
	collection: We propose a system that enhances availability with an
	efficiency close to that of in-network aggregation. To achieve this,
	our scheme relies on costly operations to localize and exclude nodes
	that manipulate the aggregation, but only when a failure is detected.
	The detection of aggregation disruptions and the removal of faulty
	nodes provides robustness. At the same time, after removing faulty
	nodes, the WSN can enjoy low cost (secure) aggregation. Thus, the
	high exclusion cost is amortized, and efficiency increases.},
  doi = {http://dx.doi.org/10.1109/NPSEC.2007.4371623},
  file = {haghani2007.pdf:haghani2007.pdf:PDF},
  isbn = {978-1-4244-1602-8},
  keywords = {secure aggregation, sensor networks},
  review = {One of the papers building on \cite{chan2006}.
	
	Adds checking phases which seek out misbehaving nodes. Assumes a static
	tree constructed by root. Some honest nodes may potentially be excluded.
	
	
	The authors build on CPS but propose to use (costly) methods to localize
	and exclude misbehaving nodes, once such nodes have been detected.
	
	
	As in CPS, this proposal deals with securing aggregation against stealthy
	data modification attacks by aggregators. Simple approach to ensuring
	cooperation: centralized (no aggregation) approach, but in-network
	aggregation is then no longer the case. The author cites \cite{wu2007}
	and \cite{yang2006} as approaches with similar goal -- to protect
	the aggregate.
	
	CPS guarantee optimal security. Haghani et.al identifies the problem
	of DoS by a single adversary destroying the aggregation and attempt
	to solve this issue. They note that the fallback of CPS, the centralized
	method, is not efficient: In this case, the efficiency of in-network
	aggregation is destroyed completely by a single misbehaving node.
	
	
	Haghani et.al use the CPS in-network aggregation for efficiency. The
	acknowledgements are delivered using "onion" authentication, enabling
	identification of non-acknowledging nodes, and allowing identification
	of misbehaving ones. 
	
	
	Network assumptions:
	
	Much like the ones of CPS. Symmetric key for ea node and root, also
	a symmetric key with each neighbor. A well connected network is assumed.
	Also assume the root knows the entire tree $T_A$ (the same shaky
	assumption that CPS make). Response to faults (malicious nodes):
	The root constructs a new tree. Note: Makes rather strong assumptions
	on the mechanisms of tree construction, some trees may be much more
	dynamic.
	
	
	Adversary model:
	
	The same as CPS. Only concerned with stealthy attacks. Their assumptions
	on efficiency and security are that each adversary is at most able
	to disrupt one round of computation.
	
	
	The method:
	
	The CPS SHIA method is used unmodified, unless failure is detected.
	If failures detected, the system launches two adversary localization
	schemes, followed by an aggregation tree rebuilding process.
	
	The first checking phase indentifies misbehaving aggregators while
	the second one addresses the trivial corruption of the check value.
	Tree building simply involves recreating the aggregation tree from
	root down, which may not hold for dynamic or self organizing aggregation
	structures.
	
	
	Issues identified in discussion:
	
	The two checking phases could be combined into one.
	
	Exclusion of correct nodes: The system cannot distinquish between
	a child making an illegitimate contribution and a parent modifying
	the ack. Both nodes are therefore excluded in the haghani approach,
	leading to exclusion of legitimate nodes (potentially) -- worst case
	is $(\Delta-1)n_a$ good nodes excluded ($n_a$ is the maximum number
	of adversaries).
	
	Aggressively removing nodes can lead to a disconnected network (which
	would serve the adversary just as well). Haghani discusses an alternative
	strategy of reputation (Dont think it makes too much sense to try
	to maintain a grading of bad nodes -- a bad node is a bad node).}
}

@ARTICLE{hall1997,
  author = {D. L. Hall and J. Llinas},
  title = {An Introduction to Multisensor Data Fusion},
  journal = {PROCEEDINGS OF THE IEEE},
  year = {1997},
  volume = {85},
  pages = {6--23},
  number = {1},
  abstract = {Multisensor data fusion is an emerging technology applied to Department
	of Defense (DoD) areas such as automated target recognition, battleﬁeld
	surveillance, and guidance and control of autonomous vehicles, and
	to non-DoD applications such as monitoring of complex machinery,
	medical diagnosis, and smart buildings. Techniques for multisensor
	data fusion are drawn from a wide range of areas including artiﬁcial
	intelligence, pattern recognition, statistical estimation, and other
	areas. This paper provides a tutorial on data fusion, introducing
	data fusion applications, process models, and identiﬁcation of applicable
	techniques. Comments are made on the state-of-the-art in data fusion.},
  file = {hall1997.pdf:hall1997.pdf:PDF},
  keywords = {aggregation, data fusion},
  owner = {kristjan},
  timestamp = {2009.08.28}
}

@INPROCEEDINGS{halpern2004,
  author = {Halpern, Joseph and Teague, Vanessa},
  title = {Rational secret sharing and multiparty computation (extended abstract)},
  booktitle = {{STOC '04}: Proceedings of the thirty-sixth annual ACM symposium
	on Theory of computing},
  year = {2004},
  pages = {623--632},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We consider the problems of secret sharing and multiparty computation,
	assuming that agents prefer to get the secret (resp., function value)
	to not getting it, and secondarily, prefer that as few as possible
	of the other agents get it. We show that, under these assumptions,
	neither secret sharing nor multiparty function computation is possible
	using a mechanism that has a fixed running time. However, we show
	that both are possible using randomized mechanisms with constant
	expected running time.},
  doi = {http://doi.acm.org/10.1145/1007352.1007447},
  file = {halpern2004.pdf:halpern2004.pdf:PDF},
  isbn = {1-58113-852-0},
  keywords = {secret sharing, multiparty computation},
  location = {Chicago, IL, USA}
}

@TECHREPORT{hammad2003a,
  author = {Moustafa A. Hammad and Walid G. Aref and Michael J. Franklin and
	Mohamed F. Mokbel and Ahmed K. Elmagarmid},
  title = {Efﬁcient Execution of Sliding-Window Queries Over Data Streams},
  institution = {Department of Computer Sciences, Purdue University},
  year = {2003},
  number = {CSD TR 03-035},
  month = {December},
  abstract = {Emerging data stream processing systems rely on windowing to enable
	on-the-ﬂy processing of continuous queries over unbounded streams.
	As a result, several recent eﬀorts have developed window-aware implementations
	of query operators such as joins and aggregates. This focus on individual
	operators, however, ignores the larger issue of how to coordinate
	the pipelined execution of such operators when combined into a full
	windowed query plan. In this paper, we ﬁrst show how the straightforward
	application of traditional pipelined query processing techniques
	to sliding window queries can result in ineﬃcient and incorrect behavior.
	We then present three alternative execution techniques that guarantee
	correct behavior for pipelined sliding window queries and develop
	new algorithms for correctly evaluating window-based duplicate elimination,
	Group-By and Set operators in this context. We implemented all of
	these techniques in a prototype data stream system and report the
	results of a detailed performance study of the system.},
  file = {StreamQueryProcessing-TechReport2003.pdf:StreamQueryProcessing-TechReport2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.10}
}

@ARTICLE{hammad2003,
  author = {Hammad, M.A. and Aref, W.G. and Elmagarmid, A.K.},
  title = {Stream window join: tracking moving objects in sensor-network databases},
  journal = {Conference on Scientific and Statistical Database Management, 2003.
	15th International},
  year = {2003},
  pages = {75-84},
  month = {9-11 July},
  abstract = {The widespread use of sensor networks presents revolutionary opportunities
	for life and environmental science applications. Many of these applications
	involve continuous queries that require the tracking, monitoring,
	and correlation of multi-sensor data that represent moving objects.
	We propose to answer these queries using a multi-way stream window
	join operator. This form of join over multi-sensor data must cope
	with the inﬁnite nature of sensor data streams and the delays in
	network transmission. This paper introduces a class of join algorithms,
	termed W-join, for joining multiple inﬁnite data streams. W-join
	addresses the inﬁnite nature of the data streams by joining stream
	data items that lie within a sliding window and that match a certain
	join condition. W-join can be used to track the motion of a moving
	object or detect the propagation of clouds of hazardous material
	or pollution spills over time in a sensor network environment. We
	describe two new algorithms for W-join, and address variations and
	local/global optimizations related to specifying the nature of the
	window constraints to fulﬁll the posed queries. The performance of
	the proposed algorithms are studied experimentally in a prototype
	stream database system, using synthetic data streams and real time-series
	data. Tradeoffs of the proposed algorithms and their advantages and
	disadvantages are highlighted, given variations in the aggregate
	arrival rates of the input data streams and the desired response
	times per query.},
  doi = {10.1109/SSDM.2003.1214967},
  file = {01214967.pdf:01214967.pdf:PDF},
  issn = {1099-3371 },
  keywords = { data analysis, query processing, sensor fusion, video databases W-join,
	data correlation, data monitoring, data stream, data tracking, environmental
	science, join algorithm, life science, multisensor data, network
	transmission, sensor network, sensor network databases}
}

@ARTICLE{hammad2004,
  author = {Hammad, M.A. and Mokbel, M.F. and Ali, M.H. and Aref, W.G. and Catlin,
	A.C. and Elmagarmid, A.K. and Eltabakh, M. and Elfeky, M.G. and Ghanem,
	T.M. and Gwadera, R. and Ilyas, I.F. and Marzouk, M. and Xiong, X.},
  title = {Nile: a query processing engine for data streams},
  journal = {Data Engineering, 2004. Proceedings. 20th International Conference
	on},
  year = {2004},
  pages = { 851-},
  month = {30 March-2 April},
  doi = {10.1109/ICDE.2004.1320080},
  file = {20650851.pdf:20650851.pdf:PDF},
  issn = {1063-6382 },
  keywords = { object-oriented databases, query processing, relational databases
	SQL operators, data streams, object-relational database management
	system, query processing engine, stream database system}
}

@ONLINE{hammer-lahav-2007,
  author = {Eran Hammer-Lahav},
  title = {{Explaining OAuth}},
  url = {http://www.hueniverse.com/hueniverse/2007/09/explaining-oaut.html},
  year = {2007},
  owner = {kristjan},
  timestamp = {2009.03.11}
}

@INPROCEEDINGS{hammoudeh2008,
  author = {Hammoudeh, M. and Shuttleworth, J. and Newman, R. and Mount, S.},
  title = {Experimental Applications of Hierarchical Mapping Services in Wireless
	Sensor Networks},
  booktitle = {{SENSORCOMM '08}. Second International Conference on Sensor Technologies
	and Applications},
  year = {2008},
  pages = {36-43},
  month = {Aug.},
  doi = {10.1109/SENSORCOMM.2008.22},
  file = {hammoudeh2008.pdf:hammoudeh2008.pdf:PDF},
  keywords = {data visualisation, distributed processing, interpolation, telecommunication
	network routing, telecommunication network topology, wireless sensor
	networkscluster-based routing algorithm, data visualization, distributed
	computation, energy constrained network, global network data mapping,
	hierarchical mapping services, interpolation services, local maps,
	low-resolution map, network nodes, sink node, topology coverage,
	wireless sensor networks}
}

@INPROCEEDINGS{handley2001,
  author = {Mark Handley and Vern Paxson and Christian Kreibich},
  title = {Network intrusion detection: Evasion, traffic normalization, and
	end-to-end protocol semantics},
  booktitle = {{SSYM'01: Proceedings of the 10th conference on USENIX Security Symposium}},
  year = {2001},
  pages = {9--9},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {A fundamental problem for network intrusion detection systems is the
	ability of a skilled attacker to evade detection by exploiting ambiguities
	in the traffic stream as seen by the monitor. We discuss the viability
	of addressing this problem by introducing a new network forwarding
	element called a traffic normalizer. The normalizer sits directly
	in the path of traffic into a site and patches up the packet stream
	to eliminate potential ambiguities before the traffic is seen by
	the monitor, removing evasion opportunities. We examine a number
	of tradeoffs in designing a normalizer, emphasizing the important
	question of the degree to which normalizations undermine end-to-end
	protocol semantics. We discuss the key practical issues of "cold
	start" and attacks on the normalizer, and develop a methodology for
	systematically examining the ambiguities present in a protocol based
	on walking the protocol's header. We then present norm, a publicly
	available user-level implementation of a normalizer that can normalize
	a TCP traffic stream at 100,000 pkts/sec in memory-to-memory copies,
	suggesting that a kernel implementation using PC hardware could keep
	pace with a bidirectional 100 Mbps link with sufficient headroom
	to weather a high-speed flooding attack of small packets.},
  location = {Washington, D.C.}
}

@BOOK{hankerson2004,
  title = {Guide to Elliptic Curve Cryptography},
  publisher = {Springer},
  year = {2004},
  author = {Darrel Hankerson and Alfred Menezes and Scott Vanslone},
  owner = {kristjan},
  timestamp = {2010.09.16}
}

@INPROCEEDINGS{haridasan2006,
  author = {Haridasan, Maya and van Renesse, Robbert},
  title = {Defense against Intrusion in a Live Streaming Multicast System},
  booktitle = {P2P '06: Proceedings of the Sixth IEEE International Conference on
	Peer-to-Peer Computing},
  year = {2006},
  pages = {185--192},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Application-level multicast systems are vulnerable to attacks that
	impede nodes from receiving desired data. Live streaming protocols
	are especially susceptible to packet loss induced by malicious behavior.
	We describe SecureStream, an application-level live streaming system
	built using a pull-based architecture that results in improved tolerance
	of malicious behavior. SecureStream is implemented as a layer running
	over Fireflies, an intrusion-tolerant membership protocol. Our paper
	describes the SecureStream system and offers simulation and experimental
	results confirming its resilience to attack.},
  doi = {http://dx.doi.org/10.1109/P2P.2006.15},
  isbn = {0-7695-2679-9},
  keywords = {gossip protocol, application layer multicast, byzantine fault tolerance},
  review = {Ref'd by alvisi2007. Byzantine fault tolerant gossiping -- streaming
	service built on top of firefly.}
}

@ARTICLE{harris2007,
  author = {Albert F. {Harris III} and Robin Kravets and Indranil Gupta},
  title = {Building trees based on aggregation efficiency in sensor networks},
  journal = {Ad Hoc Networks},
  year = {2007},
  volume = {5},
  pages = {1317 - 1328},
  number = {8},
  note = {Recent Research Directions in Wireless Ad Hoc Networking},
  abstract = {Sensor network protocols must minimize energy consumption due to their
	resource-constrained nature. Large amounts of redundant data are
	produced by the sensors in such networks; however, sending unnecessary
	data wastes energy. One common technique used to reduce the amount
	of data in sensor networks is data aggregation. Therefore, we consider
	the impact and cost of data aggregation in sensor networks to achieve
	energy-efficient operation. We propose a new notion of energy efficiency
	that can be used to decide where aggregation points in the network
	should be placed. The optimal choice of these points is determined
	by the aggregation efficiency, which determines the amount of data
	reduction, and the cost in terms of energy to perform the aggregation.
	We present our aggregation tree algorithm “Oceanus” that produces
	energy-efficient aggregation trees by taking into account both of
	these factors. Our evaluation shows that Oceanus provides higher
	energy efficiency compared to existing solutions.},
  doi = {DOI: 10.1016/j.adhoc.2007.02.021},
  file = {harris2007.pdf:harris2007.pdf:PDF},
  issn = {1570-8705},
  keywords = {Sensor networks},
  url = {http://www.sciencedirect.com/science/article/B7576-4N8BN0N-4/2/84030f4baa0d678c3ef1cfba41e5aee4}
}

@INPROCEEDINGS{harte2005,
  author = {Harte, S. and Rahman, A. and Razeeb, K.M.},
  title = {Fault tolerance in sensor networks using self-diagnosing sensor nodes},
  booktitle = {{IEEE} International Workshop on Intelligent Environments},
  year = {2005},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@TECHREPORT{hartung2005,
  author = {Carl Hartung and James Balasall\`{e} and Richard Han},
  title = {Node Compromise in Sensor Networks: The Need for Secure Systems},
  institution = {University of Colorado at Boulder},
  year = {2005},
  abstract = {While sensor network deployment is becoming more commonplace in environmental,
	business, and military applications, security of these networks emerges
	as a critical concern. Without proper security, it is impossible
	to completely trust the results reported from sensor networks deployed
	outside of controlled environments. Much of the current research
	in sensor networks has focused on protocols and authentication schemes
	for protecting the transport of information. However, all of those
	schemes are useless if an attacker can obtain a node from the network
	and extract the appropriate information, such as security keys, from
	it.
	
	
	We focus our research on the area of secure systems. In this paper
	we demonstrate the ease with which nodes can be compromised as well
	as show exactly what information can be obtained and how it can be
	used to disrupt, falsify data within, or eavesdrop on sensor networks.
	We then suggest mechanisms to detect intrusions into individual sensor
	nodes. Finally, we come up with security measures that can be implemented
	in future generation nodes to improve security.},
  file = {hartung2005.pdf:hartung2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.21}
}

@ONLINE{Hawes2006,
  author = {Joseph Hawes},
  title = {The BitTorrent Protocol},
  url = {http://morehawes.co.uk/articles/bittorrent_technical.php},
  year = {2006},
  date_accessed = {31.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{hayes2008,
  author = {Hayes, Tom and Rustagi, Navin and Saia, Jared and Trehan, Amitabh},
  title = {The forgiving tree: a self-healing distributed data structure},
  booktitle = {{PODC '08}: Proceedings of the twenty-seventh {ACM} symposium on
	Principles of distributed computing},
  year = {2008},
  pages = {203--212},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We consider the problem of self-healing in peer-to-peer networks that
	are under repeated attack by an omniscient adversary. We assume that
	the following process continues for up to n rounds where n is the
	total number of nodes initially in the network: the adversary deletes
	an arbitrary node from the network, then the network responds by
	quickly adding a small number of new edges.
	
	
	We present a distributed data structure that ensures two key properties.
	First, the diameter of the network is never more than O(log ∆) times
	its original diameter, where ∆ is the maximum degree of the network
	initially. We note that for many peer-to-peer systems, ∆ is polylogarithmic,
	so the diameter increase would be a O(log log n) multiplicative factor.
	Second, the degree of any node never increases by more than 3 over
	its original degree. Our data structure is fully distributed, has
	O(1) latency per round and requires each node to send and receive
	O(1) messages per round. The data structure requires an initial setup
	phase that has latency equal to the diameter of the original network,
	and requires, with high probability, each node v to send O(log n)
	messages along every edge incident to v. Our approach is orthogonal
	and complementary to traditional topology-based approaches to defending
	against attack.},
  doi = {http://doi.acm.org/10.1145/1400751.1400779},
  file = {hayes2008.pdf:hayes2008.pdf:PDF},
  isbn = {978-1-59593-989-0},
  keywords = {churn attacks, join leave attacks, distributed systems, security},
  location = {Toronto, Canada}
}

@ARTICLE{hayzelden1999,
  author = {Alex L. G. Hayzelden and John Bigham},
  title = {Agent technology in communications systems: an overview},
  journal = {Knowl. Eng. Rev.},
  year = {1999},
  volume = {14},
  pages = {341--375},
  number = {4},
  abstract = {Telecommunications infrastructures are a natural application domain
	for the distributed software agent paradigm. The authors clarify
	the potential application of software agent technology in legacy
	and future communications systems, and provide an overview of publicly
	available research on software agents used for communications management.
	The authors focus on the intelligent agent type of software agent,
	although the paper also reviews the reasons why mobile agents have
	made an impact in this domain. The author's objective is to describe
	some of the intricacies of using the software agent approach for
	the management of communications systems. The paper is in four main
	sections. The first section provides a brief introduction to software
	agent technology. The second section considers general problems of
	network management and the reasons why software agents may provide
	a suitable solution. The third section reviews some selected research
	on agents in a telecommunications management framework. The final
	section concludes the paper by discussing some of the problems encountered
	and some future directions for further research.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1017/S0269888999003057},
  issn = {0269-8889},
  publisher = {Cambridge University Press}
}

@INPROCEEDINGS{he2006,
  author = {Tian He and Pascal Vicaire and Ting Yan and Liqian Luo and Lin Gu
	and Gang Zhou and Radu Stoleru and Qing Cao and John~A. Stankovic
	and Tarek Abdelzaher},
  title = {Achieving Real-Time Target Tracking Using Wireless Sensor Network},
  booktitle = {{IEEE} Real Time Technology and Applications Symosium},
  year = {2006},
  pages = {37--48},
  abstract = {Target tracking systems, consisting of thousands of low-cost sensor
	nodes, have been used in many application domains such as battlefield
	surveillance, wildlife monitoring and border security. These applications
	need to meet certain real-time constraints in response to transient
	events, such as fast-moving targets. While the real-time performance
	is a major concern in these applications, it should be compatible
	with other important system properties such as energy consumption
	and accuracy. Hence, it is desirable to have the ability to exploit
	the tradeoffs among them. This work presents the real-time design
	and analysis of VigilNet, a large-scale sensor network system which
	tracks, detects and classifies targets in a timely and energy efficient
	manner. Based on a deadline partition method and theoretical derivations
	of each sub-deadline, we are able to make guided engineering decisions
	to meet the end-to-end tracking deadline. To confirm our design and
	obtain an empirical understanding of these tradeoffs, we invest significant
	efforts to perform large-scale simulations with 10,000 nodes as well
	as a field test with 200 XSM motes, running VigilNet. The results
	from both analysis and evaluation can serve as general design guidelines
	to build similar real-time systems.},
  file = {he2006.pdf:he2006.pdf:PDF},
  keywords = {wireless sensor networks, applications},
  owner = {kristjan},
  review = {An interesting application of a sensor network.},
  timestamp = {2010.01.17}
}

@ARTICLE{he2007,
  author = {Wenbo He and Xue Liu and Hoang Nguyen and K. Nahrstedt and T.T. Abdelzaher},
  title = {PDA: Privacy-Preserving Data Aggregation in Wireless Sensor Networks},
  journal = {INFOCOM 2007. 26th IEEE International Conference on Computer Communications.
	IEEE},
  year = {2007},
  pages = {2045-2053},
  month = {May},
  __markedentry = {[kristjan]},
  abstract = {Providing efﬁcient data aggregation while preserving data privacy
	is a challenging problem in wireless sensor networks research. In
	this paper, we present two privacy-preserving data aggregation schemes
	for additive aggregation functions. The ﬁrst scheme – Cluster-based
	Private Data Aggregation (CPDA)–leverages clustering protocol and
	algebraic properties of polynomials. It has the advantage of incurring
	less communication overhead. The second scheme – Slice-Mix-AggRegaTe
	(SMART)–builds on slicing techniques and the associative property
	of addition. It has the advantage of incurring less computation overhead.
	The goal of our work is to bridge the gap between collaborative data
	collection by wireless sensor networks and data privacy. We assess
	the two schemes by privacy-preservation efﬁcacy, communication overhead,
	and data aggregation accuracy. We present simulation results of our
	schemes and compare their performance to a typical data aggregation
	scheme – TAG, where no data privacy protection is provided. Results
	show the efﬁcacy and efﬁciency of our schemes. To the best of our
	knowledge, this paper is among the ﬁrst on privacy-preserving data
	aggregation in wireless sensor networks.},
  doi = {10.1109/INFCOM.2007.237},
  file = {:he2007.pdf:PDF},
  issn = {0743-166X},
  keywords = {data privacy, polynomials, protocols, telecommunication security,
	wireless sensor networksSlice-Mix-AggRegaTe scheme, cluster-based
	private data aggregation, clustering protocol, polynomial, privacy-preserving
	data aggregation scheme, wireless sensor network}
}

@MISC{healan2003,
  author = {Mike Healan},
  title = {Referer Spam},
  owner = {kristjan},
  timestamp = {2008.09.08},
  url = {http://www.spywareinfo.com/articles/referer_spam/}
}

@INPROCEEDINGS{heinzelman2000,
  author = {Heinzelman, Wendi Rabiner and Chandrakasan, Anantha and Balakrishnan,
	Hari},
  title = {Energy-Efficient Communication Protocol for Wireless Microsensor
	Networks},
  booktitle = {{HICSS} '00: Proceedings of the 33rd Hawaii International Conference
	on System Sciences-Volume 8},
  year = {2000},
  pages = {8020},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Wireless distributed micro-sensor systems will enable the reliable
	monitoring of a variety of environments for both civil and military
	applications. In this paper, we look at communication protocols,
	which can have significant impact on the overall energy dissipation
	of these networks.Based on our findings that the conventional protocols
	of direct transmission, minimum-transmission-energy, multihop routing,
	and static clustering may not be optimal for sensor networks, we
	propose LEACH (Low-Energy Adaptive Clustering Hierarchy), a clustering-based
	protocol that utilizes randomized rotation of local cluster base
	stations (cluster-heads) to evenly distribute the energy load among
	the sensors in the network. LEACH uses localized coordination to
	enable scalability and robustness for dynamic net-works, and incorporates
	data fusion into the routing protocol to reduce the amount of information
	that must be transmitted to the base station. Simulations show that
	LEACH can achieve as much as a factor of 8 reduction in energy dissipation
	compared with conventional routing protocols. In addition, LEACH
	is able to distribute energy dissipation evenly throughout the sensors,
	doubling the useful system lifetime for the networks we simulated.},
  file = {heinzelman2000.ps:heinzelman2000.ps:PostScript},
  isbn = {0-7695-0493-0},
  keywords = {sensor network, security, clustering, LEACH},
  review = {Considers clustering algorithms for wireless sensor networks. Primarily
	(seems) in terms of power efficiency.}
}

@INPROCEEDINGS{heinzelman1999,
  author = {Heinzelman, Wendi Rabiner and Kulik, Joanna and Balakrishnan, Hari},
  title = {Adaptive protocols for information dissemination in wireless sensor
	networks},
  booktitle = {{MobiCom} '99: Proceedings of the 5th annual {ACM/IEEE} international
	conference on Mobile computing and networking},
  year = {1999},
  pages = {174--185},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we present a family of adaptive protocols, called SPIN
	(Sensor Protocols for Information via Negotiation), that efficiently
	disseminates information among sensors in an energy-constrained wireless
	sensor network. Nodes running a SPIN communication protocol name
	their data using high-level data descriptors, called meta-data. They
	use meta-data negotiations to eliminate the transmission of redundant
	data throughout the network. In addition, SPIN nodes can base their
	communication decisions both upon application-specific knowledge
	of the data and upon knowledge of the resources that are available
	to them. This allows the sensors to efficiently distribute data given
	a limited energy supply. We simulate and analyze the performance
	of two specific SPIN protocols, comparing them to other possible
	approaches and a theoretically optimal protocol. We find that the
	SPIN protocols can deliver 60% more data for a given amount of energy
	than conventional approaches. We also find that, in terms of dissemination
	rate and energy usage, the SPlN protocols perform close to the theoretical
	optimum.},
  doi = {http://doi.acm.org/10.1145/313451.313529},
  file = {heinzelman1999.pdf:heinzelman1999.pdf:PDF},
  isbn = {1-58113-142-9},
  location = {Seattle, Washington, United States}
}

@INPROCEEDINGS{Helgason2008a,
  author = {Olafur Ragnar Helgason and Kristj\'{a}n Valur J\'{o}nsson},
  title = {Opportunistic Networking in {OMNeT}++},
  booktitle = {First International Conference on Simulation Tools and Techniques
	for Communications, Networks and Systems ({SIMUTOOLS} 2008), {OMNeT}++
	Workshop},
  year = {2008},
  file = {opponet.submitted.pdf:opponet.submitted.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{hellerstein2001,
  author = {Joseph L. Hellerstein and Fan Zhang and Perwez Shahabuddin},
  title = {A statistical approach to predictive detection},
  journal = {Computer Networks},
  year = {2001},
  volume = {35},
  pages = {77 - 95},
  number = {1},
  note = {Selected Topics in Network and Systems Management},
  abstract = {Service providers typically define quality of service problems using
	threshold tests, such as “Are HTTP operations greater than 12 per
	second on server XYZ?” Herein, we estimate the probability of threshold
	violations for specific times in the future. We model the threshold
	metric (e.g., HTTP operations per second) at two levels: (1) non-stationary
	behavior (as is done in workload forecasting for capacity planning)
	and (2) stationary, time-serial dependencies. Our approach is assessed
	using simulation experiments and measurements of a production Web
	server. For both assessments, the probabilities of threshold violations
	produced by our approach lie well within two standard deviations
	of the measured fraction of threshold violations.},
  doi = {DOI: 10.1016/S1389-1286(00)00151-1},
  file = {hellerstein2001.pdf:hellerstein2001.pdf:PDF},
  issn = {1389-1286},
  keywords = {Proactive management},
  url = {http://www.sciencedirect.com/science/article/B6VRG-41TN5K8-6/2/51b6a037e6aa9bac3a6c0b193cf5dfa4}
}

@INPROCEEDINGS{henzinger1999,
  author = {Monika R. Henzinger and Allan Heydon and Michael Mitzenmacher and
	Marc Najork},
  title = {Measuring index quality using random walks on the Web},
  booktitle = {WWW '99: Proceedings of the eighth international conference on World
	Wide Web},
  year = {1999},
  pages = {1291--1303},
  address = {New York, NY, USA},
  publisher = {Elsevier North-Holland, Inc.},
  doi = {http://dx.doi.org/10.1016/S1389-1286(99)00016-X},
  location = {Toronto, Canada}
}

@INPROCEEDINGS{Hernandez-Campos2004,
  author = {F. Hernandez-Campos and F. Donelson Smith and K. Jeffay and A. B.
	Nobel},
  title = {Understanding Patterns of TCP Connection Usage with Statistical Clustering},
  booktitle = {{IEEE MASCOTS}},
  year = {2005},
  pages = {35--44},
  abstract = {We describe a new methodology for understanding how applications use
	TCP to exchange data. Our approach is based on an abstract model
	of application-level communication that is suitable for statistical
	cluster analysis.},
  keywords = {networks, network analysis, TCP, modeling}
}

@ARTICLE{hesse2009,
  author = {Malte Hesse and Norbert Pohlmann},
  title = {European internet early warning system},
  journal = {Int. J. Electron. Secur. Digit. Forensic},
  year = {2009},
  volume = {2},
  pages = {1--17},
  number = {1},
  abstract = {The internet is consisting of autonomous systems each managed by individual
	and mostly rival organisations. This situation makes it very difficult
	to capture the state of the internet as a whole. An individual internet
	situation awareness for various stakeholders can be accomplished
	by creating a common basis for private and public operators to monitor
	their networks, by offering them a common smart approach to monitor
	their network individually and the additional benefit of participating
	to establish a global view, which they can use as a reference for
	their local situation. This smart approach should utilise well-proven
	existing global statistics, best practices and existing technical
	sensors, which can be adapted to the overall common framework. From
	this, output for all relevant stakeholders can be generated to fulfil
	the individual needs. Once the internet situation awareness is accomplished,
	it can be used besides others for an European internet early warning
	system.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJESDF.2009.023871},
  issn = {1751-911X},
  publisher = {Inderscience Publishers}
}

@MISC{Hindle2004,
  author = {Abram Hindle},
  title = {Analysis of the P2P BitTorrent Protocol},
  year = {2004},
  file = {BTB_paper.pdf:BTB_paper.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{hirt2000a,
  author = {Martin Hirt and Ueli Maurer},
  title = {Player Simulation and General Adversary Structures in Perfect Multiparty
	Computation},
  journal = {Journal of Cryptology},
  year = {2000},
  volume = {13},
  pages = {31--60},
  abstract = {The goal of secure multiparty computation is to transform a given
	protocol involving a trusted
	
	party into a protocol without need for the trusted party, by simulating
	the party among the players.
	
	Indeed, by the same means, one can simulate an arbitrary player in
	any given protocol. We formally
	
	deﬁne what it means to simulate a player by a multiparty protocol
	among a set of (new) players, and
	
	we derive the resilience of the new protocol as a function of the
	resiliences of the original protocol
	
	and the protocol used for the simulation.
	
	
	In contrast to all previous protocols that specify the tolerable adversaries
	by the number of cor-
	
	ruptible players (a threshold), we consider general adversaries characterized
	b y an adversary struc-
	
	ture, a set of subsets of the player set, where the adversary may
	corrupt the players of one set in the
	
	structure. Recursively applying the simulation technique to standard
	threshold multiparty protocols
	
	results in protocols secure against general adversaries.
	
	
	The classical results in unconditional multiparty computation among
	a set of n players state that,
	
	in the passive model, any adversary that corrupts less than n=2 players
	can be tolerated, and in the
	
	active model, any adversary that corrupts less than n=3 players can
	be tolerated. Strictly generalizing
	
	these results we prove that in the passive model, every function (more
	generally, every cooperation
	
	speciﬁed by involving a trusted party) can be computed securely with
	respect to a given adversary
	
	structure if and only if no two sets in the adversary structure cover
	the full set of players, and in
	
	the active model, if and only if no three sets cover the full set
	of players. The complexities of the
	
	protocols are polynomial in the number of maximal adverse player sets
	in the adversary structure.},
  file = {hirt2000a.pdf:hirt2000a.pdf:PDF},
  keywords = {Multiparty computation, Information-theoretic security, Player simulation,
	General adversaries, Adversary structures.}
}

@INCOLLECTION{hirt2000,
  author = {Martin Hirt and Ueli Maurer and Bartosz Przydatek},
  title = {Efficient Secure Multi-party Computation},
  booktitle = {Advances in Cryptology — {ASIACRYPT} 2000},
  publisher = {Springer Berlin / Heidelberg},
  year = {2000},
  volume = {1976/2000},
  abstract = {Since the introduction of secure multi-party computation, all proposed
	protocols that provide security against cheating players suﬀer from
	very high communication complexities. The most eﬃcient unconditionally
	secure protocols among n players, tolerating cheating by up to t
	< n/3 of them, require communicating O(n6 ) ﬁeld elements for each
	multiplication of two elements, even if only one player cheats. 
	
	
	In this paper, we propose a perfectly secure multi-party protocol
	which requires communicating O(n3 ) ﬁeld elements per multiplication.
	In this protocol, the number of invocations of the broadcast primitive
	is independent of the size of the circuit to be computed. The proposed
	techniques are generic and apply to other protocols for robust distributed
	computations.
	
	
	Furthermore, we show that a sub-protocol proposed in [GRR98] for improving
	the eﬃciency of unconditionally secure multi-party computation is
	insecure.},
  file = {hirt2000.pdf:hirt2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.16}
}

@INPROCEEDINGS{hirt2001,
  author = {Hirt, Martin and Maurer, Ueli M.},
  title = {Robustness for Free in Unconditional Multi-party Computation},
  booktitle = {{CRYPTO} '01: Proceedings of the 21st Annual International Cryptology
	Conference on Advances in Cryptology},
  year = {2001},
  pages = {101--118},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {We present a very efficient multi-party computation protocol unconditionally
	secure against an active adversary. The security is maximal, i.e.,
	active corruption of up to t < n=3 of the n players is tolerated.
	The communication complexity for securely evaluating a circuit with
	m multiplication gates over a finite field is O(mn 2 ) field elements,
	including the communication required for simulating broadcast, but
	excluding some overhead costs (independent of m) for sharing the
	inputs and reconstructing the outputs. This corresponds to the complexity
	of the best known protocols for the passive model, where the corrupted
	players are guaranteed not to deviate from the protocol. The complexity
	of our protocol may well be optimal. The constant overhead factor
	for robustness is small and the protocol is practical.},
  file = {hirt2001.pdf:hirt2001.pdf:PDF},
  isbn = {3-540-42456-3}
}

@INPROCEEDINGS{hirt2005,
  author = {Martin Hirt and Jesper Buus Nielsen},
  title = {Upper Bounds on the Communication Complexity of Optimally Resilient
	Cryptographic Multiparty Computation},
  booktitle = {Advances in Cryptology - {ASIACRYPT} 2005},
  year = {2005},
  abstract = {We give improved upper bounds on the communication complexity of optimally-resilient
	secure multiparty computation in the cryptographic model. We consider
	evaluating an n-party randomized function and show that if f can
	be computed by a circuit of size c, then MediaObjects/InlineFigure1.png
	is an upper bound for active security with optimal resilience t <
	n/2 and security parameter κ. This improves on the communication
	complexity of previous protocols by a factor of at least n. This
	improvement comes from the fact that in the new protocol, only MediaObjects/InlineFigure2.png
	messages (of size MediaObjects/InlineFigure3.png each) are broadcast
	during the whole protocol execution, in contrast to previous protocols
	which require at least MediaObjects/InlineFigure4.png broadcasts
	per gate.
	
	Furthermore, we improve the upper bound on the communication complexity
	of passive secure multiparty computation with resilience t<n from
	MediaObjects/InlineFigure5.png to MediaObjects/InlineFigure6.png.
	This improvement is mainly due to a simple observation.},
  file = {hirt2005.pdf:hirt2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.16}
}

@INPROCEEDINGS{Hjalmtysson2004_1,
  author = {Hj{\'{a}}lmt{\'{y}}sson, G. and Brynj{\'{u}}lfsson, B. and Helgason,
	{\'{O}}.R.},
  title = {Self-configuring Lightweight Internet Multicast},
  booktitle = {{IEEE} International Conference on Systems, Man and Cybernetics},
  year = {2004},
  volume = {5},
  pages = {4619- 4624},
  abstract = {Some of the greatest benefits of the Internet come from its simple
	service model and the avoidance of regulatory and contractual legacy
	of the telecom industry. Successful integration of multicast into
	the global Internet promises to bring similar benefits to group communications.
	In spite of this promise and massive research and experimentation
	with IP multicast, efforts to realize multicast services on the Internet
	have so far failed. A key element to facilitate IP multicast is to
	reduce the amount of infrastructure and network support specifically
	introduced for multicast.
	
	
	We have defined, implemented and experimented with a lightweight single
	source multicast paradigm for the Internet that self-configures over
	the unicast infrastructure using only commonly available router functions.
	Our protocol avoids multicast specific control infrastructure. The
	only multicast specific functions are the control plane topology
	management, which operates out of data-path and manipulates router
	classifiers (forwarding table) and tunnel facilities.},
  file = {:hjalmtysson2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.10.18}
}

@INPROCEEDINGS{ho2008,
  author = {Ho, Chi and {van Renesse}, Robbert and Bickford, Mark and Dolev,
	Danny},
  title = {Nysiad: practical protocol transformation to tolerate Byzantine failures},
  booktitle = {{NSDI'08}: Proceedings of the 5th {USENIX} Symposium on Networked
	Systems Design and Implementation},
  year = {2008},
  pages = {175--188},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {The paper presents and evaluates Nysiad, a system that implements
	a new technique for transforming a scalable distributed system or
	network protocol tolerant only of crash failures into one that tolerates
	arbitrary failures, including such failures as freeloading and malicious
	attacks. The technique assigns to each host a certain number of guard
	hosts, optionally chosen from the available collection of hosts,
	and assumes that no more than a configurable number of guards of
	a host are faulty. Nysiad then enforces that a host either follows
	the system's protocol and handles all its inputs fairly, or ceases
	to produce output messages altogether--a behavior that the system
	tolerates. We have applied Nysiad to a link-based routing protocol
	and an overlay multicast protocol, and present measurements of running
	the resulting protocols on a simulated network.},
  file = {ho2008.pdf:ho2008.pdf:PDF},
  isbn = {111-999-5555-22-1},
  keywords = {accountability systems},
  location = {San Francisco, California}
}

@ARTICLE{holme2002,
  author = {P. Holme and B. J. Kim},
  title = {Growing scale-free networks with tunable clustering},
  journal = {Phys. Rev. E},
  year = {2002},
  volume = {65},
  pages = {026107},
  number = {2},
  abstract = {We extend the standard scale-free network model to include a ‘‘triad
	formation step.’’ We analyze the
	
	geometric properties of networks generated by this algorithm both
	analytically and by numerical calculations,
	
	and ﬁnd that our model possesses the same characteristics as the standard
	scale-free networks such as the
	
	power-law degree distribution and the small average geodesic length,
	but with the high clustering at the same
	
	time. In our model, the clustering coefﬁcient is also shown to be
	tunable simply by changing a control
	
	parameter—the average number of triad formation trials per time step.},
  file = {holme2002.pdf:holme2002.pdf:PDF}
}

@ARTICLE{hu2009a,
  author = {Hu, Hongbing and Chen, Yu and Ku, Wei\&\#45;Shinn and Su, Zhou and
	Chen, Chung\&\#45;Han J.},
  title = {Weighted trust evaluation\&\#45;based malicious node detection for
	wireless sensor networks},
  journal = {Int. J. Inf. Comput. Secur.},
  year = {2009},
  volume = {3},
  pages = {132--149},
  number = {2},
  abstract = {Deployed in a hostile environment, the individual Sensor Node (SN)
	of a Wireless Sensor Network (WSN) could be easily compromised by
	an adversary due to constraints such as limited memory space and
	computing capability. Therefore, it is critical to detect and isolate
	compromised nodes in order to avoid being misled by the falsified
	information injected by adversaries through compromised nodes. However,
	it is challenging to secure the flat topology networks effectively
	because of the poor scalability and high communication overhead.
	On top of a hierarchical WSN architecture, a novel algorithm based
	on Weighted Trust Evaluation (WTE) to detect malicious nodes for
	hierarchical sensor networks is proposed in this paper. The hierarchical
	network can reduce the communication overhead among SNs by utilising
	clustered topology. The proposed algorithm models a cluster of SNs
	and detects malicious nodes by examining their weights that represent
	the reliability of SNs. Through intensive simulations, the accuracy
	and effectiveness of the proposed detection algorithm are verified.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJICS.2009.028810},
  issn = {1744-1765},
  publisher = {Inderscience Publishers},
  review = {newer version of atakli2008??
	
	That paper looked weak (at first glance) so this one is not too interesting
	at the moment.}
}

@ARTICLE{hu2003,
  author = {Lingxuan Hu and D. Evans},
  title = {Secure aggregation for wireless networks},
  journal = {Symposium on Applications and the Internet Workshops},
  year = {2003},
  pages = {384-391},
  month = {Jan.},
  abstract = {An emerging class of important applications uses ad-hoc wireless networks
	of low-power sensor devices to monitor and send information about
	a possibly hostile environment to a powerful base station connected
	to a wired network. To conserve power, intermediate network nodes
	should aggregate results from individual sensors. However, this opens
	the risk that a single compromised sensor device can render the network
	useless, or worse, mislead the operator into trusting a false reading.
	We present a protocol that provides a secure aggregation mechanism
	for wireless networks that is resilient to both intruder devices
	and single device key compromises. Our protocol is designed to work
	within the computation, memory and power consumption limits of inexpensive
	sensor devices, but takes advantage of the properties of wireless
	networking, as well as the power asymmetry between the devices and
	the base station.
	
	
	Objective: prevent single node compromise by delayed aggregation and
	delayed authentication. Messages are forwarded unmodified to the
	grandparent where aggregation takes place. Allows detection of corrupt
	parent node at the expense of added messaging. MACs are used as attestation.},
  file = {:hu2003.pdf:PDF},
  issn = { },
  keywords = { ad hoc networks, cryptography, energy conservation, protocols, sensor
	fusion, telecommunication security ad hoc wireless networks, computation
	limits, hostile environment, intermediate network nodes, intruder
	devices, low-power sensor devices, memory limits, monitoring, power
	asymmetry, power conservation, power consumption limits, powerful
	base station, secure aggregation mechanism, single device key compromises,
	wired network},
  review = {See w regards to leapfrog path idea. See also chain of keys in zhu2007.
	Can something similar be used to construct virtual redundant paths?
	
	
	The authors present an approach to securing in-network aggregation.
	Their focus is on integrity -- confidentiality disregarded.
	
	
	Use mu-tesla (perrig) in their work -- the protocol proposes is inspired
	by and dependent on mu-tesla. Symmetric key primitives of authenticated
	broadcast used.
	
	
	Based on delayed aggregation and delayed authentication. Messages
	are not aggregated at the next hop (by the parent) but forwarded
	unchanged. Messages are aggregated by the grand-parent of the production
	node. Uses symmetric authentication keys and delayed key revelation.
	The grandparent, which received all committments can verify after
	the delay has expired and it holds the keys.
	
	
	The base station generates a key chain using a oneway function. Each
	device stores an initial key K0 created by n applications of F to
	a secret K. The first base station transmission will be encrypted
	using K1 -- n-1 applications of F to K. After all messages transmitted
	under K1 have been received, the base station reveals the key. The
	sensor nodes can verify the key K1 by computing F(K1)=F(F^{n-1}(K)
	and check that it matches K0=F^n(K).
	
	
	Each sensor node has a pre-installed symmetric key shared with the
	base station. A temporary encryption key will be computed by encrypting
	a counter with this key. Assume the base station can synchronize
	counters with the sensor nodes. Sensor nodes send their readings
	and unique id to their parents. Authenticated by a MAC computed with
	the temporary (counter encryption) key. This key is known to the
	generating node and the base station but at this time to no other
	nodes. The parent node will store the message and the MAC until the
	key is revealed by the base station -- at that time it can verify
	the MAC and raise an alarm if it does not match. The received values
	are transmitted (after a brief delay) to the next node -- grandparents
	aggregate values produced by their grandchildren. A MAC over the
	aggregate of the child contribution is transmitted from the parent
	to the grandparent (computed using the parents temporary key) --
	the aggregate computed for the MAC should be identical to the value
	computed by the next node in the hierarchy (grandparent), but is
	not needed since all contributions are sent along with the MAC. A
	MAC computed by the parent will authenticate the value computed by
	the grandparent.
	
	Once all messages have reached the base station, it reveals the temporary
	keys along with a MAC produced by the current mu-tesla key. The base
	station then advances to the next mu-tesla key in the chain.
	
	
	NOTE: Nonces not needed since each counter derived key is used only
	once by a sensor node.
	
	
	Goal: Ensure that a single compromised node can only fake its own
	value, not affect the aggregation. The base station can verify the
	authenticity of the final step message using the childrens shared
	keys. The base station also receives the values and MACs computed
	by the grandchildren and can validate those.
	
	Now, the base station reveals the temporary node keys for the network,
	along with a MAC of the current mu-tesla key as authentication. Parents
	now know the temporary keys of their children and can validate their
	contributions. Inconsistent MACs from a child or a gandchild can
	be detected.
	
	
	A corrupt node can transmit false readings without detection -- authors
	claim no cryptographic way to prevent this.
	
	In-network aggregation can be secured (for a single corrupt node)
	. An intermediary node expects to see MACs of all child contributions
	of a corrupt node and will raise an alarm if this fails. However,
	it may not be clear if the child or the grandchild is corrupt --
	both may have to be excluded from the network.
	
	
	The protocol does not detect an adversary that can corrupt both a
	parent and a child node. Such a collusion can generate arbitrary
	values.
	
	
	A drawback of the protocol is the large number of keys that the base
	station has to reveal in each round. The authors propose a variation
	involving mu-tesla chain establishment between parent and child,
	which reduces the number of keys which need to be broadcast.
	
	
	Note that the protocol, especially the authenticated broadcast, depend
	on the radio broadcast assumptions of sensor networks. The key revelation
	would be somewhat more complex in a wired network.}
}

@INPROCEEDINGS{hu2009,
  author = {Wen Hu and Peter Corke and Wen Chan Shih and Leslie Overs},
  title = {{secFleck}: A Public Key Technology Platform for Wireless Sensor
	Networks},
  booktitle = {Wireless Sensor Networks},
  year = {2009},
  abstract = {We describe the design and implementation of a public-key
	
	platform, secFleck, based on a commodity Trusted Platform Module
	
	(TPM) chip that extends the capability of a standard node. Unlike
	
	previous software public-key implementations this approach provides
	E-
	
	Commerce grade security; is computationally fast, energy efficient;
	and
	
	has low financial cost — all essential attributes for secure large-scale
	sen-
	
	sor networks. We describe the secFleck message security services such
	as
	
	confidentiality, authenticity and integrity, and present performance
	re-
	
	sults including computation time, energy consumption and cost. This
	is
	
	followed by examples, built on secFleck, of symmetric key management,
	
	secure RPC and secure software update.},
  file = {hu2009.pdf:hu2009.pdf:PDF},
  keywords = {TPM, trusted platform module, public key encryption, sensor network},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{hu2002a,
  author = {Yih-Chun Hu and David B. Johnson and Adrian Perrig},
  title = {{SEAD}: Secure Efficient Distance Vector Routing for Mobile Wireless
	Ad Hoc Networks},
  booktitle = {4th IEEE Workshop on Mobile Computing Systems and Applications (WMCSA
	2002)},
  year = {2002},
  pages = {3--13},
  abstract = {An ad hoc network is a collection of wireless computers (nodes), communicating
	among themselves over possibly multihop paths, without the help of
	any infrastructure such as base stations or access points. Although
	many previous ad~hoc network routing protocols have been based in
	part on distance vector approaches, they have generally assumed a
	trusted environment. In this paper, we design and evaluate the Secure
	Efficient Distance Vector routing protocol (SEAD), a secure ad hoc
	network routing protocol based on the design of the Destination-Sequenced
	Distance-Vector routing protocol (DSDV). In order to support use
	with nodes of limited CPU processing capability, and to guard against
	Denial-of-Service (DoS) attacks in which an attacker attempts to
	cause other nodes to consume excess network bandwidth or processing
	time, we use efficient one-way hash functions and do not use asymmetric
	cryptographic operations in the protocol. SEAD performs well over
	the range of scenarios we tested, and is robust against multiple
	uncoordinated attackers creating incorrect routing state in any other
	node, even in spite of any active attackers or compromised nodes
	in the network.},
  file = {hu2002a.pdf:hu2002a.pdf:PDF}
}

@ARTICLE{hu2005a,
  author = {Hu, Yih-Chun and Perrig, Adrian and Johnson, David B.},
  title = {Ariadne: a secure on-demand routing protocol for ad hoc networks},
  journal = {Wirel. Netw.},
  year = {2005},
  volume = {11},
  pages = {21--38},
  number = {1-2},
  abstract = {An ad hoc network is a group of wireless mobile computers (or nodes),
	in which individual nodes cooperate by forwarding packets for each
	other to allow nodes to communicate beyond direct wireless transmission
	range. Prior research in ad hoc networking has generally studied
	the routing problem in a non-adversarial setting, assuming a trusted
	environment. In this paper, we present attacks against routing in
	ad hoc networks, and we present the design and performance evaluation
	of a new secure on-demand ad hoc network routing protocol, called
	Ariadne. Ariadne prevents attackers or compromised nodes from tampering
	with uncompromised routes consisting of uncompromised nodes, and
	also prevents many types of Denial-of-Service attacks. In addition,
	Ariadne is efficient, using only highly efficient symmetric cryptographic
	primitives.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11276-004-4744-y},
  file = {hu2005a.pdf:hu2005a.pdf:PDF},
  issn = {1022-0038},
  keywords = {ad-hoc network, security, secure routing},
  publisher = {Kluwer Academic Publishers}
}

@TECHREPORT{Hu2002,
  author = {Yih-Chun Hu and Adrian Perrig and David B. Johnson},
  title = {Wormhole detection in wireless ad hoc networks},
  institution = {Department of Computer Science, Rice University},
  year = {2002},
  number = {TR01-384},
  abstract = {As mobile ad hoc network applications are deployed, security emerges
	as a central requirement. In this paper, we introduce the wormhole
	attack, a severe attack against ad hoc routing protocols that is
	particularly challenging to defend against. We show how an attacker
	can use the wormhole attack to cripple a range of ad hoc network
	routing protocols. In the wormhole attack, an attacker records packets
	(or bits) at one location in the network, tunnels them to another
	location, and retransmits them there into the network. Most existing
	ad hoc network routing protocols, without some mechanism to defend
	them against the wormhole attack, would be unable to ﬁnd routes longer
	than one or two hops, severely disrupting communication.
	
	
	 In this paper, we present the design of two protocols capable of
	detecting a wormhole attack at the receiver: the Slot Authenticated
	MAC protocol and the TIK protocol. Both protocols rely on tight time
	synchronization, which can be readily available through off-the-shelf
	hardware. These two protocols make different tradeoffs: the Slot
	Authenticated MAC is a simple, very resource-efﬁcient approach based
	on a TDMA MAC, whereas TIK is a practical, novel approach that has
	somewhat higher network overhead and resource requirements, but features
	signiﬁcantly reduced latency. The computational requirements of TIK
	are well within the range of existing handhelds computers. For example,
	in an 11Mbps wireless LAN, a Compaq iPaq 3870 PocketPC is capable
	of handling the maximum rate of cryptographic operations associated
	with TIK, using just 3% of its built-in memory and 18% of its CPU
	time.},
  file = {:hu2002.pdf:PDF},
  review = {referenced by karlof2003 which adapt parts to impl attacks against
	sensor networks.}
}

@INPROCEEDINGS{hu2006,
  author = {Yi Hu and Nuo Yu and Xiaohua Jia},
  title = {Energy efficient real-time data aggregation in wireless sensor networks},
  booktitle = {{IWCMC} '06: Proceedings of the 2006 international conference on
	Wireless communications and mobile computing},
  year = {2006},
  pages = {803--808},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper studies the energy efficient routing for data aggregation
	in wireless sensor networks. The data aggregation tree is a tree
	where the root of the tree is the data center called the sink node
	and the other nodes are sensor nodes. The sensor nodes sense the
	data and pass the data back to the data center along the data aggregation
	tree. We consider a real-time scenario where the data aggregation
	must be performed within a specified latency constraint. The objective
	is to minimize the overall energy cost of the sensor nodes for data
	aggregation subject to the latency constraint. The original contributions
	of the paper include: 1) Development of an analytic model for IEEE
	Standard 802.15.4 CSMA-CA to compute the worst case delay for a sensor
	node to aggregate the data from all its child nodes in the aggregation
	tree; 2) Proposal of a heuristic algorithm for constructing data
	aggregation trees that minimize total energy cost under the latency
	bound obtained from our analytical model. Extensive simulations have
	been conducted and the results verify the validity of the proposed
	analytical model and the superior performance of the proposed algorithm
	for constructing aggregation trees.},
  doi = {http://doi.acm.org/10.1145/1143549.1143710},
  file = {hu2006.pdf:hu2006.pdf:PDF},
  isbn = {1-59593-306-9},
  location = {Vancouver, British Columbia, Canada}
}

@MISC{hu2005,
  author = {Zhou Hu},
  title = {{NAT} Traversal Techniques and Peer-to-Peer Applications},
  year = {2005},
  abstract = {Network Address Translation (NAT) is very useful in Small Ofﬁce and
	Home Ofﬁce (SOHO) community to build a small private network by sharing
	global routable IP addresses. NAT creates a private IP address realm
	behind NAT translators. According to common ﬁrewall and NAT rule,
	hosts in private address realm cannot be reached directly from public
	Internet. In Peer to Peer network, hosts behind NAT gateway have
	to be reached directly by some way in order to communicate with other
	peers. NAT techniques hide private hosts thus causing peers not reachable
	globally. The main reason of the trouble is NAT mangling IP addresses
	and port numbers thus breaking common end-to-end connections. NAT
	Traversal Techniques is to let enable end-to-end protocol and application
	packets through NAT gateway directly or indirectly. NAT is and will
	be widely adopted over the Internet community, especially in SOHO
	community. However, NAT technologies are diverse, de facto but not
	standardized so that the proliferation of NAT devices makes Peer-to-Peer
	application maker confused and hard to inter-operate with. This paper
	reviews commonly existing and Peer-to-Peer widely using NAT transversal
	techniques. I try to give some advise about what should be done on
	NAT side and Peer-to-Peer application side in order that two things
	inter-operate smoothly. There is no heal-all technique to make NAT
	devices fully inter-operable with P2P applications. On the other
	hand, P2P applications could have to make use general purpose method
	combined with special efforts to cope with different NAT environment.},
  file = {hu2005.pdf:hu2005.pdf:PDF},
  keywords = {networks, network operation, NAT, NAT traversal, survey},
  owner = {kristjan},
  review = {Student paper?},
  timestamp = {2009.08.24}
}

@ARTICLE{huang2008,
  author = {Dijiang Huang and Deep Medhi},
  title = {A secure group key management scheme for hierarchical mobile ad hoc
	networks},
  journal = {Ad Hoc Netw.},
  year = {2008},
  volume = {6},
  pages = {560--577},
  number = {4},
  abstract = {In this paper, we present a secure group key management scheme for
	hierarchical mobile ad hoc networks. Our approach aims to improve
	both scalability and survivability of group key management for large-scale
	wireless ad hoc networks. To achieve our goal, we propose the following
	approaches: (1) a multi-level security model, which follows a modified
	Bell-La Padula security model that is suitable in a hierarchical
	mobile ad hoc networking environment, and (2) a decentralized group
	key management infrastructure to achieve such a multi-level security
	model. Our approaches reduce the key management overhead and improve
	resilience to any single point failure problem. In addition, we have
	developed a roaming protocol that is able to provide secure group
	communication involving group members from different groups without
	requiring new keys; an advantage of this protocol is that it is able
	to provide continuous group communication even when the group manager
	fails.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2007.04.006},
  file = {:huang2008.pdf:PDF},
  issn = {1570-8705},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{hubaux2001,
  author = {Jean-Pierre Hubaux and Levente Butty\'{a}n and Srdan Capkun},
  title = {The quest for security in mobile ad hoc networks},
  booktitle = {{MobiHoc '01: Proceedings of the 2nd ACM international symposium
	on Mobile ad hoc networking \& computing}},
  year = {2001},
  pages = {146--155},
  address = {New York, NY, USA},
  publisher = {ACM},
  file = {hubaux2001.pdf:hubaux2001.pdf:PDF},
  isbn = {1-58113-428-2},
  keywords = {mobile ad-hoc network, security},
  location = {Long Beach, CA, USA}
}

@PHDTHESIS{huda2007,
  author = {Md. Nurul Huda},
  title = {A Mobile Agent-based Privacy Protection Mechanism in Solving Multi-party
	Computation Problems},
  school = {The Graduate University for Advanced Studies ({SOKENDAI}). Department
	of Informatics, School of Multidisciplinary Science.},
  year = {2007},
  abstract = {A multi-party computation (MPC) allows n parties to compute an agreed-upon
	function of their inputs and every party learns the correct function
	output. To solve a multi-party computation problem (MPCP), the participants
	may need to share their private data (inputs) between one another,
	resulting in data privacy loss. The key research issue that has been
	addressed in this thesis is - how to solve multi-party computation
	problems without disclosing anyone’s private data to others.
	
	
	Firstly, by studying and analyzing the traditional computational models,
	we have devised a privacy loss model for multi-party computation
	problems and proposed a novel metric, called the Min privacy metric,
	for quantitatively measuring the amount of data privacy loss in solving
	the MPCPs. Then, we have presented a mobile agent-based scheduling
	algorithm that applies pseudonymization technique to reduce data
	privacy loss. Finally, we have proposed the security system design,
	including security policies and security architecture, of an agent
	server platform for enhancing data privacy protection while solving
	the MPCPs.
	
	
	The privacy loss model has identiﬁed three factors aﬀecting the amount
	of privacy loss in solving the MPCPs: (1) the fraction of private
	data which is shared with others, (2) the probability of associating
	the shared private data with the data subject, and (3) the probability
	of disclosing the shared private data to unauthorized parties. Privacy
	loss can be reduced by any mechanisms which reduces the values of
	any of the three factors. The proposed Min privacy metric accounts
	for the number of participants that lose their private data and the
	amount of private data disclosed to unauthorized parties, regardless
	of how many parties they are revealed to. 
	
	
	Existing scheduling algorithms aim for a global objective function.
	As a result, they incur performance penalties in computational complexity
	and data privacy. This thesis describes a mobile agent-based scheduling
	scheme called Eﬃcient and Privacy-aware Meeting Scheduling (EPMS),
	which results in a tradeoﬀ among complexity, privacy, and global
	utility for scheduling multiple events concurrently. We have introduced
	multiple criteria for evaluating privacy in the meeting scheduling
	problem. A common computational space has been utilized in EPMS for
	reducing the complexity and pseudonymization technique has been applied
	to reduce the privacy loss in the scheduling problem. The analytical
	results show that EPMS has a polynomial time computational complexity.
	In addition, simulation results show that the obtained global utility
	for scheduling multiple meetings with EPMS is close to the optimal
	level and the resulting privacy loss is less than for those in existing
	algorithms.
	
	
	Cryptography-based algorithms for MPCPs are either too complex to
	be used practically or applicable only to the speciﬁc applications
	for which they have been developed. In addition, traditional (non-cryptography-based)
	algorithms do not provide good privacy protection for MPCPs. We have
	proposed a novel privacy protection mechanism in which MPCPs are
	solved by mobile agents using traditional algorithms at an agent
	server platform, called isolated Closed-door One-way Platform (iCOP).
	The participating mobile agents are trapped into iCOP where they
	are allowed to share their private information to solve the problem
	using traditional algorithms. However, they are protected from disclosing
	the shared private information to the outside world. The enforcement
	of the security policies protects the participating agents from sending
	anything other than the computational result to the users. The security
	and privacy analysis illustrates that the proposed mechanism provides
	very good privacy protection if the participants solve the problem
	with distributed algorithms and can provide complete privacy protection
	if the participants exchange inputs within the iCOP and each of them
	solve the problem with centralized algorithms. Finally, experimental
	evaluation shows that the proposed agent platform security system
	signiﬁcantly enhances privacy protection while solving many MPCPs
	with traditional algorithms.
	
	
	 i},
  file = {huda2007.pdf:huda2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.16}
}

@INPROCEEDINGS{huebsch2005,
  author = {Ryan Huebsch and Brent Chun and Joseph M. Hellerstein and Boon Thau
	Loo and Petros Maniatis and Timothy Roscoe and Scott Shenker and
	Ion Stoica and Aydan R. Yumerefendi},
  title = {The Architecture of {PIER}: an Internet-Scale Query Processor},
  booktitle = {CIDR Conference},
  year = {2005},
  abstract = {This paper presents the architecture of PIER , an Internet-scale query
	engine we have been building over the last three years. PIER is the
	ﬁrst general-purpose relational query processor targeted at a peer-to-peer
	(p2p) architecture of thousands or millions of participating nodes
	on the Internet. It supports massively distributed, database-style
	dataﬂows for snapshot and continuous queries. It is intended to serve
	as a building block for a diverse set of Internet-scale information-centric
	applications, particularly those that tap into the standardized data
	readily available on networked machines, including packet headers,
	system logs, and ﬁle names. In earlier papers we presented the vision
	for PIER, its application relevance, and initial simulation results
	[28, 32]. We have also presented real-world results showing the beneﬁts
	of using PIER in a p2p ﬁlesharing network [41, 43]. In this paper
	we present, for the ﬁrst time, a detailed look at PIER’s architecture
	and implementation. Implemented in Java, PIER targets an unusual
	design point for a relational query engine, and its architecture
	reﬂects the challenges at all levels, from the core runtime system
	through its aggressive multi-purpose use of overlay networks, up
	into the implementation of query engine basics including data representation,
	query dissemination, query operators, and its approach to system
	metadata. In addition to reporting on PIER’s architecture, we discuss
	additional design concerns that have arisen since the system has
	sbecome real, which we are addressing in our current work.},
  file = {pier-cidr05.pdf:pier-cidr05.pdf:PDF},
  keywords = {distributed query processing, distributed databases, PIER},
  owner = {kristjan},
  timestamp = {2008.03.06}
}

@INPROCEEDINGS{huebsch2003,
  author = {Ryan Huebsch and Joseph M. Hellerstein and Nick Lanham and Boon Thau
	Loo and Scott Shenker and Ion Stoica},
  title = {Querying the internet with {PIER}},
  booktitle = {vldb'2003: Proceedings of the 29th international conference on Very
	large data bases},
  year = {2003},
  pages = {321--332},
  publisher = {VLDB Endowment},
  abstract = {The database research community prides itself on scalable technologies.
	Yet database systems traditionally do not excel on one important
	scalability dimension: the degree of distribution. This limitation
	has hampered the impact of database technologies on massively distributed
	systems like the Internet.
	
	
	In this paper, we present the initial design of PIER, a massively
	distributed query engine based on overlay networks, which is intended
	to bring database query processing facilities to new, widely distributed
	environments. We motivate the need for massively distributed queries,
	and argue for a relaxation of certain traditional database research
	goals in the pursuit of scalability and widespread adoption. We present
	simulation results showing PIER gracefully running relational queries
	across thousands of machines, and show results from the same software
	base in actual deployment on a large experimental cluster.},
  file = {p321-huebsch.pdf:p321-huebsch.pdf:PDF},
  isbn = {0-12-722442-4},
  keywords = {distributed query processing, distributed databases, PIER},
  location = {Berlin, Germany}
}

@ARTICLE{Hyytia2006,
  author = {Esa Hyytia and Pasi Lassila and Jorma Virtamo},
  title = {Spatial Node Distribution of the Random Waypoint Mobility Model with
	Applications},
  journal = {IEEE Transactions on Mobile Computing},
  year = {2006},
  volume = {05},
  pages = {680-694},
  number = {6},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TMC.2006.86},
  issn = {1536-1233},
  owner = {kristjan},
  publisher = {IEEE Computer Society},
  timestamp = {2008.09.19}
}

@TECHREPORT{iannaccone2004,
  author = {Gianluca Iannaccone and Christophe Diot and Derek McAuley and Andrew
	Moore and Ian Pratt and Luigi Rizzo},
  title = {{The CoMo White Paper}},
  institution = {{Intel Research}},
  year = {2004},
  number = {IRC-TR-04-17},
  abstract = {CoMo (Continuous Monitoring) is a passive monitoring system. CoMo
	has been designed to be the basic building block of an open network
	monitoring infrastructure that would allow researchers and network
	operators to easily process and share network trafﬁc statistics over
	multiple sites. This paper identiﬁes the challenges that lie ahead
	in the deployment of such an open infrastructure. These main challenges
	are: (1) the system must allow any generic metric to be computed
	on the incoming trafﬁc stream, (2) it must provide privacy and security
	guarantees to the owner of the monitored link, the network users
	and the CoMo users, and (3) it must be robust in the face of anomalous
	trafﬁc patterns. We describe the high-level architecture of CoMo
	and, in greater detail, the resource management, query processing
	and security aspects.},
  file = {como.whitepaper.pdf:como.whitepaper.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@MISC{ieee-1363-2000,
  author = {{IEEE}},
  title = {{IEEE Std. 1363-2000} Standard Specifications for Public-Key Cryptography},
  month = {January},
  year = {2000},
  abstract = {This standard specifies common public-key cryptographic techniques,
	including
	
	mathematical primitives for secret value (key) derivation, public-key
	encryption, and digital
	
	signatures, and cryptographic schemes based on those primitives. It
	also specifies related
	
	cryptographic parameters, public keys, and private keys. The purpose
	of this standard is to provide
	
	a reference for specifications on a variety of techniques from which
	applications may select.},
  file = {ieee-1363-2000.pdf:ieee-1363-2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.07.26}
}

@INPROCEEDINGS{ilgun1993,
  author = {Koral Ilgun},
  title = {USTAT: A Real-Time Intrusion Detection System for UNIX},
  booktitle = {SP '93: Proceedings of the 1993 IEEE Symposium on Security and Privacy},
  year = {1993},
  pages = {16},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  file = {00287646.pdf:00287646.pdf:PDF}
}

@ARTICLE{intanagonwiwat2002,
  author = {Chalermek Intanagonwiwat and Deborah Estrin and Ramesh Govindan and
	John Heidemann},
  title = {Impact of Network Density on Data Aggregation in Wireless Sensor
	Networks},
  journal = {Distributed Computing Systems, International Conference on},
  year = {2002},
  volume = {0},
  pages = {457},
  abstract = {In-network data aggregation is essential for wireless sensor networks
	where energy resources are limited. In a previously proposed data
	dissemination scheme (directed diffusion with opportunistic aggregation),
	data is opportunistically aggregated at intermediate nodes on a low-latency
	tree. In this paper, we explore and evaluate greedy aggregation,
	a novel approach that adjusts aggregation points to increase the
	amount of path sharing, reducing energy consumption. Our preliminary
	results suggest that, under investigated scenarios, greedy aggregation
	can achieve up to 45% energy savings over opportunistic aggregation
	in high-density networks without adversely impacting latency or robustness.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICDCS.2002.1022289},
  file = {intanagonwiwat2002.pdf:intanagonwiwat2002.pdf:PDF},
  issn = {1063-6927},
  publisher = {IEEE Computer Society},
  review = {In-network data aggregation is essential for wireless sensor networks
	where energy resources are limited. In a previously proposed data
	dissemination scheme (directed diffusion with opportunistic aggregation),
	data is opportunistically aggregated at intermediate nodes on a low-latency
	tree. In this paper, we explore and evaluate greedy aggregation,
	a novel approach that adjusts aggregation points to increase the
	amount of path sharing, reducing energy consumption. Our preliminary
	results suggest that, under investigated scenarios, greedy aggregation
	can achieve up to 45% energy savings over opportunistic aggregation
	in high-density networks without adversely impacting latency or robustness.}
}

@INPROCEEDINGS{intanagonwiwat2000,
  author = {Chalermek Intanagonwiwat and Ramesh Govindan and Deborah Estrin},
  title = {Directed Diffusion: A Scalable and Robust Communication Paradigm
	for Sensor Networks},
  year = {2000},
  pages = {56--67},
  abstract = {Advances in processor, memory and radio technology will enable small
	and cheap nodes capable of sensing, communication and computation.
	Networks of such nodes can coordinate to perform distributed sensing
	of environmental phenomena. In this paper, we explore the directed
	diffusion paradigm for such coordination. Directed diffusion is datacentric
	in that all communication is for named data. All nodes in a directed
	diffusion-based network are applicationaware. This enables diffusion
	to achieve energy savings by selecting empirically good paths and
	by caching and processing data in-network. We explore and evaluate
	the use of directed diffusion for a simple remote-surveillance sensor
	network.},
  file = {intanagonwiwat2000.pdf:intanagonwiwat2000.pdf:PDF;intanagonwiwat2000.ps:intanagonwiwat2000.ps:PostScript},
  keywords = {networking, sensor networks, in-network aggregation, directed diffusion},
  owner = {kristjan},
  review = {Tree based aggregation network (CHECK)},
  timestamp = {2009.09.07}
}

@INPROCEEDINGS{Ioannidis2001,
  author = {Sotiris Ioannidis and Steven M. Bellovin},
  title = {Building a Secure Web Browser},
  booktitle = {USENIX Annual Technical Conference, FREENIX Track},
  year = {2001},
  pages = {127--134},
  abstract = {Over the last several years, popular application such as Microsoft
	Internet Explorer and Netscape Navigator have become prime targets
	of attacks. These applications are targeted because their function
	is to process unauthenticated network data that often carry active
	content. The processing is done either by helper applications, or
	by the web browser itself. In both cases the software is often too
	complex to be bug free. To make matters worse, the underlying operating
	system can do very little to protect the users against such attacks
	since the software is running with the user's privileges. We present
	the architecture of a secure browser, designed to handle attacks
	by incoming malicious objects. Our design is based on an operating
	system that oers process-specic protection mechanisms.},
  file = {:10.1.1.5.9557.pdf:PDF}
}

@ARTICLE{ishida1999,
  author = {K. Ishida and Y. Kakuda and T. Kikuno and K. Amano},
  title = {A distributed routing protocol for finding two node-disjoint paths
	in computer networks},
  journal = {{IEICE Trans. Commun.} Special issue on Distributed Processing for
	Controlling Telecommunications Systems},
  year = {1999},
  volume = {E82-B},
  number = {6},
  month = {June},
  file = {ishida1999.pdf:ishida1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.01}
}

@MISC{ISO/IEC1996,
  author = {ISO/IEC},
  title = {Information technology - Open Systems Interconnection - Basic Reference
	Model: The Basic Model},
  year = {1996},
  file = {ISO_IEC_7498-1_OSI_basic.pdf:ISO_IEC_7498-1_OSI_basic.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{Izal2004,
  author = {M. Izal and G. Urvoy-Keller and E. Biersack and P. Felber and A.
	Hamra and L. Garces-Erice},
  title = {Dissecting {BitTorrent}: Five months in a torrent's lifetime},
  year = {2004},
  owner = {kristjan},
  text = {M. Izal, G. Urvoy-Keller, E.W. Biersack, P.A. Felber, A. Al Hamra,
	and L. Garces-Erice, Dissecting BitTorrent: Five months in a torrent's
	lifetime, in Proceedings of the 5th Passive and Active Measurement
	Workshop, Apr. 2004.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/izal04dissecting.html}
}

@ARTICLE{josang2001,
  author = {J\"{o}sang, Audun},
  title = {A logic for uncertain probabilities},
  journal = {Int. J. Uncertain. Fuzziness Knowl.-Based Syst.},
  year = {2001},
  volume = {9},
  pages = {279--311},
  number = {3},
  abstract = {We first describe a metric for uncertain probabilities called opinion,
	and subsequently a set of logical operators that can be used for
	logical reasoning with uncertain propositions. This framework which
	is called subjective logic uses elements from the Dempster-Shafer
	belief theory and we show that it is compatible with binary logic
	and probability calculus.},
  address = {River Edge, NJ, USA},
  file = {josang2001.pdf:josang2001.pdf:PDF},
  issn = {0218-4885},
  keywords = {belief, evidence, reasoning, uncertainty, probability, logic, subjective
	logic},
  publisher = {World Scientific Publishing Co., Inc.}
}

@INPROCEEDINGS{Josang1999,
  author = {Audun J\"{o}sang},
  title = {An Algebra for Assessing Trust in Certification Chains},
  booktitle = {Proceedings of the Network and Distributed Systems Security Symposium
	(NDSS'99). The Internet Society},
  year = {1999},
  abstract = {Open networks allow users to communicate without any prior arrangements
	such as contractual agreement or organisation membership. However,
	the very nature of open networks makes authenticity difficult to
	verify. We show that authentication can not be based on public key
	certificates alone, but also needs to include the binding between
	the key used for certification and it's owner, as well as the trust
	relationships between users. We develop a simple algebra around these
	elements and describe how it can be used to compute measures of authenticity.},
  file = {Josang1999.pdf:Josang1999.pdf:PDF}
}

@INPROCEEDINGS{jonsson2009,
  author = {Kristj\'{a}n Valur J\'{o}nsson},
  title = {{HttpTools}: A Toolkit for Simulation of Web Hosts in {OMNeT++}},
  booktitle = {Proceedings of the 2nd International Workshop on {OMNeT++} (hosted
	by {SIMUTools} 2009)},
  year = {2009},
  address = {Rome, Italy},
  month = {March},
  file = {:jonsson2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.01.30}
}

@MISC{jonsson2008a,
  author = {Kristj\'{a}n Valur J\'{o}nsson},
  title = {A scalable distributed reference monitor for web applications (Grant
	application to Rann\'{i}s, the Icelandic research fund)},
  month = {March},
  year = {2008},
  file = {jonsson2008a.pdf:jonsson2008a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.18}
}

@INPROCEEDINGS{jackson2007,
  author = {Collin Jackson and Adam Barth and Andrew Bortz and Weidong Shao and
	Dan Boneh},
  title = {Protecting Browsers from {DNS} Rebinding Attacks},
  booktitle = {{Proceedings of ACM CCS 07}},
  year = {2007},
  file = {dns-rebinding.pdf:dns-rebinding.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.04.10}
}

@INPROCEEDINGS{jackson2006,
  author = {Collin Jackson and Andrew Bortz and Dan Boneh and John C. Mitchell},
  title = {Protecting browser state from web privacy attacks},
  booktitle = {{WWW '06: Proceedings of the 15th international conference on World
	Wide Web}},
  year = {2006},
  pages = {737--744},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1135777.1135884},
  file = {p737-jackson.pdf:p737-jackson.pdf:PDF},
  isbn = {1-59593-323-9},
  location = {Edinburgh, Scotland}
}

@INPROCEEDINGS{jadia2004,
  author = {P. Jadia and A. Mathuria},
  title = {Efficient secure aggregation in sensor networks},
  booktitle = {{11th International Conference on High Performance Computing}},
  year = {2004},
  abstract = {In many applications of sensor networks, readings from sensor nodes
	are aggregated at intermediate nodes to reduce the communication
	cost. The messages that are relayed in the data aggregation hierarchy
	may need confidentiality. We present a secure data aggregation protocol
	for sensor networks that uses encryption for confidentiality, but
	without requiring decryption at intermediate nodes. A salient feature
	of the protocol is the use of two-hop pairwise keys to provide integrity
	while minimizing the communication required between the base station
	and sensor nodes. We analyze the performance of our protocol and
	compare its efficiency with a protocol proposed by Hu and Evans.},
  file = {jadia2004.pdf:jadia2004.pdf:PDF},
  owner = {kristjan},
  review = {Based on the protocol of hu2003 and improves it in several ways.
	
	
	The authors consider confidentiality as well as integrity. A simple
	homomorphic transformation is used -- symmetric with counter-derived
	keys. The initial secret is a individual key (unique per node) shared
	wiith the base station (root). No nonces needed since unique keys
	are used for each encryption (but how about synchronization problems?).
	See ahitur1987 on the homomorphic transformation used.
	
	
	A delayed aggregation mechanism, similar to that of hu and evans,
	is used. However, nodes carry two pairwise keys -- one shared with
	parent and the other with the grandparent. The one and two-hop pairwise
	keys eliminate the overhead associated with the verification step
	of the hu and evans protocol -- no need for the base station to broadcast
	the revealed keys},
  timestamp = {2009.12.07}
}

@INPROCEEDINGS{jarecki2007,
  author = {S. Jarecki and V. Shmatikov},
  title = {Efficient Two-Party Secure Computation on Committed Inputs},
  booktitle = {{EUROCRYPT}},
  year = {2007},
  abstract = {We present an efﬁcient construction of Yao’s “garbled circuits” protocol
	for securely computing any two-party circuit on committed inputs.
	The protocol is secure in a universally composable way in the presence
	of malicious adversaries under the decisional composite residuosity
	(DCR) and strong RSA assumptions, in the common reference string
	model. The protocol requires a constant number of rounds (four-ﬁve
	in the standard model, two-three in the random oracle model, depending
	on whether both parties receive the output), O(|C|) modular exponentiations
	per player, and a bandwidth of O(|C|) group elements, where |C| is
	the size of the computed circuit.
	
	Our technical tools are of independent interest. We propose a homomorphic,
	semantically secure variant of the Camenisch-Shoup veriﬁable cryptosystem,
	which uses shorter keys, is unambiguous (it is infeasible to generate
	two keys which successfully decrypt the same ciphertext), and allows
	efﬁcient proofs that a committed plaintext is encrypted under a committed
	key. Our second tool is a practical four-round (two-round in ROM)
	protocol for committed oblivious transfer on strings (string-COT)
	secure against malicious participants. The string-COT protocol takes
	a few exponentiations per player, and is UC-secure under the DCR
	assumption in the common reference string model. Previous protocols
	of comparable efﬁciency achieved either committed OT on bits, or
	standard (non-committed) OT on strings.},
  file = {jarecki2007.pdf:jarecki2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@TECHREPORT{javitz1994,
  author = {Harold S. Javitz and Alfonso Valdes},
  title = {The {NIDES} statistical component description and justification},
  institution = {Computer Science Laboratory, {SRI International}},
  year = {1994},
  file = {NIDES-STA-description.pdf:NIDES-STA-description.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@TECHREPORT{jelasity2002,
  author = {M\´{a}rk Jelasity and Maarten {van Steen}},
  title = {Large-scale newscast computing on the Internet},
  institution = {Vrije Universiteit Amsterdam, Department of Computer Science},
  year = {2002},
  number = {IR-503},
  abstract = {This paper introduces the newscast model of computation for large-scale
	computing on the Internet. The engine realizing this model is a lazy
	fully distributed information propagation protocol among the participants
	which is responsible for membership management and communication.
	It maintains a constantly changing communication graph over the participants.
	This graph has useful emergent properties like small diameter and
	sufﬁciently random structure without deploying special purpose protocols
	to achieve these properties. For adding a new participant only the
	address of an arbitrary member is needed and for removal no action
	is necessary. We provide theoretical and empirical evidence that—besides
	being simple and lightweight—our newscast computing engine is extremely
	scalable and robust. We also suggest some interesting application
	areas including information dissemination, monitoring of large systems,
	resource sharing and efﬁcient multicasting.},
  file = {:IR-503.02.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.12}
}

@INPROCEEDINGS{jelasity2004a,
  author = {M\'{a}rk Jelasity and Rachid Guerraoui and Anne-Marie Kermarrec and
	Maarten {van Steen}},
  title = {The peer sampling service: experimental evaluation of unstructured
	gossip-based implementations},
  booktitle = {Middleware '04: Proceedings of the 5th {ACM/IFIP/USENIX} international
	conference on Middleware},
  year = {2004},
  pages = {79--98},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  abstract = {In recent years, the gossip-based communication model in large-scale
	distributed systems has become a general paradigm with important
	applications which include information dissemination, aggregation,
	overlay topology management and synchronization. At the heart of
	all of these protocols lies a fundamental distributed abstraction:
	the peer sampling service. In short, the aim of this service is to
	provide every node with peers to exchange information with. Analytical
	studies reveal a high reliability and eﬃciency of gossip-based protocols,
	under the (often implicit) assumption that the peers to send gossip
	messages to are selected uniformly at random from the set of all
	nodes. In practice – instead of requiring all nodes to know all the
	peer nodes so that a random sample could be drawn – a scalable and
	eﬃcient way to implement the peer sampling service is by constructing
	and maintaining dynamic unstructured overlays through gossiping membership
	information itself. This paper presents a generic framework to implement
	reliable and efﬁcient peer sampling services. The framework generalizes
	existing approaches and makes it easy to introduce new ones. We use
	this framework to explore and compare several implementations of
	our abstraction. Through extensive experimental analysis, we show
	that all of them lead to diﬀerent peer sampling services none of
	which is uniformly random. This clearly renders traditional theoretical
	approaches invalid, when the underlying peer sampling service is
	based on a gossip-based scheme. Our observations also help explain
	important diﬀerences between design choices of peer sampling algorithms,
	and how these impact the reliability of the corresponding service.},
  file = {:p79-jelasity.pdf:PDF},
  isbn = {3-540-23428-4},
  location = {Toronto, Canada}
}

@INPROCEEDINGS{jelasity2004b,
  author = {M\'{a}rk Jelasity and Alberto Montresor},
  title = {Epidemic-Style Proactive Aggregation in Large Overlay Networks},
  booktitle = {{ICDCS} '04: Proceedings of the 24th International Conference on
	Distributed Computing Systems},
  year = {2004},
  pages = {102--109},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Aggregation & that is, the computation of global properties like average
	or maximal load, or the number of nodes & is an important basic functionality
	in fully distributed environments. In many cases & which include
	protocols responsible for self-organization in large-scale systems
	and collaborative environments & it is useful if all nodes know thevalue
	of some aggregates continuously. In this paper we present and analyze
	novel protocols capable of providing this service. The proposed anti-entropy
	aggregation protocols compute different aggregates of component properties
	like extremal values, average and counting. Our protocols are inspired
	by the anti-entropy epidemic protocol where random pairs of databases
	periodically resolve their differences. In the case of aggregation,
	resolving difference is generalized to an arbitrary (numeric) computation
	based on the states of the two communicating peers. The advantage
	of this approach is that it is proactive and "democratic", which
	means it has no performance bottlenecks, and the approximation of
	the aggregates is present continuously at all nodes. These properties
	make our protocol suitable for implementing e.g. collective decision
	making or automatic system maintenance based on global information
	in a fully distributed fashion. As our main contribution we provide
	fundamental theoretical results on the proposed averaging protocol.},
  file = {jelasity2004b.pdf:jelasity2004b.pdf:PDF},
  isbn = {0-7695-2086-3}
}

@ARTICLE{jelasity2005,
  author = {M\'{a}rk Jelasity and Alberto Montresor and Ozalp Babaoglu},
  title = {Gossip-based aggregation in large dynamic networks},
  journal = {{ACM} Trans. Comput. Syst.},
  year = {2005},
  volume = {23},
  pages = {219-252},
  number = {1},
  abstract = {As computer networks increase in size, become more heterogeneous and
	span greater geographic distances, applications must be designed
	to cope with the very large scale, poor reliability, and often, with
	the extreme dynamism of the underlying network. Aggregation is a
	key functional building block for such applications: it refers to
	a set of functions that provide components of a distributed system
	access to global information including network size, average load,
	average uptime, location and description of hotspots, and so on.
	Local access to global information is often very useful, if not indispensable
	for building applications that are robust and adaptive. For example,
	in an industrial control application, some aggregate value reaching
	a threshold may trigger the execution of certain actions; a distributed
	storage system will want to know the total available free space;
	load-balancing protocols may benefit from knowing the target average
	load so as to minimize the load they transfer. We propose a gossip-based
	protocol for computing aggregate values over network components in
	a fully decentralized fashion. The class of aggregate functions we
	can compute is very broad and includes many useful special cases
	such as counting, averages, sums, products, and extremal values.
	The protocol is suitable for extremely large and highly dynamic systems
	due to its proactive structure---all nodes receive the aggregate
	value continuously, thus being able to track any changes in the system.
	The protocol is also extremely lightweight, making it suitable for
	many distributed applications including peer-to-peer and grid computing
	systems. We demonstrate the efficiency and robustness of our gossip-based
	protocol both theoretically and experimentally under a variety of
	scenarios including node and communication failures.},
  file = {aggregation-tocs.pdf:aggregation-tocs.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.06}
}

@INPROCEEDINGS{jelasity2004,
  author = {Márk Jelasity and Alberto Montresor and Ozalp Babaoglu},
  title = {Detection and removal of malicious peers in gossip-based protocols},
  booktitle = {In Proceedings of {FuDiCo}},
  year = {2004},
  file = {:jelasity-montresor-babaoglu.pdf:PDF},
  review = {Consider detection and removal of byzantine members in a gossip network.
	Byzantine behavor includes
	
	* spurious manufacturing of updates (can lead to DoS attack)
	
	* too few updates -- similar to crash failures and handled by several
	existing gossip protocols
	
	* stealthy manipulation of the aggregate, e.g. fixing the local belief
	at some value. This can lead to divergence or slower convergence
	of the aggregate.
	
	
	Correct nodes are required to maintain logs of their actions with
	cryptographic commitments for non-refutation. Logs are exchanged
	in regular pairwise gossip. Nodes then pick a peer at random from
	the received list and query to verify the information provided. Discovered
	malicious nodes are removed by blacklisting. 
	
	
	The authors claim that accompanying each blacklisting item with the
	proof of malicious behavior, in the form of inconsistent records,
	prevents false blacklisting of correct nodes. I think a stronger
	proof of this property is in order.}
}

@INPROCEEDINGS{jenkins2001,
  author = {Kate Jenkins and Ken Hopkinson and Ken Birman},
  title = {A Gossip Protocol for Subgroup Multicast},
  booktitle = {{ICDCSW} '01: Proceedings of the 21st International Conference on
	Distributed Computing Systems},
  year = {2001},
  pages = {25},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Gossip-based multicast can be an effective tool for providing highly
	reliable and scalable message dissemination. In this paper, we consider
	the problem of gossiping within overlapping process groups. If each
	subgroup independently runs a uniform gossip protocol, then the total
	gossip overhead could be high for a process that is a member of many
	subgroups. We present a novel gossip protocol that allows individual
	subgroup members to trade-off update quality for gossip overhead,
	enabling processes to belong to several subgroups while maintaining
	a low total gossip overhead. Our results include a mathematical model
	for message dissemination under this modified gossip protocol, and
	an algorithm that computes gossip parameters such that all processes
	within a subgroup achieve their desired update quality.},
  file = {jenkins2001.pdf:jenkins2001.pdf:PDF},
  isbn = {0-7695-1080-9}
}

@INPROCEEDINGS{Jiang2002,
  author = {S. Jiang and X. Zhuang},
  title = {LIRS: An efficient low inter-reference recency set replacement policy
	to improve buffer cache performance},
  booktitle = {In Proc. of SIGMETRICS 2002},
  year = {2002},
  owner = {kristjan},
  text = {S. Jiang and X. Zhuang. LIRS: An efficient low inter-reference recency
	set replacement policy to improve buffer cache performance. In Proc.
	of SIGMETRICS 2002.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/article/jiang02lirs.html}
}

@INPROCEEDINGS{jim2007,
  author = {Trevor Jim and Nikhil Swamy and Michael Hicks},
  title = {Defeating script injection attacks with browser-enforced embedded
	policies},
  booktitle = {WWW '07: Proceedings of the 16th international conference on World
	Wide Web},
  year = {2007},
  pages = {601--610},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Web sites that accept and display content such as wiki articles or
	comments typically ﬁlter the content to prevent injected script code
	from running in browsers that view the site. The diversity of browser
	rendering algorithms and the desire to allow rich content make ﬁltering
	quite diﬃcult, however, and attacks such as the Samy and Yamanner
	worms have exploited ﬁltering weaknesses. This paper proposes a simple
	alternative mechanism for preventing script injection called Browser-Enforced
	Embedded Policies (BEEP). The idea is that a web site can embed a
	policy in its pages that speciﬁes which scripts are allowed to run.
	The browser, which knows exactly when it will run a script, can enforce
	this policy perfectly. We have added BEEP support to several browsers,
	and built tools to simplify adding policies to web applications.
	We found that supporting BEEP in browsers requires only small and
	localized modiﬁcations, modifying web applications requires minimal
	eﬀort, and enforcing policies is generally lightweight.},
  doi = {http://doi.acm.org/10.1145/1242572.1242654},
  file = {p601-jim.pdf:p601-jim.pdf:PDF},
  isbn = {978-1-59593-654-7},
  location = {Banff, Alberta, Canada}
}

@ARTICLE{johansen2006,
  author = {Johansen, H{\aa}vard and Allavena, Andr\'{e} and van Renesse, Robbert},
  title = {Fireflies: scalable support for intrusion-tolerant network overlays},
  journal = {SIGOPS Oper. Syst. Rev.},
  year = {2006},
  volume = {40},
  pages = {3--13},
  number = {4},
  abstract = {This paper describes and evaluates Fireﬂies, a scalable protocol for
	supporting intrusion-tolerant network overlays. While such a protocol
	cannot distinguish Byzantine nodes from correct nodes in general,
	Fireﬂies provides correct nodes with a reasonably current view of
	which nodes are live, as well as a pseudo-random mesh for communication.
	The amount of data sent by correct nodes grows linearly with the
	aggregate rate of failures and recoveries, even if provoked by Byzantine
	nodes. The set of correct nodes form a connected submesh; correct
	nodes cannot be eclipsed by Byzantine nodes. Fireﬂies is deployed
	and evaluated on PlanetLab.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1218063.1217937},
  file = {johansen2006.pdf:johansen2006.pdf:PDF},
  issn = {0163-5980},
  keywords = {gossip protocol, byzantine fault tolerance},
  publisher = {ACM},
  review = {Ref'd by alvisi2007. byzantine fault tolerant membership protocol.}
}

@INPROCEEDINGS{johns2006,
  author = {Martin Johns},
  title = {{SessionSafe}: Implementing {XSS} Immune Session Handling},
  booktitle = {Computer Security {ESORICS} 2006},
  year = {2006},
  pages = {444-460},
  abstract = {With the growing trend towards the use of web applications
	
	the danger posed by cross site scripting vulnerabilities gains severity.
	The
	
	most serious threats resulting from cross site scripting vulnerabilities
	are
	
	session hijacking attacks: Exploits that steal or fraudulently use
	the vic-
	
	tim’s identity. In this paper we classify currently known attack methods
	
	to enable the development of countermeasures against this threat.
	By
	
	close examination of the resulting attack classes, we identify the
	web
	
	application’s characteristics which are responsible for enabling the
	sin-
	
	gle attack methods: The availability of session tokens via JavaScript,
	
	the pre-knowledge of the application’s URLs and the implicit trust
	re-
	
	lationship between webpages of same origin. Building on this work
	we
	
	introduce three novel server side techniques to prevent session hijack-
	
	ing attacks. Each proposed countermeasure removes one of the identiﬁed
	
	prerequisites of the attack classes. SessionSafe, a combination of
	the pro-
	
	posed methods, protects the web application by removing the fundamen-
	
	tal requirements of session hijacking attacks, thus disabling the
	attacks
	
	reliably.},
  file = {johns2006.pdf:johns2006.pdf:PDF},
  owner = {kristjan},
  review = {Uses same-origin policy to enforce client side policies.},
  timestamp = {2008.02.27}
}

@MISC{johns_dns_blog_2006,
  author = {Martin Johns},
  title = {(Somewhat) breaking the same-origin policy by undermining dns-pinning},
  howpublished = {[online] http://www.securityfocus.com/archive/107/443429/30/180/threaded},
  month = {August},
  year = {2006},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://www.securityfocus.com/archive/107/443429/30/180/threaded}
}

@INCOLLECTION{johns2007,
  author = {Martin Johns and Justus Winter},
  title = {Protecting the Intranet Against "JavaScript Malware" and Related
	Attacks},
  booktitle = {Detection of Intrusions and Malware, and Vulnerability Assessment},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {4579/2007},
  series = {Lecture Notes in Computer Science},
  pages = {40-59},
  file = {:johns2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@INBOOK{Johnson2001,
  chapter = {5},
  pages = {139--172},
  title = {{DSR}: The Dynamic Source Routing Protocol for Multihop Wireless
	Ad Hoc Networks},
  publisher = {Addison-Wesley},
  year = {2001},
  editor = {C.E. Perkins},
  author = {D. Johnson and D. Maltz and J. Broch},
  file = {johnson01.pdf:/home/kristjan/articles/johnson01.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@TECHREPORT{johnson2001a,
  author = {Don Johnson and Alfred Menezes and Scott Vanstone},
  title = {The Elliptic Curve Digital Signature Algorithm ({ECDSA})},
  institution = {Certicom Corporation},
  year = {2001},
  abstract = {The Elliptic Curve Digital Signature Algorithm (ECDSA) is the elliptic
	curve analogue of the Digital Signature Algorithm (DSA). It was accepted
	in 1999 as an ANSI standard, and was accepted in 2000 as IEEE and
	NIST standards. It was also accepted in 1998 as an ISO standard,
	and is under consideration for inclusion in some other ISO standards.
	Unlike the ordinary discrete logarithm problem and the integer factorization
	problem, no subexponential-time algorithm is known for the elliptic
	curve discrete logarithm problem. For this reason, the strength-per-key-bit
	is substantially greater in an algorithm that uses elliptic curves.
	This paper describes the ANSI X9.62 ECDSA, and discusses related
	security, implementation, and interoperability issues.},
  file = {:johnson_ecdsa_2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INCOLLECTION{Johnson1996,
  author = {David B Johnson and David A Maltz},
  title = {Dynamic Source Routing in Ad Hoc Wireless Networks},
  booktitle = {Mobile Computing},
  publisher = {Kluwer Academic Publishers},
  year = {1996},
  editor = {Imielinski and Korth},
  volume = {353},
  file = {johnson96dynamic.pdf:/home/kristjan/articles/johnson96dynamic.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/johnson96dynamic.html}
}

@INPROCEEDINGS{johnson2002,
  author = {Johnson, Robert and Molnar, David and Song, Dawn Xiaodong and Wagner,
	David},
  title = {Homomorphic Signature Schemes},
  booktitle = {{CT-RSA '02}: Proceedings of the The Cryptographer's Track at the
	RSA Conference on Topics in Cryptology},
  year = {2002},
  pages = {244--262},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {Privacy homomorphisms, encryption schemes that are also homomorphisms
	relative to some binary operation, have been studied for some time,
	but one may also consider the analogous problem of homomorphic signature
	schemes. In this paper we introduce basic definitions of security
	for homomorphic signature systems, motivate the inquiry with example
	applications, and describe several schemes that are homomorphic with
	respect to useful binary operations. In particular, we describe a
	scheme that allows a signature holder to construct the signature
	on an arbitrarily redacted submessage of the originally signed message.
	We present another scheme for signing sets that is homomorphic with
	respect to both union and taking subsets. Finally, we show that any
	signature scheme that is homomorphic with respect to integer addition
	must be insecure.},
  file = {johnson2002.pdf:johnson2002.pdf:PDF},
  isbn = {3-540-43224-8},
  keywords = {cryptographic signatures, homomorphic signature schemes, redactable
	signatures}
}

@INPROCEEDINGS{Johnson1994,
  author = {Theodore Johnson and Dennis Shasha},
  title = {2Q: a low overhead high performance buffer management replacement
	algorithm},
  booktitle = {Proceedings of the Twentieth International Conference on Very Large
	Databases},
  year = {1994},
  pages = {439-450},
  location = {Santiago, Chile},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{jonsson2010,
  author = {Kristjan Jonsson and Mads Dam},
  title = {Towards Flexible and Secure Distributed Aggregation},
  booktitle = {{AIMS 2010 - PhD Workshop}},
  year = {2010},
  month = {jun},
  abstract = {Distributed aggregation protocols are important in many present and
	future computing applications. However, after a decade of research,
	there are still numerous open security issues to consider. We intend
	to address a particular aspect of the security properties of dis-
	tributed aggregation protocols their security against active attacks
	on the integrity of the aggregate computation. Our work is currently
	in its initial stages, but we have identi&#64257;ed promising research
	leads, which we present in this paper.},
  days = {21-25},
  file = {jonsson2010.pdf:jonsson2010.pdf:PDF}
}

@INPROCEEDINGS{Jonsson2007,
  author = {Kristjan Valur Jonsson and Olafur Ragnar Helgason and Gunnar Karlsson},
  title = {A Gateway for Wireless Broadcasting},
  booktitle = {3rd International {Conference on emerging Networking EXperiments
	and Technologies} ({CoNEXT}), Student Workshop},
  year = {2007},
  address = {New York, NY, U.S.A.},
  month = {December 10},
  file = {gw_paper_final.pdf:gw_paper_final.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INCOLLECTION{josephson2005,
  author = {William K. Josephson and Emin G\"{u}n Sirer and Fred B. Schneider},
  title = {Peer-to-Peer Authentication with a Distributed Single Sign-On Service},
  booktitle = {{Peer-to-Peer Systems III}},
  publisher = {Springer Berlin / Heidelberg},
  year = {2005},
  volume = {3279/2005},
  pages = {250-258},
  abstract = {CorSSO is a distributed service for authentication in networks. It
	allows application servers to delegate client identity checking to
	combinations of authentication servers that reside in separate administrative
	domains. CorSSO authentication policies enable the system to tolerate
	expected classes of attacks and failures. A novel partitioning of
	the work associated with authentication of principals means that
	the system scales well with increases in the numbers of users and
	services.},
  file = {:josephson2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.17}
}

@ARTICLE{jovanovic-2006,
  author = {Jovanovic, Nenad and Kirda, Engin and Kruegel, Christopher},
  title = {Preventing Cross Site Request Forgery Attacks},
  journal = {Securecomm and Workshops, 2006},
  year = {2006},
  pages = {1-10},
  month = {28 2006-Sept. 1},
  abstract = {The web has become an indispensable part of our lives.
	
	 Unfortunately, as our dependency on the web increases, so
	
	 does the interest of attackers in exploiting web applications
	
	 and web-based information systems. Previous work in the
	
	field of web application security has mainlyfocused on the
	
	 mitigation of Cross Site Scripting (XSS) and SQL injection
	
	 attacks. In contrast, Cross Site Request Forgery (XSRF) at-
	
	 tacks have not received much attention. In an XSRF attack,
	
	 the trust of a web application in its authenticated users is
	
	 exploited by letting the attacker make arbitrary HTTP re-
	
	 quests on behalf of a victim user. The problem is that web
	
	 applications typically act upon such requests without ver-
	
	 ifying that the performed actions are indeed intentional.
	
	Because XSRF is a relatively new security problem, it is
	
	 largely unknown by web application developers. As a re-
	
	sult, there exist many web applications that are vulnerable
	
	 to XSRF Unfortunately, existing mitigation approaches are
	
	 time-consuming and error-prone, as they require manual ef-
	
	fort to integrate defense techniques into existing systems. In
	
	 this paper, we present a solution that provides a completely
	
	 automatic protection from XSRF attacks. More precisely,
	
	 our approach is based on a server-side proxy that detects
	
	 and prevents XSRF attacks in a way that is transparent to
	
	 p
	
	 users as well as to the web application itself We provide
	
	 experimental results that demonstrate that we can use our
	
	prototype to secure a number ofpopular open-source web
	
	 applications, without negatively affecting their behavior},
  doi = {10.1109/SECCOMW.2006.359531},
  file = {jovanovic-csrf.pdf:jovanovic-csrf.pdf:PDF},
  keywords = {Internet, SQL, hypermedia, security of data, transport protocolsHTTP
	requests, SQL injection attack, Web application security, Web-based
	information systems, cross site request forgery attack prevention,
	cross site scripting attack, open-source Web applications, server-side
	proxy}
}

@TECHREPORT{Jovanovic_pixy_techrep,
  author = {Nenad Jovanovic and Christopher Kruegel and Engin Kirda},
  title = {{Pixy: A Static Analysis Tool for Detecting Web Application Vulnerabilities}},
  institution = {Vienna University of Technology},
  abstract = {The number and the importance of Web applications have increased rapidly
	over the last years. At the same
	
	time, the quantity and impact of security vulnerabilities in such
	applications have grown as well. Since manual code
	
	reviews are time-consuming, error-prone and costly, the need for automated
	solutions has become evident.
	
	 In this paper, we address the problem of vulnerable Web applications
	by means of static source code analysis.
	
	More precisely, we use ﬂow-sensitive, interprocedural and context-sensitive
	data ﬂow analysis to discover vulnerable
	
	points in a program. In addition, alias and literal analysis are employed
	to improve the correctness and precision of
	
	the results. The presented concepts are targeted at the general class
	of taint-style vulnerabilities and can be applied
	
	to the detection of vulnerability types such as SQL injection, cross-site
	scripting, or command injection.
	
	 Pixy, the open source prototype implementation of our concepts, is
	targeted at detecting cross-site scripting
	
	vulnerabilities in PHP scripts. Using our tool, we discovered and
	reported 15 previously unknown vulnerabilities in
	
	three web applications, and reconstructed 36 known vulnerabilities
	in three other web applications. The observed
	
	false positive rate is at around 50% (i.e., one false positive for
	each vulnerability) and therefore, low enough to
	
	permit effective security audits.},
  file = {pixy_techreport.pdf:pixy_techreport.pdf:PDF},
  owner = {kristjan},
  review = {See also jovanovic2006 -- a much longer tech report.},
  timestamp = {2008.02.25}
}

@INPROCEEDINGS{jovanovic2006,
  author = {Nenad Jovanovic and Christopher Kruegel and Engin Kirda},
  title = {Pixy: A Static Analysis Tool for Detecting Web Application Vulnerabilities
	(Short Paper)},
  booktitle = {IEEE Symposium on Security and Privacy},
  year = {2006},
  volume = {0},
  pages = {258-263},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  abstract = {The number and the importance of Web applications have increased rapidly
	over the last years. At the same time, the quantity and impact of
	security vulnerabilities in such applications have grown as well.
	Since manual code reviews are time-consuming, error-prone and costly,
	the need for automated solutions has become evident. In this paper,
	we address the problem of vulnerable Web applications by means of
	static source code analysis.
	
	More precisely, we use ﬂow-sensitive, interprocedural and context-sensitive
	data ﬂow analysis to discover vulnerable points in a program. In
	addition, alias and literal analysis are employed to improve the
	correctness and precision of the results. The presented concepts
	are targeted at the general class of taint-style vulnerabilities
	and can be applied to the detection of vulnerability types such as
	SQL injection, cross-site scripting, or command injection. Pixy,
	the open source prototype implementation of our concepts, is targeted
	at detecting cross-site scripting vulnerabilities in PHP scripts.
	Using our tool, we discovered and reported 15 previously unknown
	vulnerabilities in three web applications, and reconstructed 36 known
	vulnerabilities in three other web applications. The observed false
	positive rate is at around 50% (i.e., one false positive for each
	vulnerability) and therefore, low enough to permit effective security
	audits.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SP.2006.29},
  file = {pixy.pdf:pixy.pdf:PDF},
  keywords = {web security, static analysis},
  review = {See also tech report Jovanovic_pixy_techrep}
}

@INPROCEEDINGS{jung2002,
  author = {Jaeyeon Jung and Balachander Krishnamurthy and Michael Rabinovich},
  title = {Flash crowds and denial of service attacks: characterization and
	implications for {CDNs} and web sites},
  booktitle = {{WWW '02: Proceedings of the 11th international conference on World
	Wide Web}},
  year = {2002},
  pages = {293--304},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The paper studies two types of events that often overload Web sites
	to a point when their services are degraded or disrupted entirely
	- flash events (FEs) and denial of service attacks (DoS). The former
	are created by legitimate requests and the latter contain malicious
	requests whose goal is to subvert the normal operation of the site.
	We study the properties of both types of events with a special attention
	to characteristics that distinguish the two. Identifying these characteristics
	allows a formulation of a strategy for Web sites to quickly discard
	malicious requests. We also show that some content distribution networks
	(CDNs) may not provide the desired level of protection to Web sites
	against flash events. We therefore propose an enhancement to CDNs
	that offers better protection and use trace-driven simulations to
	study the effect of our enhancement on CDNs and Web sites.},
  doi = {http://doi.acm.org/10.1145/511446.511485},
  file = {jung2002.pdf:jung2002.pdf:PDF},
  isbn = {1-58113-449-5},
  keywords = {networks, network measurements, network analysis, security, ddos,
	flash crowd},
  location = {Honolulu, Hawaii, USA},
  url = {http://www2002.org/CDROM/refereed/342}
}

@ARTICLE{jung2008,
  author = {Jaehoon Jung and Seunghak Lee and Namgi Kim and Hyunsoo Yoon},
  title = {Efficient service discovery mechanism for wireless sensor networks},
  journal = {Computer Communications},
  year = {2008},
  volume = {31},
  pages = {3292 - 3298},
  number = {14},
  abstract = {A ubiquitous computing environment is a large-scale mobile environment
	where numerous sensor devices are widely distributed and connected
	through wireless networks. However, existing service discovery protocols
	in sensor networks are inappropriate for such environments since
	they are not scalable. This paper proposes a DHT (Distributed Hash
	Table) based service discovery protocol including the mechanism that
	constructs topology-aware overlay networks in ubiquitous environments.
	Our protocol is scalable since it does not require a central lookup
	server and does not rely on multicast or ﬂooding. Simulation results
	show that our protocol is scalable and outperforms traditional ﬂooding-based
	protocols.},
  doi = {DOI: 10.1016/j.comcom.2008.05.015},
  file = {jung2008.pdf:jung2008.pdf:PDF},
  issn = {0140-3664},
  keywords = {Service discovery, wireless sensor network, DHTs},
  url = {http://www.sciencedirect.com/science/article/B6TYP-4SMF00R-6/2/78a308dd2c20666183b6e38e0c2e30f9}
}

@TECHREPORT{jurca2009,
  author = {Dan Jurca and Rolf Stadler},
  title = {Computing Histograms of Local Variables for Real-Time Monitoring
	using Aggregation Trees},
  institution = {Royal Institute of Technology (KTH)},
  year = {2009},
  month = {August},
  abstract = {In this paper we present a protocol for the continuous monitoring
	of a local network state variable. Our aim is to provide a management
	station with the value distribution of the local variables across
	the network, by means of partial histogram aggregation, with minimum
	protocol overhead. Our protocol is decentralized and asynchronous
	to achieve robustness and scalability, and it executes on an overlay
	interconnecting management processes in network devices. On this
	overlay, the protocol maintains a spanning tree and updates the histogram
	of the network state variables through incremental aggregation. The
	protocol allows to control the trade-off between protocol overhead
	and a global accuracy objective. This functionality is implemented
	by a dynamic conﬁguration of local error ﬁlters that control whether
	an update is sent towards the management station or not. We evaluate
	our protocol by means of simulations. Our results demonstrate the
	controllability of our method in a wide selection of scenarios, and
	the scalability of our protocol for large-scale networks.},
  file = {jurca2009.pdf:jurca2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.04}
}

@MISC{RFC-2315-kaliski-1998,
  author = {B. Kaliski},
  title = {{RFC-2315}: {PKCS \#7}: Cryptographic Message Syntax},
  month = {March},
  year = {1998},
  owner = {kristjan},
  timestamp = {2010.09.02},
  url = {http://tools.ietf.org/html/rfc2315}
}

@MISC{Kamkar2005,
  author = {S. Kamkar},
  title = {Technical explanation of the {MySpace} worm},
  howpublished = {[online] http://namb.la/popular/tech.html},
  month = {October},
  year = {2005},
  note = {kamkar2005},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://namb.la/popular/tech.html}
}

@INPROCEEDINGS{kamvar2003,
  author = {Sepandar D. Kamvar and Mario T. Schlosser and Hector Garcia-Molina},
  title = {The Eigentrust algorithm for reputation management in P2P networks},
  booktitle = {WWW '03: Proceedings of the 12th international conference on World
	Wide Web},
  year = {2003},
  pages = {640--651},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/775152.775242},
  file = {p640-kamvar.pdf:p640-kamvar.pdf:PDF},
  isbn = {1-58113-680-3},
  location = {Budapest, Hungary}
}

@MISC{kanatoko2007,
  author = {Kanatoko},
  title = {{Anti-DNS Pinning (DNS Rebinding) + Socket in FLASH}},
  howpublished = {[online] http://www.jumperz.net/index.php?i=2\&a=3\&b=3},
  month = {Janurary},
  year = {2007},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://www.jumperz.net/index.php?i=2&a=3&b=3}
}

@INPROCEEDINGS{kandula2005,
  author = {Srikanth Kandula and Dina Katabi and Matthias Jacob and Arthur Berger},
  title = {Botz-4-Sale: Surviving Organized {DDoS} Attacks That Mimic Flash
	Crowds},
  booktitle = {{NSDI ’05: 2nd Symposium on Networked Systems Design \& Implementation}},
  year = {2005},
  file = {kandula2005.pdf:kandula2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.18}
}

@INPROCEEDINGS{karger1994,
  author = {David R. Karger},
  title = {Random sampling in cut, flow, and network design problems},
  booktitle = {STOC '94: Proceedings of the twenty-sixth annual ACM symposium on
	Theory of computing},
  year = {1994},
  pages = {648--657},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/195058.195422},
  file = {karger1994.pdf:karger1994.pdf:PDF},
  isbn = {0-89791-663-8},
  location = {Montreal, Quebec, Canada}
}

@INPROCEEDINGS{karlof2004,
  author = {Karlof, Chris and Sastry, Naveen and Wagner, David},
  title = {{TinySec}: a link layer security architecture for wireless sensor
	networks},
  booktitle = {{SenSys} '04: Proceedings of the 2nd international conference on
	Embedded networked sensor systems},
  year = {2004},
  pages = {162--175},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We introduce TinySec, the first fully-implemented link layer security
	architecture for wireless sensor networks. In our design, we leverage
	recent lessons learned from design vulnerabilities in security protocols
	for other wireless networks such as 802.11b and GSM. Conventional
	security protocols tend to be conservative in their security guarantees,
	typically adding 16--32 bytes of overhead. With small memories, weak
	processors, limited energy, and 30 byte packets, sensor networks
	cannot afford this luxury. TinySec addresses these extreme resource
	constraints with careful design; we explore the tradeoffs among different
	cryptographic primitives and use the inherent sensor network limitations
	to our advantage when choosing parameters to find a sweet spot for
	security, packet overhead, and resource requirements. TinySec is
	portable to a variety of hardware and radio platforms. Our experimental
	results on a 36 node distributed sensor network application clearly
	demonstrate that software based link layer protocols are feasible
	and efficient, adding less than 10% energy, latency, and bandwidth
	overhead.},
  doi = {http://doi.acm.org/10.1145/1031495.1031515},
  file = {karlof2004.pdf:karlof2004.pdf:PDF},
  isbn = {1-58113-879-2},
  keywords = {sensor networks, key distribution, security mechanisms},
  location = {Baltimore, MD, USA},
  review = {hop-by-hop and end-to-end encryption modes for sensor networks, based
	on the SkipJack cipher. No homomorphic properties. Private key algorithms
	-- require key distribution.
	
	
	Linklayer encryption and authentication using SkipJack or RC5 ciphers.}
}

@INPROCEEDINGS{karlof2007,
  author = {Chris Karlof and J.D. Tygar and David Wagner and Umesh Shankar},
  title = {Dynamic pharming attacks and the locked same-origin policies for
	web browsers},
  booktitle = {{Proceedings of the 14th ACM Conference on Computer and Communication
	Security (CCS ’07)}},
  year = {2007},
  month = {October},
  file = {pharming-ccs07.pdf:pharming-ccs07.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.04.10}
}

@INPROCEEDINGS{Karlof2003,
  author = {Chris Karlof and David Wagner},
  title = {Secure routing in wireless sensor networks: Attacks and countermeasures},
  booktitle = {{First IEEE International Workshop on Sensor Network Protocols and
	Applications}},
  year = {2003},
  pages = {113--127},
  abstract = {We consider routing security in wireless sensor networks. Many sensor
	network routing protocols have been proposed, but none of them have
	been designed with security as a goal. We propose security goals
	for routing in sensor networks, show how attacks against ad-hoc and
	peer-to-peer networks can be adapted into powerful attacks against
	sensor networks, introduce two classes of novel attacks against sensor
	networks — sinkholes and HELLO ﬂoods, and analyze the security of
	all the major sensor network routing protocols. We describe crippling
	attacks against all of them and suggest countermeasures and design
	considerations. This is the ﬁrst such analysis of secure routing
	in sensor networks.},
  file = {10.1.1.13.4672.pdf:10.1.1.13.4672.pdf:PDF},
  review = {Consider sensor network security, in particular routing issues in
	wireless sensor networks. Discuss a number of security vulnerabilities
	and countermeasures. Authors emphasize that security must be built
	into the system from the beginning rather than an afterthought.
	
	
	In summary, a list of issues, some of which can be applied to aggregation
	networks in general.
	
	
	
	\textbf{Attacks}
	
	
	Identified attacks:
	
	\begin{itemize}
	
	\item \textit{Spoofed, altered or replayed}: The authors are discussing
	attacks against routing, but this also applies to p2p aggregation
	networks.
	
	\item \textit{Selective forwarding} is another attack relevant in
	p2p aggregation networks. A malicious node which manages to get inserted
	into a spanning tree could selectively forward messages or drop all
	received (black hole).
	
	\item \textit{Sinkhole attacks} place a node in an advantageous position
	by e.g.\ advertising it on an attractive route. Thereby, it lures
	traffic toward itself and can then launch other attacks, like selective
	forwarding. I'm not too sure how this would apply in general to p2p
	networks, at least not tree-based.
	
	\item \textit{The Sybil attack} \cite{Douceur2002} is a tricky and
	highly relevant attack for p2p networks in general. Sybil attack
	can significantly reduce effectiveness of fault-tolerant schemes
	s.a. distributed storage \cite{castro1999}, \cite{Castro1999}, dispersity
	[25] and multipath routing \cite{ishida1999}, and topology maintenance
	\cite{xu2001},\cite{chen2002}. Also threat to geographic routing
	protocols.
	
	\item \textit{Wormhole attacks} \cite{Hu2002} involve a malicious
	node forwarding messages in a way which violates the rules of the
	network. Most commonly, two attackers tunnel messages over a out-of-band
	low latency link to shape the path to their advantage. This can be
	used to launch e.g.\ sinkhole or selective forwarding attacks.
	
	\item \textit{HELLO flood} attack is identified as novel by the authors.
	As far as I understand, this is a specific to wireless networks --
	attackers broadcast HELLO messages with enough power to be received
	by every node in the network. Not directly applicable in general
	to p2p networks.
	
	\item \textit{Acknowledgement spoofing} is a link-layer specific attack
	in which an adversary spoofs acks. This is really only applicable
	to a broadcast medium -- not really applicable to p2p networks in
	general.
	
	\end{itemize}
	
	
	\textbf{Countermeasures}
	
	
	Outsider attacks can be prevented by link layer encryption and authentication
	with a single shared key. This eliminates Sybil attacks and a lot
	of the other attacks described in theory. Of course insider attacks
	are still a problem and also if the shared key is cracked or nodes
	are captured. The rest of the countermeasures outlined are for these
	cases.
	
	
	Sybil attacks can be countered using verifiable identities, e.g.\
	using public key cryptography. Also propose to use \citeA{needham1978}
	authentication with symmetric keys shared with a trusted base station
	to establish node-to-node communications. There are however numerous
	reported attacks against this protocol in its unmodified form. It
	is however used as the basis for Kerberos and can thus presumably
	be sufficiently secured. This protocol is e.g.\ discussed by \citeA{boyd1997}.
	
	
	Countermeasures to the HELLO flood attack are discussed, e.g.\ verifying
	the bidirectionality of any link.
	
	
	Wormholes and sinkholes are difficult to counter. Wormholes are difficult
	to detect since they use an out-of-band channel. Same applies to
	wormholes in a p2p aggregation network, presumably.
	
	
	Leveraging global knowledge can be used to enhance security. For example,
	newly deployed sensor nodes can register with a base station, establishing
	the network layout. Suspicious changes can then be flagged as possible
	violations. Requiring authentication for nodes joining a p2p aggregation
	network could serve a similar purpose.
	
	%
	
	Multipath routing and probabilistic selection (gossiping) of next
	hop can help to secure geographic routing protocols. These measures
	are also identified as helpful to counter the selective forwarding
	attack; providing multiple paths lessens the influence of the attacker.
	Braided paths \cite{ganesan2001} are identified as easier to establish
	than completely disjoint paths. This is certainly an avenue to investigate
	in secure aggregation protocols.
	
	
	
	References to look into later:
	
	
	Numerous good references for ad-hoc networks. \cite{zhou1999}, \cite{stajano1999}
	-- This paper received considerable attention in the past.
	
	%
	
	\textit{On use of public key cryptography}: \cite{zhou1999}, \cite{hubaux2001},
	\cite{kong2001}, \cite{kong2002}, \cite{luo2002},\cite{binkley2001},\cite{sanzgiri2002}.
	All refer to ad-hoc networks, but parts may be applicable to aggregation
	networks in general. Some additional references on secure routing
	for ad-hoc networks using distance vector or source routing -- perhaps
	take a look at these: \cite{hu2002a}, \cite{hu2005a}, \cite{basagni2001},
	\cite{papadimitratos2002}. Note that this is ad-hoc wireless specific
	but check.
	
	%
	
	\textit{On punishment, holding grudges etc to minimize bad behavior}:
	\cite{marti2000}, \cite{buchegger2002}.
	
	%
	
	\textit{On secure protocols for sensor networks}: \cite{perrig2002}.
	
	Authenticated broadcast. See $\mu$-Tesla \cite{perrig2002}.}
}

@ARTICLE{Karlsson2007,
  author = {Gunnar Karlsson and Vincent Lenders and Martin May},
  title = {Delay-Tolerant Broadcasting},
  journal = {IEEE Transactions on Broadcasting - Special Issue on Mobile Multimedia
	Broadcasting},
  year = {2007},
  volume = {53 no 1},
  pages = {369-381},
  month = {April},
  file = {dtb.pdf:/home/kristjan/articles/dtb.pdf:PDF},
  institution = {KTH},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{karp2000,
  author = {R. Karp and C. Schindelhauer and S. Shenker and B. Vocking},
  title = {Randomized rumor spreading},
  journal = {Foundations of Computer Science, Annual IEEE Symposium on},
  year = {2000},
  volume = {0},
  pages = {565},
  abstract = {Investigates the class of epidemic algorithms that are commonly used
	for the lazy transmission of updates to distributed copies of a database.
	These algorithms use a simple randomized communication mechanism
	to ensure robustness. Suppose n players communicate in parallel rounds
	in each of which every player calls a randomly selected communication
	partner. In every round, players can generate rumors (updates) that
	are to be distributed among all players. Whenever communication is
	established between two players, each one must decide which of the
	rumors to transmit. The major problem is that players might not know
	which rumors their partners have already received. For example, a
	standard algorithm forwarding each rumor form the calling to the
	called players for /spl Theta/(ln n) rounds needs to transmit the
	rumor /spl Theta/(n ln n) times in order to ensure that every player
	finally receives the rumor with high probability. We investigate
	whether such a large communication overhead is inherent to epidemic
	algorithms. On the positive side, we show that the communication
	overhead can be reduced significantly. We give an algorithm using
	only O(n ln ln n) transmissions and O(ln n) rounds. In addition,
	we prove the robustness of this algorithm. On the negative side,
	we show that any address-oblivious algorithm needs to send /spl Omega/(n
	ln ln n) messages for each rumor, regardless of the number of rounds.
	Furthermore, we give a general lower bound showing that time and
	communication optimality cannot be achieved simultaneously using
	random phone calls, i.e. every algorithm that distributes a rumor
	in O(ln n) rounds needs /spl omega/(n) transmissions.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SFCS.2000.892324},
  file = {karp2000.pdf:karp2000.pdf:PDF},
  issn = {0272-5428},
  keywords = {epidemic algorithms, multicast},
  publisher = {IEEE Computer Society}
}

@INCOLLECTION{katz2008,
  author = {Jonathan Katz and Andrew Y. Lindell},
  title = {Aggregate Message Authentication Codes},
  booktitle = {Topics in Cryptology – {CT-RSA'08} (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  abstract = {We propose and investigate the notion of aggregate message authentication
	codes (MACs) which have the property that multiple MAC tags, computed
	by (possibly) different senders on multiple (possibly different)
	messages, can be aggregated into a shorter tag that can still be
	verified by a recipient who shares a distinct key with each sender.
	We suggest aggregate MACs as an appropriate tool for authenticated
	communication in mobile ad-hoc networks or other settings where resource-constrained
	devices share distinct keys with a single entity (such as a base
	station), and communication is an expensive resource.},
  file = {katz2008.pdf:katz2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@ARTICLE{kavitha2010,
  author = {T. Kavitha and D. Sridharan},
  title = {Security Vulnerabilities in Wireless Sensor Networks: A survey},
  journal = {Journal of Information Assurance and Security},
  year = {2010},
  volume = {5},
  pages = {31--44},
  abstract = {The significant advances of hardware manufacturing technology and
	the development of efficient software algorithms make technically
	and economically feasible a network composed of numerous, small,
	low-cost sensors using wireless communications, that is, a wireless
	sensor network (WSN). Security is becoming a major concern for WSN
	protocol designers because of the wide security-critical applications
	of WSNs. In this article, how WSN differs from wired network and
	other wireless network and also basic information about the WSN and
	its security issues compared with wired network and other wireless
	networks is discoursed. Summarization of typical attacks on sensor
	networks and survey about the literatures on several important security
	issues relevant to the sensor networks are also dissertated.},
  file = {kavitha2010.pdf:kavitha2010.pdf:PDF},
  keywords = {Wireless sensor network, security, vulnerabilities, security mechanisms,
	survey},
  owner = {kristjan},
  review = {Not badly written but not too interesting. A rehash of previous sensor
	network security papers. No clear contribution, frankly.},
  timestamp = {2010.01.15}
}

@ONLINE{keizer-techweb-news-2005,
  author = {Gregg Keizer},
  title = {Dutch Botnet Bigger Than Expected},
  url = {http://www.informationweek.com/news/security/government/showArticle.jhtml?articleID=172303265},
  year = {2005},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@INPROCEEDINGS{kelsey2005,
  author = {John Kelsey and Bruce Schneier},
  title = {Second preimages on n-bit hash functions for much less than $2^n$
	work},
  booktitle = {Advances In Cryptology {EUROCRYPT}},
  year = {2005},
  pages = {474--490},
  abstract = {We provide a second preimage attack on all n-bit iterated hash functions
	with Damgård-Merkle strengthening and n-bit intermediate states,
	allowing a second preimage to be found for a 2 k-message-block message
	with about k × 2 n/2+1 + 2 n−k+1 work. Using SHA1 as an example,
	our attack can find a second preimage for a 2^60 byte message in
	2^106 work, rather than the previously expected 2^160 work. We also
	provide slightly cheaper ways to find multicollisions than the method
	of Joux[J04]. Both of these results are based on expandable messages
	– patterns for producing messages of varying length, which all collide
	on the intermediate hash result immediately after processing the
	message. We also provide algorithms for finding expandable messages
	for a hash function, using only a small multiple of the work done
	to find a single collision in the hash function.},
  file = {kelsey2005.pdf:kelsey2005.pdf:PDF}
}

@INPROCEEDINGS{kempe2003,
  author = {David Kempe and Alin Dobra and Johannes Gehrke},
  title = {Gossip-Based Computation of Aggregate Information},
  booktitle = {{44th Annual IEEE Symposium on Foudations of Computer Science (FOCS'03)}},
  year = {2003},
  address = {Cambridge, MA, USA},
  month = {October},
  abstract = {Over the last decade, we have seen a revolution in connectivity between
	computers, and a resulting paradigm shift from centralized to highly
	distributed systems. With massive scale also comes massive instability,
	as node and link failures become the norm rather than the exception.
	For such highly volatile systems, decentralized gossip-based protocols
	are emerging as an approach to maintaining simplicity and scalability
	while achieving fault-tolerant information dissemination.
	
	 In this paper, we study the problem of computing aggregates with
	gossip-style protocols. Our ﬁrst contribution is an analysis of simple
	gossip-based protocols for the computations of sums, averages, random
	samples, quantiles, and other aggregate functions, and we show that
	our protocols converge exponentially fast to the true answer when
	using uniform gossip.
	
	 Our second contribution is the deﬁnition of a precise notion of the
	speed with which a node’s data diffuses through the network. We show
	that this diffusion speed is at the heart of the approximation guarantees
	for all of the above problems. We analyze the diffusion speed of
	uniform gossip in the presence of node and link failures, as well
	as for ﬂooding-based mechanisms. The latter expose interesting connections
	to random walks on graphs.},
  file = {kempe2003.pdf:kempe2003.pdf:PDF},
  owner = {kristjan},
  review = {see also brief mention in keshav2006.},
  timestamp = {2009.04.03}
}

@ARTICLE{Kent1995,
  author = {Christopher A. Kent and Jeffrey C. Mogul},
  title = {Fragmentation considered harmful},
  journal = {ACM SIGCOMM Computer Communication Review},
  year = {1995},
  volume = {25},
  pages = {75-87},
  number = {1},
  file = {p75-kent.pdf:p75-kent.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{kephart2003,
  author = {Kephart, Jeffrey O. and Chess, David M.},
  title = {The Vision of Autonomic Computing},
  journal = {Computer},
  year = {2003},
  volume = {36},
  pages = {41--50},
  number = {1},
  abstract = {A 2001 IBM manifesto observed that a looming software complexity crisis¿caused
	by applications and environments that number into the tens of millions
	of lines of code¿threatened to halt progress in computing. The manifesto
	noted the almost impossible difficulty of managing current and planned
	computing systems, which require integratingseveral heterogeneous
	environments into corporate-wide computing systems that extend into
	the Internet. Autonomic computing, perhaps the most attractive approach
	to solving this problem, creates systems that can manage themselves
	when given high-level objectives from administrators.},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/MC.2003.1160055},
  file = {kephart2003.pdf:kephart2003.pdf:PDF},
  issn = {0018-9162},
  keywords = {autonomic computing},
  publisher = {IEEE Computer Society Press}
}

@MISC{keshav-paper-reading,
  author = {S. Keshav},
  title = {How to Read a Paper},
  file = {:paper-reading.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.03}
}

@ARTICLE{keshav2006,
  author = {S. Keshav},
  title = {Efficient and decentralized computation of approximate global state},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {2006},
  volume = {36},
  pages = {69--74},
  number = {1},
  abstract = {The need for efficient computation of approximate global state lies
	at the heart of a wide range of problems in distributed systems.
	Examples include routing in the Internet, sensor fusion, search in
	peer-to-peer networks, coordinated intrusion detection, and Top-K
	queries in stream-oriented databases. Efficient algorithms that determine
	approximate global state could enable near-optimal local decision-making
	with little overhead. In this position paper, we model this problem
	and summarize recent work on randomized algorithms that navigate
	a four-way tradeo between accuracy, robustness, performance and overhead.
	Despite these recent successes, many open problems remain. We believe
	that solving these problems can radically improve the design of robust,
	efficient and self-managed distributed systems},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1111322.1111338},
  file = {keshav2006.pdf:keshav2006.pdf:PDF},
  issn = {0146-4833},
  publisher = {ACM},
  review = {Position paper on in-network aggregation and open issues. See on general
	background.
	
	
	"The need for efficient computation of approximate global state lies
	at the heart of a wide range of problems in distributed systems"
	
	"Efficient algorithms that determine approximate global state could
	enable near optimal local decision making with little overhead"
	
	
	A brief summary of use of aggregation in various systems. Of interest
	distributed systems and network security points.
	
	Put forth a formal model for global computation and show that it cannot
	be computed if the distributed system suffers from node failures
	and messge losses. However, the global state can be computed if either
	is present. In general, the global function F cannot be computed;
	however, the value can be approximated in many cases of interest.
	
	
	Provides a taxonomy of the problem space: the functions which can
	be computed, network topologies (incl refences on power-law nature
	of Internet), state changes in distributed systems over time.
	
	
	Computation of approximate global state involves a four way tradeoff
	between accuracy, cost, performance and robustness.
	
	
	A survey of solution approaches: Centralization in general not scalable
	but relatively robust since it tolerates losses of all nodes except
	root. Widely used. Tree-based solutions (cites TAG and Astrolabe)
	fragile in the sense that compromise of a single node can disrupt
	the tree. Scalable. Flooding algorithms (push based) but rather inefficient
	unless in-network aggregation is added to the basic approach. Random
	walk solutions (double counting problems). Also only probabilistic
	approximation. Random gossip, also called simple epidemic (see Boyd,
	Kempe, Demers).
	
	
	Discusses "sketches" -- partial aggregates. Aggregation of updates
	necessary to bound size. Functions computed over partial state which
	converge to final solution over time. Double counting is a problem
	which arises in gossip and similar algorithms. Duplicate insensitive
	sketches are one solution (see Flajolet-Martin). Push synopses (Kempe)
	is another approach which uses a principle of mass conservation to
	prevent double counting.
	
	
	Identifies NAT related problems (ford reference). Also references
	van-renesse-2003 (astrolabe paper) on preventing corruption in the
	computation due to malicious nodes.
	
	
	Theory for computability of a distributed function -- impossible in
	a system that can suffer message loss or node failures. (can be approximated)}
}

@INPROCEEDINGS{keys2001,
  author = {Ken Keys and David Moore and Ryan Koga and Edouard Lagache and Michael
	Tesch and K. Claffy},
  title = {The Architecture of {CoralReef}: An Internet Traffic Monitoring Software
	Suite},
  booktitle = {{PAM 2001}},
  year = {2001},
  abstract = {Passive data collection tools have traditionally been designed for
	specific tasks such as accounting (NeTraMet [1]) or packet capture
	(tcpdump [2]). The CoralReef suite was designed to provide a uniform
	interface to passive data for a wide range of applications at many
	levels, from raw capture to real-time report generation. CoralReef
	provides a convenient set of passive data tools for a diverse audience,
	from network administrators to researchers. CoralReef is a package
	of libraries, device drivers, classes, and applications written in,
	and for use with, several programming languages. By highlighting
	design and architectural decisions at all levels in CoralReef, we
	will show how CoralReef is a powerful, extensible, efficient, and
	convenient package for passive data collection and analysis.},
  file = {keys2001.pdf:keys2001.pdf:PDF}
}

@INPROCEEDINGS{Khelil2005,
  author = {Abdelmajid Khelil and Pedro Jose Marron and Kurt Rothermel},
  title = {Contact-Based Mobility Metrics for Delay-Tolerant Ad Hoc Networking},
  year = {2005},
  volume = {00},
  pages = {435-444},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  doi = {http://doi.ieeecomputersociety.org/10.1109/MASCOT.2005.20},
  issn = {1526-7539},
  journal = {mascots},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{kiayias2001,
  author = {Kiayias, Aggelos and Yung, Moti},
  title = {Secure Games with Polynomial Expressions},
  booktitle = {{ICALP '01}: Proceedings of the 28th International Colloquium on
	Automata, Languages and Programming,},
  year = {2001},
  pages = {939--950},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {kiayias2001.pdf:kiayias2001.pdf:PDF},
  isbn = {3-540-42287-0},
  keywords = {PIR, private information retrievalchor}
}

@INPROCEEDINGS{kiciman2007,
  author = {Emre Kiciman and Ben Livshits},
  title = {{AjaxScope: A Platform for Remotely Monitoring the Client-side Behavior
	of Web 2.0 Applications}},
  booktitle = {{21st ACM Symposium on Operating Systems Principles (SOSP'07)}},
  year = {2007},
  address = {Stevenson, WA, USA},
  month = {October},
  abstract = {The rise of the software-as-a-service paradigm has led to the development
	of a new breed of sophisticated, interactive applications often called
	Web 2.0. While web applications have become larger and more complex,
	web application developers today have little visibility into the
	end-to-end behavior of their systems. This paper presents AjaxScope,
	a dynamic instrumentation platform that enables cross-user monitoring
	and just-in-time control of web application behavior on end-user
	desktops. AjaxScope is a proxy that performs on-the-ﬂy parsing and
	instrumentation of JavaScript code as it is sent to users’ browsers.
	AjaxScope provides facilities for distributed and adaptive instrumentation
	in order to reduce the client-side overhead, while giving ﬁne-grained
	visibility into the code-level behavior of web applications. We present
	a variety of policies demonstrating the power of AjaxScope, ranging
	from simple error reporting and performance proﬁling to more complex
	memory leak detection and optimization analyses. We also apply our
	prototype to analyze the behavior of over 90 Web 2.0 applications
	and sites that use large amounts of JavaScript.},
  file = {ajaxscope-sosp.pdf:ajaxscope-sosp.pdf:PDF},
  owner = {kristjan},
  review = {*See also [[kiciman2007a]]*
	
	
	AjaxScope [[kiciman2007]],[[kiciman2007a]] describes a method of distributed
	profiling of JavaScript
	
	applications. A proxy dynamically rewrites JavaScript code embedded
	in web pages, instrumenting the
	
	code in various ways before it reaches the browser. Measurements are
	then sent back to the proxy and 
	
	processed. _Instant redeployability_ is a unique feature of web applications
	- the ability to execute
	
	new and possibly unique versions of code on the users browser each
	time the application is used. AjaxScope takes advantage of this property
	to instrument the code on the fly. A web application can be instrumented
	for profiling (eg. drilling down to slow running code) or for analysing
	bugs. _Adaptive instrumentation_ can be implemented where instrumentation
	code is added or removed from the application dynamically as behaviour
	is observed across the user population. Distributed testing can be
	performed in which the instrumentation is distributed amongst the
	user population in order to distribute the workload. Examples of
	distributed and adaptive instrumentation are given in the article.},
  timestamp = {2008.02.07}
}

@INPROCEEDINGS{kiciman2007a,
  author = {Emre Kiciman and Helen Wang},
  title = {Live Monitoring: Using Adaptive Instrumentation and Analysis to Debug
	and Maintain Web Applications},
  booktitle = {{11th Workshop on Hot Topics in Operating Systems (HotOS XI)}},
  year = {2007},
  address = {San Diego, CA},
  month = {May},
  abstract = {AJAX-based web applications are enabling the next generation of rich,
	client-side web applications, but today’s web application developers
	do not have the end-to-end visibility required to effectively build
	and maintain a re liable system. We argue that a new capability of
	the web application environment—the ability for a system to automatically
	create and serve different versions of an application to each user—can
	be exploited for adaptive, cross-user monitoring of the behavior
	of web applications on end-user desktops. In this paper, we propose
	a live monitoring framework for building a new class of development
	and maintenance techniques that use a continuous loop of automatic,
	adaptive application rewriting, observation and analysis. We outline
	two such adaptive techniques for localizing data corruption bugs
	and automatically placing function result caching. The live monitoring
	framework requires only minor changes to web application servers,
	no changes to application code and no modiﬁcations to existing browsers.},
  file = {webappmonitoring.pdf:webappmonitoring.pdf:PDF},
  owner = {kristjan},
  review = {*See [[livshits2007]]*},
  timestamp = {2008.02.07}
}

@INPROCEEDINGS{kienzle2003,
  author = {Darrell M. Kienzle and Matthew C. Elder},
  title = {Recent worms: a survey and trends},
  booktitle = {WORM '03: Proceedings of the 2003 ACM workshop on Rapid malcode},
  year = {2003},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we present a broad overview of recent worm activity.
	Virus information repositories, such as the Network Associates' Virus
	Information Library, contain over 4500 different entries (through
	the first quarter of 2003). While many of these entries are interesting,
	a great number of them are now simply historical and a large percentage
	of them are completely derivative in nature. However, these virus
	information repositories are the best source of material on the breadth
	of malicious code, including worms.This paper is meant to provide
	worm researchers with a high-level roadmap to the vast body of virus
	and worm information. After sifting through hundreds of entries,
	we present only those that we considered breakthrough or novel, primarily
	from a technical perspective. As a result, we found ourselves omitting
	some of the most notorious worms simply because they lacked any original
	aspects. It is our hope that others in the community who need to
	get up to speed in the worm literature can benefit from this survey.
	While this study does not contain any original research, it provides
	an overview of worms using a truly breadth-first approach, which
	has been lacking in the existing worm literature.From this raw data,
	we have also extracted a number of broad quantitative and qualitative
	trends that we have found to be interesting. We believe that a workshop
	discussion of these, and other thoughts, will be engaging and informative.},
  doi = {http://doi.acm.org/10.1145/948187.948189},
  file = {kienzle2003.pdf:kienzle2003.pdf:PDF},
  isbn = {1-58113-785-0},
  location = {Washington, DC, USA}
}

@INPROCEEDINGS{kifayat2007,
  author = {Kifayat, K. and Merabti, M. and Qi Shi and Llewellyn-Jones, D.},
  title = {Applying Secure Data Aggregation techniques for a Structure and Density
	Independent Group Based Key Management Protocol},
  booktitle = {Information Assurance and Security, 2007. IAS 2007. Third International
	Symposium on},
  year = {2007},
  pages = {44-49},
  month = {Aug.},
  doi = {10.1109/IAS.2007.60},
  file = {kifayat2007.pdf:kifayat2007.pdf:PDF},
  keywords = {cryptography, data privacy, protocols, telecommunication network management,
	telecommunication security, wireless sensor networksdata privacy,
	decryption method, energy conservation, group based key management
	protocol, secure data aggregation technique, security issue, wireless
	sensor network}
}

@INPROCEEDINGS{kihlstrom1998,
  author = {Kihlstrom, Kim Potter and Moser, L. E. and Melliar-Smith, P. M.},
  title = {The SecureRing Protocols for Securing Group Communication},
  booktitle = {{HICSS '98: Proceedings of the Thirty-First Annual Hawaii International
	Conference on System Sciences}},
  year = {1998},
  pages = {317},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {The SecureRing group communication protocols provide reliable ordered
	message delivery and group membership services despite Byzantine
	faults such as might be caused by modifications to the programs of
	a group member following illicit access to, or capture of, a group
	member. The protocols multicast messages to groups of processors
	within an asynchronous distributed system and deliver messages in
	a consistent total order to all members of the group. They ensure
	that correct members agree on changes to the membership, that correct
	processors are eventually included in the membership, and that processors
	that exhibit detectable Byzantine faults are eventually excluded
	from the membership. To provide these message delivery and group
	membership services, the protocols make use of an unreliable Byzantine
	fault detector.},
  doi = {http://dx.doi.org/10.1109/HICSS.1998.656294},
  isbn = {0-8186-8239-6}
}

@INPROCEEDINGS{kilian1992,
  author = {Kilian, Joe},
  title = {A note on efficient zero-knowledge proofs and arguments (extended
	abstract)},
  booktitle = {{STOC '92}: Proceedings of the twenty-fourth annual {ACM} symposium
	on Theory of computing},
  year = {1992},
  pages = {723--732},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this note, we present new zero-knowledge interactive proofs and
	arguments for languages in NP. To show that x &egr; L, with an error
	probability of at most 2-k, our zero-knowledge proof system requires
	O(|x|c1)+O(lgc2|x|)k ideal bit commitments, where c1 and c2 depend
	only on L. This construction is the first in the ideal bit commitment
	model that achieves large values of k more efficiently than by running
	k independent iterations of the base interactive proof system. Under
	suitable complexity assumptions, we exhibit zero knowledge arguments
	that require O(lgc|x|kl bits of communication, where c depends only
	on L, and l is the security parameter for the prover. This is the
	first construction in which the total amount of communication can
	be less than that needed to transmit the NP witness. Our protocols
	are based on efficiently checkable proofs for NP[4].},
  doi = {http://doi.acm.org/10.1145/129712.129782},
  file = {kilian1992.pdf:kilian1992.pdf:PDF},
  isbn = {0-89791-511-9},
  keywords = {zero-knowledge proofs},
  location = {Victoria, British Columbia, Canada}
}

@MISC{KIM2000,
  author = {J. KIM and J. CHOI and J. KIM and S. NOH and S. MIN and Y. CHO and
	C. KIM},
  title = {A low-overhead high-performance unified buffer management scheme
	that exploits sequential and looping references},
  year = {2000},
  owner = {kristjan},
  text = {KIM, J. M., CHOI, J., KIM, J., NOH, S. H., MIN, S. L., CHO, Y., AND
	KIM, C. S. A low-overhead high-performance unified buffer management
	scheme that exploits sequential and looping references. In Proceedings
	of the 4th Symposium on Operating Systems Design and Implementation
	(OSDI) (San Diego, CA, Oct. 2000), pp. 119--134.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/kim00lowoverhead.html}
}

@TECHREPORT{Kim,
  author = {Jonghyun Kim and Vinay Sridhara and Stephan Bohacek},
  title = {Realistic Simulation of Urban Mesh Networks - Part I: Urban Mobility},
  institution = {University of Delaware},
  abstract = {It is a truism that simulations of mobile wireless networks are not
	realistic. There has been little effort in
	
	developing realistic mobility models. In urban areas, the mobility
	of vehicles and pedestrians is greatly inﬂuenced
	
	by the environement (e.g., the location of buildings) as well as by
	interaction with other nodes. For example, on a
	
	congested street of sidewalk, nodes cannot travel at their desired
	speed. Furthermore, the location of streets, sidewalks,
	
	hallways, etc. restricts the position of nodes and trafﬁc lights imapct
	the ﬂow of nodes. In this paper, simulation
	
	of propagation and mobility for urban wireless networks is addressed.
	Techniques for simulation, models, model
	
	parameters, computational complexity, and accuracy are all examined.
	Nearly all aspects of the mobility models and
	
	model parameters can be derived from urban planing and trafﬁc engineering
	research. Simulation of propagation is
	
	discussed extensively in the part II of this paper. The simulation
	approaches discussed in this paper and in part II of
	
	this paper are implemented in a freely available suite of simulation
	tools that are available for download.},
  file = {MobilityTechRep.pdf:MobilityTechRep.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{kim2004,
  author = {Myung-Sup Kim and Hun-Jeong Kang and Seong-Cheol Hong and Seung-Hwa
	Chung and James W. Hong},
  title = {A Flow-based Method for Abnormal Network Traffic Detection},
  booktitle = {{IEEE/IFIP Network Operations and Management}},
  year = {2004},
  abstract = {One recent trend in network security attacks is an increasing number
	of indirect attacks which influence network traffic negatively, instead
	of directly entering a system and damaging it. In future, damages
	from this type of attack are expected to become more serious. In
	addition, the bandwidth consumption by these attacks influences the
	entire network performance. This paper presents an abnormal network
	traffic detecting method and a system prototype. By aggregating packets
	that belong to the identical flow, we can reduce processing overhead
	in the system. We suggest a detecting algorithm using changes in
	traffic patterns that appear during attacks. This algorithm can detect
	even mutant attacks that use a new port number or changed payload,
	while signature-based systems are not capable of detecting these
	types of attacks. Furthermore, the proposed algorithm can identify
	attacks that cannot be detected by examining only single packet information.},
  file = {kim2004.pdf:kim2004.pdf:PDF},
  keywords = {networks, network security, anomaly detection},
  owner = {kristjan},
  timestamp = {2009.08.24}
}

@INCOLLECTION{kinateder2003,
  author = {Michael Kinateder and Siani Pearson},
  title = {A Privacy-Enhanced Peer-to-Peer Reputation System},
  booktitle = {E-Commerce and Web Technologies},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  volume = {2738/2003},
  pages = {206-215},
  abstract = {In this paper, a method is described for providing a distributed reputation
	system with enhanced privacy and security as a design feature. This
	is achieved using a network of trusted agents on each client platform
	that exploit Trusted Computing Platform Alliance (TCPA) technology.},
  file = {:kinateder2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.17}
}

@INPROCEEDINGS{kirda2006,
  author = {E. Kirda and C. Kruegel and G. Vigna and N. Jovanovic},
  title = {Noxes: A client-side solution for mitigating cross-site scripting
	attacks},
  booktitle = {{21st ACM Symposium on Applied Computing (SAC 2006)}},
  year = {2006},
  file = {kirda06noxes.pdf:kirda06noxes.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.25}
}

@ARTICLE{Kistler1992,
  author = {James J. Kistler and M. Satyanarayanan},
  title = {Disconnected operation in the Coda File System},
  journal = {ACM Trans. Comput. Syst.},
  year = {1992},
  volume = {10},
  pages = {3--25},
  number = {1},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/146941.146942},
  file = {p3-kistler.pdf:p3-kistler.pdf:PDF},
  issn = {0734-2071},
  owner = {kristjan},
  publisher = {ACM Press},
  timestamp = {2008.09.19}
}

@MISC{klein2005,
  author = {Amit Klein},
  title = {DOM Based Cross Site Scripting or XSS of the Third Kind. A look at
	an overlooked flavor of XSS.},
  howpublished = {[online] http://www.webappsec.org/projects/articles/071105.shtml},
  month = {April},
  year = {2005},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://www.webappsec.org/projects/articles/071105.shtml}
}

@INPROCEEDINGS{kleinberg2000,
  author = {Jon Kleinberg},
  title = {The small-world phenomenon: An algorithmic perspective},
  booktitle = {STOC '00: Proceedings of the thirty-second annual ACM symposium on
	Theory of computing},
  year = {2000},
  pages = {163--170},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Long a matter of folklore, the "small-world phenomenon" -- the principle
	that we are all linked by short chains of acquaintances -- was inaugurated
	as an area of experimental study in the social sciences through the
	pioneering work of Stanley Milgram in the 1960's. This work was among
	the first to make the phenomenon quantitative, allowing people to
	speak of the "six degrees of separation" between any two people in
	the United States.
	
	Since then, a number of network models have been proposed as frameworks
	in which to study the problem analytically. One of the most refined
	of these models was formulated in recent work of Watts and Strogatz;
	their
	
	framework provided compelling evidence that the small-world phenomenon
	is p@rvasive in a range of networks arising in nature and technology,
	and a fundamental ingredient in the evolution of the World Wide Web.
	
	 But existing models are insufficient to explain the striking algorithmic
	component of Milgram's original findings: that individuals using
	local information are collectively very effective at actually constructing
	short paths between two points in a social network. Although recently
	proposed network models are rich in short paths, we prove that no
	decentralized algorithm, operating with local information only, can
	construct short paths in these networks with non-negligible probability.
	We then define an infinite family of network models that naturally
	generalizes the Watts-Strogatz model, and show that for one of these
	models, there is a decentralized algorithm capable of finding short
	paths with high probability. More generally, we provide a strong
	characterization of this family of network models, showing that there
	is in fact a unique model within the family for which decentralized
	algorithms are effective.},
  doi = {http://doi.acm.org/10.1145/335305.335325},
  file = {kleinberg2000.pdf:kleinberg2000.pdf:PDF},
  isbn = {1-58113-184-4},
  location = {Portland, Oregon, United States},
  review = {On the "small-world" phenonmenon in social networks -- six degrees
	of separation.
	
	Based on watts1998.
	
	See also techreport by Kleinberg}
}

@TECHREPORT{kleinberg1999,
  author = {Jon Kleinberg},
  title = {The Small-World Phenomenon: An Algorithmic Perspective},
  year = {1999},
  address = {Ithaca, NY, USA},
  publisher = {Cornell University},
  review = {On the "small-world" phenonmenon in social networks -- six degrees
	of separation. See also conference paper kleinberg2000.},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Acornellcs%3ACORNELLCS%3ATR99-1776}
}

@ONLINE{kleinfeld2002,
  author = {Judith S. Kleinfeld},
  title = {{Could It Be a Big World After All? The "Six Degrees of Separation"
	Myth}},
  url = {http://www.uaf.edu/northern/big_world.html},
  year = {2002},
  owner = {kristjan},
  timestamp = {2009.04.02}
}

@ONLINE{knorr2008,
  author = {Eric Knorr and Galen Gruman},
  title = {What Cloud Computing Really Means},
  url = {http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html},
  year = {2008},
  owner = {kristjan},
  timestamp = {2009.03.11}
}

@INCOLLECTION{knudsen2007,
  author = {Lars R. Knudsen and Vincent Rijmen},
  title = {Known-Key Distinguishers for Some Block Ciphers},
  booktitle = {Advances in Cryptology -- {ASIACRYPT 2007}},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  volume = {4833/2008},
  abstract = {We present two block cipher distinguishers in a setting where the
	attacker knows the key. One is a distinguisher for AES reduced the
	seven rounds. The second is a distinguisher for a class of Feistel
	ciphers with seven rounds. This setting is quite different from traditional
	settings. We present an open problem: the definition of a new notion
	of security that covers attacks like the ones we present here, but
	not more.},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@PHDTHESIS{ko1996,
  author = {Calvin Ko},
  title = {{Execution Monitoring of Security-Critical Programs in a Distributed
	System: A Specification-Based Approach}},
  school = {{Department of Computer Science: University of California, Davis}},
  year = {1996},
  month = {September},
  file = {ko96-phd-thesis.pdf:ko96-phd-thesis.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@ARTICLE{ko1994,
  author = {Calvin Ko and George Fink and Karl Levitt},
  title = {Automated detection of vulnerabilities in privileged programs by
	execution monitoring},
  journal = {Computer Security Applications Conference, 1994. Proceedings., 10th
	Annual},
  year = {5-9 Dec 1994},
  pages = {134-144},
  abstract = {Presents a method for detecting exploitations of vulnerabilities in
	privileged programs by monitoring their execution using audit trails,
	where the monitoring is with respect to specifications of the security-relevant
	behavior of the programs. Our work is motivated by the intrusion
	detection paradigm, but is an attempt to avoid ad hoc approaches
	to codifying misuse behavior. Our approach is based on the observation
	that although privileged programs can be exploited (due to errors)
	to cause security compromises in systems because of the privileges
	accorded to them, the intended behavior of privileged programs is,
	of course, limited and benign. The key, then, is to specify the intended
	behavior (i.e. the program policy) and to detect any action by a
	privileged program that is outside the intended behavior and that
	imperils security. We describe a program policy specification language,
	which is based on simple predicate logic and regular expressions.
	In addition, we present specifications of privileged programs in
	Unix, and a prototype execution monitor for analyzing audit trails
	with respect to these specifications. The program policies are surprisingly
	concise and clear, and in addition, capable of detecting exploitations
	of known vulnerabilities in these programs. Although our work has
	been motivated by the known vulnerabilities in Unix, we believe that
	by tightly restricting the behavior of all privileged programs, exploitations
	of unknown vulnerabilities can be detected. As a check on the specifications,
	work is in progress on verifying them with respect to an abstract
	security policy},
  doi = {10.1109/CSAC.1994.367313},
  file = {00367313.pdf:00367313.pdf:PDF},
  keywords = {Unix, authorisation, system monitoringUnix, abstract security policy,
	audit trails, automated vulnerability detection, errors, execution
	monitoring, intended behavior, intrusion detection, misuse behavior,
	predicate logic, privileged programs, program execution monitoring,
	program policy specification language, regular expressions, security
	compromises, security-relevant behavior specification, vulnerability
	exploitation}
}

@INPROCEEDINGS{ko1997,
  author = {Calvin Ko and Manfred Ruschitzka and Karl Levitt},
  title = {Execution monitoring of security-critical programs in distributed
	systems: a specification-based approach},
  booktitle = {{IEEE} Symposium on Security and Privacy,},
  year = {1997},
  pages = {175-187},
  month = {May},
  abstract = {We describe a specification-based approach to detect exploitations
	of vulnerabilities in security-critical programs. The approach utilizes
	security specifications that describe the intended behavior of programs
	and scans audit trails for operations that are in violation of the
	specifications. We developed a formal framework for specifying the
	security-relevant behavior of programs, on which we based the design
	and implementation of a real-time intrusion detection system for
	a distributed system. Also, we wrote security specifications for
	15 Unix setuid root programs. Our system detects attacks caused by
	monitored programs, including security violations caused by improper
	synchronization in distributed programs. Our approach encompasses
	attacks that exploit previously unknown vulnerabilities in security-critical
	programs},
  file = {ko97_00601332.pdf:ko97_00601332.pdf:PDF},
  owner = {kristjan},
  review = {Describe a specification based approach to detect exploitation of
	vulnerabilities in security critical programs. Utilize security specifications
	that describe intended behaviour of programs and scan audit trails
	for operations that are in violation of the specifications. Develop
	a formal framework for specification of security relevant behaviour
	of programs and implement a real-time intrusion detection system
	for distributed systems. Wrote specifications for several Unix setuid
	programs.
	
	
	Intrusion detection is an alternative to testing and verification
	for dealing with security problems in software. Three major approaches:
	
	
	1) Anomaly detection.
	
	Assumes that attacks will result in behaviour different than that
	normally observed in a system. See eg \cite{anderson1980,denning1987}.
	
	Statistics based, rule based and immunology based methods have been
	used to model this behaviour (see citations). Have the advantage
	that no specific knowledge about security flaws is required in order
	to detect penetrations. Difficult to set up thresholds so that attacks
	produce significant anomalies. In addition, not all attacks produce
	a identifiable anomaly.
	
	
	2) Misuse detection
	
	Attempts to identify known patterns of intrusions (signatures). Susch
	a IDS detects intrusions by matching audit trails with the set of
	predefined signatures. Weakness: Cannot detect previously unknown
	attacks since the signature will then be unknown.
	
	
	3) Specification based detection
	
	Relies on program specifications that describe the intended behaviour
	of programs. IDS using this method detects deviation from specifications
	rather than a specific signature. Attacks can thus be detected even
	though they may not have been previously encountered (and described
	as a signature).
	
	
	The paper introduces a formal intrusion detection model which uses
	traces (ordered sequences of execution events) for specifying the
	intended behaviour of concurrent programs in a distributed system.
	Specifications (trace policies) describe valid operation sequences
	of one or more programs, collectively called a monitored subject.
	
	Novel type of grammar presented: Parallel environment grammar (PE-grammar).
	
	The parsing of audit trails is the detection mechanism.
	
	
	NOTES:
	
	Parsing of audit trails implies offline processing.
	
	Not immediately obvious from the article how this method is applicable
	across a distributed system.
	
	Can process algrebras be used in this application instead of PE-grammar?
	
	Can model checkers (e.g. UppAal) be applied in this model?
	
	Can trace policies be induced from automatic analysis of processes?},
  timestamp = {2008.02.27}
}

@ARTICLE{koblitz1987,
  author = {Neal Koblitz},
  title = {Elliptic curve cryptosystems},
  journal = {Mathematics of Computation},
  year = {1987},
  volume = {48},
  pages = {203-209},
  number = {177},
  file = {koblitz1987.pdf:koblitz1987.pdf:PDF},
  keywords = {crypto, elliptic curve crypto, EC},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{kompella2004,
  author = {Ramana Rao Kompella and Sumeet Singh and George Varghese},
  title = {On Scalable Attack Detection in the Network},
  booktitle = {{IMC}'04},
  year = {2004},
  address = {Taormina, Sicily, Italy.},
  month = {October 25-27},
  abstract = {Current intrusion detection and prevention systems seek to detect
	a wide class of network intrusions (e.g., DoS attacks, worms, port
	scans) at network vantage points. Unfortunately, all the IDS systems
	we know of keep per-connection or per-ﬂow state. Thus it is hardly
	surprising that IDS systems (other than signature detection mechanisms)
	have not scaled to multi-gigabit speeds. By contrast, note that both
	router lookups and fair queuing have scaled to high speeds using
	aggregation via preﬁx lookups or DiﬀServ. Thus in this paper, we
	initiate research into the question as to whether one can detect
	attacks without keeping per-ﬂow state. We will show that such aggregation,
	while making fast implementations possible, immediately cause two
	problems. First, aggregation can cause behavioral aliasing where,
	for example, good behaviors can aggregate to look like bad behaviors.
	Second, aggregated schemes are susceptible to spooﬁng by which the
	intruder sends attacks that have appropriate aggregate behavior.
	We examine a wide variety of DoS attacks and show that several categories
	(bandwidth based, claim-and-hold, host scanning) can be scalably
	detected. By contrast, it appears that stealthy port-scanning cannot
	be scalably detected without keeping per-ﬂow state.},
  file = {attackdetection-imc04.pdf:attackdetection-imc04.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.06}
}

@ARTICLE{kong2002,
  author = {Jiejun Kong and Haiyun Luo and Kaixin Xu and Daniel Lihui Gu and
	Mario Gerla and Songwu Lu},
  title = {Adaptive Security for Multi-layer Ad-hoc Networks},
  journal = {Special Issue of Wireless Communications and Mobile Computing},
  year = {2002},
  note = {Wiley Interscience Press},
  abstract = {Secure communication is critical in military environments where the
	network infrastructure is vulnerable to various attacks and compromises.
	A conventional centralized solution breaks down when the security
	servers are destroyed by the enemies. In this paper we design and
	evaluate a security framework for multi-layer ad-hoc wireless networks
	with unmanned aerial vehicles (UAVs). In battleﬁelds, the framework
	adapts to the contingent damages on the network infrastructure. Depending
	on the availability of the network infrastructure, our design is
	composed of two modes. In infrastructure mode, security services,
	speciﬁcally the authentication services, are implemented on UAVs
	that feature low overhead and ﬂexible managements. When the UAVs
	fail or are destroyed, our system seamlessly switches to infrastructureless
	mode, a backup mechanism that maintains comparable security services
	among the surviving units. In the infrastructureless mode, the security
	services are localized to each node’s vicinity to comply with the
	ad-hoc communication mechanism in the scenario. We study the instantiation
	of these two modes and the transitions between them. Our implementation
	and simulation measurements conﬁrm the effectiveness of our design.},
  file = {kong2002.pdf:kong2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.31}
}

@INPROCEEDINGS{kong2001,
  author = {Jiejun Kong and Petros Zerfos and Haiyun Luo and Songwu Lu and Lixia
	Zhang},
  title = {Providing Robust and Ubiquitous Security Support for Mobile Ad-hoc
	Networks},
  year = {2001},
  pages = {251--260},
  abstract = {Providing security support for mobile ad-hoc networks is challenging
	for several reasons: (a) wireless networks are susceptible to attacks
	ranging from passive eavesdropping to active interfering, occasional
	break-ins by adversaries may be inevitable in a large time window;
	(b) mobile users demand “anywhere, anytime” services; (c) a scalable
	solution is needed for a large-scale mobile network. In this paper,
	we describe a solution that supports ubiquitous security services
	for mobile hosts, scales to network size, and is robust against break-ins.
	In our design, we distribute the certiﬁcation authority functions
	through a threshold secret sharing mechanism, in which each entity
	holds a secret share and multiple entities in a local neighborhood
	jointly provide complete services. We employ localized certiﬁcation
	schemes to enable ubiquitous services. We also update the secret
	shares to further enhance robustness against break-ins. Both simulations
	and implementation conﬁrm the effectiveness of our design.},
  file = {kong2001.pdf:kong2001.pdf:PDF},
  keywords = {asymmetric crypto, asymmetric signatures, localized threshold signatures},
  review = {See ref by hu2003 on asymmetric mechanisms using localized threshold
	signatures for certificates.}
}

@ARTICLE{konopka1995,
  author = {R. Konopka and M. Trommer},
  title = {A multilayer-architecture for SNMP-based, distributed and hierarchical
	management of local area networks},
  journal = {Computer Communications and Networks, International Conference on},
  year = {1995},
  volume = {0},
  pages = {0272},
  abstract = {In 'traditional' SNMP-management, the management task is divided into
	two layers: agents and managers. The agents provide management data
	that is read out and processed by the manager. In this paper this
	architecture is expanded by an intermediate layer. Preprocessors
	an introduced which behave like a manager in the view of an agent
	and behave like an agent in the view of a manager. They read out
	the information in the MIBs of the agents, process it and make it
	available to the manager in another MIB. The preprocessors offer
	frequently used network management functions with a standardized
	interface to ease the workload of management applications. Traffic
	on the network caused by the management is reduced as well. The realization
	of such preprocessors is shown in an example for a MIB providing
	statistics, limit surveillance, history and prognosis functionality.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICCCN.1995.540129},
  isbn = {0-8186-7180-7},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{koo2004,
  author = {Koo, Chiu-Yuen},
  title = {Broadcast in radio networks tolerating byzantine adversarial behavior},
  booktitle = {{PODC} '04: Proceedings of the twenty-third annual {ACM} symposium
	on Principles of distributed computing},
  year = {2004},
  pages = {275--282},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Much work has focused on the Byzantine Generals (or secure broadcast)
	problem in the standard model in which pairwise communication is
	available between all parties in the network. Some research has also
	explored the problem when pairwise channels exist only between selected
	pairs of players, or under the assumption of "k-cast channels" shared
	by all subsets of players of size k. However, none of these models
	are appropriate for radio networks in which a player can communicate
	only by multicasting a message which is then received by all players
	within some radius r (i.e., the neighbors of the transmitting node).
	Yet, as far as we are aware, obtaining secure broadcast in radio
	networks in the presence of a Byzantine adversary has not been studied
	before.This paper corrects this omission, and provides the first
	analysis of secure broadcast in radio networks for the case of Byzantine
	adversaries. We note that secure broadcast is impossible in the presence
	of an omnipotent adversary. To bypass this barrier, we make the following
	assumption: there exists a prefixed schedule for players to communicate
	and everyone (including corrupted ones) adheres to this schedule.
	Under this assumption, we give a simple broadcast protocol which
	is provably secure whenever the adversary corrupts at most 1<over>4
	r(r+√rover2 + 1)-3 neighbors (roughly a 1/4π fraction) of any honest
	player. On the other hand, we show that it is impossible to achieve
	secure broadcast when the adversary corrupts ⌈1/2 r(2r+1)⌉ (roughly
	a 1/π fraction) neighbors of any honest player.},
  doi = {http://doi.acm.org/10.1145/1011767.1011807},
  file = {koo2004.pdf:koo2004.pdf:PDF},
  isbn = {1-58113-802-4},
  keywords = {sensor network, fault tolerance, byzantine},
  location = {St. John's, Newfoundland, Canada},
  review = {Byzantine fault tolerance in radio networks}
}

@ARTICLE{konrad2006,
  author = {Korad, Uttara and Sivalingam, Krishna M.},
  title = {Reliable data delivery in wireless sensor networks using distributed
	cluster monitoring},
  journal = {Int. J. Sen. Netw.},
  year = {2006},
  volume = {1},
  pages = {75--83},
  number = {1/2},
  abstract = {In a clustering-based Wireless Sensor Network (WSN), cluster heads
	play an important role by serving as data forwarders amongst other
	network organisation functions. Thus, malfunctioning and/or compromised
	sensor nodes that serve as Cluster Head (CH) can lead to unreliable
	data delivery. In this paper, we propose a scheme (called Secure
	Low Energy Clustering (SecLEC)) that incorporates secure cluster
	head selection and distributed cluster head monitoring to achieve
	reliable data delivery. The SecLEC framework is flexible and can
	accommodate various tracking and monitoring mechanisms. Our goal
	in this paper is to understand the performance impact of adding such
	security mechanisms to the clustering architecture in terms of energy
	consumed and prevented data losses. Our experiments show that with
	SecLEC, BS detects such anomalous nodes with the latency of one network
	operation round and the data loss due to malicious nodes is up to
	0.5% with a reasonable communication overhead.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJSNET.2006.010839},
  issn = {1748-1279},
  publisher = {Inderscience Publishers}
}

@INPROCEEDINGS{kosanovic2008,
  author = {M. Kosanovi\'{c} and M. Stoj\v{c}ev},
  title = {Reliable Transport of Data in Wireless Sensor Network},
  booktitle = {6th International Conference On Microelectronics ({MIEL} 2008)},
  year = {2008},
  abstract = {Reliable transport of data in Wireless Sensor Networks (WSN) has become
	a big challenging issue for researcher community in the last few
	years. WSNs are currently deployed in a wide range of applications
	as a sensor is becoming smaller and production cost is smaller.
	
	
	In this paper, we look at the problem of efficient and reliable data
	transport in WSN. We propose a suitable solution for information
	delivery in both directions, in upstream (from sensor node to master
	node – sink) and in downstream (form master node to sensor node).
	Our proposal ensures a reliable data transport in both directions,
	with reduced traffic between sensor nodes and sink.},
  file = {kosanovic2008.pdf:kosanovic2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{kotla2007,
  author = {Kotla, Ramakrishna and Alvisi, Lorenzo and Dahlin, Mike and Clement,
	Allen and Wong, Edmund},
  title = {Zyzzyva: speculative byzantine fault tolerance},
  booktitle = {{SOSP '07: Proceedings of twenty-first ACM SIGOPS symposium on Operating
	systems principles}},
  year = {2007},
  pages = {45--58},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present Zyzzyva, a protocol that uses speculation to reduce the
	cost and simplify the design of Byzantine fault tolerant state machine
	replication. In Zyzzyva, replicas respond to a client's request without
	first running an expensive three-phase commit protocol to reach agreement
	on the order in which the request must be processed. Instead, they
	optimistically adopt the order proposed by the primary and respond
	immediately to the client. Replicas can thus become temporarily inconsistent
	with one another, but clients detect inconsistencies, help correct
	replicas converge on a single total ordering of requests, and only
	rely on responses that are consistent with this total order. This
	approach allows Zyzzyva to reduce replication overheads to near their
	theoretical minimal.},
  doi = {http://doi.acm.org/10.1145/1294261.1294267},
  file = {kotla2007.pdf:kotla2007.pdf:PDF},
  isbn = {978-1-59593-591-5},
  location = {Stevenson, Washington, USA},
  review = {Builds on state machine replication for fault tolerance in client-server
	systems. In contrast to PBFT, much of the work is moved to the client
	side, essentially requiring majority of servers to concur.}
}

@INPROCEEDINGS{koudas2003,
  author = {Nick Koudas and Divesh Srivastava},
  title = {Data stream query processing: A tutorial},
  booktitle = {vldb'2003: Proceedings of the 29th international conference on Very
	large data bases},
  year = {2003},
  pages = {1149--1149},
  publisher = {VLDB Endowment},
  file = {p1149-koudas.pdf:p1149-koudas.pdf:PDF},
  isbn = {0-12-722442-4},
  location = {Berlin, Germany}
}

@INCOLLECTION{krugel2002,
  author = {Christopher Kr\"{u}gel and Thomas Toth and Clemens Kerer},
  title = {Decentralized Event Correlation for Intrusion Detection},
  booktitle = {Lecture Notes in Computer Science. Information Security and Cryptology
	— ICISC 2001},
  publisher = {Springer Berlin / Heidelberg},
  year = {2002},
  volume = {Volume 2288/2002},
  pages = {59-95},
  abstract = {Evidence of attacks against a network and its resources is often scattered
	over several hosts. Intrusion detection systems (IDS) which attempt
	to detect such attacks therefore have to collect and correlate information
	from different sources. We propose a completely decentralized approach
	to solve the task of event correlation and information fusing of
	data gathered from multiple points within the network.
	
	Our system models an intrusion as a pattern of events that can occur
	at different hosts and consists of collaborating sensors deployed
	at various locations throughout the protected network installation.
	
	We present a specification language to define intrusions as distributed
	patterns and a mechanism to specify their simple building blocks.
	The peer-to-peer algorithm to detect these patterns and its prototype
	implementation, called Quicksand, are described. Problems and their
	solutions involved in the management of such a system are discussed.},
  file = {krugel2002.pdf:krugel2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.06.30}
}

@INPROCEEDINGS{krasniewski2005,
  author = {Krasniewski, M. and Padma Varadharajan and Rabeler, B. and Bagchi,
	S. and Hu, Y.C.},
  title = {{TIBFIT}: trust index based fault tolerance for arbitrary data faults
	in sensor networks},
  booktitle = {{DSN} Dependable Systems and Networks},
  year = {2005},
  pages = { 672-681},
  month = {June-1 July},
  doi = {10.1109/DSN.2005.92},
  file = {krasniewski2005.pdf:krasniewski2005.pdf:PDF},
  keywords = { fault tolerance, protocols, safety systems, sensor fusion, telecommunication
	network reliability, wireless sensor networks TIBFIT protocol, arbitrary
	data faults, event aggregation, event decisions, event detection,
	event-driven wireless sensor network, intelligent malicious fault,
	intrusion tolerant systems, network simulator, secure tolerant systems,
	sensed event reasoning, sensor data, trust index based fault tolerance}
}

@ARTICLE{kraui2008,
  author = {Krau\'{\i}, Christoph and Schneider, Markus and Eckert, Claudia},
  title = {On handling insider attacks in wireless sensor networks},
  journal = {Inf. Secur. Tech. Rep.},
  year = {2008},
  volume = {13},
  pages = {165--172},
  number = {3},
  abstract = {Wireless sensor networks can be used in various security-critical
	applications. The most challenging security problems are insider
	attacks. In this article we present security strategies to cope with
	insider attacks and a classification of mechanisms which apply the
	strategies. We show that strategies and mechanisms for wireless sensor
	networks have different characteristics and realizations than in
	classic computer systems because of the special requirements and
	conditions.},
  address = {Oxford, UK, UK},
  doi = {http://dx.doi.org/10.1016/j.istr.2008.10.011},
  issn = {1363-4127},
  publisher = {Elsevier Advanced Technology Publications}
}

@MISC{krauss2008,
  author = {Christoph Krau\ss and Markus Schneider and Claudia Eckert},
  title = {On handling insider attacks in wireless sensor networks},
  year = {2008},
  abstract = {Wireless sensor networks can be used in various security-critical
	applications. The most challenging security problems are insider
	attacks. In this article we present security strategies to cope with
	insider attacks and a classification of mechanisms which apply the
	strategies. We show that strategies and mechanisms for wireless sensor
	networks have different characteristics and realizations than in
	classic computer systems because of the special requirements and
	conditions.},
  doi = {DOI: 10.1016/j.istr.2008.10.011},
  file = {krauss2008.pdf:krauss2008.pdf:PDF},
  issn = {1363-4127},
  journal = {Information Security Technical Report},
  keywords = {Wireless Sensor Networks},
  number = {3},
  pages = {165 - 172},
  url = {http://www.sciencedirect.com/science/article/B6VJC-4TTMNJS-1/2/ad0908e412dd4640f2ccbad6db7b13e6},
  volume = {13}
}

@INPROCEEDINGS{krauss2007,
  author = {Christoph Krau\ss and Frederic Stumpf and Claudia Eckert},
  title = {Detecting Node Compromise in Hybrid Wireless Sensor Networks Using
	Attestation Techniques},
  booktitle = {{ESAS}},
  year = {2007},
  abstract = {Node compromise is a serious threat in wireless sensor net-
	
	works. Particular in networks which are organized in clusters, nodes
	act-
	
	ing as cluster heads for many cluster nodes are a valuable target
	for
	
	an adversary. We present two efficient hardware-based attestation
	proto-
	
	cols for detecting compromised cluster heads. Cluster heads are equipped
	
	with a Trusted Platform Module and possess much more resources than
	
	the majority of cluster nodes which are very constrained in their
	capabil-
	
	ities. A cluster node can verify the trustworthiness of a cluster
	head using
	
	the Trusted Platform Module as a trust anchor and therefore validate
	
	whether the system integrity of a cluster head has not been tampered
	
	with. The first protocol provides a broadcast attestation, i.e., allowing
	
	a cluster head to attest its system integrity to multiple cluster
	nodes
	
	simultaneously, while the second protocol is able to carry out a direct
	
	attestation between a single cluster node (or the sink) and one cluster
	
	head. In contrast to timing-based software approaches,the attestation
	
	can be performed even if nodes are multiple hops away from each other.},
  file = {krauss2007.pdf:krauss2007.pdf:PDF},
  keywords = {sensor network, TPM},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@MISC{rfc-2104-1997,
  author = {H. Krawczyk and M. Bellare and R. Canetti},
  title = {{RFC 2104}. {HMAC}: Keyed-Hashing for Message Authentication},
  year = {1997},
  owner = {kristjan},
  timestamp = {2010.03.04}
}

@MISC{kreitz2009,
  author = {Gunnar Kreitz and Mads Dam and Douglas Wikstr\"{o}m},
  title = {Private Information Aggregation in Large Incomplete Networks},
  abstract = {Emerging approaches to network monitoring involve large numbers of
	agents collaborating to produce performance or security related statistics
	on huge and generally incomplete networks. The aggregation process
	often involves security or business-critical information which network
	providers are generally unwilling to share without strong privacy
	protection. We present eﬃcient and scalable protocols for privately
	computing a large range of aggregation functions based on addition,
	disjunction, and max/min. For addition, we give a protocol that is
	information-theoretically secure against a passive adversary, and
	which requires only one additional round compared to non-private
	protocols for computing sums. For disjunctions, we present both a
	computationally secure, and an information-theoretically secure solution.
	The latter uses a general composition approach which executes the
	sum protocol together with a standard multi-party protocol for a
	complete subgraph of “trusted servers”. This can be used, for instance,
	when a large network can be partitioned into a smaller number of
	provider domains.},
  file = {new draft 2010:kreitz-mpc_incomplete-2009.pdf:PDF;original draft 2009:mpc_incomplete.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@INPROCEEDINGS{krishnamachari2002,
  author = {Krishnamachari, Bhaskar and Estrin, Deborah and Wicker, Stephen B.},
  title = {The Impact of Data Aggregation in Wireless Sensor Networks},
  booktitle = {{ICDCSW} '02: Proceedings of the 22nd International Conference on
	Distributed Computing Systems},
  year = {2002},
  pages = {575--578},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Sensor networks are distributed event-based systems that differ from
	traditional communication networks in several ways: sensor networks
	have severe energy constraints, redundant low-rate data, and many-to-one
	flows. Data-centric mechanisms that perform in-network aggregation
	of data are needed in this setting for energy-efficient information
	flow. In this paper we model data-centric routing and compare its
	performance with traditional end-to-endrouting schemes. We examine
	the impact of source-destination placement and communication network
	density on the energy costs and delay associated with data aggregation.
	We show that data-centric routing offers significant performance
	gains across a wide range of operational scenarios. We also examine
	the complexity of optimal data aggregation, showing that although
	it is an NP-hard problem in general, there exist useful polynomial-time
	special cases.},
  file = {krishnamachari2002.pdf:krishnamachari2002.pdf:PDF},
  isbn = {0-7695-1588-6},
  review = {CHECKOUT: Optimal data aggregation as a NP-hard problem.}
}

@ARTICLE{krishnamachari2004,
  author = {Krishnamachari, Bhaskar and Lyengar, Sitharama},
  title = {Distributed Bayesian Algorithms for Fault-Tolerant Event Region Detection
	in Wireless Sensor Networks},
  journal = {{IEEE} Trans. Comput.},
  year = {2004},
  volume = {53},
  pages = {241--250},
  number = {3},
  abstract = {We propose a distributed solution for a canonical task in wireless
	sensor networks--the binary detection of interesting environmental
	events. We explicitly take into account the possibility of sensor
	measurement faults and develop a distributed Bayesian algorithm for
	detecting and correcting such faults. Theoretical analysis and simulation
	results show that 85-95 percent of faults can be corrected using
	this algorithm, even when as many as 10 percent of the nodes are
	faulty.},
  address = {Washington, DC, USA},
  doi = {http://dx.doi.org/10.1109/TC.2004.1261832},
  file = {krishnamachari2004.pdf:krishnamachari2004.pdf:PDF},
  issn = {0018-9340},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{krishnamurthy2001,
  author = {Balachander Krishnamurthy and Jia Wang and Yinglian Xie},
  title = {Early measurements of a cluster-based architecture for {P2P} systems},
  booktitle = {{IMW '01: Proceedings of the 1st ACM SIGCOMM Workshop on Internet
	Measurement}},
  year = {2001},
  pages = {105--109},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/505202.505216},
  file = {krishnamurthy2001.pdf:krishnamurthy2001.pdf:PDF},
  isbn = {1-58113-435-5},
  location = {San Francisco, California, USA},
  review = {Referenced by sit2002 on frequency of joins and leaves in a p2p system
	-- churn measurements.}
}

@ARTICLE{Krishnan2000,
  author = {P. Krishnan and Danny Raz and Yuval Shavitt},
  title = {The Cache Location Problem},
  journal = {IEEE/ACM Transactions on Networking},
  year = {2000},
  volume = {8},
  pages = {568--582},
  abstract = {This paper studies the problem of where to place network caches. Emphasis
	is given to caches that are transparent to the clients since they
	are easier to manage and they require no cooperation from the clients.
	Our goal
	
	is to minimize the overall ow or the average delay by placing a given
	number of caches in the network. We formulate these location problems
	both for general caches and for transparent en-route caches (TERCs),
	and identify that in general they are intractable. We give optimal
	algorithms for line and ring networks, and present closed form formulae
	for some special cases. We also present a computationally e cient
	dynamic-programming algorithm
	
	for the single server case. This last case is of particular practical
	interest. It models a network that wishes to minimize the average
	access delay for a single web server. We experimentally study the
	e ects of our algorithm using real web server data. We observe that
	a small number of TERCs are su cient to reduce the network tra c
	signi cantly. Furthermore, there is a surprising consistency over
	time in the relative amount of web tra c from the server along a
	path, lending a stability to our TERC location solution. Our techniques
	can be used by network providers to reduce tra c load in their network.},
  file = {:10.1.1.43.4091.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.12.05}
}

@INPROCEEDINGS{Kruegel2003,
  author = {Christopher Kruegel and Giovanni Vigna},
  title = {Anomaly detection of web-based attacks},
  year = {2003},
  pages = {251--261},
  publisher = {ACM Press},
  abstract = {Web-based vulnerabilities represent a substantial portion of the security
	exposures of computer networks. In order to detect known web-based
	attacks, misuse detection systems are equipped with a large number
	of signatures. Unfortunately, it is diﬃcult to keep up with the daily
	disclosure of web-related vulnerabilities, and, in addition, vulnerabilities
	may be introduced by installation-speciﬁc web-based applications.
	Therefore, misuse detection systems should be complemented with anomaly
	detection systems. This paper presents an intrusion detection system
	that uses a number of diﬀerent anomaly detection techniques to detect
	attacks against web servers and web-based applications. The system
	correlates the server-side programs referenced by client queries
	with the parameters contained in these queries. The application-speciﬁc
	characteristics of the parameters allow the system to perform focused
	analysis and produce a reduced number of false positives. The system
	derives automatically the parameter proﬁles associated with web applications
	(e.g., length and structture of parameters) from the analyzed data.
	Therefore, it can be deployed in very diﬀerent application environments
	without having to perform time-consuming tuning and conﬁguration.},
  file = {10.1.1.4.8030.pdf:10.1.1.4.8030.pdf:PDF}
}

@ARTICLE{frey2001,
  author = {Frank R. Kschischang and Brendan J. Frey and Hans-Andrea Loeliger},
  title = {Factor Graphs and the Sum-Product Algorithm},
  journal = {IEEE Transactions on Information Theory},
  year = {2001},
  volume = {47},
  pages = {498--519},
  number = {2},
  abstract = {Algorithms that must deal with complicated global functions of many
	variables often exploit the manner in which the given functions factor
	as a product of “local” functions, each of which depends on a subset
	of the variables. Such a factorization can be visualized with a bipartite
	graph that we call a factor graph. In this tutorial paper, we present
	a generic message-passing algorithm, the sum-product algorithm, that
	operates in a factor graph. Following a single, simple computational
	rule, the sum-product algorithm computes—either exactly or approximately—various
	marginal functions derived from the global function. A wide variety
	of algorithms developed in artificial intelligence, signal processing,
	and digital communications can be derived as specific instances of
	the sum-product algorithm, including the forward/backward algorithm,
	the Viterbi algorithm, the iterative “turbo” decoding algorithm,
	Pearl’s belief propagation algorithm for Bayesian networks, the Kalman
	filter, and certain fast Fourier transform (FFT) algorithms.},
  file = {frey2001.pdf:frey2001.pdf:PDF},
  keywords = {Belief propagation, factor graphs, fast Fourier transform, forward/backward
	algorithm, graphical models, iterative decoding, Kalman filtering,
	marginalization, sum-product algorithm, Tanner graphs, Viterbi algorithm},
  owner = {kristjan},
  timestamp = {2009.05.26}
}

@ARTICLE{kubota2006,
  author = {Ayumu Kubota and Yutaka Miyake and Toshiaki Tanaka},
  title = {Secure Host Name Resolution Infrastructure for Overlay Networks},
  journal = {{IEICE} Transactions on Communications},
  year = {2005},
  volume = {E89-B},
  pages = {2434-2439},
  number = {9},
  abstract = {In order to introduce new routing functionality without changing the
	Internet infrastructure, many routing overlays have been proposed
	in recent years. Although such overlays allow us to dynamically and
	flexibly form various types of networks, the current host name resolution
	mechanism used in the Internet, i.e. DNS, cannot provide us such
	flexibility in host name referencing because of its delegation-based
	administration scheme of domain names. And also, it cannot provide
	us security because of the lack of wide deployment of its security
	extension, DNSSEC. 
	
	
	In this paper, we propose a generic framework for secure and flexible
	host name resolution infrastructure that can be shared among many
	routing overlays. In contrast to DNS with which users are forced
	to use the domain name space managed by IANA/ICANN, our framework
	separates the name resolution mechanism from the name spaces it handles,
	which allows users to choose whatever name space they think appropriate
	for the identity scheme of their overlay-networking community. This
	realizes decentralized management of domain names and gives users
	freedom in domain name acquisition. The basic idea to achieve this
	is to use a cryptographically generated identifier (i.e. a hash of
	a public key) as a reference to an administrative domain of overlay
	networking hosts and allow the owner of the domain to securely publish
	host information using the corresponding private key. We show that
	a referencing mechanism for such host information can be easily implemented
	by using distributed hash tables (DHTs), and then show how such "semantic-free"
	references to domains can be linked to existing identity scheme in
	order to allow "human-friendly" referencing.},
  keywords = {routing overlays, domain names, cryptographically generated identifiers,
	PKI},
  owner = {kristjan},
  timestamp = {2009.09.02}
}

@INPROCEEDINGS{kuhn2005,
  author = {Fabian Kuhn and Stefan Schmid and Roger Wattenhofer},
  title = {A Self-repairing Peer-to-Peer System Resilient to Dynamic Adversarial
	Churn},
  booktitle = {{IPTPS}},
  year = {2005},
  pages = {13-23},
  abstract = {We present a dynamic distributed hash table where peers may join and
	leave at any time. Our system tolerates a powerful adversary which
	has complete visibility of the entire state of the system and can
	continuously add and remove peers. Our system provides worst-case
	fault-tolerance, maintaining desirable properties such as a low peer
	degree and a low network diameter.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://dx.doi.org/10.1007/11558989_2},
  file = {kuhn2005.pdf:kuhn2005.pdf:PDF},
  keywords = {peer-to-peer, churn, adversarial churn, distributed systems, distributed
	hash tables, DHTs, join leave attacks}
}

@ARTICLE{kulik2002,
  author = {Joanna Kulik and Wendi Heinzelman and Hari Balakrishnan},
  title = {Negotiation-Based Protocols for Disseminating Information in Wireless
	Sensor Networks},
  journal = {Wireless Networks},
  year = {2002},
  volume = {8},
  number = {2-3},
  month = {March},
  abstract = {In this paper, we present a family of adaptive protocols, called SPIN
	(Sensor Protocols for Information via Negotiation), that efficiently
	disseminate information among sensors in an energy-constrained wireless
	sensor network. Nodes running a SPIN communication protocol name
	their data using high-level data descriptors, called meta-data. They
	use meta-data negotiations to eliminate the transmission of redundant
	data throughout the network. In addition, SPIN nodes can base their
	communication decisions both upon application-specific knowledge
	of the data and upon knowledge of the resources that are available
	to them. This allows the sensors to efficiently distribute data given
	a limited energy supply. We simulate and analyze the performance
	of four specific SPIN protocols: SPIN-PP and SPIN-EC, which are optimized
	for a point-to-point network, and SPIN-BC and SPIN-RL, which are
	optimized for a broadcast network. Comparing the SPIN protocols to
	other possible approaches, we find that the SPIN protocols can deliver
	60% more data for a given amount of energy than conventional approaches
	in a point-to-point network and 80% more data for a given amount
	of energy in a broadcast network. We also find that, in terms of
	dissemination rate and energy usage, the SPIN protocols perform close
	to the theoretical optimum in both point-to-point and broadcast networks.},
  file = {kulik2002.pdf:kulik2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.01}
}

@INPROCEEDINGS{kumar_witty_2005,
  author = {Abhishek Kumar and Vern Paxson and Nicholas Weaver},
  title = {Exploiting Underlying Structure for Detailed Reconstruction of an
	Internet-scale Event},
  booktitle = {Proceedings of the Internet Measurement Conference},
  year = {2005},
  address = {Berkeley, CA},
  abstract = {Network “telescopes” that record packets sent to unused blocks of
	Internet address space have emerged as an important tool for observing
	Internet-scale events such as the spread of worms and the backscatter
	from ﬂooding attacks that use spoofed source addresses. Current telescope
	analyses produce detailed tabulations of packet rates, victim population,
	and evolution over time. While such cataloging is a crucial ﬁrst
	step in studying the telescope observations, incorporating an understanding
	of the underlying processes generating the observations allows us
	to construct detailed inferences about the broader “universe” in
	which the Internet-scale activity occurs, greatly enriching and deepening
	the analysis in the process.
	
	 In this work we apply such an analysis to the propagation of the
	Witty worm, a malicious and well-engineered worm that when released
	in March 2004 infected more than 12,000 hosts world-wide in 75 minutes.
	We show that by carefully exploiting the structure of the worm, especially
	its pseudo-random number generation, from limited and imperfect telescope
	data we can with high ﬁdelity: extract the individual rate at which
	each infectee injected packets into the network prior to loss; correct
	distortions in the telescope data due to the worm’s volume overwhelming
	the monitor; reveal the worm’s inability to fully reach all of its
	potential victims; determine the number of disks attached to each
	infected machine; compute when each infectee was last booted, to
	sub-second accuracy; explore the “who infected whom” infection tree;
	uncover that the worm speciﬁcally targeted hosts at a US military
	base; and pinpoint Patient Zero, the initial point of infection,
	i.e., the IP address of the system the attacker used to unleash Witty.},
  file = {witty-imc05.pdf:witty-imc05.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.06}
}

@PHDTHESIS{kumar1995,
  author = {Sandeep Kumar},
  title = {Classification and Detection of Computer Intrusions},
  school = {Department of Computer Science, Purdue University},
  year = {1995},
  month = {August},
  abstract = {Some computer security breaches cannot be prevented using access and
	information fow control techniques. These breaches may be a consequence
	of system software bugs, hardware or software failures, incorrect
	system administration procedures, or failure of the system authentication
	module. Intrusion detection techniques can have a signicant role
	in the detection of computer abuse in such cases.
	
	 This dissertation describes a pattern matching approach to representing
	and detecting intrusions, a hitherto untried approach in this field.
	We have classified intrusions on the basis of structural interrelationships
	among observable system events. The classification formalizes detection
	of specific exploitations by examining their manifestations in the
	system event trace. Thus, we can talk about intrusion signatures
	belonging to particular categories in the classication, instead
	of vulnerabilities that result in intrusions.
	
	 The classification developed in this dissertation can also be used
	for developing computational models to detect intrusions in each
	category by exploiting the common structural interrelationships of
	events comprising the signatures in that category. We can then look
	at signatures of interest that can be matched eciently, instead
	of attempting to devise a comprehensive set of techniques to detect
	any violation of the security policy. We define and justify a computational
	model in which intrusions from our classification can be represented
	and matched. We also present experimental results based on an implementation
	of the model tested against real-world intrusions.},
  file = {kumar-intdet-phddiss.pdf:kumar-intdet-phddiss.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@INPROCEEDINGS{kurian2008,
  author = {Jinu Kurian and Kamil Sarac},
  title = {A Security Framework for Service Overlay Networks: Access Control},
  year = {2008},
  abstract = {Service overlay networks (SONs) have recently been proposed to support
	various value-added services including multicast, resilient routing,
	QoS support, and DoS resistant communication in the Internet. Access
	control plays an important role for various SON applications yet
	most SON proposals do not consider access control or assume that
	it is a pre-existing service. The lack of a proper access control
	mechanism may introduce security or efﬁciency problems for various
	SON applications. In this paper, we present a scalable, distributed
	access control scheme with very low state information required to
	be maintained at the SON nodes. Using this service, a SON access
	node can decide if an end user’s trafﬁc should be accepted into the
	SON overlay for processing and forwarding towards its intended destination.
	We present our scheme and evaluate it via a combination of formal
	veriﬁcation, security analysis, and an experimental evaluation work
	on its practicality.},
  file = {kurian2008.pdf:kurian2008.pdf:PDF},
  owner = {kristjan},
  review = {TODO: Perhaps use on overlay network security and authenticaion.},
  timestamp = {2009.09.02}
}

@BOOK{Kurose2005,
  title = {Computer Networking. A Top-Down Approach Featuring the Internet},
  publisher = {Pearson Education, Inc / Addison-Wesley},
  year = {2005},
  author = {James F. Kurose and Keith W. Ross},
  edition = {Third edition},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INCOLLECTION{kutylstrokowski2003,
  author = {Miroslstrokaw Kutylstrokowski and Daniel Letkiewicz},
  title = {Computing Average Value in Ad Hoc Networks},
  booktitle = {Mathematical Foundations of Computer Science},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  pages = {511-520},
  abstract = {We consider a single-hop sensor network with n=THgr(N) stations using
	R independent communication channels. Communication between the stations
	can fail at random or be scrambled by an adversary so that it cannot
	be distinguished from a random noise.
	
	Assume that each station S i holds an integer value T i . The problem
	that we consider is to replace the values T i by their average (rounded
	to integer values). A typical situation is that we have a local sensor
	network that needs to make a decision based on the values read by
	sensors by computing the average value or some kind of voting.
	
	We design a protocol that solves this problem in steps. The protocol
	is robust: a constant random fraction of messages can be lost (by
	communication channel failure, by action of an adversary or by synchronization
	problems). Also a constant fraction of stations may go down (or be
	destroyed by an adversary) without serious consequences for the rest.
	
	The algorithm is well suited for dynamic systems, for which the values
	T i may change and the protocol once started works forever.},
  file = {kutylstrokowski2003.pdf:kutylstrokowski2003.pdf:PDF},
  keywords = {mobile computing, radio network, sensor network, distributed aggregation},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{lam2006,
  author = {V.T. Lam and S. Antonatos and P. Akritidis and K.G. Anagnostakis},
  title = {Puppetnets: Misusing Web Browsers as a Distributed Attack Infrastructure},
  booktitle = {CCS06},
  year = {2006},
  address = {Alexandria, Virginia, USA.},
  month = {October},
  abstract = {Most of the recent work on Web security focuses on preventing attacks
	that directly harm the browser’s host machine and user. In this paper
	we attempt to quantify the threat of browsers being indirectly misused
	for attacking third parties. Speciﬁcally, we look at how the existing
	Web infrastructure (e.g., the languages, protocols, and security
	policies) can be exploited by malicious Web sites to remotely instruct
	browsers to orchestrate actions including denial of service attacks,
	worm propagation and reconnaissance scans. We show that, depending
	mostly on the popularity of a malicious Web site and user browsing
	patterns, attackers are able to create powerful botnet-like infrastructures
	that can cause signiﬁcant damage. We explore the eﬀectiveness of
	countermeasures including anomaly detection and more ﬁne-grained
	browser security policies.},
  file = {puppetnets-ccs06.pdf:puppetnets-ccs06.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.05}
}

@TECHREPORT{lam2006a,
  author = {V. T. Lam and S. Antonatos and P. Akritidis and K. G. Anagnostakis},
  title = {Puppetnets: Misusing Web Browsers as a Distributed Attack Infrastructure
	(Extended Version)},
  institution = {I2R},
  year = {2006},
  abstract = {Most of the recent work on Web security focuses on preventing attacks
	that directly harm the browser’s host machine and user. In this paper
	we attempt to quantify the threat of browsers being indirectly misused
	for attacking third parties. Speciﬁcally, we look at how the existing
	Web infrastructure (e.g., the languages, protocols, and security
	policies) can be exploited by malicious Web sites to remotely instruct
	browsers to orchestrate actions including denial of service attacks,
	worm propagation and reconnaissance scans. We show that, depending
	mostly on the popularity of a malicious Web site and user browsing
	patterns, attackers are able to create powerful botnet-like infrastructures
	that can cause signiﬁcant damage. We explore the effectiveness of
	countermeasures including anomaly detection and more ﬁne-grained
	browser security policies.},
  file = {:puppetnets-extended.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@ARTICLE{lamport1978,
  author = {Lamport, Leslie},
  title = {Time, clocks, and the ordering of events in a distributed system},
  journal = {{Commun. ACM}},
  year = {1978},
  volume = {21},
  pages = {558--565},
  number = {7},
  abstract = {The concept of one event happening before another in a distributed
	system is examined, and is shown to define a partial ordering of
	the events. A distributed algorithm is given for synchronizing a
	system of logical clocks which can be used to totally order the events.
	The use of the total ordering is illustrated with a method for solving
	synchronization problems. The algorithm is then specialized for synchronizing
	physical clocks, and a bound is derived on how far out of synchrony
	the clocks can become.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/359545.359563},
  file = {lamport1978.pdf:lamport1978.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM}
}

@ARTICLE{lamport1980,
  author = {Leslie Lamport and Marshall Pease and Robert Shostak},
  title = {Reaching Agreement in the Presence of Faults},
  journal = {Journal of the {ACM}},
  year = {1980},
  volume = {27},
  number = {2},
  abstract = {The problem addressed here concerns a set of isolated processors,
	some unknown subset of which may be faulty, that communicate only
	by means of two-party messages. Each nonfaulty processor has a private
	value of reformation that must be communicated to each other nonfanlty
	processor. Nonfaulty processors always communicate honestly, whereas
	faulty processors may lie The problem is to devise an algorithm in
	which processors communicate their own values and relay values received
	from others that allows each nonfaulty processor to refer a value
	for each other processor The value referred for a nonfanlty processor
	must be that processor's private value, and the value inferred for
	a faulty one must be consistent wRh the corresponding value inferred
	by each other nonfanlty processor
	
	
	It is shown that the problem is solvable for, and only for, n >_ 3m
	+ 1, where m IS the number of faulty processors and n is the total
	number. It is also shown that if faulty processors can refuse to
	pass on reformation but cannot falsely relay information, the problem
	is solvable for arbitrary n _> m _> 0. This weaker assumption can
	be approxunated m practice using cryptographic methods.},
  file = {lamport1980.pdf:lamport1980.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.11}
}

@ARTICLE{lamport82,
  author = {Leslie Lamport and Robert Shostak and Marshall Pease},
  title = {The Byzantine generals problem},
  journal = {ACM Transactions on Programming Languages and Systems},
  year = {1982},
  volume = {4},
  pages = {382--401},
  abstract = {Reliable computer systems must handle malfunctioningcomponents that
	give conflicting information to different parts of the system. This
	situation can be expressed abstractly in terms of a group of generals
	of the Byzantine army camped with their troops around an enemy city.
	Communicating only by messenger, the generals must agree upon a common
	battle plan. However, one or more of them may be traitors who will
	try to confuse the others. The problem is to find an algorithm to
	ensure that the loyal generals will reach agreement. It is shown
	that, using only oral messages, this problem is solvable if and only
	if more than two-thirds of the generals are loyal; so a single traitor
	can confound two loyal generals. With unforgeable written messages,
	the problem is solvable for any number of generals and possible traitors.
	Applications of the solutions to reliable computer systems are then
	discussed.},
  file = {10.1.1.12.1697.pdf:10.1.1.12.1697.pdf:PDF}
}

@ARTICLE{lampson1974,
  author = {Butler W. Lampson},
  title = {Protection},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {1974},
  volume = {8},
  pages = {18--24},
  number = {1},
  abstract = {Abstract models are given which reflect the properties of most existing
	mechanisms for enforcing protection or access control, together with
	some possible implementations. The properties of existing systems
	are explicated in terms of the model and implementations.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/775265.775268},
  file = {p18-lampson.pdf:p18-lampson.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM}
}

@INPROCEEDINGS{lampson1969,
  author = {B. W. Lampson},
  title = {Dynamic protection structures},
  booktitle = {{AFIPS} '69 (Fall): Proceedings of the November 18-20, 1969, fall
	joint computer conference},
  year = {1969},
  pages = {27--38},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1478559.1478563},
  file = {:p27-lampson.pdf:PDF},
  location = {Las Vegas, Nevada}
}

@ARTICLE{lane99,
  author = {Terran Lane and Carla E. Brodley},
  title = {Temporal sequence learning and data reduction for anomaly detection},
  journal = {ACM Trans. Inf. Syst. Secur.},
  year = {1999},
  volume = {2},
  pages = {295--331},
  number = {3},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/322510.322526},
  file = {p295-lane.pdf:p295-lane.pdf:PDF},
  issn = {1094-9224},
  publisher = {ACM}
}

@INPROCEEDINGS{larrea2006,
  author = {Larrea, Mikel and Mart\'{\i}n, Cristian and Astrain, Jos\'{e} Javier},
  title = {Coordinated data aggregation in wireless sensor networks using the
	Omega failure detector},
  booktitle = {{PE-WASUN} '06: Proceedings of the 3rd {ACM} international workshop
	on Performance evaluation of wireless ad hoc, sensor and ubiquitous
	networks},
  year = {2006},
  pages = {114--122},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present an algorithm implementing the failure detector class omega
	(Ω) in the crash-recovery model to coordinate data aggregation in
	wireless sensor networks. The algorithm ensures the agreement on
	a common aggregator by all sensors of a region, as well as on a common
	super-aggregator among the set of aggregators of the network, hence
	providing a hierarchical energy-efficient data aggregation mechanism.
	We also introduce a battery depletion threshold to enhance the quality
	of service of the wireless sensor network},
  doi = {http://doi.acm.org/10.1145/1163610.1163629},
  file = {larrea2006.pdf:larrea2006.pdf:PDF},
  isbn = {1-59593-487-1},
  location = {Terromolinos, Spain}
}

@ARTICLE{larrea2009,
  author = {Larrea, Mikel and Martin, Cristian and Astrain, Jose Javier},
  title = {Fault\&\#45;tolerant aggregator election and data aggregation in
	wireless sensor networks},
  journal = {Int. J. Commun. Netw. Distrib. Syst.},
  year = {2009},
  volume = {3},
  pages = {93--115},
  number = {2},
  abstract = {This paper presents three algorithms for aggregator election and data
	aggregation in wireless sensor networks where sensors can crash and
	recover. The network is divided in several regions. The algorithms
	ensure the election of a common data aggregator sensor within each
	region, in charge of the collection of local data and the election
	of a unique super-aggregator sensor, in charge of the collection
	of global data, among all the aggregators. Both elections are achieved
	by implementing the Omega failure detector, which provides a self-organising
	and fault-tolerant leader election service. Each algorithm is based
	on a different connectivity assumption. The first algorithm assumes
	that every pair of sensors in a region can communicate directly.
	The second algorithm only requires some correct sensor to communicate
	directly with the rest of sensors. Finally, the third algorithm only
	requires the existence of a multi-hop bidirectional path from some
	correct sensor to the rest of sensors. We also introduce a battery
	depletion threshold to enhance the quality of service of the wireless
	sensor network.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJCNDS.2009.026821},
  issn = {1754-3916},
  publisher = {Inderscience Publishers}
}

@ARTICLE{Larsen1997,
  author = {Kim G. Larsen and Paul Pettersson and Wang Yi},
  title = {{UppAal in a nutshell}},
  journal = {{International Journal on Software Tools for Technology Transfer
	(STTT)}.
	
	Special section on timed and hybrid systems},
  year = {1997},
  volume = {1},
  pages = {134-152},
  number = {1-2},
  file = {jpaper.ps:jpaper.ps:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{open_laszlo_platform,
  author = {{Laszlo Systems, Inc}},
  title = {{Open Laszlo: The premier open-source platform for rich Internet
	applications}},
  howpublished = {http://www.openlaszlo.org/},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://www.openlaszlo.org/}
}

@INPROCEEDINGS{Lazarevic2003,
  author = {Aleksandar Lazarevic and Aysel Ozgur and Levent Ertoz and Jaideep
	Srivastava and Vipin Kumar},
  title = {A Comparative Study of Anomaly Detection Schemes in Network Intrusion
	Detection},
  booktitle = {{SIAM} International Conference on Data Mining},
  year = {2003},
  address = {San Francisco, CA},
  month = {May},
  abstract = {Intrusion detection corresponds to a suite of techniques that are
	used to identify attacks against computers and network infrastructures.
	Anomaly detection is a key element of intrusion detection in which
	perturbations of normal behavior suggest the presence of intentionally
	or unintentionally induced attacks, faults, defects, etc. This paper
	focuses on a detailed comparative study of several anomaly detection
	schemes for identifying different network intrusions. Several existing
	supervised and unsupervised anomaly detection schemes and their variations
	are evaluated on the DARPA 1998 data set of network connections [9]
	as well as on real network data using existing standard evaluation
	techniques as well as using several specific metrics that are appropriate
	when detecting attacks that involve a large number of connections.
	Our experimental results indicate that some anomaly detection schemes
	appear very promising when detecting novel intrusions in both DARPA’98
	data and real network data.},
  file = {sdm03_03.pdf:sdm03_03.pdf:PDF},
  owner = {kristjan},
  review = {Anomaly detection is a key element of intrusion detection systems
	in which perturbations of normal bejhavior suggest attacks, misuse,
	faults etc.
	
	
	The most widely deployed methods involve signature-bsed detection
	techniques. Such methods can only detect previously known attacks
	whose signature is known - a signature database has to be updated
	for each newly discovered attack. These limitations have lead to
	increasing interest in intrusion detecion methods based on data mining
	- see e.g. \cite{lee1998,bloedorn2001,barbara2001,manganaris2000}.
	
	
	Data mining based intrusion detection techniques broadly fall into
	two categories:
	
	1) Misuse detection. Each instance in a data set is labeled as normal
	or intrusion and a learning algorithm trained over the dataset. Advantage
	that this method can accurately detect known attacks while its drawback
	is that it is unable to detect previously seen attacks.
	
	2) Anomaly detection. Build models of normal data and detect deviations
	from the normal model in observed data. Originally proposed by \cite{denning1987}.
	This model has the advantage that it can detect new types of intrusions
	as deviations from normal usage (see \cite{javitz1993}). Algorihtm
	is trained on a normal dataset and then determines whether a new
	piece of test data belongs to the normal set or exhibits anomalous
	behaviour. Authors refer to this as supervised anomaly detection.
	Unsupervised anomaly detection attempts to detect anomalous behaviour
	without using any knowledge of "normal" behaviour. Both types of
	anomaly detection suffer from high rate of false alarms, primarily
	as previously unseen (but legitimate) events are seen as abnormal.
	
	
	The paper presents a comparative study of several anomaly detection
	schemes and evaluates on simulated and collected event logs.
	
	
	Tow types of attacks: 1) Attacks that involve single connections and
	2) Attacks that involve bursts of connections (multiple connections).
	Therefore, two types of analysis.
	
	
	The methods used for the experiments are LOF (density based local
	outliers) \cite{breunig2000}, NN (see Kth-Nearest Neighbor \cite{ramaswamy2000})
	and Mahalanobis-based approaches. LOF most successful in the authors
	experiments. Have successfully applied this mechanism to detect a
	number of attacks.},
  timestamp = {2008.02.26}
}

@INPROCEEDINGS{le2003,
  author = {Long Le and Jay Aikat and Kevin Jeffay and F. Donelson Smith},
  title = {The effects of active queue management on web performance},
  booktitle = {{SIGCOMM '03: Proceedings of the 2003 conference on Applications,
	technologies, architectures, and protocols for computer communications}},
  year = {2003},
  pages = {265--276},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present an empirical study of the effects of active queue management
	(AQM) on the distribution of response times experienced by a population
	of web users. Three prominent AQM schemes are considered: the Proportional
	Integrator (PI) controller, the Random Exponential Marking (REM)
	controller, and Adaptive Random Early Detection (ARED). The effects
	of these AQM schemes were studied alone and in combination with Explicit
	Congestion Notification (ECN). Our major results are:
	
	1. For offered loads up to 80% of bottleneck link capacity, no AQM
	scheme provides better response times than simple drop-tail FIFO
	queue management.
	
	2. For loads of 90% of link capacity or greater when ECN is not used,
	PI results in a modest improvement over drop-tail and the other AQM
	schemes.
	
	3. With ECN, both PI and REM provide significant response time improvement
	at offered loads above 90% of link capacity. Moreover, at a load
	of 90% PI and REM with ECN provide response times competitive to
	that achieved on an unloaded network.
	
	4. ARED with recommended parameter settings consistently resulted
	in the poorest response times which was unimproved by the addition
	of ECN. 
	
	We conclude that without ECN there is little end-user performance
	gain to be realized by employing the AQM designs studied here. However,
	with ECN, response times can be significantly improved. In addition
	it appears likely that provider links may be operated at near saturation
	levels without significant degradation in user-perceived performance.},
  doi = {http://doi.acm.org/10.1145/863955.863986},
  file = {:p265-le.pdf:PDF},
  isbn = {1-58113-735-4},
  location = {Karlsruhe, Germany}
}

@MISC{Leach2005,
  author = {P. Leach and M. Mealling and R. Salz},
  title = {A Universally Unique Identifier ({UUID}) {URN} Namespace},
  month = {July},
  year = {2005},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://www.ietf.org/rfc/rfc4122.txt}
}

@MISC{Lee1997,
  author = {D. Lee and J. Choi and H. Choe and S. Noh and S. Min and Y. Cho},
  title = {Implementation and Performance Evaluation of the {LRFU} Replacement
	Policy},
  year = {1997},
  owner = {kristjan},
  text = {D. Lee, J. Choi, H. Choe, S. H. Noh, S. L. Min, and Y. Cho, Implementation
	and Performance Evaluation of the LRFU Replacement Policy, in Proceeding
	of the 23th Euromicro Conference, pp. 106--111, 1997.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/lee97implementation.html}
}

@MISC{lee2005a,
  author = {HangRok Lee and YongJe Choi and HoWon Kim},
  title = {Implementation of {TinyHash} based on Hash Algorithm for Sensor Network},
  year = {2005},
  abstract = {In recent years, it has been proposed security
	
	architecture for sensor network.[2][4]. One of these, TinySec by Chris
	
	Kalof, Naveen Sastry, David Wagner had proposed Link layer security
	
	architecture, considering some problems of sensor network. (i.e :
	
	energy, bandwidth, computation capability,etc). The TinySec employs
	
	CBC_mode of encryption and CBC-MAC for authentication based on
	
	SkipJack Block Cipher. Currently, This TinySec is incorporated in
	the
	
	TinyOS for sensor network security.
	
	This paper introduces TinyHash based on general hash algorithm.
	
	TinyHash is the module in order to replace parts of authentication
	and
	
	integrity in the TinySec. it implies that apply hash algorithm on
	
	TinySec architecture. For compatibility about TinySec, Components
	
	in TinyHash is constructed as similar structure of TinySec. And
	
	TinyHash implements the HMAC component for authentication and
	
	the Digest component for integrity of messages. Additionally, we
	
	define the some interfaces for service associated with hash algorithm.
	
	Abstract—In recent years, it has been proposed security},
  file = {lee2005a.pdf:lee2005a.pdf:PDF},
  keywords = {sensor network, hash algorithm},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{lee2006,
  author = {Lee, Suk-Bok and Choi, Yoon-Hwa},
  title = {A resilient packet-forwarding scheme against maliciously packet-dropping
	nodes in sensor networks},
  booktitle = {{SASN} '06: Proceedings of the fourth {ACM} workshop on Security
	of ad hoc and sensor networks},
  year = {2006},
  pages = {59--70},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper focuses on defending against compromised nodes' dropping
	of legitimate reports and investigates the misbehavior of a maliciously
	packet-dropping node in sensor networks. We present a resilient packet-forwarding
	scheme using Neighbor Watch System (NWS), specifically designed for
	hop-by-hop reliable delivery in face of malicious nodes that drop
	relaying packets, as well as faulty nodes that fail to relay packets.
	Unlike previous work with multipath data forwarding, our scheme basically
	employs single-path data forwarding, which consumes less power than
	multipath schemes. As the packet is forwarded along the single-path
	toward the base station, our scheme, however, converts into multipath
	data forwarding at the location where NWS detects relaying nodes'
	misbehavior. Simulation experiments show that, with the help of NWS,
	our forwarding scheme achieves a high success ratio in face of a
	large number of packet-dropping nodes, and effectively adjusts its
	forwarding style, depending on the number of packet-dropping nodes
	en-route to the base station.},
  doi = {http://doi.acm.org/10.1145/1180345.1180353},
  file = {lee2006.pdf:lee2006.pdf:PDF},
  isbn = {1-59593-554-1},
  location = {Alexandria, Virginia, USA}
}

@INPROCEEDINGS{lee2001a,
  author = {Sung-Ju Lee and Mario Gerla},
  title = {Split Multipath Routing with Maximally Disjoint Paths in Ad hoc Networks},
  booktitle = {{IEEE} International Conference on Communications},
  year = {2001},
  abstract = {In recent years, routing has been the most focused area in ad
	
	hoc networks research. On-demand routing in particular, is widely
	devel-
	
	oped in bandwidth constrained mobile wireless ad hoc networks because
	of
	
	its effectiveness and efficiency. Most proposed on-demand routing
	protocols
	
	however, build and rely on single route for each data session. Whenever
	there
	
	is a link disconnection on the active route, the routing protocol
	must per-
	
	form a route recovery process. In QoS routing for wired networks,
	multiple
	
	path routing is popularly used. Multiple routes are however, constructed
	us-
	
	ing link-state or distance vector algorithms which are not well-suited
	for ad
	
	hoc networks. We propose an on-demand routing scheme called Split
	Multi-
	
	path Routing (SMR) that establishes and utilizes multiple routes of
	maximally
	
	disjoint paths. Providing multiple routes helps minimizing route recovery
	pro-
	
	cess and control message overhead. Our protocol uses a per-packet
	allocation
	
	scheme to distribute data packets into multiple paths of active sessions.
	This
	
	traffic distribution efficiently utilizes available network resources
	and prevents
	
	nodes of the route from being congested in heavily loaded traffic
	situations.
	
	We evaluate the performance of our scheme using extensive simulation.},
  file = {lee2001a.pdf:lee2001a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.15}
}

@INPROCEEDINGS{lee2005,
  author = {SooHyung Lee and HyunJu Kim and JungChan Na and JongSu Jang},
  title = {Abnormal Traffic Detection and Its Implementation},
  booktitle = {The 7th International Conference on Advanced Communication Technology
	{ICACT} 2005.},
  year = {2005},
  pages = {246-250},
  abstract = {Wide spread of Internet usage has introduced many network security
	threats, and the recent trend of attack is to cause serious network
	performance degradation by introducing large amount of malicious
	traffic into the network. In this paper we discuss traffic analysis
	method in point of view of network security, present our abnormal
	traffic detection method which is based on anomaly analysis. We show
	experimental results of our analysis model, which was made on 8 days
	real world traffic at the international backbone link, and introduce
	our implementation prototype},
  file = {lee2005.pdf:lee2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.06.30}
}

@INPROCEEDINGS{lee1998,
  author = {Wenke Lee and Salvatore J. Stolfo},
  title = {Data mining approaches for intrusion detection},
  booktitle = {SSYM'98: Proceedings of the 7th conference on USENIX Security Symposium,
	1998},
  year = {1998},
  pages = {6--6},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {In this paper we discuss our research in developing general and systematic
	methods for intrusion detection. The key ideas are to use data mining
	techniques to discover consistent and useful patterns of system features
	that describe program and user behavior, and use the set of relevant
	system features to compute (inductively learned) classiﬁers that
	can recognize anomalies and known intrusions. Using experiments on
	the sendmail system call data and the network tcpdump data, we demonstrate
	that we can construct concise and accurate classiﬁers to detect anomalies.
	We provide an overview on two general data mining algorithms that
	we have implemented: the association rules algorithm and the frequent
	episodes algorithm. These algorithms can be used to compute the intra-
	and inter- audit record patterns, which are essential in describing
	program or user behavior. The discovered patterns can guide the audit
	data gathering process and facilitate feature selection. To meet
	the challenges of both efﬁcient learning (mining) and real-time detection,
	we propose an agent-based architecture for intrusion detection systems
	where the learning agents continuously compute and provide the updated
	(detection) models to the detection agents.},
  file = {p6-lee.pdf:p6-lee.pdf:PDF},
  location = {San Antonio, Texas}
}

@ARTICLE{lee2001,
  author = {Wenke Lee and Dong Xiang},
  title = {Information-Theoretic Measures for Anomaly Detection},
  journal = {{IEEE Symposium on Security and Privacy}},
  year = {2001},
  volume = {00},
  pages = {0130},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SECPRI.2001.924294},
  issn = {1540-7993},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{Lei1997,
  author = {Hui Lei and Dan Duchamp},
  title = {An analytical approach to file prefetching},
  booktitle = {USENIX Annual Technical Conference},
  year = {1997},
  month = {jan},
  file = {usenix97-prefetch.ps:usenix97-prefetch.ps:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{leland1994,
  author = {Will E. Leland and Murad S. Taqqu and Walter Willinger and Daniel
	V. Wilson},
  title = {On the self-similar nature of Ethernet traffic (extended version)},
  journal = {IEEE/ACM Trans. Netw.},
  year = {1994},
  volume = {2},
  pages = {1--15},
  number = {1},
  abstract = {We demonstrate that Ethernet LAN traffic is statistically se~-simi/ar,
	that none of the commonly used traffic models is able to capture
	this fra([al-like behavior, that such behavior has serious implications
	for the design, control, and analysis of high-speed, cell-based networks,
	and that aggregating streams of such traffic typically intensifies
	the self-similarity (“burstiness”) instead of smoothing it. Our conclusions
	are supported by a rigorous statistical analysis of hundreds of millions
	of high quality Ethernet traffic measurements colleeted between 1999
	and 1992, coupled with a discussion of tbe underlying mathematical
	and statistical properties of self-similarity and their relationship
	with actual network behavior. We also present traffic models based
	on self-similar stochastic processes that provide simple, accurate,
	and realistic descriptions of traffic scenarios expected during B-ISDN
	deployment.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/90.282603},
  file = {leland1994.pdf:leland1994.pdf:PDF},
  issn = {1063-6692},
  publisher = {IEEE Press}
}

@INPROCEEDINGS{lemke2004,
  author = {Kerstin Lemke and Kai Schramm and Christof Paar},
  title = {Paar: {DPA} on n-Bit Sized Boolean and Arithmetic Operations and
	Its Application to {IDEA}, {RC6}, and the {HMAC}-Construction},
  booktitle = {Cryptographic Hardware and Embedded Systems - {CHES}},
  year = {2004},
  pages = {205--219},
  publisher = {Springer-Verlag},
  abstract = {Differential Power Analysis (DPA) has turned out to be an efficient
	method to attack the implementations of cryptographic algorithms
	and has been well studied for ciphers that incorporate a nonlinear
	substitution box as e.g. in DES. Other product ciphers and message
	authentication codes are based on the mixing of different algebraic
	groups and do not use look-up tables. Among these are IDEA, the AES
	finalist RC6 and HMAC-constructions such as HMAC-SHA-1 and HMAC-RIPEMD-160.
	These algorithms restrict the use of the selection function to the
	Hamming weight and Hamming distance of intermediate data as the addresses
	used do not depend on cryptographic keys. Because of the linearity
	of the primitive operations secondary DPA signals arise. This article
	gives a deeper analysis of the characteristics of DPA results obtained
	on the basic group operations XOR, addition modulo 2 n and modular
	multiplication using multi-bit selection functions. The results shown
	are based both on simulation and experimental data. Experimental
	results are included for an AVR ATM163 microcontroller which demonstrate
	the application of DPA to an IDEA implementation.},
  file = {lemke2004.pdf:lemke2004.pdf:PDF}
}

@ARTICLE{lenstra2001,
  author = {Arjen K. Lenstra and Eric R. Verheul},
  title = {Selecting Cryptographic Key Sizes},
  journal = {Journal of Cryptology},
  year = {2001},
  volume = {14},
  pages = {255-293},
  number = {4},
  month = {December},
  abstract = {In this article we offer guidelines for the determination of key sizes
	for symmetric cryptosystems, RSA, and discrete logarithm-based cryptosystems
	both over finite fields and over groups of elliptic curves over prime
	fields. Our recommendations are based on a set of explicitly formulated
	parameter settings, combined with existing data points about the
	cryptosystems.},
  file = {lenstra2001.pdf:lenstra2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@MISC{leskovec2008,
  author = {Jure Leskovec and Eric Horvitz},
  title = {Planetary-Scale Views on an Instant-Messaging Network},
  abstract = {We present a study of anonymized data capturing a month of high-level
	communication activities within the whole of the Microsoft Messenger
	instant-messaging system. We examine characteristics and patterns
	that emerge from the collective dynamics of large numbers of people,
	rather than the actions and characteristics of individuals. The dataset
	contains summary properties of 30 billion conversations among 240
	million people. From the data, we construct a communication graph
	with 180 million nodes and 1.3 billion undirected edges, creating
	the largest social network constructed and analyzed to date. We report
	on multiple aspects of the dataset and synthesized graph. We find
	that the graph is well-connected and robust to node removal. We investigate
	on a planetary-scale the oft-cited report that people are separated
	by ``six degrees of separation'' and find that the average path length
	among Messenger users is 6.6. We also find that people tend to communicate
	more with each other when they have similar age, language, and location,
	and that cross-gender conversations are both more frequent and of
	longer duration than conversations with the same gender.},
  file = {leskovec2008.pdf:leskovec2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{lesniewski-laas-2008,
  author = {Chris Lesniewski-Laas},
  title = {{A Sybil-proof one-hop DHT}},
  booktitle = {{SocialNets} '08: Proceedings of the 1st workshop on Social network
	systems},
  year = {2008},
  pages = {19--24},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Decentralized systems, such as structured overlays, are subject to
	the Sybil attack, in which an adversary creates many false identities
	to increase its inﬂuence. This paper describes a one-hop distributed
	hash table which uses the social links between users to strongly
	resist the Sybil attack. The social network is assumed to be fast
	mixing, meaning that a random walk in the honest part of the network
	quickly approaches the uniform distribution. As in the related SybilLimit
	system [25], with a social network of n honest nodes and m honest
	edges, the protocol can tolerate up to o(n/ log n) attack edges (social
	links from honest nodes to compromised √nodes). The routing tables
	contain O( m log m) entries per node and are constructed efﬁciently
	by a distributed protocol. This is the ﬁrst sublinear solution to
	this problem. Preliminary simulation results are presented to demonstrate
	the
	
	approach’s effectiveness.},
  doi = {http://doi.acm.org/10.1145/1435497.1435501},
  file = {:p19-lesniewski-laas.pdf:PDF},
  isbn = {978-1-60558-124-8},
  location = {Glasgow, Scotland}
}

@INPROCEEDINGS{levin2009,
  author = {Levin, Dave and Douceur, John R. and Lorch, Jacob R. and Moscibroda,
	Thomas},
  title = {{TrInc}: small trusted hardware for large distributed systems},
  booktitle = {{NSDI'09}: Proceedings of the 6th {USENIX} symposium on Networked
	systems design and implementation},
  year = {2009},
  pages = {1--14},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {A simple yet remarkably powerful tool of selfish and malicious participants
	in a distributed system is "equivocation": making conflicting statements
	to others. We present TrInc, a small, trusted component that combats
	equivocation in large, distributed systems. Consisting fundamentally
	of only a non-decreasing counter and a key, TrInc provides a new
	primitive: unique, once-in-a-lifetime attestations.
	
	
	We show that TrInc is practical, versatile, and easily applicable
	to a wide range of distributed systems. Its deployment is viable
	because it is simple and because its fundamental components--a trusted
	counter and a key--are already deployed in many new personal computers
	today. We demonstrate TrInc's versatility with three detailed case
	studies: attested append-only memory (A2M), PeerReview, and BitTorrent.
	
	
	We have implemented TrInc and our three case studies using real, currently
	available trusted hardware. Our evaluation shows that TrInc eliminates
	most of the trusted storage needed to implement A2M, significantly
	reduces communication overhead in PeerReview, and solves an open
	incentives issue in BitTorrent. Microbenchmarks of our TrInc implementation
	indicate directions for the design of future trusted hardware.},
  file = {levin2009.pdf:levin2009.pdf:PDF},
  keywords = {distributed systems, fault tolerance, trusted platform module, trusted
	log, non-equivocation},
  location = {Boston, Massachusetts},
  review = {The authors present a small trusted component -- a "trinket" -- which
	may help to deny malicious participants the opportunity to equivocate
	-- that is make conflicting statements to others. The trinket consists
	of a monotonically increasing counter (several can be created) and
	a key. The authors demonstrate TrInc usage in case studies: Attested
	append-only memory (A2M), PeerReview and BitTorrent.
	
	
	======
	
	
	See \cite{chun2007} on A2M, \cite{haeberlen2007} on PeerReview.
	
	
	======
	
	
	Previous work on security in distributed systems largely assumed that
	the systems are completely untrusted: \cite{abdelmalek2005}, \cite{castro2002a},
	\cite{cowling2006}, \cite{kotla2007}, \cite{lian2008} (see other
	references in the TrInc paper). We have made similar assumptions
	in our secure aggregation work.
	
	%
	
	This assumption has been questioned recently, e.g.\ in work on A2M
	\cite{chun2007} -- \textit{Attested append-only memory}. This work
	assumes a small trusted module on each node can significantly improve
	security. Define trusted log -- an abstraction for a trusted module.
	They did also show that their abstractioin could improve the byzantine
	fault tolerance in the server component of a client-server system.
	
	
	\cite{levin2009} continue along the lines of the A2M research, essentially
	addressing two issues: 1) Reduction of the storage space required
	for a trusted log and 2) demonstrate the applicability of this approach
	to a number of client/server and p2p systems. The authors note that
	TrInc's core components are included in the TPM (trusted platform
	module) \cite{trusted-platform-module} found on many modern PCs.
	
	
	
	\subsection*{Equivocation in distributed systems}
	
	
	\citeA{lamport82} established that to tolerate $f$ byzantine faults,
	we need $n > 3f$ participants in total. In contrast, crash fault
	tolerance requires $n > 2f$ participants. \cite{chun2007} observed
	that the property of byzantine faults responsible for this difference
	is \textit{equivocation} -- the ability to make conflicting statements
	to different participants. A2M provides a mechanism to prevant equivocation,
	essentially transforming a byzantine fault tolerant system to a crash
	tolerant one. Equivocation, partly following a protocol to maximize
	ones own benefit, is \textbf{rational behavor} \cite{Aiyer2005,Nielson2005}
	for many protocols. In a distributed aggregation system, we want
	all nodes to be \textit{altruistic} -- that is, follow the protocol
	without deviation (altruistic is the strictest compliance with the
	protocol according to the BAR fault model).
	
	
	PeerReview and Nysiad are examples of \textit{accountability systems}
	-- essentially mechanisms that allow users to be held accountable
	for their actions.
	
	
	\textit{PeerReview} \cite{haeberlen2007}: Witnesses collect tamper
	evident records of all messages in a distributed system. Does not
	provide fault tolerance as such but the authors argue that the eventual
	fault detection leads to fault deterrence. The tamper evident logs
	allow detection of equivocation. Requires a witness set of nodes.
	Superlinear number of messages required -- unacceptable messaging
	complexity for what we need. The goals are similar to Byzantine Fault
	Tolerance (BFT) \cite{castro2002a} but instead of preventing bad
	behavior (as in BFT, assuming the ratio of $f$ to $n$ is observed),
	PeerReview ensures that the misbehavior will eventually be discovered.
	
	
	\textit{Nysiad} \cite{ho2008}: Transforms crash tolerant systems into
	byzantine fault tolerant ones. A set of guards (witnesses really)
	is assigned to each host in the system. The guards validate the mesasges
	sent by their associated hosts, using replicas of the hosts execution
	engines. Guards exchange information on received messages by gossiping
	amongst themselves. Nysiad enforces consistency, not eventual detection
	as PeerReview does. Works for non-deterministic execution engines
	with some modifications. Also super-linear complexity (?).
	
	
	\textbf{Note: Both PeerReview and Nysiad appear to be expensive in
	terms of messages and auxilary nodes. Room for improvement.}
	
	
	A2M \cite{chun2007} provides a trusted log and thereby removes the
	option to equivocate. No communications are required to commit to
	the log -- communications are limited to the cryptographic attestations
	which must be attached to protocol messages.
	
	
	\textbf{Note: MPC protocols allow a distributed system to skip the
	middle man -- implement security features requiring a trusted middleman.
	Read up on this a bit more. In general, too expensive in terms of
	communications for our purposes.}
	
	
	\subsection*{Trusted hardware}
	
	
	The TPM \cite{trusted-platform-module} is a trusted piece of hardware
	and planned to be integrated into machines in the future. Note: Have
	to read up on the services and actual security of TPM. Virtutal monotonic
	counters similar to the TrInc idea \cite{sarmenta2006} -- similar
	to counters included in current TPM specification. The TPM specifications
	use four counters -- multiple monotonic counters can however be emulated
	using a single one \cite{van-dijk-2006}. Other proposals taknig advantage
	of trusted modules include \cite{maheshwari2000}, \cite{perrig2002a}.
	
	
	TrInc \cite{levin2009} involves installation of a small device --
	a \textit{trinket} -- on the users computer. The trinket does not
	need access to the state of the host computer -- it only provides
	the services of the monotonically increasing counters and the attestation
	they enable. All it needs is an untrusted channel to communicate
	to the host computer. An USB trinkett could be envisioned. TrInc
	is supposed to be small and easy to use, with an API for use when
	creating distributed systems software.
	
	
	\subsection*{The TrInc approach}
	
	
	Mallory sends a message $m$ to Alice. Mallory attaches an \textit{attestation}
	from her trinket that binds $m$ to a certain counter value and ensures
	Alice that no message will ever be bound to that value of the counter.
	A number of counters can be initialized on each trinket, but each
	monotonic and with an unique ID. Attestations are signed using a
	shared symmetric key, stored in trusted memory and not readable by
	users. Each trinket comes preloaded with an unique identity and a
	public/private keypair to create and verify attestations. The authors
	note that symmetric keys can also be used but then the devices need
	a trusted mechanism to exchange the keys (do not go into detail on
	this). An attestation of trust $\mathcal{A}$ is also included by
	the manufacturer, to be evaluated by users to make sure the trinket
	is trustworthy, e.g.\ a certificate chain. An array of counters,
	each with an unique ID and key, can be created. Alternatively, the
	private key of the trinket can be used to create attestations. An
	attestation is $a \leftarrow \langle I, i, c, c',h \rangle_K$, where
	K is the symmetric (alternatively private) key, $I$ is the trinkets
	identity, $i$ is the counter identity, $c$ is the current counter
	value, $c'$ is the requested counter value, and $h$ is a hash over
	the message $m$ which is to be attested. 
	
	%
	
	A trinket stores a certain number of messages in trusted memory for
	verification at a later time.
	
	
	\subsection*{Verification of attestations}
	
	
	Alice with trinket $A$ sends a message $m$ to user Bob, which has
	trinket $B$. Alice calls \texttt{Attest} on her trinket $A$, creating
	an attestation $a$ for the message $m$. The attestation is sent along
	with $m$ to Bob. How can Bob be convinced the trinket is valid? In
	case a private key was used to generate the trinket, Bob can use
	an API call $\texttt{GetCertificate}$ which returns a certificate
	of the form $(I,K_pub,\mathcal{A})$ -- Alice can use this call to
	construct a certificate to send to Bob. Bob can use this certificate
	$\mathcal{C}^A$ to learn Alices public key and to verify that it
	is indeed a valid key for a trinket.
	
	In case a symmetric key is used, we use the API call \texttt{CheckAttestation}
	instead: The trinket (Bobs) checks if the attestation supplied by
	Alice is valid, given the key, counter and counter value used in
	creating the attestation $a$. 
	
	
	\textbf{TODO: Dig into the case studies for A2M and PeerReview.}
	
	
	\textbf{Note: The authors mention in passing an overconsumption attack
	on the device -- probably only relevant several untrusted applications
	are running on the platform. Should be considered.}
	
	
	\textbf{TODO: Summarize the trusted logs and accountability systems.
	What are the parallels? What are the differences? Clear the accountability
	systems break our scalability requirements but can we use some of
	the ideas?}}
}

@TECHREPORT{levine2006,
  author = {Brian Neil Levine and Clay Shields and N. Boris Margolin},
  title = {A Survey of Solutions to the Sybil Attack.},
  institution = {University of Massachusetts},
  year = {2006},
  address = {Amherst, Amherst MA},
  month = {October},
  abstract = {Many security mechanisms are based on speciﬁc assumptions of identity
	and are vulnerable to attacks when these assumptions are violated.
	For example, impersonation is the well-known consequence when authenticating
	credentials are stolen by a third party. Another attack on identity
	occurs when credentials for one identity are purposely shared by
	multiple individuals, for example to avoid paying twice for a service.
	Such shared accounts are common in practice: friends exchange iTunes
	passwords to share purchased music; BugMeNot.com is a community that
	shares website registration passwords; and network address translation
	[29] devices allow multiple users to pay for a single IP address
	which is then shared among them.
	
	
	In this paper, we survey the impact of the Sybil attack [26], an attack
	against identity in which an individual entity masquerades as multiple
	simultaneous identities. The Sybil attack is a fundamental problem
	in many systems, and it has so far resisted a universally applicable
	solution.
	
	
	Many distributed applications and everyday services assume each participating
	entity controls exactly one identity. When this assumption is unveriﬁable
	or unmet, the sevice is subject to attack and the results of the
	application are questionable if not incorrect. A concrete example
	of this would be an online voting system where one person can vote
	using many online identities. Notably, this problem is currently
	only solved if a central authority, such as the administrator of
	a certiﬁcate authority, can guarantee that each person has a single
	identity represented by one key; in practice, this is very diﬃcult
	to ensure on a large scale and would require costly manual attention.},
  file = {:levine.sybil.tr.2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.19}
}

@INCOLLECTION{lewis2005,
  author = {F. L. Lewis},
  title = {Wireless Sensor Networks},
  booktitle = {Smart environments: technologies, protocols, and applications},
  publisher = {Wiley},
  year = {2005},
  editor = {D.J. Cook and S.K. Das},
  address = {New York},
  owner = {kristjan},
  review = {Good overall intro to sensor networks.},
  timestamp = {2010.05.01}
}

@INPROCEEDINGS{li2006a,
  author = {H. Li and A. Clement and E. Wong and J. Napper and I. Roy and L.
	Alvisi and M. Dahlin},
  title = {{BAR} Gossip},
  booktitle = {Proceedings of the 2006 {USENIX} Operating Systems Design and Implementation
	({OSDI})},
  year = {2006},
  month = {Nov},
  abstract = {We present the ﬁrst peer-to-peer data streaming application that guarantees
	predictable throughput and low latency in the BAR (Byzantine/Altruistic/Rational)
	model, in which non-altruistic nodes can behave in ways that are
	self-serving (rational) or arbitrarily malicious (Byzantine). At
	the core of our solution is a BAR-tolerant version of gossip, a well-known
	technique for scalable and reliable data dissemination. BAR Gossip
	relies on veriﬁable pseudo-random partner selection to eliminate
	non-determinism that can be used to game the system while maintaining
	the robustness and rapid convergence of traditional gossip. A novel
	fair enough exchange primitive entices cooperation among selﬁsh nodes
	on short timescales, avoiding the need for long-term node reputations.
	Our initial experience provides evidence for BAR Gossip’s robustness.
	Our BAR-tolerant streaming application provides over 99% convergence
	for broadcast updates when all clients are selﬁsh but not colluding,
	and over 95% convergence when up to 40% of clients collude while
	the rest follow the protocol. BAR Gossip also performs well when
	the client population consists of both selﬁsh and Byzantine nodes,
	achieving over 93% convergence even when 20% of the nodes are Byzantine.},
  file = {li2006a.pdf:li2006a.pdf:PDF},
  review = {Ref'd by alvisi2007. Byzantine / rational tolerant gossip protocol
	for live streaming.}
}

@INPROCEEDINGS{li2005,
  author = {Jun Li and Toby Ehrenkranz and Geoff Kuenning and Peter Reiher},
  title = {Simulation and Analysis on the Resiliency and Efficiency of Malnets},
  booktitle = {{PADS '05: Proceedings of the 19th Workshop on Principles of Advanced
	and Distributed Simulation}},
  year = {2005},
  pages = {262--269},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Future network intruders will probably use an organized army of malicious
	nodes (here called “malnodes”, or collectively a “malnet”) to deliver
	many diﬀerent attacks, rather than recruiting a disorganized set
	of compromised nodes per attack. However, partly due to the lack
	of understanding of the resiliency and eﬃciency a malnet can have,
	countering malnets has been ineﬀective. This paper begins to address
	this deﬁciency. Through calculation and simulation for three representative
	malnets—random, small-world, and Gnutella-like—we show that extremely
	resilient malnets can be formed to deliver attack code quickly. In
	particular, we show that disconnecting malnets is possible, but extremely
	naive approaches such as randomly disinfecting malnodes will not
	suﬃce, and eﬀective defenses must either happen very quickly during
	a second-wave attack, or take eﬀect prior to it.},
  doi = {http://dx.doi.org/10.1109/PADS.2005.29},
  file = {:li2005.pdf:PDF},
  isbn = {0-7695-2383-8}
}

@ARTICLE{li2004a,
  author = {Jun Li and Reiher, P.L. and Popek, G.J.},
  title = {Resilient self-organizing overlay networks for security update delivery},
  journal = {IEEE Journal on Selected Areas in Communications},
  year = {2004},
  volume = {22},
  pages = {189-202},
  number = {1},
  abstract = {Rapid and widespread dissemination of security updates throughout
	the Internet will be invaluable for many purposes, including sending
	early-warning signals, updating certificate revocation lists, distributing
	new virus signatures, etc. Notifying a large number of machines securely,
	quickly, and reliably is challenging. Such a system must outpace
	the propagation of threats, handle complexities in a large-scale
	environment, deal with interruption attacks on dissemination, and
	also secure itself. Revere addresses these problems by building a
	large-scale, self-organizing, and resilient overlay network on top
	of the Internet. We discuss how to secure the dissemination procedure
	and the overlay network, considering possible attacks and countermeasures.
	We present experimental measurements of a prototype implementation
	of Revere gathered using a large-scale-oriented approach. These measurements
	suggest that Revere can deliver security updates at the required
	scale, speed and resiliency for a reasonable cost.},
  owner = {kristjan},
  timestamp = {2009.09.02}
}

@MISC{li2006,
  author = {Li (Erran) Li and Mohammad Mahdian and Vahab S. Mirrokni},
  title = {Secure Overlay Network Design},
  howpublished = {Whitepaper, Alcatel-Lucent},
  abstract = {Due to the increasing security threats in the Internet, new overlay
	network architectures have been proposed to secure privileged services.
	In these architectures, the application servers are protected by
	a defense perimeter where only traﬃc from entities called servelets
	are allowed to pass. End users must be authorized and can only communicate
	with entities called access points (APs). APs relay authorized users’
	requests to servelets, which in turn pass them to the servers. The
	identity of APs are publicly known while the servelets are typically
	secret. All communications are done through the public Internet.
	Thus all the entities involved forms an overlay network. The main
	component of this distributed system consists of n APs. and m servelets.
	A design for a network is a bipartite graph with APs on one side,
	and the servelets on the other side. If an AP is compromised by an
	attacker, all the servelets that are connected to it are subject
	to attack. An AP is blocked, if all servelets connected to it are
	subject to attack. We consider two models for the failures: In the
	average case model, we assume that each AP i fails with a given probability
	pi . In the worst case model, we assume that there is an adversary
	that knowing the topology of the network, chooses at most k APs to
	compromise. In both models, our objective is to design the connections
	between APs and servelets to minimize the (expected/worst-case) number
	of blocked APs. In this paper, we give a polynomial-time algorithm
	for this problem in the average-case model when the number of servelets
	is a constant. We also show that if the probability of failure of
	each AP is at least 1/2, then in the optimal design each AP is connected
	to only one servelet (we call such designs star-shaped), and give
	a polynomial-time algorithm to ﬁnd the best star-shaped design. We
	observe that this statement is not true if the failure probabilities
	are small. In the worst-case model, we show that the problem is related
	to a problem in combinatorial set theory, and use this connection
	to give bounds on the maximum number of APs that a perfectly failure-resistant
	design with a given number of servelets can support. Our results
	provide the ﬁrst rigorous theoretical foundation for practical secure
	overlay network design.},
  file = {li2006.pdf:li2006.pdf:PDF},
  keywords = {network design, network security, optimization, combinatorics.},
  owner = {kristjan},
  timestamp = {2009.09.02}
}

@MISC{Li2002,
  author = {L. Li and J. Halpern and Z. Haas},
  title = {Gossip-based Ad Hoc Routing},
  year = {2002},
  owner = {kristjan},
  text = {L. Li, J. Halpern, Z. J. Haas, Gossip-based Ad Hoc Routing, unpublished.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/article/haas02gossipbased.html}
}

@ARTICLE{Li2004,
  author = {Ming Li},
  title = {An approach to reliably identifying signs of {DDOS} flood attacks
	based on {LRD} traffic pattern recognition},
  journal = {Computers \& Security},
  year = {2004},
  volume = {23},
  pages = {549 - 558},
  number = {7},
  abstract = {In the aspect of intrusion detection, reliable detection remains a
	challenge issue as stated in Kemmrer and Vigna (Suppl IEEE Comput
	(IEEE Secur Priv) 35(4) (2002) 28). ‘‘The challenge is to develop
	a system that detects close to 100% of attacks with minimal false
	positives. We are still far from achieving this goal.’’ Hence, reliable
	detection of distributed denial-of-service (DDOS) attacks is worth
	studying. By reliable detection, we mean that signs of attacks can
	be identiﬁed with predetermined detection probability and false alarm
	probability. This paper focuses on reliable detection of DDOS ﬂood
	attacks by identifying pattern of trafﬁc with long-range dependence
	(LRD). In this aspect, there are three fundamental issues in theory
	and practice:
	
	 * What is a statistical feature of trafﬁc to be used for pattern
	recognition?
	
	 * How to represent distributions of identiﬁcation probability, false
	alarm probability and miss probability?
	
	 * How to assure a decision-making that has high identiﬁcation probability,
	low false alarm probability and low miss probability?
	
	 This paper gives a statistical detection scheme based on identifying
	abnormal variations of LRD trafﬁc time series. The representations
	of three probability distributions mentioned above are given and
	a decision-making region is explained. Withthis region, one can know
	what an identiﬁcation (or false alarm or miss) probability is for
	capturing signs of DDOS ﬂood attacks. The signiﬁcance of a decision-making
	region is that it provides a guideline to set appropriate threshold
	value so as to assure high identiﬁcation probability, low false alarm
	probability and low miss probability. A case study is demonstrated.},
  doi = {DOI: 10.1016/j.cose.2004.04.005},
  file = {:li2004.pdf:PDF},
  issn = {0167-4048},
  keywords = {Anomaly intrusion detection},
  url = {http://www.sciencedirect.com/science/article/B6V8G-4CN9NXJ-1/2/1ac6f132cd07810a49cfa1f111cdbf51}
}

@MISC{li2005a,
  author = {Tieyan Li},
  title = {Security Map of Sensor Network},
  abstract = {The short paper draws a concrete map (Fig. 1) of security issues in
	sensor network. The
	
	literature survey is done and the sensor-relevant security areas are
	categorized into a table
	
	(Tab. 1). A concise summary is given at the end.},
  file = {li2005a.pdf:li2005a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{li2008,
  author = {Zhijun Li and Guang Gong},
  title = {{DHT}-Based Detection of Node Clone in Wireless Sensor Networks},
  booktitle = {5th {IEEE} International. Conference on Mobile Ad Hoc and Sensor
	Systems (MASS 2008)},
  year = {2008},
  abstract = {Wireless sensor networks are vulnerable to the node clone attack because
	of low-cost, resource-constrained sensor nodes, and uncontrolled
	environments where they are left unattended. Several distributed
	protocols have been proposed for detecting clone. However, some protocols
	rely on an implicit assumption that every node is aware of all other
	nodes’ existence; other protocols using an geographic hash table
	require that nodes know the general network deployment graph. Those
	assumptions hardly hold for many sensor networks. In this paper,
	we present a novel node clone detection protocol based on Distributed
	Hash Table (DHT). DHT provides good distributed properties and our
	protocol is practical for every kind of sensor networks. We analyze
	the protocol performance theoretically. Moreover, we implement our
	protocol in the OMNeT++ simulation framework. The extensive simulation
	results show that our protocol can detect clone efficiently and holds
	strong resistance against adversaries.},
  file = {li2008.pdf:li2008.pdf:PDF},
  keywords = {DTH, wireless sensor network, node clone detection},
  owner = {kristjan},
  review = {Propose a node clone detection method by superimposing a DHT on top
	of the sensor network. The DHT nodes run on the sensor platform itself
	-- trust issues must be considered.
	
	
	Not very well written, but a decent idea. Consider in relation with
	the secure DHT idea for a security service.},
  timestamp = {2010.02.25}
}

@INPROCEEDINGS{li2005b,
  author = {Li, Zang and Trappe, Wade and Zhang, Yanyong and Nath, Badri},
  title = {Robust statistical methods for securing wireless localization in
	sensor networks},
  booktitle = {{IPSN} '05: Proceedings of the 4th international symposium on Information
	processing in sensor networks},
  year = {2005},
  pages = {12},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  abstract = {Many sensor applications are being developed that require the location
	of wireless devices, and localization schemes have been developed
	to meet this need. However, as location-based services become more
	prevalent, the localization infrastructure will become the target
	of malicious attacks. These attacks will not be conventional security
	threats, but rather threats that adversely affect the ability of
	localization schemes to provide trustworthy location information.
	This paper identifies a list of attacks that are unique to localization
	algorithms. Since these attacks are diverse in nature, and there
	may be many unforseen attacks that can bypass traditional security
	countermeasures, it is desirable to alter the underlying localization
	algorithms to be robust to intentionally corrupted measurements.
	In this paper, we develop robust statistical methods to make localization
	attack-tolerant. We examine two broad classes of localization: triangulation
	and RF-based fingerprinting methods. For triangulation-based localization,
	we propose an adaptive least squares and least median squares position
	estimator that has the computational advantages of least squares
	in the absence of attacks and is capable of switching to a robust
	mode when being attacked. We introduce robustness to fingerprinting
	localization through the use of a median-based distance metric. Finally,
	we evaluate our robust localization schemes under different threat
	conditions.},
  file = {li2005b.pdf:li2005b.pdf:PDF},
  isbn = {0-7803-9202-7},
  location = {Los Angeles, California}
}

@ARTICLE{lian2008,
  author = {Lian, Qiao and Peng, Yu and Yang, Mao and Zhang, Zheng and Dai, Yafei
	and Li, Xiaoming},
  title = {Robust incentives via multi-level Tit-for-Tat: Research Articles},
  journal = {{Concurr. Comput. : Pract. Exper.}},
  year = {2008},
  volume = {20},
  pages = {167--178},
  number = {2},
  abstract = {Much work has been done to address the need for incentive models in
	real deployed peer-to-peer networks. In this paper, we discuss problems
	found with the incentive model in a large, deployed peer-to-peer
	network, Maze. We evaluate several alternatives, and propose an incentive
	system that generates preferences for well-behaved nodes while correctly
	punishing colluders. We discuss our proposal as a hybrid between
	Tit-for-Tat and EigenTrust, and show its effectiveness through simulation
	of real traces of the Maze system.},
  address = {Chichester, UK},
  doi = {http://dx.doi.org/10.1002/cpe.v20:2},
  file = {lian2008.pdf:lian2008.pdf:PDF},
  issn = {1532-0626},
  publisher = {John Wiley and Sons Ltd.}
}

@INPROCEEDINGS{lian2007,
  author = {Qiao Lian and Zheng Zhang and Mao Yang and Ben Y. Zhao and Yafei
	Dai and Xiaoming Li},
  title = {An Empirical Study of Collusion Behavior in the Maze P2P File-Sharing
	System},
  booktitle = {ICDCS '07: Proceedings of the 27th International Conference on Distributed
	Computing Systems},
  year = {2007},
  pages = {56},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Peer-to-peer networks often use incentive policies to encourage cooperation
	between nodes. Such systems are generally susceptible to collusion
	by groups of users in order to gain unfair advantages over others.
	While techniques have been proposed to combat web spam collusion,
	there are few measurements of real collusion in deployed systems.
	In this paper, we report analysis and measurement results of user
	collusion in Maze, a large-scale peer-to-peer file sharing system
	with a non-net-zero point-based incentive policy. We search for colluding
	behavior by examining complete user logs, and incrementally refine
	a set of collusion detectors to identify common collusion patterns.We
	find collusion patterns similar to those found in web spamming. We
	evaluate how proposed reputation systems would perform on the Maze
	system. Our results can help guide the design of more robust incentive
	schemes.},
  doi = {http://dx.doi.org/10.1109/ICDCS.2007.84},
  file = {lian2007.pdf:lian2007.pdf:PDF},
  isbn = {0-7695-2837-3}
}

@ARTICLE{liebeherr2007,
  author = {J\"{o}rg Liebeherr and Guangyu Dong},
  title = {An overlay approach to data security in ad-hoc networks},
  journal = {Ad Hoc Netw.},
  year = {2007},
  volume = {5},
  pages = {1055--1072},
  number = {7},
  abstract = {While it has been argued that application-layer overlay protocols
	can enhance services in mobile ad-hoc networks, hardly any empirical
	data is available on the throughput and delay performance achievable
	in this fashion. This paper presents performance measurements of
	an application-layer overlay approach that ensures integrity and
	confidentiality of application data in an ad-hoc environment. A key
	management and encryption scheme, called neighborhood key method,
	is presented where each node shares secrets only with authenticated
	neighbors in the ad-hoc network, thus avoiding global re-keying operations.
	All proposed solutions have been implemented and empirically evaluated
	in an existing software system for application-layer overlay networking.
	Results from indoor and outdoor measurement experiments with mobile
	handheld devices provide insight into the performance and overhead
	of overlay networking and application-layer security services in
	ad-hoc networks.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2006.05.017},
  file = {:liebeherr2007.pdf:PDF},
  issn = {1570-8705},
  publisher = {Elsevier Science Publishers B. V.}
}

@ARTICLE{lim2005,
  author = {Lim, K.-S. and Stadler, R.},
  title = {Real-time views of network traffic using decentralized management},
  journal = {{9th IFIP/IEEE International Symposium on Integrated Network Management}},
  year = {2005},
  pages = {119-132},
  month = {15-19 May},
  abstract = {The ability to create views of a network on a fast time scale becomes
	increasingly important as the complexity and diversity of networks
	increase. These views, which combine information from many distributed
	points in the network, can provide an administrator with a better
	understanding of the interdependencies and interactions between network
	elements and traffic conditions. Applications that could benefit
	from being able to compute such "near" real-time views of the network
	range from performance monitoring to fault management. In this paper,
	we present the architecture of a distributed management infrastructure
	that enables such views to be computed. Based on our earlier work
	on decentralized management, our architecture takes a novel database
	approach that combines the expressive power of SQL with distributed
	algorithms. We describe the implementation of the system on platform
	of embedded Linux devices attached to a network of routers. We provide
	specific examples of how the system can be used as a powerful distributed
	real-time monitoring platform. Finally, we derive a performance model
	of the system and validate it with a set of experiments.},
  doi = {10.1109/INM.2005.1440778},
  file = {01440778.pdf:01440778.pdf:PDF},
  issn = { },
  keywords = { SQL, distributed algorithms, monitoring, real-time systems, telecommunication
	computing, telecommunication network management, telecommunication
	network routing, telecommunication traffic distributed algorithm,
	distributed management infrastructure, distributed real-time monitoring
	platform, fault management, network traffic, performance monitoring}
}

@INPROCEEDINGS{lim2003,
  author = {Koon-Seng Lim and Stadler, R.},
  title = {Weaver: realizing a scalable management paradigm on commodity routers},
  booktitle = {{8th IFIP/IEEE Int. Symp. on Integrated Network Management (IM 2003)}},
  year = {2003},
  pages = { 409-424},
  month = {March},
  abstract = {While there is agreement on the drawbacks of centralized management,
	many approaches that address those do not scale well to large networks.
	We believe that effective management of future large-scale networks
	requires decentralized but coordinated control. In our previous work,
	we introduced the paradigm of pattern-based management, an approach
	that formalizes the use of graph traversal algorithms for controlling
	and coordinating lightweight agents that perform computations and
	data aggregation inside the network. We have shown analytically and
	through simulations that such a management system potentially scales
	to tens of millions of nodes, without significant performance problems
	regarding execution time and traffic overhead. We report on a first
	implementation designed to realize the paradigm. Our system, Weaver,
	consists of active nodes constructed from small, low-cost Linux computers
	that are deployed onto a network of commodity routers. Management
	programs are written in C++ and can be validated and tested for performance
	on a simulator before being deployed. From the design of Weaver,
	we derive a simple performance model that allows us to predict the
	performance of a management operation running on a Weaver system
	for a large-scale network and thus show that our system is likely
	to meet the scaling potential of the paradigm.},
  file = {lim2003.pdf:lim2003.pdf:PDF},
  issn = { },
  journal = {Integrated Network Management, 2003. IFIP/IEEE Eighth International
	Symposium on},
  keywords = {Unix, decentralised control, digital simulation, operating systems
	(computers), telecommunication control, telecommunication network
	management, telecommunication network routing, telecommunication
	traffic C++, Weaver, active nodes, centralized management, commodity
	routers, coordinated control, data aggregation, decentralized control,
	execution time, graph traversal algorithms, large-scale network,
	large-scale network management, lightweight agents control, lightweight
	agents coordination, low-cost Linux computers, management operation
	performance, management programs, management system, pattern-based
	management, performance model, scalable management paradigm, simulations,
	simulator, traffic overhead}
}

@INPROCEEDINGS{lim2001,
  author = {Lim, K-S. and Stadler, R.},
  title = {A navigation pattern for scalable Internet management},
  year = {2001},
  pages = {405-420},
  abstract = {Performing global management operations on the Internet in an efficient
	way is difficult, because of the continuous changes to the Internet
	topology, its large number of nodes and the lack of an up-to-date
	global database. In practice, these difficulties appear in the management
	of large private IP networks and large autonomous systems, which
	form the sub-topologies of the Internet and are under independent
	administration. This paper introduces the echo pattern, a scheme
	for distributing management operations, which addresses these difficulties.
	Management operations based on this pattern do not need knowledge
	of the network topology, they can dynamically adapt to changes in
	the topology, and they scale well in very large networks. A management
	operation based on the echo pattern has two phases. In a first phase,
	the network is being flooded with management commands to be run on
	the network elements. In the second phase, the results of the local
	management operations are aggregated inside the network. We analyze
	the echo pattern with respect to time and traffic complexity and
	compare its performance to that of a centralized management scheme.
	Our results show that “typical” echo-based management operations
	could be executed within some 18 seconds on the entire Internet.
	This short time is due to (1) the high degree of parallelism and
	distributed control in this pattern and (2) some specific properties
	of the Internet topology},
  doi = {10.1109/INM.2001.918056},
  file = {lim2001.pdf:lim2001.pdf:PDF},
  journal = {Integrated Network Management Proceedings, 2001 IEEE/IFIP International
	Symposium on},
  keywords = {Internet, computer network management, distributed control, network
	topology, performance evaluation, telecommunication control, telecommunication
	traffic, transport protocolsInternet topology, centralized management,
	distributed control, distributed management operations, echo pattern,
	echo-based management operations, global management operations, large
	autonomous systems, local management operations, management commands,
	navigation pattern, network elements, network nodes, private IP networks,
	scalable Internet management, sub-topologies, time complexity, traffic
	complexity}
}

@TECHREPORT{lin1999,
  author = {Lin, Meng and Marzullo, Keith and Masini, Stefano},
  title = {Gossip versus Deterministic Flooding: Low Message Overhead and High
	Reliability for Broadcasting on Small Networks},
  year = {1999},
  number = {CS1999-0637},
  address = {La Jolla, CA, USA},
  abstract = {Rumor mongering (also known as gossip) is an epidemiological protocol
	that implements broadcasting with a reliability that can be very
	high. Rumor mongering is attractive because it is generic, scalable,
	adapts well to failures and recoveries, and has a reliability that
	gracefully degrades with the number of failures in a run. In this
	paper we present a protocol that superficially resembles rumor mongering
	but is deterministic. We show that this new protocol has most of
	the same attractions as rumor mongering. The one attraction that
	rumor mongering has - namely graceful degradation - comes at a high
	cost in terms of the number of messages sent. We compare the two
	approaches both at an abstract level and in terms of how they perform
	in an Ethernet.},
  file = {lin1999.pdf:lin1999.pdf:PDF},
  publisher = {University of California at San Diego},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aucsd_cs%3Ancstrl.ucsd_cse%2F%2FCS1999-0637}
}

@INPROCEEDINGS{lincoln2004,
  author = {Patrick Lincoln and Phillip Porras and Vitally Shmatikov},
  title = {Privacy-preserving sharing and correction of security alerts},
  booktitle = {{SSYM'04: Proceedings of the 13th conference on USENIX Security Symposium}},
  year = {2004},
  pages = {17--17},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {We present a practical scheme for Internet-scale collaborative analysis
	of information security threats which provides strong privacy guarantees
	to contributors of alerts. Wide-area analysis centers are proving
	a valuable early warning service against worms, viruses, and other
	malicious activities. At the same time, protecting individual and
	organizational privacy is no longer optional in today's business
	climate. We propose a set of data sanitization techniques and correlation,
	while maintaining privacy for alert contributors. Our approach is
	practical, scalable, does not rely on trusted third parties or secure
	multiparty computation schemes, and does not require sophisticated
	schemes, and does not require sophisticated key management.},
  file = {lincoln2004.pdf:lincoln2004.pdf:PDF},
  location = {San Diego, CA},
  url = {http://www.usenix.org/event/sec04/tech/full_papers/lincoln/lincoln_html/}
}

@INPROCEEDINGS{lindell2007,
  author = {Yehuda Lindell and Benny Pinkas},
  title = {An Efficient Protocol for Secure Two-Party Computation in the Presence
	of Malicious Adversaries},
  booktitle = {{EUROCRYPT}},
  year = {2007},
  pages = {52--79},
  abstract = {We show an eﬃcient secure two-party protocol, based on Yao’s construction,
	which provides security against malicious adversaries. Yao’s original
	protocol is only secure in the presence of semi-honest adversaries,
	and can be transformed into a protocol that achieves security against
	malicious adversaries by applying the compiler of Goldreich, Micali
	and Wigderson (the “GMW compiler”). However, this approach does not
	seem to be very practical as it requires using generic zero-knowledge
	proofs.
	
	
	 Our construction is based on applying cut-and-choose techniques to
	the original circuit and inputs. Security is proved according to
	the ideal/real simulation paradigm, and the proof is in the standard
	model (with no random oracle model or common reference string assumptions).
	The resulting protocol is computationally eﬃcient: the only usage
	of asymmetric cryptography is for running O(1) oblivious transfers
	for each input bit (or for each bit of a statistical security parameter,
	whichever is larger). Our protocol combines techniques from folklore
	(like cut-and-choose) along with new techniques for eﬃciently proving
	consistency of inputs. We remark that a naive implementation of the
	cut-and-choose technique with Yao’s protocol does not yield a secure
	protocol. This is the ﬁrst paper to show how to properly implement
	these techniques, and to provide a full proof of security. 
	
	 Our protocol can also be interpreted as a constant-round black-box
	reduction of secure two-party computation to oblivious transfer and
	perfectly-hiding commitments, or a black-box reduction of secure
	two-party computation to oblivious transfer alone, with a number
	of rounds which is linear in a statistical security parameter. These
	two reductions are comparable to Kilian’s reduction, which uses OT
	alone but incurs a number of rounds which is linear in the depth
	of the circuit [19].},
  file = {lindell2007.pdf:lindell2007.pdf:PDF},
  keywords = {security, two party computation},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@MISC{linhart-2005,
  author = {Chaim Linhart and Amit Klein and Ronen Heled and Steve Orrin},
  title = {{HTTP} Request Smuggling},
  howpublished = {Whitepaper, {Whatchfire Corp.}},
  file = {HTTP-Request-Smuggling.pdf:HTTP-Request-Smuggling.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://www.cgisecurity.com/lib/HTTP-Request-Smuggling.pdf}
}

@INPROCEEDINGS{Lipperts1999,
  author = {Steffen Lipperts},
  title = {Mobile Agenten zur Unterstutzung kooperierender Managementprozesse},
  booktitle = {{GI} Jahrestagung},
  year = {1999},
  pages = {231-238},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/lipperts99mobile.html}
}

@INPROCEEDINGS{liu2008,
  author = {Liu, An and Ning, Peng},
  title = {{TinyECC}: A Configurable Library for Elliptic Curve Cryptography
	in Wireless Sensor Networks},
  booktitle = {{IPSN} '08: Proceedings of the 7th international conference on Information
	processing in sensor networks},
  year = {2008},
  pages = {245--256},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Public Key Cryptography (PKC) has been the enabling technology underlying
	many security services and protocols in traditional networks such
	as the Internet. In the context of wireless sensor networks, elliptic
	curve cryptography (ECC), one of the most efficient types of PKC,
	is being investigated to provide PKC supportin sensor network applications
	so that the existing PKC-based solutions can be exploited. This paper
	presents the design, implementation, and evaluation of TinyECC, a
	configurable library for ECC operations in wireless sensor networks.
	The primary objective of TinyECC is to provide a ready-to-use, publicly
	available software package for ECC-based PKC operations that can
	be flexibly configured and integrated into sensor network applications.
	TinyECC provides a number of optimization switches, which can turn
	specific optimizations on or off based on developers' needs. Different
	combinations of the optimizations have different execution time andresource
	consumptions, giving developers great flexibility in integrating
	TinyECC into sensor network applications. This paperalso reports
	the experimental evaluation of TinyECC on several common sensor platforms,
	including MICAz, Tmote Sky, and Imote2. The evaluation results show
	the impacts of individual optimizations on the execution time and
	resource consumptions, and give the most computationally efficient
	and the most storage efficient configuration of TinyECC.},
  doi = {http://dx.doi.org/10.1109/IPSN.2008.47},
  file = {liu2008.pdf:liu2008.pdf:PDF},
  isbn = {978-0-7695-3157-1},
  keywords = {sensor networks, ECC, elliptic curve cryptography}
}

@INPROCEEDINGS{liu2007,
  author = {Liu, Donggang},
  title = {Efficient and distributed access control for sensor networks},
  booktitle = {{DCOSS}'07: Proceedings of the 3rd {IEEE} international conference
	on Distributed computing in sensor systems},
  year = {2007},
  pages = {21--35},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {Sensor networks are often used to sense the physical world and provide
	observations for various uses. In hostile environments, it is critical
	to control the network access to ensure the integrity, availability,
	and at times confidentiality of the sensor data. This paper develops
	efficient methods for distributed access control in sensor networks.
	The paper starts with a baseline approach, which provides a more
	flexible and efficient way to enforce access control when compared
	with previous solutions. This paper then extends the baseline approach
	to enable privilege delegation, which allows a user to delegate its
	privilege to other users without using a trusted server, and broadcast
	query, which allows a user to access the network at a large scale
	efficiently. The privilege delegation and broadcast query are very
	useful in practice; none of the current solutions can achieve these
	two properties.},
  file = {liu2007.pdf:liu2007.pdf:PDF},
  isbn = {978-3-540-73089-7},
  keywords = {sensor network, access control},
  location = {Santa Fe, NM, USA}
}

@ARTICLE{liu2005a,
  author = {Liu, Donggang and Ning, Peng},
  title = {Improving key predistribution with deployment knowledge in static
	sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2005},
  volume = {1},
  pages = {204--239},
  number = {2},
  abstract = {Pairwise key establishment is a fundamental security service for sensor
	networks. However, establishing pairwise keys in sensor networks
	is a challenging problem, particularly due to the resource constraints
	on sensor nodes and the threat of node compromises. This article
	proposes to use both predeployment and postdeployment knowledge to
	improve pairwise key predistribution in static sensor networks. By
	exploiting the predeployment knowledge, this article first develops
	two key predistribution schemes, a closest pairwise keys scheme and
	a closest polynomials scheme. The analysis shows that these schemes
	can achieve better performance if the expected location information
	is available and that the smaller the deployment error is, the better
	performance they can achieve. The article then investigates how to
	use postdeployment knowledge to improve pairwise key predistribution
	in static sensor networks. The idea is to load an excessive amount
	of predistributed keys on sensor nodes, prioritize these keys based
	on sensors' actual locations discovered after deployment, and discard
	low-priority keys to thwart node compromise attacks. This approach
	is then used to improve the random subset assignment scheme proposed
	recently to demonstrate its practicality and effectiveness. The analysis
	indicates that the postdeployment knowledge can also greatly improve
	the performance and security of key predistribution.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1105688.1105691},
  file = {liu2005a.pdf:liu2005a.pdf:PDF},
  issn = {1550-4859},
  keywords = {sensor network, key predistribution},
  publisher = {ACM}
}

@INPROCEEDINGS{liu2003,
  author = {Liu, Donggang and Ning, Peng},
  title = {Establishing pairwise keys in distributed sensor networks},
  booktitle = {{CCS '03}: Proceedings of the 10th {ACM} conference on Computer and
	communications security},
  year = {2003},
  pages = {52--61},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Pairwise key establishment is a fundamental security service in sensor
	networks; it enables sensor nodes to communicate securely with each
	other using cryptographic techniques. However, due to the resource
	constraints on sensors, it is infeasible to use traditional key management
	techniques such as public key cryptography and key distribution center
	(KDC). To facilitate the study of novel pairwise key predistribution
	techniques, this paper presents a general framework for establishing
	pairwise keys between sensors on the basis of a polynomial-based
	key predistribution protocol [2]. This paper then presents two efficient
	instantiations of the general framework: a random subset assignment
	key predistribution scheme and a grid-based key predistribution scheme.
	The analysis in this paper indicates that these two schemes have
	a number of nice properties, including high probability (or guarantee)
	to establish pairwise keys, tolerance of node captures, and low communication
	overhead. Finally, this paper presents a technique to reduce the
	computation at sensors required by these schemes.},
  doi = {http://doi.acm.org/10.1145/948109.948119},
  file = {liu2003.pdf:liu2003.pdf:PDF},
  isbn = {1-58113-738-9},
  keywords = {sensor networks, wireless networks, pairwise key establishment, cryptography},
  location = {Washington D.C., USA},
  review = {very higly referenced.
	
	On establishing shared keys using only knowledge of node id's. see
	ref by di-pietro-2009}
}

@ARTICLE{liu2008b,
  author = {Liu, Donggang and Ning, Peng and Du, Wenliang},
  title = {Group-based key predistribution for wireless sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2008},
  volume = {4},
  pages = {1--30},
  number = {2},
  abstract = {Many key predistribution techniques have been developed recently to
	establish pairwise keys between sensor nodes in wireless sensor networks.
	To further improve these schemes, researchers have also proposed
	to take advantage of the sensors' expected locations and discovered
	locations to help the predistribution of the keying materials. However,
	in many cases, it is very difficult to deploy sensor nodes at their
	expected locations or guarantee the correct location discovery at
	sensor nodes in hostile environments. In this article, a group-based
	deployment model is developed to improve key predistribution. In
	this model, sensor nodes are only required to be deployed in groups.
	The critical observation in the article is that the sensor nodes
	in the same group are usually close to each other after deployment.
	This deployment model is practical; it greatly simplifies the deployment
	of sensor nodes, while still providing an opportunity to improve
	key predistribution. Specifically, the article presents a novel framework
	for improving key predistribution using the group-based deployment
	knowledge. This framework does not require the knowledge of the sensors'
	expected or discovered locations and is thus suitable for applications
	where it is difficult to deploy the sensor nodes at their expected
	locations or correctly estimate the sensors' locations after deployment.
	To seek practical key predistribution schemes, the article presents
	two efficient instantiations of this framework, a hash key-based
	scheme and a polynomial-based scheme. The evaluation shows that these
	two schemes are efficient and effective for pairwise key establishment
	in sensor networks; they can achieve much better performance than
	the previous key predistribution schemes when the sensor nodes are
	deployed in groups.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1340771.1340777},
  file = {liu2008b.pdf:liu2008b.pdf:PDF},
  issn = {1550-4859},
  publisher = {ACM}
}

@INPROCEEDINGS{liu2005,
  author = {Liu, Donggang and Ning, Peng and Du, Wenliang},
  title = {Group-based key pre-distribution in wireless sensor networks},
  booktitle = {{WiSe} '05: Proceedings of the 4th {ACM} workshop on Wireless security},
  year = {2005},
  pages = {11--20},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Many key pre-distribution techniques have been developed recently
	to establish pairwise keys for wireless sensor networks. To further
	improve these schemes, researchers have proposed to take advantage
	of sensors' expected locations to help pre-distributing keying materials.
	However, it is usually very difficult, and sometimes impossible,
	to guarantee the knowledge of sensors' expected locations. In order
	to remove the dependency on expected locations, this paper proposes
	a practical deployment model, where sensor nodes are deployed in
	groups, and the nodes in the same group are close to each other after
	the deployment. Based on this model, the paper develops a novel group-based
	key pre-distribution framework, which can be combined with any of
	existing key pre-distribution techniques. A distinguishing property
	of this framework is that it does not require the knowledge of sensors'
	expected locations and greatly simplifies the deployment of sensor
	networks. The analysis also shows that the framework can substantially
	improve the security as well as the performance of existing key pre-distribution
	techniques.},
  doi = {http://doi.acm.org/10.1145/1080793.1080798},
  file = {liu2005.pdf:liu2005.pdf:PDF},
  isbn = {1-59593-142-2},
  keywords = {sensor network, security, key distribution},
  location = {Cologne, Germany}
}

@INPROCEEDINGS{liu2005b,
  author = {Liu, Donggang and Ning, Peng and Du, Wenliang Kevin},
  title = {Attack-resistant location estimation in sensor networks},
  booktitle = {{IPSN} '05: Proceedings of the 4th international symposium on Information
	processing in sensor networks},
  year = {2005},
  pages = {13},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  file = {liu2005b.pdf:liu2005b.pdf:PDF},
  isbn = {0-7803-9202-7},
  keywords = {sensor network, secure location estimation},
  location = {Los Angeles, California}
}

@ARTICLE{liu2008a,
  author = {Liu, Donggang and Ning, Peng and Liu, An and Wang, Cliff and Du,
	Wenliang Kevin},
  title = {Attack-Resistant Location Estimation in Wireless Sensor Networks},
  journal = {{ACM Trans. Inf. Syst. Secur.}},
  year = {2008},
  volume = {11},
  pages = {1--39},
  number = {4},
  abstract = {Many sensor network applications require sensors' locations to function
	correctly. Despite the recent advances, location discovery for sensor
	networks in hostile environments has been mostly overlooked. Most
	of the existing localization protocols for sensor networks are vulnerable
	in hostile environments. The security of location discovery can certainly
	be enhanced by authentication. However, the possible node compromises
	and the fact that location determination uses certain physical features
	(e.g., received signal strength) of radio signals make authentication
	not as effective as in traditional security applications. This article
	presents two methods to tolerate malicious attacks against range-based
	location discovery in sensor networks. The first method filters out
	malicious beacon signals on the basis of the “consistency” among
	multiple beacon signals, while the second method tolerates malicious
	beacon signals by adopting an iteratively refined voting scheme.
	Both methods can survive malicious attacks even if the attacks bypass
	authentication, provided that the benign beacon signals constitute
	the majority of the beacon signals. This article also presents the
	implementation and experimental evaluation (through both field experiments
	and simulation) of all the secure and resilient location estimation
	schemes that can be used on the current generation of sensor platforms
	(e.g., MICA series of motes), including the techniques proposed in
	this article, in a network of MICAz motes. The experimental results
	demonstrate the effectiveness of the proposed methods, and also give
	the secure and resilient location estimation scheme most suitable
	for the current generation of sensor networks.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1380564.1380570},
  file = {liu2008a.pdf:liu2008a.pdf:PDF},
  issn = {1094-9224},
  publisher = {ACM}
}

@ARTICLE{liu2006,
  author = {Yonghe Liu and Das, S.K.},
  title = {Information-intensive wireless sensor networks: potential and challenges},
  journal = {{IEEE Communications Magazine}},
  year = {2006},
  volume = {44},
  pages = {142-147},
  number = {11},
  month = {November},
  abstract = {Conventional wireless sensor networks rely mostly on simple scalar
	data (such as temperature or humidity) and specialize in single-purpose
	applications. Taking a fundamental departure, in this article we
	motivate information-rich wireless video sensor networks that emulate
	the compound eyes found in certain arthropods. Although constrained
	by scarce resources, sensor nodes can only serve extremely low-resolution
	video streams; the availability of vast amount of such streams due
	to deployment redundance can suffice for the need of information
	hungry applications. Unfortunately, the unique characteristics of
	wireless video sensor networks will introduce novel uncertainty-driven
	challenges in the information-intensive and yet resource-constrained
	environment. Correspondingly, we describe key research problems in
	the areas of networking, security, sensor design, and video-data
	analysis},
  booktitle = {{IEEE} Communications Magazine},
  file = {liu2006.pdf:liu2006.pdf:PDF},
  keywords = {sensor network, aggregation},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@TECHREPORT{livshits2007a,
  author = {Benjamin Livshits and Weidong Cui},
  title = {Spectator: Detection and Containment of JavaScript Worms},
  institution = {Microsoft Research},
  year = {2007},
  number = {MSR-TR-2007-55},
  file = {spectator_tr.pdf:spectator_tr.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.19}
}

@INPROCEEDINGS{livshits2007,
  author = {Benjamin Livshits and {\'{U}}lfar Erlingsson},
  title = {Using web application construction frameworks to protect against
	code injection attacks},
  booktitle = {{PLAS} '07: Proceedings of the 2007 workshop on Programming languages
	and analysis for security},
  year = {2007},
  pages = {95--104},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In recent years, the security landscape has changed, with Web applications
	vulnerabilities becoming more prominent that vulnerabilities stemming
	from the lack of type safety, such as buffer overruns. Many reports
	point to code injection attacks such as cross-site scripting and
	RSS injection as being the most common attacks against Web applications
	to date. With Web 2.0 existing security problems are further exacerbated
	by the advent of Ajax technology that allows one to create and compose
	HTML content from different sources within the browser at runtime,
	as exempliﬁed by customizable mashup pages like My Yahoo! or Live.com.
	This paper proposes a simple to support, yet a powerful scheme for
	eliminating a wide range of script injection vulnerabilities in applications
	built on top of popular Ajax development frameworks such as the Dojo
	Toolkit, prototype.js, and AJAX.NET. Unlike other client-side runtime
	enforcement proposals, the approach we are advocating requires only
	minor browser modiﬁcations. This is because our proposal can be viewed
	as a natural ﬁner-grained extension of the same-origin policy for
	JavaScript already supported by the majority of mainstream browsers,
	in which we treat individual user interface widgets as belonging
	to separate domains.
	
	Fortunately, in many cases no changes to the development process need
	to take place: for applications that are built on top of frameworks
	described above, a slight framework modiﬁcation will result in appropriate
	changes in the generated HTML, completely obviating the need for
	manual code annotation. In this paper we demonstrate how these changes
	can prevent cross-site scripting and RSS injection attacks using
	the Dojo Toolkit, a popular Ajax library, as an example.},
  doi = {http://doi.acm.org/10.1145/1255329.1255346},
  file = {p95-livshits.pdf:p95-livshits.pdf:PDF},
  isbn = {978-1-59593-711-7},
  location = {San Diego, California, USA},
  review = {Security problems exacerberated by Web 2.0 applications which allow
	HTML to be created and composed
	
	from different sources within the browser at runtime as exemplified
	by mashups (e.g.\ http://my.yahoo.com
	
	and http://www.housingmaps.com. See also \cite{web_mashups}). 
	
	The paper proposes a scheme for enforcing security in applications
	built
	
	on top of popular Ajax frameworks such as the Dojo Toolkit \cite{dojo_toolkit},
	prototype.js and AJAX.NET. 
	
	This approach
	
	involves minor browser modifications. Framework modifications may
	be sufficient to generate HTML which
	
	is safe from code injection attacks (e.g. cross-site scripting and
	RSS injection). 
	
	%
	
	
	A \textit{wide attack surface} is a vulnerability factor in web applications.
	Web applications often developed 
	
	by programmers with less security sophistication. Functionality often
	more important to managers and developers
	
	than security and performance.
	
	
	Developers have to consider the various ways of passing JavaScript
	code into an application - see e.g.\ 
	
	\cite{rsnake_xss}. The authors however maintain that web applications
	can be made safe by default. 
	
	Web application code is increasingly being produced using web application
	frameworks - libraries
	
	of AJAX code which is used by developers to assemble sophisticated
	web applications. This provides
	
	opportunities to create code which uses safe defaults which would
	be enforced on the client side.
	
	The Dojo toolkit is considered in particular.
	
	Other toolkits include AJAX.NET. Open Laszlo \cite{open_laszlo_platform}
	which converts HTML and JavaScript
	
	into Flash or DHTML. Google Web Toolkit \cite{google_web_toolkit}
	transforms Java into JavaScript and
	
	HTML. There are thus rich opportunities to use frameworks and code
	generating tools to enforce
	
	safe defaults.
	
	
	Proposes extension of the same-origin policy already present in JavaScript.
	Each UI widget acts as a principal
	
	The code associated with the widget would correspond to the principal
	so that it can only asccess DOM elements
	
	within the widget itself. The authors propose to modify the Ajax frameworks
	to support generation of principals.
	
	
	Same origin policy of JavaScript limits acces to DOM and other browser
	resources such as cookies by carefully keeping track of the origin
	of a particular piece of code. The principal in the default same-origin
	scheme is a triple (host,protocol,port) and the origin of a piece
	of JavaScript code is determined by where it is embedded in the HTML
	DOM. The origins of both a DOM element and a piece of sipt are determinted
	by walking to the top of the DOM tree. JavaScript access to DOM is
	only allowed if the origin is the same. Code with an assigned principal
	can run as long as it does not affect areas of the page with another
	prinicpal.
	
	
	Finer grained protection is possible, eg. isolating individual tree
	nodes by assigning individual principals to each one.}
}

@TECHREPORT{livshits2005,
  author = {V. Benjamin Livshits and Monica S. Lam},
  title = {Finding Security Errors in {J}ava Programs with Static Analysis},
  institution = {Stanford University},
  year = {2005},
  month = aug,
  abstract = {A number of recently discovered security vulnerabilities such as SQL
	injections, cross-site scripting, and HTTP splitting attacks are
	caused by programming errors in Web-based applications. These vulnerabilities
	can lead to unauthorized data access by malicious users, loss of
	sensitive data, and application crashes. In this paper we propose
	a static analysis framework that detects all these and other vulnerabilities
	in Java applications. The user describes the vulnerabilities they
	wish to find in an intuitive specification language. This language
	makes the vulnerabilities above as well as new, yet undiscovered
	vulnerability patterns easy to describe. User-provided specifications
	are automatically translated into a sound and precise static analysis.
	Analysis results are presented to the user for assessment in a GUI
	auditing interface integrated within Eclipse, a popular Java development
	environment.
	
	
	Our framework unifies vulnerabilities that stem from unchecked user
	input, which is widely recognized as the most common source of vulnerabilities
	in Web applications. We describe a static approach based on a sound
	context-sensitive inclusion-based points-to analysis implemented
	using binary decision diagrams, or BDDs. This analysis is precise,
	sound, and scalable, a combination that can solve problems impossible
	with other static techniques: we find all potential vulnerabilities
	in large real-life applications with a low false positive rate.
	
	
	The static analysis approach described in this paper allows us to
	find 29 security vulnerabilities in 9 large, widely used open-source
	applications, including two vulnerabilities in widely used Java libraries.
	In fact, all but one applications in our benchmark suite have at
	least one vulnerability. Our analysis technique achieves high precision
	and only one of our benchmark applications generates false positives.},
  file = {livshits_webappsec_tr.pdf:livshits_webappsec_tr.pdf:PDF},
  review = {see also conference paper livshits2005a}
}

@INPROCEEDINGS{livshits2005a,
  author = {V. Benjamin Livshits and Monica S. Lam},
  title = {Finding Security Errors in {J}ava Programs with Static Analysis},
  booktitle = {Proceedings of the 14th Usenix Security Symposium},
  year = {2005},
  pages = {271--286},
  month = aug,
  abstract = {A number of recently discovered security vulnerabilities such as SQL
	injections, cross-site scripting, and HTTP splitting attacks are
	caused by programming errors in Web-based applications. These vulnerabilities
	can lead to unauthorized data access by malicious users, loss of
	sensitive data, and application crashes. In this paper we propose
	a static analysis framework that detects all these and other vulnerabilities
	in Java applications. The user describes the vulnerabilities they
	wish to find in an intuitive specification language. This language
	makes the vulnerabilities above as well as new, yet undiscovered
	vulnerability patterns easy to describe. User-provided specifications
	are automatically translated into a sound and precise static analysis.
	Analysis results are presented to the user for assessment in a GUI
	auditing interface integrated within Eclipse, a popular Java development
	environment.
	
	
	Our framework unifies vulnerabilities that stem from unchecked user
	input, which is widely recognized as the most common source of vulnerabilities
	in Web applications. We describe a static approach based on a sound
	context-sensitive inclusion-based points-to analysis implemented
	using binary decision diagrams, or BDDs. This analysis is precise,
	sound, and scalable, a combination that can solve problems impossible
	with other static techniques: we find all potential vulnerabilities
	in large real-life applications with a low false positive rate.
	
	
	The static analysis approach described in this paper allows us to
	find 29 security vulnerabilities in 9 large, widely used open-source
	applications, including two vulnerabilities in widely used Java libraries.
	In fact, all but one applications in our benchmark suite have at
	least one vulnerability. Our analysis technique achieves high precision
	and only one of our benchmark applications generates false positives.},
  file = {usenixsec05.pdf:usenixsec05.pdf:PDF},
  review = {see also techreport livshits2005.}
}

@INPROCEEDINGS{lochert2007,
  author = {Lochert, Christian and Scheuermann, Bj\"{o}rn and Mauve, Martin},
  title = {Probabilistic aggregation for data dissemination in {VANETs}},
  booktitle = {{VANET} '07: Proceedings of the fourth ACM international workshop
	on Vehicular ad hoc networks},
  year = {2007},
  pages = {1--8},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1287748.1287750},
  file = {lochert2007.pdf:lochert2007.pdf:PDF},
  isbn = {978-1-59593-739-1},
  location = {Montreal, Quebec, Canada},
  owner = {kristjan}
}

@INPROCEEDINGS{luk2007,
  author = {Mark Luk and Ghita Mezzour and Adrian Perrig and Virgil Gligor},
  title = {{MiniSec}: A Secure Sensor Network Communication Architecture},
  booktitle = {{IPSN} -- Sixth International Conference on Information Processing
	in Sensor Networks},
  year = {2007},
  abstract = {Secure sensor network communication protocols need to provide three
	basic properties: data secrecy, authentication, and replay protection.
	Secure sensor network link layer protocols such as TinySec [10] and
	ZigBee [24] enjoy signiﬁcant attention in the community. However,
	TinySec achieves low energy consumption by reducing the level of
	security provided. In contrast, ZigBee enjoys high security, but
	suffers from high energy consumption. MiniSec is a secure network
	layer that obtains the best of both worlds: low energy consumption
	and high security. MiniSec has two operating modes, one tailored
	for single-source communication, and another tailored for multi-source
	broadcast communication. The latter does not require per-sender state
	for replay protection and thus scales to large networks. We present
	a publicly available implementation of MiniSec for the Telos platform,
	and experimental results demonstrate our low energy utilization.},
  file = {luk2007.pdf:luk2007.pdf:PDF},
  keywords = {sensor network, security},
  owner = {kristjan},
  timestamp = {2010.05.01}
}

@ARTICLE{lunt1989,
  author = {Lunt, T.F.},
  title = {Real-time intrusion detection},
  journal = {COMPCON Spring '89. Thirty-Fourth IEEE Computer Society International
	Conference: Intellectual Leverage, Digest of Papers.},
  year = {1989},
  pages = {348-353},
  month = {27 February -- 3 March},
  abstract = {This paper describes a real-time intrusion-detection expert system
	(IDES) that observes user behavior on a monitored computer system
	and adaptively learns what is normal for individual users, groups,
	remote hosts, and the overall system behavior. Observed behavior
	is flagged as a potential intrusion if it deviates significantly
	from the expected behavior or if it triggers a rule in the expert-system
	rule base.},
  doi = {10.1109/CMPCON.1989.301954},
  file = {00301954.pdf:00301954.pdf:PDF},
  keywords = {expert systems, real-time systems, safety systems, security of dataIDES,
	adaptive learning, anomalous behavior, expected behavior, groups,
	individual users, monitored computer system, normal, overall system
	behavior, real-time intrusion-detection expert system, remote hosts,
	rule base, statistical user profile, user behaviour observations}
}

@INPROCEEDINGS{luo2002,
  author = {Haiyun Luo and Petros Zerfos and Jiejun Kong and Songwu Lu and Lixia
	Zhang},
  title = {Self-Securing Ad Hoc Wireless Networks},
  booktitle = {ISCC '02: Proceedings of the Seventh International Symposium on Computers
	and Communications (ISCC'02)},
  year = {2002},
  pages = {567},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Mobile ad hoc networking offers convenient infrastructureless communication
	over the shared wireless channel. However, the nature of ad hoc networks
	makes them vulnerable to security attacks. Examples of such attacks
	include passive eavesdropping over the wireless channel, denial of
	service attacks by malicious nodes and attacks from compromised nodes
	or stolen devices. Unlike their wired counterpart, infrastructureless
	ad hoc networks do not have a clear line of defense, and every node
	must be prepared for encounters with an adversary. Therefore, a centralized
	or hierarchical network security solution does not work well. This
	work provides scalable, distributed authentication services in ad
	hoc networks. Our design takes a self-securing approach, in which
	multiple nodes (say, k) collaboratively provide authentication services
	for other nodes in the network. We ﬁrst formalize a localized trust
	model that lays the foundation for the design. We further propose
	reﬁned localized certiﬁcation services based on our previous work,
	and develop a new scalable share update to resist more powerful adversaries.
	Finally, we evaluate the solution through simulation and implementation.},
  file = {luo2002.pdf:luo2002.pdf:PDF},
  isbn = {0-7695-1671-8}
}

@BOOK{lynch1996,
  title = {Distributed Algorithms},
  publisher = {Morgan Kaufmann},
  year = {1996},
  author = {Nancy A. Lynch},
  owner = {kristjan},
  timestamp = {2009.08.20}
}

@INPROCEEDINGS{madden2002,
  author = {S. Madden and M.J. Franklin and J.M. Hellerstein and W. Hong},
  title = {{TAG}: A {Tiny AGgregation} service for ad-hoc sensor networks},
  booktitle = {{5th Symposium on Operating Systems Design and Implementation}},
  year = {2002},
  pages = {131-146},
  abstract = {We present the Tiny AGgregation (TAG) service for aggregation in low-power,
	distributed, wireless environments. TAG allows users to express simple,
	declarative queries and have them distributed and executed efﬁciently
	in networks of low-power, wireless sensors. We discuss various generic
	properties of aggregates, and show how those properties affect the
	performance of our in network approach. We include a performance
	study demonstrating the advantages of our approach over traditional
	centralized, out-of-network methods, and discuss a variety of optimizations
	for improving the performance and faulttolerance of the basic solution.},
  file = {tag-osdi02.pdf:tag-osdi02.pdf:PDF},
  keywords = {sensor network, in-network aggregation},
  owner = {kristjan},
  review = {A tree-based sensor network using in-network aggregation for efficiency.
	Also present an alternative version running over a DAG which sends
	a proportion of the share on each leg (to avoid double counting).},
  timestamp = {2008.03.27}
}

@INPROCEEDINGS{madden2002a,
  author = {Samuel Madden and Michael J. Franklin and Joseph M. Hellerstein and
	Wei Hong},
  title = {The Design of an Acquisitional Query Processor for Sensor Networks},
  booktitle = {In ACM SIGMOD},
  year = {2002},
  pages = {491--502},
  publisher = {ACM Press},
  abstract = {We discuss the design of an acquisitional query processor for data
	collection in sensor networks. Acquisitional issues are those that
	pertain to where, when, and how often data is physically acquired
	(sampled) and delivered to query processing operators. By focusing
	on the locations and costs of acquiring data, we are able to significantly
	reduce power consumption over traditional passive systems that assume
	the a priori existence of data. We discuss simple extensions to SQL
	for controlling data acquisition, and show how acquisitional issues
	influence query optimization, dissemination, and execution. We evaluate
	these issues in the context of TinyDB, a distributed query processor
	for smart sensor devices, and show how acquisitional techniques can
	provide significant reductions in power consumption on our sensor
	devices.},
  file = {madden2002a.pdf:madden2002a.pdf:PDF}
}

@INPROCEEDINGS{madden2002b,
  author = {Samuel Madden and Robert Szewczyk and Michael J. Franklin and David
	Culler},
  title = {Supporting Aggregate Queries over Ad-Hoc Wireless Sensor Networks},
  booktitle = {Mobile Computing and Systems Applications Workshop},
  year = {2002},
  pages = {49--58},
  abstract = {We show how the database community's notion of a generic query interface
	for data aggregation can be applied to ad-hoc networks of sensor
	devices. As has been noted in the sensor network literature, aggregation
	is important as a data-reduction tool; networking approaches, however,
	have focused on application specific solutions, whereas our innetwork
	aggregation approach is driven by a general purpose, SQL-style interface
	that can execute queries over any type of sensor data while providing
	opportunities for significant optimization. We present a variety
	of techniques to improve the reliability and performance of our solution.
	We also show how grouped aggregates can be efficiently computed and
	offer a comparison to related systems and database projects.},
  file = {madden2002b.pdf:madden2002b.pdf:PDF}
}

@INPROCEEDINGS{mah-1997,
  author = {Bruce A. Mah},
  title = {An Empirical Model of HTTP Network Traffic},
  booktitle = {INFOCOM '97: Proceedings of the INFOCOM '97. Sixteenth Annual Joint
	Conference of the IEEE Computer and Communications Societies. Driving
	the Information Revolution},
  year = {1997},
  pages = {592},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {The workload of the global Internet is dominated by the Hypertext
	Transfer Protocol (HTTP), an application protocol used by World Wide
	Web clients and servers. Simulation studies of IP networks will require
	a model of the traffic patterns of the World Wide Web, in order to
	investigate the effects of this increasingly popular application.
	We have developed an empirical model of network traffic produced
	by HTTP. Instead of relying on server or client logs, our approach
	is based on packet traces of HTTP conversations. Through traffic
	analysis, we have determined statistics and distributions for higher-level
	quantities such as the size of HTTP files, the number of files per
	"Web page", and user browsing behavior. These quantities form a model
	can then be used by simulations to mimic World Wide Web network applications.},
  file = {:mah-infocom.pdf:PDF},
  isbn = {0-8186-7780-5}
}

@INPROCEEDINGS{maheshwari2000,
  author = {Maheshwari, Umesh and Vingralek, Radek and Shapiro, William},
  title = {How to build a trusted database system on untrusted storage},
  booktitle = {{OSDI}'00: Proceedings of the 4th conference on Symposium on Operating
	System Design \& Implementation},
  year = {2000},
  pages = {10--10},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {Some emerging applications require programs to maintain sensitive
	state on untrusted hosts. This paper presents the architecture and
	implementation of a trusted database system, TDB, which leverages
	a small amount of trusted storage to protect a scalable amount of
	untrusted storage. The database is encrypted and validated against
	a collision-resistant hash kept in trusted storage, so untrusted
	programs cannot read the database or modify it undetectably. TDB
	integrates encryption and hashing with a low-level data model, which
	protects data and metadata uniformly, unlike systems built on top
	of a conventional database system. The implementation exploits synergies
	between hashing and log-structured storage. Preliminary performance
	results show that TDB outperforms an off-the-shelf embedded database
	system, thus supporting the suitability of the TDB architecture.},
  file = {maheshwari2000.pdf:maheshwari2000.pdf:PDF},
  location = {San Diego, California}
}

@INPROCEEDINGS{mahimkar2004,
  author = {Mahimkar, A. and Rappaport, T.S.},
  title = {{SecureDAV}: a secure data aggregation and verification protocol
	for sensor networks},
  booktitle = {IEEE Global Telecommunications Conference, {GLOBECOM'04}},
  year = {2004},
  volume = {4},
  pages = { 2175-2179 Vol.4},
  month = {Nov.-3 Dec.},
  abstract = {Sensor networks include nodes with limited computation and communication
	capabilities. One of the basic functions of sensor networks is to
	sense and transmit data to the end users. The resource constraints
	and security issues pose a challenge to information aggregation in
	large sensor networks. Bootstrapping keys is another challenge because
	public key cryptosystems are unsuitable for use in resource-constrained
	sensor networks. In this paper, we propose a solution by dividing
	the problem in two domains. First, we present a protocol for establishing
	cluster keys in sensor networks using verifiable secret sharing.
	We chose elliptic curve cryptosystems for security because of their
	smaller key size, faster computations and reductions in processing
	power. Second, we develop a secure data aggregation and verification
	(SecureDAV) protocol that ensures that the base station never accepts
	faulty aggregate readings. An integrity check of the readings is
	done using Merkle hash trees, avoiding over-reliance on the cluster-heads.},
  doi = {10.1109/GLOCOM.2004.1378395},
  file = {mahimkar2004.pdf:mahimkar2004.pdf:PDF},
  keywords = {cryptography, protocols, telecommunication security, wireless sensor
	networks Merkle hash trees, SecureDAV protocol, base station aggregate
	reading reception, cluster keys, cluster-heads, data verification
	protocol, elliptic curve cryptosystems, key establishment protocol,
	key size, reading integrity checking, resource constraints, secure
	data aggregation, verifiable secret sharing, wireless sensor networks},
  review = {CHECK: File under integrity, confidentiality or both?
	
	
	Two contributions: 1) A Key establishment protocol using verifiable
	secret sharing and 2) a clustering based aggregation framework tolerating
	a threshold t compromised sensors within each cluster.
	
	Goal: ensure that the base station accepts readings with high reliability,
	despite compromized clusterheads. The attacker model is very vaque
	-- in one place they say that the goal is to protect against compromized
	clusterheads, while in another they talk about faulty sensors.
	
	
	The key estabishment protocol is ECC based and uses verifiable secret
	sharing. Perhaps interesting -- leave for later. Generates a secret
	key for each cluster -- each sensor has a partial share of the cluster
	key. The partal cluster key is used to sign individual contributions
	-- the clusterhead assembles the final signature and sends to the
	base station. A threshold t of sensors needed to assemble a valid
	signature.
	
	
	Aggregation protocol:
	
	The clusterhead aggregates the sensor readings and computes the average.
	The average is broadcastto all members within the cluster. Each sensor
	compares its local value with the broadcast average and signs the
	aggregate if the difference is less than a threshold. A partial cluster
	key is used for the signing, ensuring that at least t sensors have
	to participate in the validation. The clusterhead assembles the signatures
	received into a final signature which is sent along with the average
	to the base station. The base station (and all members of the cluster)
	hold the public key corresponding to the secret cluster key and can
	hence verify the result.
	
	Sensors transmit encrypted values along with commitment hashes to
	the cluster head. The clusterhead constructs a Merkle tree. The base
	station can query clusterheads to verify integrity of individual
	readings. This ensures integrity of the clusterhead (aggregator),
	but imposes considerable overhead (this is more or less ignored in
	the paper)
	
	
	Problems: Supports only the average function and hinges on a theshold
	in variance of results -- strong domain assumptions. How about natural
	outliers?
	
	
	Attacker model a bit unclear.}
}

@INPROCEEDINGS{maier2008,
  author = {Gregor Maier and Robin Sommer and Holger Dreger and Anja Feldmann
	and Vern Paxson and Fabian Schneider},
  title = {Enriching network security analysis with time travel},
  booktitle = {{SIGCOMM '08: Proceedings of the ACM SIGCOMM 2008 conference on Data
	communication}},
  year = {2008},
  pages = {183--194},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In many situations it can be enormously helpful to archive the raw
	contents of a network trafﬁc stream to disk, to enable later inspection
	of activity that becomes interesting only in retrospect. We present
	a Time Machine (TM) for network trafﬁc that provides such a capability.
	The TM leverages the heavy-tailed nature of network ﬂows to capture
	nearly all of the likely-interesting trafﬁc while storing only a
	small fraction of the total volume. An initial
	
	proof-of-principle prototype established the forensic value of such
	an approach, contributing to the investigation of numerous attacks
	at a site with thousands of users. Based on these experiences, a
	rearchitected implementation of the system provides ﬂexible, high-performance
	trafﬁc stream capture, indexing and retrieval, including an interface
	between the TM and a real-time network intrusion detection system
	(NIDS). The NIDS controls the TM by dynamically adjusting recording
	parameters, instructing it to permanently store suspicious activity
	for ofﬂine forensics, and fetching trafﬁc from the past for retrospective
	analysis. We present a detailed performance evaluation of both stand-alone
	and joint setups, and report on experiences with running the system
	live in high-volume environments.},
  doi = {http://doi.acm.org/10.1145/1402958.1402980},
  file = {:p183-maier.pdf:PDF},
  isbn = {978-1-60558-175-0},
  location = {Seattle, WA, USA}
}

@INPROCEEDINGS{mainwaring2002,
  author = {Mainwaring, Alan and Culler, David and Polastre, Joseph and Szewczyk,
	Robert and Anderson, John},
  title = {Wireless sensor networks for habitat monitoring},
  booktitle = {{WSNA} '02: Proceedings of the 1st ACM international workshop on
	Wireless sensor networks and applications},
  year = {2002},
  pages = {88--97},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We provide an in-depth study of applying wireless sensor networks
	to real-world habitat monitoring. A set of system design requirements
	are developed that cover the hardware design of the nodes, the design
	of the sensor network, and the capabilities for remote data access
	and management. A system architecture is proposed to address these
	requirements for habitat monitoring in general, and an instance of
	the architecture for monitoring seabird nesting environment and behavior
	is presented. The currently deployed network consists of 32 nodes
	on a small island off the coast of Maine streaming useful live data
	onto the web. The application-driven design exercise serves to identify
	important areas of further work in data sampling, communications,
	network retasking, and health monitoring.},
  doi = {http://doi.acm.org/10.1145/570738.570751},
  file = {mainwaring2002.pdf:mainwaring2002.pdf:PDF},
  isbn = {1-58113-589-0},
  keywords = {wireless sensor networks, applications},
  location = {Atlanta, Georgia, USA}
}

@TECHREPORT{malan2004,
  author = {David Malan and David Malan},
  title = {Crypto for Tiny Objects},
  institution = {Harvard University},
  year = {2004},
  __markedentry = {[kristjan]},
  abstract = {This work presents the first known implementation of elliptic curve
	cryptography for sensor networks, motivated by those networks' need
	for an e#cient, secure mechanism for shared cryptographic keys' distribution
	and redistribution among nodes. Through instrumentation of UC Berkeley's
	TinyOS, this work demonstrates that secret-key cryptography is already
	viable on the MICA2 mote. Through analyses of another's implementation
	of modular exponentiation and of its own implementation of elliptic
	curves, this work concludes that public-key infrastructure may also
	be tractable in 4 kilobytes of primary memory on this 8-bit, 7.3828-MHz
	device.},
  file = {malan2004.pdf:malan2004.pdf:PDF},
  keywords = {sensor networks, cryptographic algorithms implementations}
}

@ARTICLE{malan2008,
  author = {Malan, David J. and Welsh, Matt and Smith, Michael D.},
  title = {Implementing public-key infrastructure for sensor networks},
  journal = {{ACM} Trans. Sen. Netw.},
  year = {2008},
  volume = {4},
  pages = {1--23},
  number = {4},
  __markedentry = {[kristjan]},
  abstract = {We present a critical evaluation of the first known implementation
	of elliptic curve cryptography over F2p for sensor networks based
	on the 8-bit, 7.3828-MHz MICA2 mote. We offer, along the way, a primer
	for those interested in the field of cryptography for sensor networks.
	We discuss, in particular, the decisions underlying our design and
	alternatives thereto. And we elaborate on the methodologies underlying
	our evaluation.
	
	
	Through instrumentation of UC Berkeley's TinySec module, we argue
	that, although symmetric cryptography has been tractable in this
	domain for some time, there has remained a need, unfulfilled until
	recently, for an efficient, secure mechanism for distribution of
	secret keys among nodes. Although public-key infrastructure has been
	thought impractical, we show, through analysis of our original implementation
	for TinyOS of point multiplication on elliptic curves, that public-key
	infrastructure is indeed viable for TinySec keys' distribution, even
	on the MICA2. We demonstrate that public keys can be generated within
	34 seconds and that shared secrets can be distributed among nodes
	in a sensor network within the same time, using just over 1 kilobyte
	of SRAM and 34 kilobytes of ROM. We demonstrate that communication
	costs are minimal, with only 2 packets required for transmission
	of a public key among nodes. We make available all of our source
	code for other researchers to download and use. And we discuss recent
	results based on our work that corroborate and improve upon our conclusions.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1387663.1387668},
  file = {malan2008.pdf:malan2008.pdf:PDF},
  issn = {1550-4859},
  keywords = {sensor networks, cryptographic algorithms implementations, public
	key infrastructure},
  publisher = {ACM}
}

@ARTICLE{malioutov2006,
  author = {Dmitry M. Malioutov and Jason K. Johnson and Alan S. Willsky},
  title = {Walk-Sums and Belief Propagation in Gaussian Graphical Models},
  journal = {J. Mach. Learn. Res.},
  year = {2006},
  volume = {7},
  pages = {2031--2064},
  abstract = {We present a new framework based on walks in a graph for analysis
	and inference in Gaussian graphical models. The key idea is to decompose
	the correlation between each pair of variables as a sum over all
	walks between those variables in the graph. The weight of each walk
	is given by a product of edgewise partial correlation coefficients.
	This representation holds for a large class of Gaussian graphical
	models which we call walk-summable. We give a precise characterization
	of this class of models, and relate it to other classes including
	diagonally dominant, attractive, non-frustrated, and pairwise-normalizable.
	We provide a walk-sum interpretation of Gaussian belief propagation
	in trees and of the approximate method of loopy belief propagation
	in graphs with cycles. The walk-sum perspective leads to a better
	understanding of Gaussian belief propagation and to stronger results
	for its convergence in loopy graphs.},
  address = {Cambridge, MA, USA},
  file = {malioutov2006.pdf:malioutov2006.pdf:PDF},
  issn = {1533-7928},
  publisher = {MIT Press}
}

@INPROCEEDINGS{malkhi1999,
  author = {Malkhi, Dahlia and Mansour, Yishay and Reiter, Michael K.},
  title = {On Diffusing Updates in a Byzantine Environment},
  booktitle = {{SRDS} '99: Proceedings of the 18th {IEEE} Symposium on Reliable
	Distributed Systems},
  year = {1999},
  pages = {134},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {We study how to efficiently diffuse updates to a large distributed
	system of data replicas, some of which may exhibit arbitrary (Byzantine)
	failures. We assume that strictly fewer than t replicas fail, and
	that each update is initially received by at least t correct replicas.
	The goal is to diffuse each update to all correct replicas while
	ensuring that correct replicas accept no updates generated spuriously
	by faulty replicas. To achieve reliable diffusion, each correct replica
	accepts an update only after receiving it from at least t others.We
	provide the first analysis of epidemic-style protocols for such environments.
	This analysis is fundamentally different from known analyses for
	the benign case due to our treatment of fully Byzantine failures-which,
	among other things, precludes the use of digital signatures for authenticating
	forwarded updates. We propose two epidemic-style diffusion algorithms
	and two measures that characterize the efficiency of diffusion algorithms
	in general. We characterize both of our algorithms according to these
	measures, and also prove lower bounds with regards to these measures
	that show that our algorithms are close to optimal.},
  file = {malkhi1999.pdf:malkhi1999.pdf:PDF},
  isbn = {0-7695-0290-3},
  keywords = {byzantine faults, gossip networks},
  review = {See ref by alvisi2007
	
	The paper that initiated byzantine gossip research}
}

@INPROCEEDINGS{malkhi2001,
  author = {Malkhi, Dahlia and Pavlov, Elan and Sella, Yaron},
  title = {Optimal Unconditional Information Diffusion},
  booktitle = {{DISC} '01: Proceedings of the 15th International Conference on Distributed
	Computing},
  year = {2001},
  pages = {63--77},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {We present an algorithm for propagating updates with information theoretic
	security that propagates an update in time logarithmic in the number
	of replicas and linear in the number of corrupt replicas. We prove
	a matching lower bound for this problem.},
  file = {malkhi2001.pdf:malkhi2001.pdf:PDF},
  isbn = {3-540-42605-1},
  review = {Ref'd by alvisi2007. Annotated propagation paths onto updates}
}

@ARTICLE{malkhi1998,
  author = {Dahlia Malkhi and Michael Reiter},
  title = {Byzantine Quorum System},
  journal = {{Distributed Computing}},
  year = {1998},
  volume = {11},
  pages = {569--578},
  abstract = {this paper we consider the arbitrary (Byzantine) failure of data repositories
	and present the first study of quorum system requirements and constructions
	that ensure data availability and consistency despite these failures.
	We also consider the load associated with our quorum systems, i.e.,
	the minimal access probability of the busiest server. For services
	subject to arbitrary failures, we demonstrate quorum systems over
	n servers with a load of O( ), thus meeting the lower bound on load
	for benignly fault-tolerant quorum systems. We explore several variations
	of our quorum systems and extend our constructions to cope with arbitrary
	client failures},
  file = {malkhi1998.pdf:malkhi1998.pdf:PDF},
  keywords = {byzantine fault tolerance, quorum systems}
}

@INPROCEEDINGS{malkhi1997,
  author = {Malkhi, Dahlia and Reiter, Michael},
  title = {Unreliable Intrusion Detection in Distributed Computations},
  booktitle = {{CSFW '97: Proceedings of the 10th IEEE workshop on Computer Security
	Foundations}},
  year = {1997},
  pages = {116},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Distributed coordination is difficult, especially when the system
	may suffer intrusions that corrupt some component processes. In this
	paper we introduce the abstraction of a _failure detector_ that a
	process can use to (imperfectly) detect the corruption (Byzantine
	failure) of another process. In general, our failure detectors can
	be unreliable, both by reporting a correct process to be faulty or
	by reporting a faulty process to be correct. However, we show that
	if these detectors satisfy certain plausible properties, then the
	well-known distributed consensus problem can be solved. We also present
	a randomized protocol using failure detectors that solves the consensus
	problem if either the requisite properties of failure detectors hold
	or if certain highly probable events eventually occur. This work
	can be viewed as a generalization of benign failure detectors popular
	in the distributed computing literature.},
  file = {malkhi1997.pdf:malkhi1997.pdf:PDF},
  isbn = {0-8186-7990-5}
}

@ARTICLE{manganaris2000,
  author = {Stefanos Manganaris and Marvin Christensen and Dan Zerkle and Keith
	Hermiz},
  title = {A data mining analysis of {RTID} alarms},
  journal = {{Comput. Networks}},
  year = {2000},
  volume = {34},
  pages = {571--577},
  number = {4},
  abstract = {IBM's emergency response service provides real-time intrusion detection
	(RTID) services through the Internet for a variety of clients. As
	the number of clients increases, the volume of alerts generated by
	the RTID sensors becomes intractable. This problem is aggravated
	by the fact that some sensors may generate hundreds or even thousands
	of innocent alerts per day. With an eye towards managing these alerts
	more eectively, IBM's data mining services group analyzed a database
	of RTID reports. The ®rst objective was an approach for characterizing
	the ``normal'' stream of alerts from a sensor. Using such models
	tuned to individual sensors, we then developed a methodology for
	detecting anomalies. In contrast to many popular approaches, the
	decision to ®lter an alarm out or not takes into consideration the
	context in which it occurred and the historical behavior of the sensor
	it came from. Our second objective was to identify all the dierent
	pro®les of our clients. Based on their history of alerts, we discovered
	several dierent types of clients, with dierent alert behaviors
	and thus dierent monitoring needs. We present the issues encountered,
	solutions, and ®ndings, and discuss how our results may be used in
	large-scale RTID operations.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S1389-1286(00)00138-9},
  file = {sdarticle.pdf:sdarticle.pdf:PDF},
  issn = {1389-1286},
  publisher = {Elsevier North-Holland, Inc.},
  url = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6VRG-411FRK9-3&_user=5915045&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000068843&_version=1&_urlVersion=0&_userid=5915045&md5=a3e0d0a5ffe58fa38cebf64ee5f9bbdd}
}

@INPROCEEDINGS{maniatis2003,
  author = {Petros Maniatis and David S. H. Rosenthal and Mema Roussopoulos and
	Mary Baker and Yanto Muliadi},
  title = {Preserving Peer Replicas by Rate-Limited Sampled Voting in {LOCKSS}},
  booktitle = {{SOSP}},
  year = {2003},
  pages = {44--59},
  publisher = {ACM Press},
  abstract = {The LOCKSS project has developed and deployed in a world-wide test
	a peer-to-peer system for preserving access to journals and other
	archival information published on the Web. It consists of a large
	number of independent, low-cost, persistent web caches that cooperate
	to detect and repair damage to their content by voting in “opinion
	polls.” Based on this experience, we present a design for and simulations
	of a novel protocol for voting in systems of this kind. It incorporates
	rate limitation and intrusion detection to ensure that even some
	very powerful adversaries attacking over many years have only a small
	probability of causing irrecoverable damage before being detected.},
  file = {10.1.1.10.600.pdf:10.1.1.10.600.pdf:PDF},
  keywords = {reputation systems}
}

@ARTICLE{maniatis2005,
  author = {Petros Maniatis and Mema Roussopoulos and T. J. Giuli and David S.
	H. Rosenthal and Mary Baker},
  title = {The {LOCKSS} peer-to-peer digital preservation system},
  journal = {{ACM Trans. Comput. Syst.}},
  year = {2005},
  volume = {23},
  pages = {2--50},
  number = {1},
  abstract = {The LOCKSS project has developed and deployed in a world-wide test
	a peer-to-peer system for preserving access to journals and other
	archival information published on the Web. It consists of a large
	number of independent, low-cost, persistent Web caches that cooperate
	to detect and repair damage to their content by voting in “opinion
	polls.” Based on this experience, we present a design for and simulations
	of a novel protocol for voting in systems of this kind. It incorporates
	rate limitation and intrusion detection to ensure that even some
	very powerful adversaries attacking over many years have only a small
	probability of causing irrecoverable damage before being detected.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1047915.1047917},
  file = {maniatis2005.pdf:maniatis2005.pdf:PDF},
  issn = {0734-2071},
  keywords = {reputation systems},
  publisher = {ACM}
}

@INPROCEEDINGS{manjhi2005,
  author = {Manjhi, Amit and Nath, Suman and Gibbons, Phillip B.},
  title = {Tributaries and deltas: efficient and robust aggregation in sensor
	network streams},
  booktitle = {{SIGMOD} '05: Proceedings of the 2005 {ACM SIGMOD} international
	conference on Management of data},
  year = {2005},
  pages = {287--298},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {Existing energy-efficient approaches to in-network aggregation in
	sensor networks can be classified into two categories, tree-based
	and multi-path-based, with each having unique strengths and weaknesses.
	In this paper, we introduce Tributary-Delta, a novel approach that
	combines the advantages of the tree and multi-path approaches by
	running them simultaneously in different regions of the network.
	We present schemes for adjusting the regions in response to changes
	in network conditions, and show how many useful aggregates can be
	readily computed within this new framework. We then show how a difficult
	aggregate for this context---finding frequent items---can be efficiently
	computed within the framework. To this end, we devise the first algorithm
	for frequent items (and for quantiles) that provably minimizes the
	worst case total communication for non-regular trees. In addition,
	we give a multi-path algorithm for frequent items that is considerably
	more accurate than previous approaches. These algorithms form the
	basis for our efficient Tributary-Delta frequent items algorithm.
	Through extensive simulation with real-world and synthetic data,
	we show the significant advantages of our techniques. For example,
	in computing Count under realistic loss rates, our techniques reduce
	answer error by up to a factor of 3 compared to any previous technique.},
  doi = {http://doi.acm.org/10.1145/1066157.1066191},
  file = {manjhi2005.pdf:manjhi2005.pdf:PDF},
  isbn = {1-59593-060-4},
  location = {Baltimore, Maryland}
}

@ARTICLE{manulis2009,
  author = {Manulis, Mark and Schwenk, J\"{o}rg},
  title = {Security model and framework for information aggregation in sensor
	networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2009},
  volume = {5},
  pages = {1--28},
  number = {2},
  __markedentry = {[kristjan]},
  abstract = {Information aggregation is an important operation in wireless sensor
	networks (WSNs) executed for the purpose of monitoring and reporting
	environmental data. Due to the performance constraints of sensor
	nodes the in-network form of the aggregation is especially attractive
	since it allows saving expensive resources during frequent network
	queries. Easy accessibility of networks and nodes and almost no physical
	protection against corruptions raise high security challenges. Protection
	against attacks aiming to falsify the aggregated result is considered
	to be of prime importance.
	
	
	In this article we design the first general framework for secure information
	aggregation in WSNs focusing on scenarios where aggregation is performed
	by one of its nodes. The framework achieves security against node
	corruptions and is based solely on the symmetric cryptographic primitives
	that are more suitable for WSNs in terms of efficiency. We analyze
	performance of the framework and unlike many previous approaches
	increase confidence in it by a rigorous proof of security within
	the specially designed formal security model.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1498915.1498919},
  file = {manulis2009.pdf:manulis2009.pdf:PDF},
  issn = {1550-4859},
  publisher = {ACM},
  review = {See also earlier conference paper manulis2007.
	
	
	Consider protection against falsification of in-network aggregates
	-- integrity guarantees. Provable security (claimed) in a single
	aggregator model. Uses only symmetric crypto primitives.}
}

@INPROCEEDINGS{manulis2007,
  author = {Mark Manulis and J\"{o}rg Schwenk},
  title = {Provably Secure Framework for Information Aggregation in Sensor Networks},
  booktitle = {Computational Science and Its Applications – {ICCSA 2007}},
  year = {2007},
  abstract = {Information aggregation is an important operation in wireless sensor
	networks executed for the purpose of monitoring and reporting of
	the environmental data. Due to the performance constraints of sensor
	nodes the in-network form of the aggregation is especially attractive
	since it allows to save expensive resources during the frequent network
	queries. Easy accessibility of networks and nodes and almost no physical
	protection against corruptions arise high challenges on the security
	of the aggregation process. Especially, protection against attacks
	aiming to falsify the aggregated result is considered to be of prime
	importance.
	
	
	In this paper we propose a novel security model for the aggregation
	process based on the well-established cryptographic techniques, focusing
	on the scenario with the single aggregator node. In order to show
	soundness and feasibility of our definitions we describe a generic
	practical approach that achieves security against node corruptions
	during the aggregation process in a provable cryptographic way based
	solely on the symmetric cryptographic primitives. To the best of
	our knowledge this is the first paper which aims to combine the paradigm
	of provable security in the cryptographic sense with the task of
	information aggregation in WSNs.},
  file = {manulis2007.pdf:manulis2007.pdf:PDF},
  owner = {kristjan},
  review = {Consider protection against falsification of in-network aggregates
	-- integrity guarantees. Provable security (claimed) in a single
	aggregator model. Uses only symmetric crypto primitives. See later
	magazine paper manulis2009.},
  timestamp = {2010.01.26}
}

@INCOLLECTION{margolin2008,
  author = {N. Boris Margolin and Brian Neil Levine},
  title = {Quantifying Resistance to the Sybil Attack},
  booktitle = {Financial Cryptography and Data Security},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  volume = {5143/2008},
  series = {Lecture Notes in Computer Science},
  pages = {1-15},
  abstract = {Sybil attacks have been shown to be unpreventable except under the
	protection of a vigilant central authority. We use an economic analysis
	to show quantitatively that some applications and protocols are more
	robust against the attack than others. In our approach, for each
	distributed application and an attacker objective, there is a critical
	value that determines the cost-effectiveness of the attack. A Sybil
	attack is worthwhile only when the critical value is exceeded by
	the ratio of the value of the attacker’s goal to the cost of identities.
	We show that for many applications, successful Sybil attacks may
	be expensive even when the Sybil attack cannot be prevented. Specifically,
	we propose the use of a recurring fee as a deterrent against the
	Sybil attack. As a detailed example, we look at four variations of
	the Sybil attack against a recurring fee based onion routing anonymous
	routing network and quantify its vulnerability.},
  file = {margolin2008.pdf:margolin2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@INCOLLECTION{margolin2008a,
  author = {N. Boris Margolin and Brian N. Levine},
  title = {Informant: Detecting Sybils Using Incentives},
  booktitle = {Financial Cryptography and Data Security},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  volume = {4886/2008},
  pages = {192-207},
  abstract = {We propose an economic approach to Sybil attack detection. In our
	Informant protocol, a detective offers a reward for Sybils to reveal
	themselves. The detective accepts from one identity a security deposit
	and the name of target peer; the deposit and a reward are given to
	the target. We prove the optimal strategy for the informant is to
	play the game if and only if she is Sybil with a low opportunity
	cost, and the target will cooperate if and only if she is identical
	to the informant. Informant uses a Dutch auction to find the minimum
	possible reward that will reveal a Sybil attacker. Because our approach
	is economic, it is not limited to a specific application and does
	not rely on a physical device or token.},
  file = {margolin2008a.pdf:margolin2008a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{proenca2005,
  author = {Mario Lemes {Proenca}, Jr. and Bruno B. Zarpelao and Leonardo S.
	Mendes},
  title = {Anomaly Detection for Network Servers Using Digital Signature of
	Network Segment},
  booktitle = {AICT-SAPIR-ELETE '05: Proceedings of the Advanced Industrial Conference
	on Telecommunications/Service Assurance with Partial and Intermittent
	Resources Conference/E-Learning on Telecommunications Workshop},
  year = {2005},
  pages = {290--295},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Network anomaly detection is essential for rapid fault recovery and
	increasing network reliability. This paper presents results of the
	utilization of digital signature of network segments (DSNS) for network
	servers to characterize the traffic that flow through the network
	servers. Itýs also presented an alarm system model that use the network
	servers` traffic characterization generated by DSNS. The obtained
	results validate the experiment and show in practice significant
	advantages in networks management.},
  doi = {http://dx.doi.org/10.1109/AICT.2005.26},
  file = {proenca2005.pdf:proenca2005.pdf:PDF},
  isbn = {0-7695-2388-9}
}

@ARTICLE{garcia-molina-2006,
  author = {Sergio Marti and Hector Garcia-Molina},
  title = {Taxonomy of trust: categorizing P2P reputation systems},
  journal = {Computer Networks},
  year = {2006},
  volume = {50},
  pages = {472--484},
  number = {4},
  abstract = {The ﬁeld of peer-to-peer reputation systems has exploded in the last
	few years. Our goal is to organize existing ideas and work to facilitate
	system design. We present a taxonomy of reputation system components,
	their properties, and discuss how user behavior and technical constraints
	can conﬂict. In our discussion, we describe research that exempliﬁes
	compromises made to deliver a useable, implementable system.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.comnet.2005.07.011},
  file = {marti_taxonomy_of_trust.pdf:marti_taxonomy_of_trust.pdf:PDF},
  issn = {1389-1286},
  keywords = {Trust, Reputation, Peer-to-peer, Security},
  publisher = {Elsevier North-Holland, Inc.}
}

@INPROCEEDINGS{marti2000,
  author = {Sergio Marti and T. J. Giuli and Kevin Lai and Mary Baker},
  title = {Mitigating routing misbehavior in mobile ad hoc networks},
  booktitle = {MobiCom '00: Proceedings of the 6th annual international conference
	on Mobile computing and networking},
  year = {2000},
  pages = {255--265},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper describes two techniques that improve throughput in an
	ad hoc network in the presence of nodes that agree to forward packets
	but fail to do so. To mitigate this problem, we propose categorizing
	nodes based upon their dynamically measured behavior. We use a watchdog
	that identifies misbehaving nodes and a patl~rater that helps routing
	protocols avoid these nodes. Through simulation we evaluate watchdog
	and pathrater using packet throughput, percentage of overhead (routing)
	transmissions, and the accuracy of misbehaving node detection. When
	used together in a network with moderate mobility, the two techniques
	increase throughput by 17% in the presence of 40% misbehaving nodes,
	while increasing the percentage of overhead transmissions from the
	standard routing protocol's 9% to 17%. During extreme mobility, watchdog
	and pathrater can increase network throughput by 27%, while increasing
	the overhead transmissions from the standard routing protocol's 12%
	to 24%.},
  doi = {http://doi.acm.org/10.1145/345910.345955},
  file = {marti2000.pdf:marti2000.pdf:PDF},
  isbn = {1-58113-197-6},
  keywords = {reputation, ad-hoc network, DSR, dynamic source routing protocol},
  location = {Boston, Massachusetts, United States},
  review = {See in related work of buchegger2003: Watchdog and pathrater components.
	Nodes rely on their own watchdog excusively and do not exchange information
	with others. Trade of robustness against longer detection delay.
	Also mentioned by hu2003.}
}

@TECHREPORT{martin2006,
  author = {Michael Martin and Benjamin Livshits and Monica S. Lam},
  title = {{SecuriFly}: Runtime vulnerability protection for Web applications.},
  institution = {{Stanford University}},
  year = {2006},
  month = {October},
  abstract = {This reports presents a runtime solution to a range of Web application
	security vulnerabilities. The solution we proposes called SecuriFly
	consists of instrumenting the application to precisely track the
	ﬂow of data. When a potential vulnerability is observed, the application
	is either terminated to prevent the vulnerability from being exploited
	or special recovery code is executed and the application is allowed
	to continue on running. We have used SecuriFly to harden and experiment
	with a range of large opensource benchmarks written in Java. Protection
	provided by SecuriFly was suﬃcient to protect against all exploits
	we were able to generate.},
  file = {securifly_tr.pdf:securifly_tr.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.22}
}

@INPROCEEDINGS{martucci2008,
  author = {Leonardo A. Martucci and Markulf Kohlweiss and Christer Andersson
	and Andriy Panchenko},
  title = {Self-certified {Sybil}-free pseudonyms},
  booktitle = {{WiSec} '08: Proceedings of the first {ACM} conference on Wireless
	network security},
  year = {2008},
  pages = {154--159},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Accurate and trusted identiﬁers are a centerpiece for any security
	architecture. Protecting against Sybil attacks in a privacy-friendly
	manner is a non-trivial problem in wireless infrastructureless networks,
	such as mobile ad hoc networks. In this paper, we introduce self-certiﬁed
	Sybil-free pseudonyms as a means to provide privacy-friendly Sybil-freeness
	without requiring continuous online availability of a trusted third
	party. These pseudonyms are self-certiﬁed and computed by the users
	themselves from their cryptographic longterm identities. Contrary
	to identity certiﬁcates, we preserve location privacy and improve
	protection against some notorious attacks on anonymous communication
	systems.},
  doi = {http://doi.acm.org/10.1145/1352533.1352558},
  file = {:p154-martucci.pdf:PDF},
  isbn = {978-1-59593-814-5},
  location = {Alexandria, VA, USA}
}

@INPROCEEDINGS{massey2007,
  author = {Daniel Massey and Lan Wang and Beichuan Zhang and Lixia Zhang},
  title = {A Scalable Routing System Design for Future Internet},
  booktitle = {{IPv6'07}},
  year = {2007},
  address = {Kyoto, Japan},
  month = {August},
  abstract = {Internet routing is at an important crossroad. The current global
	routing table, which is largely based on IPv4 addresses, has been
	growing at an alarming rate over the last few years, despite the
	constraints by the shortage of IPv4 addresses. IPv6 removes the address
	shortage problem, however its deployment may potentially further
	exacerbate the routing scalability challenges facing us today.
	
	
	In this paper, we ﬁrst examine and describe the root causes of the
	routing scalability problem and then discuss a promising direction
	towards an effective solution. The explosive growth of the Internet
	over the last decade made it no longer feasible to perform global
	routing based on all end user IP address preﬁxes. Yet at the same
	time, we must preserve the end-to-end model of the Internet architecture.
	We sketch out a basic approach to an effective solution which is
	to separate globally routable addresses (GRA) from globally deliverable
	addresses (GDA). This separation of address space can simultaneously
	achieve the goals of improved routing scalability, ease of site-multihoming
	without using multiple addresses, and elimination of the need for
	user renumbering when changing providers. An interesting aspect of
	this approach is that it both facilitates the deployment of IPv6
	at edge sites and also does not require immediate changes at large
	IPv4 deployed bases.},
  file = {massey2007.pdf:massey2007.pdf:PDF},
  keywords = {internet scalability, future internet},
  owner = {kristjan},
  review = {See on internet scalability issues.},
  timestamp = {2010.05.05}
}

@ARTICLE{massie2004,
  author = {Matthew L. Massie and Brent N. Chun and David E. Culler},
  title = {The ganglia distributed monitoring system: design, implementation,
	and experience},
  journal = {{Parallel Computing}},
  year = {2004},
  volume = {30},
  pages = {817 - 840},
  number = {7},
  abstract = {Ganglia is a scalable distributed monitoring system for high performance
	computing systems such as clusters and Grids. It is based on a hierarchical
	design targeted at federations of clusters. It relies on a multicast-based
	listen/announce protocol to monitor state within clusters and uses
	a tree of point-to-point connections amongst representative cluster
	nodes to federate clusters and aggregate their state. It leverages
	widely used technologies such as XML for data representation, XDR
	for compact, portable data transport, and RRDtool for data storage
	and visualization. It uses carefully engineered data structures and
	algorithms to achieve very low per-node overheads and high concurrency.
	The implementation is robust, has been ported to an extensive set
	of operating systems and processor architectures, and is currently
	in use on over 500 clusters around the world. This paper presents
	the design, implementation, and evaluation of Ganglia along with
	experience gained through real world deployments on systems of widely
	varying scale, configurations, and target application domains over
	the last two and a half years.},
  doi = {DOI: 10.1016/j.parco.2004.04.001},
  file = {massie2004.pdf:massie2004.pdf:PDF},
  issn = {0167-8191},
  keywords = {Monitoring},
  url = {http://www.sciencedirect.com/science/article/B6V12-4CMHWWX-2/2/b6b44ba67c732867d1c3881c510b2953}
}

@ARTICLE{mathis1997,
  author = {Matthew Mathis and Jeffrey Semke and Jamshid Mahdavi and Teunis Ott},
  title = {The macroscopic behavior of the {TCP} congestion avoidance algorithm},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {1997},
  volume = {27},
  pages = {67--82},
  number = {3},
  abstract = {In this paper, we analyze a performance model for the TCP Congestion
	Avoidance algorithm. The model predicts the bandwidth of a sustained
	TCP connection subjected to light to moderate packet losses, such
	as loss caused by network congestion. It assumes that TCP avoids
	retransmission timeouts and always has sufficient receiver window
	and sender data. The model predicts the Congestion Avoidance performance
	of nearly all TCP implementations under restricted conditions and
	of TCP with Selective Acknowledgements over a much wider range of
	Internet conditions.We verify the model through both simulation and
	live Internet measurements. The simulations test several TCP implementations
	under a range of loss conditions and in environments with both drop-tail
	and RED queuing. The model is also compared to live Internet measurements
	using the TReno diagnostic and real TCP implementations.We also present
	several applications of the model to problems of bandwidth allocation
	in the Internet. We use the model to analyze networks with multiple
	congested gateways; this analysis shows strong agreement with prior
	work in this area. Finally, we present several important implications
	about the behavior of the Internet in the presence of high load from
	diverse user communities.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/263932.264023},
  file = {mathis1997.pdf:mathis1997.pdf:PDF},
  issn = {0146-4833},
  keywords = {networks, network analysis, congestion control, TCP},
  publisher = {ACM}
}

@ARTICLE{maurer2006,
  author = {Ueli Maurer},
  title = {Secure multi-party computation made simple},
  journal = {{Discrete Appl. Math.}},
  year = {2006},
  volume = {154},
  pages = {370--381},
  number = {2},
  abstract = {A simple approach to secure multi-party computation is presented.
	Unlike previous approaches, it is based on essentially no mathematical
	structure (like bivariate polynomials) or sophisticated sub-protocols
	(like zero-knowledge proofs). It naturally yields protocols se-cure
	for mixed (active and passive) corruption and general (as opposed
	to threshold) adversary structures, con rming the previous tight
	bounds in a simpler formulation and with simpler proofs. Due to their
	simplicity, the described protocols are well-suited for didactic
	purposes, which is a main goal of this paper.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.dam.2005.03.020},
  file = {:10.1.1.8.8627.pdf:PDF},
  issn = {0166-218X},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{maymounkov2002,
  author = {Petar Maymounkov and David Mazi\`{e}res},
  title = {Kademlia: A Peer-to-peer Information System Based on the {XOR} Metric},
  booktitle = {1st International Workshop on Peer-to-Peer Systems},
  year = {2002},
  address = {Cambridge, MA},
  abstract = {We describe a peer-to-peer system which has provable consistency and
	performance in a fault-prone environment. Our system routes queries
	and locates nodes using a novel XOR-based metric topology that simpliﬁes
	the algorithm and facilitates our proof. The topology has the property
	that every message exchanged conveys or reinforces useful contact
	information. The system exploits this information to send parallel,
	asynchronous query messages that tolerate node failures without imposing
	timeout delays on users.},
  file = {maymounkov2002.pdf:maymounkov2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.20}
}

@ARTICLE{mccarthy1980,
  author = {John McCarthy},
  title = {Circumscription---A Form of Non-Monotonic Reasoning},
  journal = {Artificial Intelligence},
  year = {1980},
  volume = {13},
  pages = {27--39},
  note = {Reprinted in \cite{McC90}},
  abstract = {Humans and intelligent computer programs must often jump to the conclusion
	that the objects they can determine to have certain properties or
	relations are the only objects that do. Circumscription formalizes
	such conjectural reasoning.},
  file = {mccarthy1980.pdf:mccarthy1980.pdf:PDF}
}

@INCOLLECTION{mccarthy1969,
  author = {John McCarthy and Patrick J. Hayes},
  title = {Some Philosophical Problems from the Standpoint of Artificial Intelligence},
  booktitle = {Machine Intelligence 4},
  publisher = {Edinburgh University Press},
  year = {1969},
  editor = {B. Meltzer and D. Michie},
  pages = {463--502},
  note = {reprinted in McC90},
  abstract = {A computer program capable of acting intelligently in the world must
	have a general representation of the world in terms of which its
	inputs are interpreted. Designing such a program requires commitments
	about what knowledge is and how it is obtained. Thus, some of the
	major traditional problems of philosophy arise in artiﬁcial intelligence.
	
	 More speciﬁcally, we want a computer program that decides what to
	do by inferring in a formal language that a certain strategy will
	achieve its assigned goal. This requires formalizing concepts of
	causality, ability, and knowledge. Such formalisms are also considered
	in philosophical logic.
	
	 The ﬁrst part of the paper begins with a philosophical point of view
	that seems to arise naturally once we take seriously the idea of
	actually making an intelligent machine. We go on to the notions of
	metaphysically and epistemologically adequate representations of
	the world and then to an explanation of can, causes, and knows in
	terms of a representation of the world by a system of interacting
	automata. A proposed resolution of the prob-
	
	lem of freewill in a deterministic universe and of counterfactual
	conditional sentences is presented.
	
	 The second part is mainly concerned with formalisms within which
	it can be proved that a strategy will achieve a goal. Concepts of
	situation, ﬂuent, future operator, action, strategy, result of a
	strategy and knowledge are formalized. A method is given of constructing
	a sentence of ﬁrst order logic which will be true in all models of
	certain axioms if and only if a certain strategy will achieve a certain
	goal.
	
	 The formalism of this paper represents an advance over McCarthy (1963)
	and Green (1969) in that it permits proof of the correctness of strategies
	that contain loops and strategies that involve the acquisition of
	knowledge, and it is also somewhat more concise.
	
	 The third part discusses open problems in extending the formalism
	of Part two (section 3).
	
	 The fourth part is a review of work in philosophical logic in relation
	to problems of artiﬁcial intelligence and a discussion of previous
	eﬀorts to program ‘general intelligence’ from the point of view of
	this paper.},
  file = {mccarthy1969.pdf:mccarthy1969.pdf:PDF}
}

@INPROCEEDINGS{mccarthy1979,
  author = {John {McCarthy}},
  title = {Ascribing mental qualities to machines},
  booktitle = {{Philosophical Perspectives in Artificial Intelligence}},
  year = {1979},
  publisher = {Humanities Press},
  abstract = {Ascribing mental qualities like belief s, intentions and wants to
	a machine is sometimes correct if done conservatively and is sometimes
	necessary to express what is known about its state. We propose some
	new deﬁnitional tools for this: deﬁnitions relative to an approximate
	theory and second order structural deﬁnitions.},
  file = {mccarthy1979.pdf:mccarthy1979.pdf:PDF}
}

@INPROCEEDINGS{mccarthy1979a,
  author = {John {McCarthy}},
  title = {First Order Theories Of Individual Concepts And Propositions},
  booktitle = {{Machine Intelligence}},
  year = {1979},
  pages = {129--147},
  publisher = {Edinburgh University Press},
  abstract = {We discuss ﬁrst order theories in which individual concepts are admitted
	as mathematical objects along with the things that reify them. This
	allows very straightforward formalizations of knowledge, belief,
	wanting, and necessity in ordinary ﬁrst order logic without modal
	operators. Applications are given in philosophy and in artiﬁcial
	intelligence. We do not treat general concepts, and we do not present
	any full axiomatizations but rather show how various facts can be
	expressed.},
  file = {mccarthy1979a.pdf:mccarthy1979a.pdf:PDF}
}

@INPROCEEDINGS{mccune2005,
  author = {Jonathan M. McCune and Elaine Shi and Adrian Perrig and Michael K.
	Reiter},
  title = {Detection of Denial-of-Message Attacks on Sensor Network Broadcasts},
  booktitle = {{IEEE} Symposium on Security and Privacy},
  year = {2005},
  abstract = {So far, sensor network broadcast protocols assume a trustworthy environment.
	However, in safety and mission-critical sensor networks this assumption
	may not be valid and some sensor nodes might be adversarial. In these
	environments, malicious sensor nodes can deprive other nodes from
	receiving a broadcast message. We call this attack a Denial-of-Message
	Attack (DoM). In this paper, we model and analyze this attack, and
	present countermeasures.
	
	
	 We present SIS, a Secure Implicit Sampling scheme that permits a
	broadcasting base station to probabilistically detect the failure
	of nodes to receive its broadcast, even if these failures result
	from an attacker motivated to induce these failures undetectably.
	SIS works by eliciting authenticated acknowledgments from a subset
	of nodes per broadcast, where the subset is unpredictable to the
	attacker and tunable so as to mitigate acknowledgment implosion on
	the base station. We use a game-theoretic approach to evaluate this
	scheme in the face of an optimal attacker that attempts to maximize
	the number of nodes it denies the broadcast while remaining undetected
	by the base station, and show that SIS signiﬁcantly constrains such
	an attacker even in sensor networks exhibiting high intrinsic loss
	rates. We also discuss extensions that permit more targeted detection
	capabilities.},
  file = {mccune2005.pdf:mccune2005.pdf:PDF},
  keywords = {DDoS, denial-of-service attack, distributed systems, sensor networks},
  owner = {kristjan},
  timestamp = {2010.01.15}
}

@INCOLLECTION{mcevoy2007,
  author = {Robert McEvoy and Michael Tunstall and Colin C. Murphy and William
	P. Marnane},
  title = {Differential Power Analysis of {HMAC} Based on {SHA-2}, and Countermeasures},
  booktitle = {Information Security Applications},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {4867/2007},
  series = {Lecture Notes in Computer Science},
  abstract = {The HMAC algorithm is widely used to provide authentication and message
	integrity to digital communications. However, if the HMAC algorithm
	is implemented in embedded hardware, it is vulnerable to side-channel
	attacks. In this paper, we describe a DPA attack strategy for the
	HMAC algorithm, based on the SHA-2 hash function family. Using an
	implementation on a commercial FPGA board, we show that such attacks
	are practical in reality. In addition, we present a masked implementation
	of the algorithm, which is designed to counteract first-order DPA
	attacks.},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{Megiddo2003,
  author = {Nimrod Megiddo and Dharmendra S. Modha and Nimrod Megiddo and D.
	S. Modha},
  title = {ARC: A Self-tuning, Low Overhead Replacement Cache},
  booktitle = {Proc. 2nd USENIX Conference on File and Storage Technologies (FAST
	03), San Franciso, CA},
  year = {2003},
  month = {March 31},
  location = {San Fransisco, CA},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/megiddo03arc.html}
}

@ARTICLE{mehyar2007,
  author = {Mehyar, Mortada and Spanos, Demetri and Pongsajapan, John and Low,
	Steven H. and Murray, Richard M.},
  title = {Asynchronous distributed averaging on communication networks},
  journal = {IEEE/ACM Trans. Netw.},
  year = {2007},
  volume = {15},
  pages = {512--520},
  number = {3},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TNET.2007.893226},
  file = {mehyar2007.pdf:mehyar2007.pdf:PDF},
  issn = {1063-6692},
  keywords = {gossip protocol, crash failure model, robust gossiping},
  publisher = {IEEE Press},
  review = {Ref'd by Wuhib as a robust (crash-failure) gossip protocol}
}

@TECHREPORT{meingast2007,
  author = {Meingast, Marci Lenore and Pai, Sameer and Wicker, Stephen and Sastry,
	S. Shankar},
  title = {Privacy in Camera Networks: a Technical Perspective},
  institution = {{EECS} Department, University of California, Berkeley},
  year = {2007},
  number = {UCB/EECS-2007-94},
  month = {Jul},
  abstract = {The prevalence of camera networks in public places has increased substantially
	over the last ten years. This is in part due to improved vision algorithms
	and the development of simple, less expensive cameras. With this
	increased prevalence, a number of privacy concerns have been raised.
	Particular concern has focused on the level of detailed information
	that image data provides and the real time operation of most camera
	networks. In response to these concerns, policies and best practices
	have been suggested. In this work we look at current deployment policies
	and suggest technical solutions that enhance privacy awareness. We
	propose the use of system design measures, such as validation codes
	and online notices. We also look at different levels of data abstraction
	that can be performed using computer vision techniques, and characterize
	the information these methods provide about the scene, allowing practitioners
	to determine which data must be used for to support the network mission
	as well as the information that can be withheld. We provide experimental
	results on these measures and suggest open areas of research.},
  file = {meingast2007.pdf:meingast2007.pdf:PDF},
  keywords = {security, privacy},
  url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2007/EECS-2007-94.html}
}

@MISC{cryptoeprint:2008:378,
  author = {Carlos Aguilar Melchor and Philippe Gaborit and Javier Herranz},
  title = {Additive Homomorphic Encryption with t-Operand Multiplications},
  howpublished = {Cryptology ePrint Archive, Report 2008/378},
  year = {2008},
  note = {\url{http://eprint.iacr.org/}}
}

@ARTICLE{mendel2009,
  author = {Florian Mendel and Thomas Peyrin and Christian Rechberger and Martin
	Schl\"{a}ffer},
  title = {Improved Cryptanalysis of the Reduced {Gr{\o}stl} Compression Function,
	{ECHO} Permutation and {AES} Block Cipher},
  journal = {Selected Areas in Cryptography},
  year = {2009},
  volume = {5867},
  pages = {16-35},
  file = {mendel2009.pdf:mendel2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.16}
}

@INPROCEEDINGS{mendel2010,
  author = {Florian Mendel and Christian Rechberger and Martin Schl\"{a}ffer
	and S{\o}ren S. Thomsen},
  title = {Rebound Attacks on the Reduced {Gr{\o}stl} Hash Function},
  booktitle = {{CT-RSA}},
  year = {2010},
  file = {mendel2010.pdf:mendel2010.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.02}
}

@MISC{mendel2009a,
  author = {Florian Mendel and Christian Rechberger and Martin Schl\"{a}ffer
	and S{\o}ren S. Thomsen},
  title = {The Rebound Attack: Cryptanalysis of Reduced {Whirlpool} and {Gr{\o}stl}},
  year = {2009},
  file = {mendel2009a.pdf:mendel2009a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.16}
}

@MISC{menezes1995,
  author = {Alfred Menezes},
  title = {Elliptic Curve Cryptosystems},
  howpublished = {{RSA Laboratories CryptoBytes}},
  year = {1995},
  file = {menezes1995.pdf:menezes1995.pdf:PDF},
  owner = {kristjan},
  review = {The easy intro to elliptic curves.},
  timestamp = {2010.05.19}
}

@BOOK{menezes1996,
  title = {Handbook of Applied Cryptography},
  publisher = {CRC Press},
  year = {1996},
  author = {Alfred J. Menezes and Paul C. van Oorschot and Scott A. Vanstone},
  owner = {kristjan},
  timestamp = {2010.09.02}
}

@ARTICLE{merkel2009,
  author = {Dirk Merkel},
  title = {Yubikey One-Time Password Authentication},
  journal = {Linux Journal},
  year = {2009},
  month = {January},
  owner = {kristjan},
  timestamp = {2010.07.07},
  url = {http://www.linuxjournal.com/magazine/yubikey-one-time-password-authentication}
}

@INPROCEEDINGS{merkle1989,
  author = {Merkle, Ralph C.},
  title = {A certified digital signature},
  booktitle = {{CRYPTO} '89: Proceedings on Advances in cryptology},
  year = {1989},
  pages = {218--238},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  file = {merkle1989.pdf:merkle1989.pdf:PDF},
  isbn = {0-387-97317-6},
  keywords = {merkle tree},
  location = {Santa Barbara, California, United States}
}

@INPROCEEDINGS{merkle1980,
  author = {Ralph C. Merkle},
  title = {Protocols for Public Key Cryptosystems},
  booktitle = {{IEEE SOSP}},
  year = {1980},
  abstract = {New Cryptographic protocols which take full advantage of the unique
	properties of public key cryptosystems are now evolving. Several
	protocols for public key distribution and for digital signatures
	are briefly compared with each other and with the conventional alternative.},
  keywords = {merkle tree},
  owner = {kristjan},
  timestamp = {2010.04.15}
}

@PHDTHESIS{merkle1979,
  author = {Merkle, Ralph Charles},
  title = {Secrecy, authentication, and public key systems.},
  school = {Stanford University},
  year = {1979},
  address = {Stanford, CA, USA},
  file = {merkle1979.pdf:merkle1979.pdf:PDF},
  order_no = {AAI8001972},
  publisher = {Stanford University}
}

@ARTICLE{merwe2007,
  author = {Johann Van Der Merwe and Dawoud Dawoud and Stephen McDonald},
  title = {A survey on peer-to-peer key management for mobile ad hoc networks},
  journal = {{ACM Comput. Surv.}},
  year = {2007},
  volume = {39},
  pages = {1},
  number = {1},
  abstract = {The article reviews the most popular peer-to-peer key management protocols
	for mobile ad hoc networks (MANETs). The protocols are subdivided
	into groups based on their design strategy or main characteristic.
	The article discusses and provides comments on the strategy of each
	group separately. The discussions give insight into open research
	problems in the area of pairwise key management.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1216370.1216371},
  file = {:a1-merwe.pdf:PDF},
  issn = {0360-0300},
  publisher = {ACM}
}

@INPROCEEDINGS{michiardi2002,
  author = {Pietro Michiardi and Refik Molva},
  title = {{CORE}: A Collaborative Reputation Mechanism to enforce node cooperation
	in Mobile Ad hoc Networks},
  booktitle = {{CMS}},
  year = {2002},
  abstract = {Countermeasures for node misbehavior and selfishness are mandatory
	requirements in MANET. Selfishness that causes lack of node activity
	cannot be solved by classical security means that aim at verifying
	the correctness and integrity of an operation. We suggest a generic
	mechanism based on reputation to enforce cooperation among the nodes
	of a MANET to prevent selfish behavior. Each network entity keeps
	track of other entities' collaboration using a technique called reputation.
	The reputation is calculated based on various types of information
	on each entity's rate of collaboration. Since there is no incentive
	for a node to maliciously spread negative information about other
	nodes, simple denial of service attacks using the collaboration technique
	itself are prevented. The generic mechanism can be smoothly extended
	to basic network functions with little impact on existing protocols.},
  file = {michiardi2002.pdf:michiardi2002.pdf:PDF},
  keywords = {ad-hoc networks, MANET, reputation},
  owner = {kristjan},
  review = {See review in buchegger2003: use watchdog component.},
  timestamp = {2010.05.16}
}

@ARTICLE{milgram1967,
  author = {Stanley Milgram},
  title = {The small-world problem},
  journal = {Psycology Today},
  year = {1967},
  volume = {1},
  number = {61},
  owner = {kristjan},
  timestamp = {2009.04.20}
}

@INPROCEEDINGS{miller1985,
  author = {Victor S. Miller},
  title = {Use of elliptic curves in cryptography},
  booktitle = {{CRYPTO} Advances in cryptography},
  year = {1985},
  file = {miller1985.pdf:miller1985.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{minami2008,
  author = {Minami, Kazuhiro and Lee, Adam J. and Winslett, Marianne and Borisov,
	Nikita},
  title = {Secure aggregation in a publish-subscribe system},
  booktitle = {{WPES '08}: Proceedings of the 7th {ACM} workshop on Privacy in the
	electronic society},
  year = {2008},
  pages = {95--104},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {A publish-subscribe system is an information dissemination infrastructure
	that supports many-to-many communications among publishers and subscribers.
	In many publish-subscribe systems, in-network aggregation of input
	data is considered to be an important service that reduces the bandwidth
	requirements of the system significantly. In this paper, we present
	a scheme for securing the aggregation of inputs to such a publish-subscribe
	system. Our scheme, which focuses on the additive aggregate function,
	sum, preserves the confidentiality and integrity of aggregated data
	in the presence of untrusted routing nodes. Our scheme allows a group
	of publishers to publish aggregate data to authorized subscribers
	without revealing their individual private inputs to either the routing
	nodes or the subscribers. In addition, our scheme allows subscribers
	to verify that routing nodes perform the aggregation operation correctly.
	We use a message authentication code (MAC) scheme based on the discrete
	logarithm property to allow subscribers to verify the correctness
	of aggregated data without receiving the digitally-signed raw data
	used as input to the aggregation. In addition to describing our secure
	aggregation scheme, we provide formal proofs of its soundness and
	safety.},
  doi = {http://doi.acm.org/10.1145/1456403.1456419},
  file = {minami2008.pdf:minami2008.pdf:PDF},
  isbn = {978-1-60558-289-4},
  location = {Alexandria, Virginia, USA},
  owner = {kristjan},
  review = {cc=0}
}

@ARTICLE{minsky2003,
  author = {Minsky, Yaron M. and Schneider, Fred B.},
  title = {Tolerating malicious gossip},
  journal = {Distrib. Comput.},
  year = {2003},
  volume = {16},
  pages = {49--68},
  number = {1},
  address = {London, UK},
  doi = {http://dx.doi.org/10.1007/s00446-002-0082-4},
  file = {minsky2003.pdf:minsky2003.pdf:PDF},
  issn = {0178-2770},
  keywords = {gossip, byzantine fault tolerance},
  publisher = {Springer-Verlag},
  review = {Ref'd by alvisi2007. Annotated propagation paths onto updates}
}

@INPROCEEDINGS{miranda2009,
  author = {Fernando Miranda and Carlos Sauterre and Jose Orlicki and Ariel Futoransky},
  title = {Simulating Cyber-Attacks for Fun and Profit},
  booktitle = {{SIMUTOOLS'09}},
  year = {2009},
  abstract = {We introduce a new simulation platform called Insight, created to
	design and simulate cyber-attacks against large arbitrary target
	scenarios. Insight has surprisingly low hardware and conﬁguration
	requirements, while making the simulation a realistic experience
	from the attacker’s standpoint. The scenarios include a crowd of
	simulated actors: network devices, hardware devices, software applications,
	protocols, users, etc.
	
	 A novel characteristic of this tool is to simulate vulnerabilities
	(including 0-days) and exploits, allowing an attacker to compromise
	machines and use them as pivoting stones to continue the attack.
	A user can test and modify complex scenarios, with several interconnected
	networks, where the attacker has no initial connectivity with the
	objective of the attack.
	
	 We give a concise description of this new technology, and its possible
	uses in the security research ﬁeld, such as pen-testing training,
	study of the impact of 0-days vulnerabilities, evaluation of security
	countermeasures, and risk assessment tool.},
  file = {miranda2009.pdf:miranda2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@INPROCEEDINGS{mislove2007,
  author = {Alan Mislove and Massimiliano Marcon and Krishna P. Gummadi and Peter
	Druschel and Bobby Bhattacharjee},
  title = {Measurement and analysis of online social networks},
  booktitle = {{IMC '07: Proceedings of the 7th ACM SIGCOMM conference on Internet
	measurement}},
  year = {2007},
  pages = {29--42},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Online social networking sites like Orkut, YouTube, and Flickr are
	among the most popular sites on the Internet. Users of these sites
	form a social network, which provides a powerful means of sharing,
	organizing, and finding content and contacts. The popularity of these
	sites provides an opportunity to study the characteristics of online
	social network graphs at large scale. Understanding these graphs
	is important, both to improve current systems and to design new applications
	of online social networks.
	
	
	This paper presents a large-scale measurement study and analysis of
	the structure of multiple online social networks. We examine data
	gathered from four popular online social networks: Flickr, YouTube,
	LiveJournal, and Orkut. We crawled the publicly accessible user links
	on each site, obtaining a large portion of each social network's
	graph. Our data set contains over 11.3 million users and 328 million
	links. We believe that this is the first study to examine multiple
	online social networks at scale.
	
	
	Our results confirm the power-law, small-world, and scale-free properties
	of online social networks. We observe that the indegree of user nodes
	tends to match the outdegree; that the networks contain a densely
	connected core of high-degree nodes; and that this core links small
	groups of strongly clustered, low-degree nodes at the fringes of
	the network. Finally, we discuss the implications of these structural
	properties for the design of social network based systems.},
  doi = {http://doi.acm.org/10.1145/1298306.1298311},
  file = {mislove2007.pdf:mislove2007.pdf:PDF},
  isbn = {978-1-59593-908-1},
  location = {San Diego, California, USA}
}

@INPROCEEDINGS{mislove2008,
  author = {Mislove, A. and Post, A. and Gummadi, K. and Druschel, P.},
  title = {{Ostra}: Leveraging trust to thwart unwanted communications},
  booktitle = {{USENIX Symp. Networked Systems Design and Implementation (NSDI 2008)}},
  year = {2008},
  pages = {15-30},
  address = {San Francisco, CA},
  month = {April},
  abstract = {Online communication media such as email, instant messaging, bulletin
	boards, voice-over-IP, and social networking sites allow any sender
	to reach potentially millions of users at near zero marginal cost.
	This property enables information to be exchanged freely: anyone
	with Internet access can publish content. Unfortunately, the same
	property opens the door to unwanted communication, marketing, and
	propaganda. Examples include email spam, Web search engine spam,
	inappropriately labeled content on YouTube, and unwanted contact
	invitations in Skype. Unwanted communication wastes one of the most
	valuable resources in the information age: human attention. In this
	paper, we explore the use of trust relationships, such as social
	links, to thwart unwanted communication. Such relationships already
	exist in many application settings today. Our system, Ostra, bounds
	the total amount of unwanted communication a user can produce based
	on the number of trust relationships the user has, and relies on
	the fact that it is difﬁcult for a user to create arbitrarily many
	trust relationships.
	
	 Ostra is applicable to both messaging systems such as email and content-sharing
	systems such as YouTube. It does not rely on automatic classiﬁcation
	of content, does not require global user authentication, respects
	each recipient’s idea of unwanted communication, and permits legitimate
	communication among parties who have not had prior contact. An evaluation
	based on data gathered from an online social networking site shows
	that Ostra effectively thwarts unwanted communication while not impeding
	legitimate communication.},
  file = {mislove2008.pdf:mislove2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@INPROCEEDINGS{mislove2006,
  author = {Alan Mislove and Ansley Post and Andreas Haeberlen and Peter Druschel},
  title = {Experiences in building and operating {ePOST}, a reliable peer-to-peer
	application},
  booktitle = {{EuroSys '06: 1st ACM SIGOPS/EuroSys European Conference on Computer
	Systems}},
  year = {2006},
  pages = {147--159},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Peer-to-peer (p2p) technology can potentially be used to build highly
	reliable applications without a single point of failure. However,
	most of the existing applications, such as ﬁle sharing or web caching,
	have only moderate reliability demands. Without a challenging proving
	ground, it remains unclear whether the full potential of p2p systems
	can be realized.
	
	 To provide such a proving ground, we have designed, deployed and
	operated a p2p-based email system. We chose email because users depend
	on it for their daily work and therefore place high demands on the
	availability and reliability of the service, as well as the durability,
	integrity, authenticity and privacy of their email. Our system, ePOST,
	has been actively used by a small group of participants for over
	two years.
	
	 In this paper, we report the problems and pitfalls we encountered
	in this process. We were able to address some of them by applying
	known principles of system design, while others turned out to be
	novel and fundamental, requiring us to devise new solutions. Our
	ﬁndings can be used to guide the design of future reliable p2p systems
	and provide interesting new directions for future research.},
  doi = {http://doi.acm.org/10.1145/1217935.1217950},
  file = {p147-mislove.pdf:p147-mislove.pdf:PDF},
  isbn = {1-59593-322-0},
  location = {Leuven, Belgium}
}

@INPROCEEDINGS{mistry2009,
  author = {Mistry, Oly and G\"{u}rsel, Anil and Sen, Sandip},
  title = {Comparing trust mechanisms for monitoring aggregator nodes in sensor
	networks},
  booktitle = {{AAMAS} '09: Proceedings of The 8th International Conference on Autonomous
	Agents and Multiagent Systems},
  year = {2009},
  pages = {985--992},
  address = {Richland, SC},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  abstract = {Sensor nodes are often used to collect data from locations inaccessible
	or hazardous for humans. As they are not under normal supervision,
	these nodes are particularly susceptible to physical damage or remote
	tampering. Generally, a hierarchical data collection scheme is used
	by the sensors to report data to the base station. It is difficult
	to precisely identify and eliminate a tampered node in such a data
	collecting hierarchy. Most security schemes for sensor networks focuses
	on developing mechanism for nodes located higher in the hierarchy
	to monitor those located at lower levels. We propose a complementary
	mechanism with which the nodes at lower levels can monitor their
	parents in the hierarchy to detect malicious behavior. Every node
	maintains a reputation value of its parent and updates this at the
	end of every data reporting cycle. We propose a novel combination
	of statistical testing techniques and existing reputation management
	and reinforcement learning schemes to manage the reputation of a
	parent node. The probability that the parent node is malicious is
	calculated using various combination of the Q-learning algorithm
	and the β-Reputation scheme. The input to the β-Reputation scheme
	is a history of boolean events consisting of correct or erroneous
	data reporting events by the parent node. The boolean events are
	generated at each data reporting period using statistical tests.
	Our approach can be viewed as a mechanism composed of different modules
	for the detection of a malicious event, interpretation of the malicious
	event and updating node reputation value based on the interpretation.
	We have created different versions of our system by varying these
	components. We compared the effectiveness of these alternative designs
	in detecting different types of malicious behavior in sensor networks.},
  file = {mistry2009.pdf:mistry2009.pdf:PDF},
  isbn = {978-0-9817381-7-8},
  location = {Budapest, Hungary}
}

@ONLINE{mitre_cve,
  author = {MITRE},
  title = {Common vulnerabilities and exposures},
  url = {http://www.cve.mitre.org/cve/},
  year = {2008},
  owner = {kristjan},
  timestamp = {2008.02.22}
}

@INPROCEEDINGS{miyaguchi1991,
  author = {Miyaguchi, Shoji and Ohta, Kazuo and Iwata, Masahiko},
  title = {Confirmation that some hash functions are not collision free},
  booktitle = {{EUROCRYPT '90}: Proceedings of the workshop on the theory and application
	of cryptographic techniques on Advances in cryptology},
  year = {1991},
  pages = {326--343},
  address = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  file = {miyaguchi1991.pdf:miyaguchi1991.pdf:PDF},
  isbn = {0-387-53587-X},
  location = {Aarhus, Denmark}
}

@MISC{moallemi2007,
  author = {Ciamac C. Moallemi and Benjamin {Van Roy}},
  title = {Convergence of the Min-Sum Algorithm for Convex Optimization},
  year = {2007},
  abstract = {We establish that the min-sum message-passing algorithm and its
	
	asynchronous variants converge for a large class of unconstrained
	con-
	
	vex optimization problems.},
  file = {moallemi2007.pdf:moallemi2007.pdf:PDF},
  url = {http://www.citebase.org/abstract?id=oai:arXiv.org:0705.4253}
}

@ARTICLE{moallemi2006,
  author = {Ciamac C. Moallemi and Benjamin {Van Roy}},
  title = {Consensus propagation},
  journal = {IEEE Transactions on Information Theory},
  year = {2006},
  volume = {52},
  pages = {4753--4766},
  abstract = {We propose consensus propagation, an asynchronous distributed protocol
	for averaging numbers across a network. We establish convergence,
	characterize the convergence rate for regular graphs, and demonstrate
	that the protocol exhibits better scaling properties than pairwise
	averaging, an alternative that has received much recent attention.
	Consensus propagation can be viewed as a special case of belief propagation,
	and our results contribute to the belief propagation literature.
	In particular, beyond singly-connected graphs, there are very few
	classes of relevant problems for which belief propagation is known
	to converge. Index Terms — belief propagation, distributed averaging,
	distributed consensus, distributed signal processing, Gaussian Markov
	random fields, message-passing algorithms, max-product algorithm,
	min-sum algorithm, sum-product algorithm.},
  file = {moallemi2006.pdf:moallemi2006.pdf:PDF}
}

@MISC{modeder_yahoo_xss_2005,
  author = {Jeremy Moeder},
  title = {Yahoo RSS XSS Vulnerability},
  howpublished = {[online] http://www.securityfocus.com/archive/1/413594},
  month = {October},
  year = {2005},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://www.securityfocus.com/archive/1/413594}
}

@TECHREPORT{mogul1995,
  author = {Jeffrey C. Mogul},
  title = {Network Behavior of a Busy Web Server and its Clients},
  institution = {DEC Western Research Laboratory},
  year = {1995},
  number = {WRL 95/5},
  address = {Palo Alto, CA},
  month = {October},
  abstract = {The 1994 California Election server, which provided ‘‘live’’ election
	returns, handled over 1.5 million individual requests, including
	almost 1 million in a single 24-hour period. This may have been the
	most intensive single event on the Internet, to date, and so represented
	a novel experiment in how the network responds to heavy loads. We
	collected comprehensive traces and logs of server and network operation,
	allowing offline analysis of numerous statistics. This paper reports
	the results.},
  file = {:WRL-95-5.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.01.16}
}

@PHDTHESIS{mokryn2003,
  author = {Osnat Mokryn},
  title = {Issues in Internet’s Scalability: Structure and Applications},
  school = {Hebrew University in Jerusalem},
  year = {2003},
  abstract = {The Internet is becoming a vital tool in today’s communication, information
	and data retrieval, as
	
	well as commerce. Its fast spreading, non affected even by the recent
	bubble burst, exceeds the
	
	rate of software and hardware development, and makes it harder for
	monitoring, measuring and
	
	understanding.
	
	
	 In this work we investigate different aspects of the structural properties
	of the Internet, and
	
	suggest how to elevate some of our findings to comprise better application
	and routing layer ser-
	
	vices.
	
	
	 First, we investigate the exact structure of general shortest path
	multicast trees in the Internet.
	
	We present a thorough investigation of the structure of multicast
	trees cut from the Internet and
	
	power-law topologies. Based on both generated topologies and real
	Internet data, we characterize
	
	the structure of such trees and show that they obey the rank-degree
	power law; that most high
	
	degree tree nodes are concentrated in a low diameter neighborhood;
	and that the sub-tree size also
	
	obeys a power law.
	
	
	 Our most surprising empirical finding suggests that there is a linear
	ratio between the number
	
	of high-degree network nodes, namely nodes whose tree degree is higher
	than some constant, and
	
	the number of leaf nodes in the multicast tree (clients). We also
	derive this ratio analytically. Based
	
	on this finding, we develop the Fast Algorithm, that estimates the
	number of clients, and show that
	
	it converges faster than one round trip delay from the root to a randomly
	selected client.
	
	
	 We leverage this finding in an application layer scheme for the dissemination
	of very popular
	
	content to a very large audience. The scheme uses an integrated architecture
	of HTTP unicast
	
	and a cyclic multicast delivery of the popular content, and relies
	on an accurate evaluation of
	
	the multicast group size. We also develop an additional end to end
	counting algorithm for this
	
	evaluation.
	
	
	 We further investigate the tomography of multicast trees, and find
	that not only it conforms to
	
	the findings of the scale free properties of the tree, but also has
	the exact same characteristics as the
	
	Internet’s tomography. This finding deepens our understanding on the
	exact structure of multicast
	
	trees in the Internet, on a layer by layer basis.
	
	
	 We conclude the work by investigating the nature of the resiliency
	of the Internet at the Au-
	
	tonomous System (AS) level to failures and attacks, under the real
	constraint of business agree-
	
	ments between the ASs. The agreements impose policies that govern
	routing in the AS level, and
	
	thus the resulting topology graph is directed, and does not maintain
	transitivity. We show, using
	
	partial views obtained from the Internet, that the Internet’s resiliency
	to a deliberate attack is much
	
	smaller than previously found. Its reachability is also somewhat lower
	under random failures, with
	
	the surprising result that it becomes closer to the optimum when the
	average degree of the Internet
	
	increases. We further investigate the effect of added backup connectivity
	on the resiliency.},
  file = {mokryn2003.pdf:mokryn2003.pdf:PDF},
  keywords = {internet scalability,},
  owner = {kristjan},
  timestamp = {2010.01.16}
}

@ARTICLE{molva1998,
  author = {Molva, R. and Tsudik, G.},
  title = {Secret sets and applications},
  journal = {Inf. Process. Lett.},
  year = {1998},
  volume = {65},
  pages = {47--55},
  number = {1},
  __markedentry = {[kristjan]},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/S0020-0190(97)80449-8},
  file = {molva1998.pdf:molva1998.pdf:PDF},
  issn = {0020-0190},
  keywords = {mobile networks, security, secret sets},
  publisher = {Elsevier North-Holland, Inc.}
}

@INPROCEEDINGS{montenegro2002,
  author = {Gabriel Montenegro and Claude Castelluccia},
  title = {Statistically Unique and Cryptographically Verifiable (SUCV) Identifiers
	and Addresses},
  booktitle = {In Proceedings of the 9th Annual Network and Distributed System Security
	Symposium {(NDSS)}},
  year = {2002},
  abstract = {This paper addresses the identifier ownership problem. It does so
	by using characteristics of Statistic Uniqueness and Cryptographic
	Verifiability (SUCV) of certain entities which this document calls
	SUCV Identifiers and Addresses. Their characteristics allow them
	to severely limit certain classes of denial of service attacks and
	hijacking attacks. SUCV addresses are particularly applicable to
	solve the address ownership problem that hinders mechanisms like
	Binding Updates in Mobile IPv6.},
  file = {montenegro2002.pdf:montenegro2002.pdf:PDF},
  keywords = {unique identity, identity management},
  review = {see buchegger2003 on need for verifiable and unique identity in repuation.}
}

@MISC{mook_samy_2005,
  author = {Nate Mook},
  title = {Cross-Site Scripting Worm Hits MySpace},
  howpublished = {[online] http://www.betanews.com/article/CrossSite\_Scripting\_Worm\_Hits\_MySpace/1129232391},
  year = {2005},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://www.betanews.com/article/CrossSite_Scripting_Worm_Hits_MySpace/1129232391}
}

@INPROCEEDINGS{moore2003,
  author = {Andrew Moore and James Hall and Christian Kreibich and Euan Harris
	and Ian Pratt},
  title = {Architecture of a Network Monitor},
  booktitle = {Proceedings of the Fourth Passive and Active Measurement Workshop
	{PAM}},
  year = {2003},
  month = {April},
  abstract = {This paper describes a system for simultaneously monitoring multiple
	protocols. It performs full linerate capture and implements on-line
	analysis and compression to record interesting data without loss
	of information. We accept that the balance must be maintained in
	such a system between disk-bandwidth, CPU-capacity and data reduction
	in order to perform monitoring at full line-rate. We present the
	architecture in detail and measure the
	
	performance of our sample implementation, Nprobe.},
  file = {021720040539_224.pdf:021720040539_224.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@ARTICLE{moore2003a,
  author = {David Moore and Vern Paxson and Stefan Savage and Colleen Shannon
	and Stuart Staniford and Nicholas Weaver},
  title = {Inside the Slammer Worm},
  journal = {IEEE Security and Privacy},
  year = {2003},
  volume = {1},
  pages = {33--39},
  number = {4},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/MSECP.2003.1219056},
  issn = {1540-7993},
  publisher = {IEEE Educational Activities Department}
}

@INPROCEEDINGS{Moore02code-red,
  author = {David Moore and Colleen Shannon and K. Claffy},
  title = {Code-red: a case study on the spread and victims of an internet worm},
  year = {2002},
  pages = {273--284},
  file = {10.1.1.20.3576.pdf:10.1.1.20.3576.pdf:PDF}
}

@TECHREPORT{moore2004,
  author = {David Moore and Colleen Shannon and Geoffrey M. Voelker and Stefan
	Savage},
  title = {Network Telescopes: Technical Report},
  year = {2004},
  number = {TR-2004-04},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@MISC{moore1980,
  author = {R. C. Moore},
  title = {Reasoning about knowledge and action},
  year = {1980},
  abstract = {This paper discusses the problems of representing and reasoning with
	information about knowledge and action. The first section discusses
	the importance of having systems that understand the concept of knowledge,
	and how knowledge is related to action. Section 2 points out some
	of the special problems that are involved in reasoning about knowledge,
	and section S presents a logic of knowledge based on the idea of
	possible worlds. Section 4 integrates this with a logic of actions
	and gives an example of reasoning in the combined system. Section
	5 makes some concluding comments.},
  file = {moore1980.pdf:moore1980.pdf:PDF},
  keywords = {AI, logic, epistemic logic},
  owner = {kristjan},
  review = {See also papers by McCarthy on epistemic logic},
  timestamp = {2009.08.28}
}

@TECHREPORT{mortier2005,
  author = {Richard Mortier and Rebecca Isaacs and Paul Barham},
  title = {Anemone: using end-systems as a rich network management platform},
  institution = {Microsoft Research},
  year = {2005},
  number = {MSR-TR-2005-62},
  address = {Cambridge, UK},
  month = {May},
  abstract = {Enterprise networks contain hundreds, if not thousands, of cooperative
	end-systems. This paper advocates devoting a small fraction of their
	idle cycles, free disk space and network bandwidth to create Anemone,
	a rich platform for network management. This contrasts with current
	approaches that rely on traﬃc statistics provided by network devices.
	Anemone infers network-wide traﬃc patterns by synthesizing end-system
	ﬂow statistics with dynamic topology information obtained by passive
	snooping of IP routeing protocols. Understanding the eﬀect of the
	network on individual applications’ end-to-end performance requires
	data only available in the end-systems actually hosting applications.
	Consequently, we claim that augmenting end-systems with in-band monitoring,
	creating an overlay of real-time ‘traﬃc sensors’ will provide a more
	complete view of the network, support sophisticated network management
	queries, and supply the global statistics necessary to automate network
	control. This paper describes Anemone, discusses potential beneﬁts
	and challenges, and presents an initial simulation of the platform.},
  file = {tr-anemone.pdf:tr-anemone.pdf:PDF},
  owner = {kristjan},
  review = {(see also cooke2006)
	
	
	The system infers system wide traffic patterns from end-system statistics
	and dynamic topology information obtained by passive snooping of
	IP routing protocols.
	
	%
	
	The purpose of the system is primarily traffic analysis for network
	management purposes. End-system flow data is combined with routing
	protocol listeners to provide a more complete picture of the network
	topology and traffic to a management application. A separate data
	mining layer is envisioned, but is a work in progress at the time
	of writing. The collection of data from end-systems to the management
	platform not immediately clear from the paper. See also \cite{cooke2006}
	which is later work.},
  timestamp = {2008.02.07}
}

@INPROCEEDINGS{mosk-aoyama-2006,
  author = {Damon Mosk-Aoyama and Devavrat Shah},
  title = {Computing separable functions via gossip},
  booktitle = {{PODC} '06: Proceedings of the twenty-fifth annual {ACM} symposium
	on Principles of distributed computing},
  year = {2006},
  pages = {113--122},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Motivated by applications to sensor, peer-to-peer, and ad-hoc networks,
	we study the problem of computing functions of values at the nodes
	in a network in a totally distributed manner. In particular, we consider
	separable functions, which can be written as linear combinations
	of functions of individual variables. Known iterative algorithms
	for averaging can be used to compute the normalized values of such
	functions, but these algorithms do not extend in general to the computation
	of the actual values of separable functions.The main contribution
	of this paper is the design of a distributed randomized algorithm
	for computing separable functions based on properties of exponential
	random variables. We bound the running time of our algorithm in terms
	of the running time of an information spreading algorithm used as
	a subroutine by the algorithm. Since we are interested in totally
	distributed algorithms, we consider a randomized gossip mechanism
	for information spreading as the subroutine. Combining these algorithms
	yields a complete and simple distributed algorithm for computing
	separable functions.The second contribution of this paper is an analysis
	of the information spreading time of the gossip algorithm. This analysis
	yields an upper bound on the information spreading time, and therefore
	a corresponding upper bound on the running time of the algorithm
	for computing separable functions, in terms of the conductance of
	an appropriate stochastic matrix. These bounds imply that, for a
	class of graphs with small spectral gap (such as grid graphs), the
	time used by our algorithm to compute averages is of a smaller order
	than the time required for the computation of averages by a known
	iterative gossip scheme [5].},
  doi = {http://doi.acm.org/10.1145/1146381.1146401},
  file = {mosk-aoyama-2006.pdf:mosk-aoyama-2006.pdf:PDF},
  isbn = {1-59593-384-0},
  location = {Denver, Colorado, USA}
}

@INPROCEEDINGS{Motani2005,
  author = {Mehul Motani and Vikram Srinivasan and Pavan S. Nuggehalli},
  title = {PeopleNet: engineering a wireless virtual social network},
  booktitle = {MobiCom '05: Proceedings of the 11th annual international conference
	on Mobile computing and networking},
  year = {2005},
  pages = {243--257},
  address = {New York, NY, USA},
  publisher = {ACM Press},
  doi = {http://doi.acm.org/10.1145/1080829.1080855},
  file = {p243-motani.pdf:/home/kristjan/articles/p243-motani.pdf:PDF},
  isbn = {1-59593-020-5},
  location = {Cologne, Germany},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{motegi2006,
  author = {Motegi, Shinji and Yoshihara, Kiyohito and Horiuchi, Hiroki},
  title = {{DAG} Based In-Network Aggregation for Sensor Network Monitoring},
  booktitle = {{SAINT} '06: Proceedings of the International Symposium on Applications
	on Internet},
  year = {2006},
  pages = {292--299},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[kristjan]},
  abstract = {Wireless sensor network monitoring is important for network maintenance,
	since it keeps the observer aware of node failures, resource depletion
	etc. Since communication overheads increase if the sink collects
	data individually from all sensor nodes, in-network data aggregation
	methods have been proposed which reduce the overheads. They form
	a routing tree and data follows up from the edge of the tree to the
	sink. However, in the event of heavy packet loss, the error margin
	of the collected data received by the sink grows. Furthermore, when
	the assumed hop count of the edge of the tree is smaller than the
	actual count, data can not be followed up from the edge. For the
	reasons mentioned above, observers find it problematic to assess
	the state of the network, since the error margin increases as the
	accuracy of the collected data falls. In this paper, we propose a
	new in-network aggregation method for sensor network monitoring.
	The method provides fault tolerance for packet loss by forming a
	Directed Acyclic Graph (DAG), which allows a node to have multiple
	parent nodes. In addition, the method can ensure correct data transmission
	timing, according to the actual hop count of the edge of the DAG.
	Furthermore, we evaluated the proposed method in comparison with
	the existing methods, from the perspective of the error margin of
	the collected data.},
  doi = {http://dx.doi.org/10.1109/SAINT.2006.20},
  file = {motegi2006.pdf:motegi2006.pdf:PDF},
  isbn = {0-7695-2508-3},
  keywords = {distributed aggregation, multi-path forwarding, DAG},
  review = {Describe a method for countering the double counting problem (see
	keshav2006) in sensor networks. Exploit the wireless medium and timeouts
	to allow utilization of a DAG for forwarding data in a SN.}
}

@INPROCEEDINGS{mueller2003,
  author = {Stephen Mueller and Rose P. Tsang and Dipak Ghosal},
  title = {Multipath Routing in Mobile Ad Hoc Networks: Issues and Challenges},
  booktitle = {{MASCOTS}},
  year = {2003},
  abstract = {Mobile ad hoc networks (MANETs) consist of a collection
	
	of wireless mobile nodes which dynamically exchange data among them-
	
	selves without the reliance on a ﬁxed base station or a wired backbone
	
	network. MANET nodes are typically distinguished by their limited
	po-
	
	wer, processing, and memory resources as well as high degree of mobility.
	
	In such networks, the wireless mobile nodes may dynamically enter
	the
	
	network as well as leave the network. Due to the limited transmission
	
	range of wireless network nodes, multiple hops are usually needed
	for
	
	a node to exchange information with any other node in the network.
	
	Thus routing is a crucial issue to the design of a MANET. In this
	pa-
	
	per, we speciﬁcally examine the issues of multipath routing in MANETs.
	
	Multipath routing allows the establishment of multiple paths between
	a
	
	single source and single destination node. It is typically proposed
	in or-
	
	der to increase the reliability of data transmission (i.e., fault
	tolerance)
	
	or to provide load balancing. Load balancing is of especial importance
	
	in MANETs because of the limited bandwidth between the nodes. We
	
	also discuss the application of multipath routing to support application
	
	constraints such as reliability, load-balancing, energy-conservation,
	and
	
	Quality-of-Service (QoS).},
  file = {mueller2003.pdf:mueller2003.pdf:PDF},
  keywords = {multi-path routing, survey},
  owner = {kristjan},
  timestamp = {2010.04.15}
}

@ARTICLE{mukherjee1994,
  author = {Biswanath Mukherjee and L. Todd Heberlein and Karl N. Levitt},
  title = {Network Intrusion Detection},
  journal = {IEEE Network},
  year = {1994},
  volume = {8},
  pages = {26-41},
  number = {3},
  month = {May},
  abstract = {Intrusion detection is a new, retrofit approach for providing a sense
	of security in existing computers and data networks, while allowing
	them to operate in their current “open” mode.},
  file = {:mukherjee1994.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.17}
}

@INPROCEEDINGS{mukhopadhyay2004,
  author = {Mukhopadhyay, S. and Panigrahi, D. and Dey, S.},
  title = {Model based error correction for wireless sensor networks},
  booktitle = {{IEEE SECON} First Annual {IEEE Communications Society} Conference
	on Sensor and Ad Hoc Communications and Networks},
  year = {2004},
  pages = { 575-584},
  month = {Oct.},
  abstract = {One of the main challenges in wireless sensor networks is to provide
	low-cost, low-energy reliable data collection. Reliability against
	transient errors in sensor data can be provided using the model-based
	error correction described in (S. Mukhopadhyay et al., Mar. 2004),
	in which temporal correlation in the data is used to correct errors
	without any overheads at the sensor nodes. In the above work it is
	assumed that a perfect model of the data is available. However, as
	variations in the physical process are context-dependent and time-varying
	in a real sensor network, it is infeasible to have an accurate model
	of the data properties a priori, thus leading to reduced correction
	efficiency. In this paper, we address this issue by presenting a
	scalable methodology for improving the accuracy of data modeling
	through on-line estimation and model updates. Additionally, we propose
	enhancements to the data correction algorithm to incorporate robustness
	against dynamic model changes and potential modeling errors. We evaluate
	our system through simulations using real sensor data collected from
	different sources. Experimental results demonstrate that the proposed
	enhancements lead to an improvement of up to a factor of 10 over
	the earlier approach.},
  doi = {10.1109/SAHCN.2004.1381960},
  file = {mukhopadhyay2004.pdf:mukhopadhyay2004.pdf:PDF},
  issn = { },
  keywords = {error correction, telecommunication network reliability, wireless
	sensor networks data correction algorithm, low-energy reliable data
	collection, model based error correction, online estimation, temporal
	correlation, time-varying, wireless sensor network}
}

@ARTICLE{mundinger2008,
  author = {Mundinger, Jochen and {Le Boud\`{e}c}, Jean-Yves},
  title = {Analysis of a reputation system for Mobile Ad-Hoc Networks with liars},
  journal = {Perform. Eval.},
  year = {2008},
  volume = {65},
  pages = {212--226},
  number = {3-4},
  abstract = {The application of decentralized reputation systems is a promising
	approach to ensure cooperation and fairness, as well as to address
	random failures and malicious attacks in Mobile Ad-Hoc Networks.
	However, they are potentially vulnerable to liars. With our work,
	we provide a first step to analyzing robustness of a reputation system
	based on a deviation test. Using a mean-field approach to our stochastic
	process model, we show that liars have no impact unless their number
	exceeds a certain threshold (phase transition). We give precise formulae
	for the critical values and thus provide guidelines for an optimal
	choice of parameters.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.peva.2007.05.004},
  file = {mundinger2008.pdf:mundinger2008.pdf:PDF},
  issn = {0166-5316},
  keywords = {reputation systems, ad-hoc networks, analysis},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{mundinger2006,
  author = {Mundinger, Jochen and {Le Boud\`{e}c}, Jean-Yves},
  title = {Reputation in self-organized communication systems and beyond},
  booktitle = {Interperf '06: Proceedings from the 2006 workshop on Interdisciplinary
	systems approach in performance evaluation and design of computer
	\& communications sytems},
  year = {2006},
  pages = {3},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Efficiently handling reputation is important in dealing with free-riding,
	malicious attacks and random failures in self-organized communication
	systems. At the same time, work in this context is often found to
	be relevant in many other disciplines, in particular the social sciences.
	A number of distributed reputation systems have been proposed and
	analyzed, although research has not been very coherent. In this paper,
	for the first time, we provide an overview of the state-of-the-art
	in the various computer science communities as well as the social
	sciences. In particular, we present results obtained from our mathematical
	model devised to investigate the impact of liars on their peers'
	reputation about a subject. We find that liars have no impact unless
	their number exceeds a certain threshold (phase transition behaviour).
	We give precise formulae and quantify the impact, thereby providing
	insight into fundamental questions in social networks as well as
	facilitating performance evaluation and optimization of distributed
	reputation systems in communication networks. We conclude by suggesting
	fundamental directions for future research into reputation.},
  doi = {http://doi.acm.org/10.1145/1190326.1190328},
  isbn = {1-59593-503-7},
  location = {Pisa, Italy}
}

@ARTICLE{mundinger2005,
  author = {Mundinger, Jochen and {Le Boud\`{e}c}, Jean-Yves},
  title = {Analysis of a {R}obust {R}eputation {S}ystem for {S}elf-{O}rganized
	{N}etworks},
  journal = {European {T}ransactions on {C}ommunication},
  year = {2005},
  volume = {16},
  pages = {375--384},
  number = {5},
  abstract = {Self-organized networks require some mechanism to ensure cooperation
	and fairness. A promising approach is the use of decentralized reputation
	systems. However, their vulnerability to liars has not yet been analyzed
	in detail. In this paper, we provide a rst step to the robustness
	analysis of a reputation system based on a deviation test. Users
	accept second hand information only if this does not dier too much
	from their reputation values. We simplify the original system in
	order to obtain a one-dimensional formulation and show that it exhibits
	a phase transition. In the subcritical regime, the reputation system
	is robust. In the supercritical regime, lying has an impact. We obtain
	the critical values via a mean- eld approach and verify the results
	by explicit computation. Thus, we provide conditions for the deviation
	test to make the reputation system robust as well as quantitative
	results on what goes wrong in the supercritical regime.},
  affiliation = {EPFL},
  details = {http://infoscience.epfl.ch/record/30101},
  documenturl = {http://infoscience.epfl.ch/getfile.py?recid=30101&mode=best},
  doi = {NA},
  keywords = {WLN; LCA2-Reputation; NCCR-MICS; NCCR-MICS/CL2},
  oai-id = {oai:infoscience.epfl.ch:30101},
  oai-set = {article; fulltext; fulltext-public},
  review = {REVIEWED},
  status = {PUBLISHED},
  unit = {LCA}
}

@INPROCEEDINGS{Murphy1999,
  author = {Amy L. Murphy and Gian Pietro Picco},
  title = {Reliable Communication for Highly Mobile Agents},
  booktitle = {First International Symposium on Agent Systems and Applications ({ASA}'99)/Third
	International Symposium on Mobile Agents ({MA}'99)},
  year = {1999},
  address = {Palm Springs, CA, USA},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/article/murphy99reliable.html}
}

@INPROCEEDINGS{murray2001,
  author = {Margaret Murray and K. C. Claffy},
  title = {Measuring the Immeasurable: Global Internet Measurement Infrastructure},
  booktitle = {{PAM – A workshop on Passive and Active Measurements}},
  year = {2001},
  pages = {159--167},
  abstract = {The cooperative anarchy of the global Internet defies easy characterization
	or measurement of its behavior. Fortunately, lack of global understanding
	has not stalled the advancement of network engineering technologies
	that enable and support Internet growth - for the moment. Both Internet
	users and providers can benefit from measurements that detect and
	isolate Internet problems, and identify traffic bottlenecks. Yet
	it is neither practical nor particularly effective to monitor and
	measure every single link. Common sense supports the establishment
	of a measurement infrastructure strategically designed to yield maximal
	Internet coverage at reasonable cost. However, while individual ISPs
	monitor their own infrastructure and quality of service, business
	and other practical concerns often prevent sharing of such information.
	We survey existing public and mission-specific Internet measurement
	infrastructures, comparing them using a variety of criteria. Community
	awareness of similar measurement activities will hopefully facilitate
	opportunities for collaboration, leveraging experiences and investment
	across groups. Cataloguing these sources of Internet measurements
	also provides operations researchers with places to seek topology,
	workload, performance, and routing data that can help them refine
	metrics and methodologies for effective management of the global
	Internet.},
  file = {murray2001.pdf:murray2001.pdf:PDF},
  keywords = {networks, network measurements, network analysis, survey}
}

@TECHREPORT{musuvathi2007,
  author = {Madanlal Musuvathi and Shaz Qadeer and Thomas Ball},
  title = {{CHESS: A Systematic Testing Tool for Concurrent Software}},
  institution = {Microsoft Research},
  year = {2007},
  number = {MSR-TR-2007-149},
  file = {TR-2007-149.pdf:TR-2007-149.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.10.25}
}

@INPROCEEDINGS{mykletun2006,
  author = {Mykletun, E. and Girao, J. and Westhoff, D.},
  title = {Public Key Based Cryptoschemes for Data Concealment in Wireless Sensor
	Networks},
  booktitle = {{ICC} '06. {IEEE} International Conference on Communications},
  year = {2006},
  abstract = {In-network data aggregation is a popular technique for reducing the
	energy consumption tied to data transmission in a multi-hop wireless
	sensor network. However, data aggregation in untrusted or even hostile
	environments becomes problematic when end-to-end privacy between
	sensors and the sink is desired. In this paper we revisit and investigate
	the applicability of additively homomorphic public-key encryption
	algorithms for certain classes of wireless sensor networks. Finally,
	we provide recommendations for selecting the most suitable public
	key schemes for different topologies and wireless sensor network
	scenarios.},
  file = {mykletun2006.pdf:mykletun2006.pdf:PDF},
  keywords = {crypto, homomorphic crypto, survey},
  owner = {kristjan},
  review = {A review of homomorphic (additive) algorithms in context of sensor
	networks. Considers applicability of homomorphic public key algorithms
	to wireless sensor networks. Provide recommendations for selecting
	the most appropriate algorithms},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{mykletun2004,
  author = {Einar Mykletun and Maithili Narasimha and Gene Tsudik},
  title = {Signature Bouquets: Immutability for Aggregated/Condensed Signatures},
  booktitle = {{ESORICS}},
  year = {2004},
  pages = {160--176},
  abstract = {Database outsourcing is a popular industry trend which involves organizations
	delegating their data
	
	management needs to an external service provider. In this model, a
	service provider hosts its clients’
	
	databases and offers mechanisms for clients to create, store, update
	and access (query) their databases.
	
	Since a service provider is almost never fully trusted, security and
	privacy of outsourced data are impor-
	
	tant concerns.
	
	
	This paper focuses on integrity and authenticity issues in outsourced
	databases. Whenever someone
	
	queries a hosted database, the returned results must be demonstrably
	authentic: the querier needs to
	
	establish – in an efﬁcient manner – that both integrity and authenticity
	(with respect to the actual data
	
	owner) are assured. To this end, some recent work [19] examined two
	relevant signature schemes: one
	
	based on a condensed variant of batch RSA [3] and the other – on aggregated
	signature scheme by Boneh,
	
	et al. [4]
	
	
	In this paper, we introduce the notion of immutability for aggregated
	signature schemes. Immutabil-
	
	ity refers to the difﬁculty of computing new valid aggregated signatures
	from a set of other aggregated
	
	signatures. This is an important feature, particularly for outsourced
	databases, as lack thereof would
	
	enable a frequent querier to eventually amass enough aggregated signatures
	to answer other (un-posed)
	
	queries, thus becoming a de facto service provider. Since the schemes
	considered in [19] do not offer
	
	immutability, we propose several practical methods to achieve it.},
  file = {mykletun2004.pdf:mykletun2004.pdf:PDF},
  keywords = {cryptographic signatures, message authentication, signature aggregation}
}

@ARTICLE{nachenberg1997,
  author = {Carey Nachenberg},
  title = {Computer virus-antivirus coevolution},
  journal = {Commun. ACM},
  year = {1997},
  volume = {40},
  pages = {46--51},
  number = {1},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/242857.242869},
  file = {:p46-nachenberg.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM}
}

@TECHREPORT{Nandan2004,
  author = {A. Nandan and S. Das and G. Pau and M. Gerla and M. Sanadidi},
  title = {Co-operative Downloading in Vehicular Ad-Hoc Wireless Networks},
  institution = {UCLA CS},
  year = {2004},
  number = {040035},
  month = {October},
  abstract = {Increasing need for people to be “connected”; while at
	
	the same time remain as mobile as ever poses several in-
	
	teresting issues in wireless networks. It is conceivable in
	
	the near-future that wireless “hotspots” experience ﬂash
	
	crowds-like trafﬁc arrival pattern. A common phenomena
	
	in the Internet today characterized by sudden and unpre-
	
	dicted increase in popularity of on-line content.
	
	 In this paper, we propose SPAWN, a cooperative strat-
	
	egy for content delivery and sharing in future vehicular net-
	
	works. We study the issues involved in using such a strategy
	
	from the standpoint of Vehicular Ad-Hoc networks. In par-
	
	ticular, we show that not only content server but also wire-
	
	less access network load reduction is critical. We propose a
	
	“communication efﬁcient” swarming protocol which uses a
	
	gossip mechanism that leverages the inherent broadcast na-
	
	ture of the wireless medium, and a piece-selection strategy
	
	that takes proximity into account in decisions to exchange
	
	pieces. We show through simulation that gossip incorpo-
	
	rates location-awareness into peer selection, while incur-
	
	ring low messaging overhead, and consequently enhancing
	
	the swarming protocol performance. We develop an analyt-
	
	ical model to characterize the performance of SPAWN.},
  file = {nandan05cooperative.pdf:nandan05cooperative.pdf:PDF},
  owner = {kristjan},
  text = {Alok Nandan, Shirshanka Das, Giovanni Pau, Mario Gerla, M.Y. Sanadidi,
	Co-operative Downloading in Vehicular Ad-Hoc Wireless Networks, UCLA
	CS Technical Report # 040035, October, 2004.},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/nandan05cooperative.html}
}

@INPROCEEDINGS{Nandan2006,
  author = {Alok Nandan and Saurabh Tewari and Shirshanka Das and Mario Gerla
	and Leonard Kleinrock},
  title = {{AdTorrent}: Delivering Location Cognizant Advertisements to Car
	Networks},
  booktitle = {{WONS 2006 : Third Annual Conference on Wireless On-demand Network
	Systems and Services}},
  year = {2006},
  pages = {203-212},
  address = {Les Ménuires, France},
  month = {Jan},
  abstract = {AdTorrent is an integrated system for search, rank-
	
	ing and content delivery in car networks. AdTorrent builds on the
	
	notion of Digital Billboards, a scalable “push” model architecture
	
	for ad content delivery. We present a detailed analysis of the
	
	performance impact of key design parameters such as scope of
	
	the query ﬂooding on the query hit ratio. Our mobility model
	
	for the urban, vehicular scenario can be used in conjunction
	
	with the analytical model for estimating query hit ratio by a
	
	system designer to determine the scope of the query ﬂooding as a
	
	function of the available storage per vehicle for their application.},
  file = {Nandan-Wons06.pdf:Nandan-Wons06.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/nandan06adtorrent.html}
}

@INPROCEEDINGS{narayanan2009,
  author = {Arvind Narayanan and Vitaly Shmatikov},
  title = {De-anonymizing Social Networks},
  booktitle = {IEEE S\&P},
  year = {2009},
  address = {Oakland, CA, USA},
  abstract = {Operators of online social networks are increasingly
	
	sharing potentially sensitive information about users and
	
	their relationships with advertisers, application developers,
	
	and data-mining researchers. Privacy is typically protected
	
	by anonymization, i.e., removing names, addresses, etc.
	
	 We present a framework for analyzing privacy and
	
	anonymity in social networks and develop a new
	
	re-identiﬁcation algorithm targeting anonymized social-
	
	network graphs. To demonstrate its effectiveness on real-
	
	world networks, we show that a third of the users who
	
	can be veriﬁed to have accounts on both Twitter, a popular
	
	microblogging service, and Flickr, an online photo-sharing
	
	site, can be re-identiﬁed in the anonymous Twitter graph
	
	with only a 12% error rate.
	
	 Our de-anonymization algorithm is based purely on the
	
	network topology, does not require creation of a large
	
	number of dummy “sybil” nodes, is robust to noise and all
	
	existing defenses, and works even when the overlap between
	
	the target network and the adversary’s auxiliary information
	
	is small.},
  file = {narayanan2009.pdf:narayanan2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.08}
}

@INPROCEEDINGS{nasipuri1999,
  author = {Asis Nasipuri and Samir R. Das},
  title = {On-Demand Multipath Routing for Mobile Ad Hoc Networks},
  booktitle = {{IEEE} International Conference on Computer Communication and Networks},
  year = {1999},
  abstract = {Mobile ad hoc networks are characterized by
	
	multi-hopwireless links, absence of any cellular infrastructure,
	
	and frequent host mobility. Design of efficient routing protocols
	
	in such networks is a challenging issue. A class of routing pro-
	
	tocols called on-demand protocols has recently found attention
	
	because of their low routing overhead. The on-demand proto-
	
	cols depend on query floods to discover routes whenever a new
	
	route is needed. Such floods take up a substantialportion of net-
	
	work bandwidth. We focus on a particular on-demand protocol,
	
	called Dynamic Source Routing, and show how intelligent use of
	
	multipath techniques can reduce the frequency of query floods.
	
	We develop an analytic modeling framework to determine the
	
	relative frequency of query floods for various techniques. Re-
	
	sults show that while multipath routing is significantly better
	
	than single path routing, the performance advantage is small
	
	beyond a few paths and for long path lengths. It also shows
	
	that providing all intermediate nodes in the primary (shortest)
	
	route with alternative paths has a significantly better perfor-
	
	mance than providing only the source with alternate paths.},
  file = {nasipuri1999.pdf:nasipuri1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.15}
}

@INPROCEEDINGS{Natarajan2007,
  author = {Anirudh Natarajan and Mehul Motani and Vikram Srinivasan},
  title = {Understanding Urban Interactions from Bluetooth Phone Contact Traces},
  booktitle = {8th Passive and Active Measurement conference, PAM},
  year = {2007},
  pages = {pages 115-124},
  address = {Louvain-la-neuve, Belgium},
  month = {April},
  abstract = {The increasing sophistication of mobile devices has enabled
	
	several mobile social software applications, which are based on oppor-
	
	tunistic exchange of data amongst devices in proximity of each other.
	
	Examples include Delay Tolerant Networking (DTN) and PeopleNet. In
	
	this context, understanding user interactions is essential to designing
	
	algorithms which are eﬃcient and enhance the user experience. In our
	
	experiment, users were handed Bluetooth enabled phones and asked to
	
	carry them all the time to log information about other devices in
	their
	
	proximity. Data was logged over several months, with over 350,000
	con-
	
	tacts logged and over 10,000 unique devices discovered in this period.
	1
	
	This paper analyzes this data by charactering the distributions of
	metrics
	
	such as contact time and inter-pair-contact time, and introducing
	several
	
	other important metrics useful for understanding user interactions.
	We
	
	ﬁnd that most metrics follow a power law, except for inter-pair-contact
	
	time. We also look for patterns in user interactions, with the hope
	that
	
	these can be exploited for better algorithm design.},
  file = {Motani_PAM2007.pdf:Motani_PAM2007.pdf:PDF},
  journal = {PAM 2007, 8th
	
	Passive and Active Measurement conference, pages 115-124, Louvain-la-
	
	neuve, Belgium, April 2007.},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{nath2008,
  author = {Nath, Suman and Gibbons, Phillip B. and Seshan, Srinivasan and Anderson,
	Zachary},
  title = {Synopsis diffusion for robust aggregation in sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2008},
  volume = {4},
  pages = {1--40},
  number = {2},
  abstract = {Previous approaches for computing duplicate-sensitive aggregates in
	wireless sensor networks have used a tree topology, in order to conserve
	energy and to avoid double-counting sensor readings. However, a tree
	topology is not robust against node and communication failures, which
	are common in sensor networks. In this article, we present synopsis
	diffusion, a general framework for achieving significantly more accurate
	and reliable answers by combining energy-efficient multipath routing
	schemes with techniques that avoid double-counting. Synopsis diffusion
	avoids double-counting through the use of order- and duplicate-insensitive
	(ODI) synopses that compactly summarize intermediate results during
	in-network aggregation. We provide a surprisingly simple test that
	makes it easy to check the correctness of an ODI synopsis. We show
	that the properties of ODI synopses and synopsis diffusion create
	implicit acknowledgments of packet delivery. Such acknowledgments
	enable energy-efficient adaptation of message routes to dynamic message
	loss conditions, even in the presence of asymmetric links. Finally,
	we illustrate using extensive simulations the significant robustness,
	accuracy, and energy-efficiency improvements of synopsis diffusion
	over previous approaches.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1340771.1340773},
  file = {nath2008.pdf:nath2008.pdf:PDF},
  issn = {1550-4859},
  keywords = {synopsis diffusion, ODI synopses, robust aggregation, sensor networks,
	wireless networks},
  publisher = {ACM},
  review = {Referenced by keshav2006 (references a conference version) on using
	FM sketches to rectify the double counting problem.
	
	See also considine2004, bawa 2004 (parallel or later work).
	
	
	The authors employ the probabilistic counting methods of Flajolet
	and Martin to construction of order and duplicate insensitive synopses
	--ODI synopses -- in sensor networks. ODI sketches can be applied
	to any topology, the benefit being that multi-path networks can be
	employed without worrying about the multiple inclusion (double counting)
	problem. The authors describe an aggregation topology (network construction/maintenance
	protocol) called Rings and an improvement called Adaptive Rings --
	concept seems very similar to the stratified graph concept -- an
	acyclic graph directed towards the central node. Also discuss a flooding
	algorithm which is found to be the most accurate but also expensive
	in terms of messaging overhead.
	
	
	Synopsis diffusion employs a set of functions:
	
	 - synopsis generation SG(.)
	
	 - synopsis fusion SF(.,.)
	
	 - synopsis evaluation SE(.)
	
	Non-trivial to adapt the FM scheme to aggregation. The authors contribution
	includes a thorough presentation of some useful aggregation functions.
	
	
	Evaluation of synopsis diffusion and Rings is provided and contrasted
	with several other approaches such as the TAG and TAG over DAG. Not
	surprisingly, multiple paths and ODI sketches are found to be superior.
	
	
	Drawback of synopsis diffusion: The method is an approximation due
	to the nature of FM sketches. Performs better (by authors evaluation)
	than tree-based aggregation and gossiping in lossy and unreliable
	networks.
	
	The approximation error may be considerable (10-20%) by authors evaluation.
	keshav2006 claims the error to be as high as 33%. 
	
	
	Alternatives to synopsis diffusion: See e.g. keshav2006 on this. 
	
	- Can carry node id in sketch which is only practical in cases where
	limited number of nodes exchange info. Perhaps in a network subdivided
	into smaller clusters.
	
	- push synopses of Kempe. Uses principle of mass conservation. Mass
	loss is however a problem in practice.
	
	
	====
	
	
	See:
	
	
	Tree based approaches: \cite{bonnet2001} (Cougar), \cite{intanagonwiwat2000}
	(Directed Diffusion), \cite{madden2002} (TAG).
	
	
	Robust topologies: Their term for anything but a tree apparently.
	\cite{boyd2005}, \cite{chen2005}, \cite{dimakis2006}, \cite{kempe2003},
	\cite{gupta2001}. Kempe and variants ( \cite{boyd2005}, \cite{chen2005},
	\cite{dimakis2006} ) nodes use the principle of mass transfer / mass
	conservation. In general gossiping requires reliable commnications
	(Nath claims) see cite{Stann2003} (RMST), \cite{wan2004} (PSFQ).
	\cite{gupta2001} does not require reliable communications, but requires
	expensive operations like maintenance of a balanced tree and coarse
	time synchronization. 
	
	A special case of mass conservation is the splitting approach of \cite{madden2002}
	in TAG-over-DAG.
	
	
	Robust protocols used for information dissemination (gossip based)
	rather than aggregation: \cite{jenkins2001} (on gossip based multicast),
	\cite{karp2000}, \cite{vogels2003}.}
}

@INPROCEEDINGS{nath2009,
  author = {Nath, Suman and Yu, Haifeng and Chan, Haowen},
  title = {Secure outsourced aggregation via one-way chains},
  booktitle = {{SIGMOD '09}: Proceedings of the 35th {SIGMOD} international conference
	on Management of data},
  year = {2009},
  pages = {31--44},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {We consider the Outsourced Aggregation model, where sensing services
	outsource their sensor data collection and aggregation tasks to third-party
	service providers called aggregators. As aggregators can be untrusted
	or compromised, it is essential for a sensing service to be able
	to verify the correctness of aggregation results. This work presents
	SECOA, a framework with a family of novel and optimally-secure protocols
	for secure outsourced aggregation. Our framework is based on a unified
	use of one-way chains. It supports a large and diverse set of aggregate
	functions, can have multiple hierarchically organized aggregators,
	can deterministically detect any malicious aggregation behavior without
	communication with sensors, and incurs a small and workload-independent
	communication load on sensors. We also present extensive evaluation
	results to demonstrate the feasibility of our framework.},
  doi = {http://doi.acm.org/10.1145/1559845.1559851},
  file = {nath2009.pdf:nath2009.pdf:PDF},
  isbn = {978-1-60558-551-2},
  keywords = {secure aggregation, outsourced aggregation, hash chain, RSA encryption,
	SECOA},
  location = {Providence, Rhode Island, USA},
  owner = {kristjan},
  review = {outsourced aggregation via one way chains. The model assumes sensors
	(data providers) to deliver correct results, but the network of aggregators
	is controlled by untrusted third-parties.
	
	
	One way chains (RSA encryptions) used to secure a lower bound on the
	MAXIMUM aggregation function. The lower bound is fixed by the hash
	chain, the upper bound by a MAC of the highest reported value.
	
	
	Other functions derived from the maximum. Supports hierarchial aggregation
	by exploiting homomorphic property of RSA. Requires knowledge of
	population which authors claim is not a problem -- work with the
	abstraction of a failed nodes list in this paper (assumed to be empty).
	Revisit this claim at a later time.
	
	
	Safe cheating strategy for AM-FM sketches is discussed -- considerable
	error may be injected without detection. Also identified by garofalakis
	
	
	See note by yu2009b: The protocol can be rendered unavailable whenever
	a single aggregator keeps corrupting the values.}
}

@MISC{defenseindepth,
  author = {{National Security Agency}},
  title = {Defense in Depth: A practical strategy for achieving Information
	Assurance in today’s highly networked environments},
  file = {defenseindepth.pdf:defenseindepth.pdf:PDF},
  keywords = {defense in detph, layered security},
  owner = {kristjan},
  timestamp = {2010.04.30}
}

@ARTICLE{Navidi2004,
  author = {William Navidi and Tracy Camp},
  title = {Stationary Distributions for the Random Waypoint Mobility Model},
  journal = {IEEE Transactions on Mobile Computing},
  year = {2004},
  volume = {3},
  pages = {99-108},
  number = {1},
  month = {Jan},
  abstract = {In simulations of mobile ad hoc networks, the probability distribution
	governing the move-
	
	ment of the nodes typically varies over time, and converges to a “steady-state”
	distribution,
	
	known in the probability literature as the stationary distribution.
	Some published simulation
	
	results ignore this initialization discrepancy. For those results
	that attempt to account for this
	
	discrepancy, the practice is to discard an initial sequence of observations
	from a simulation
	
	in the hope that the remaining values will closely represent the stationary
	distribution. This
	
	approach is inefﬁcient and not always reliable. However, if the initial
	locations and speeds of
	
	the nodes are chosen from the stationary distribution, convergence
	is immediate and no data
	
	need be discarded. We derive the stationary distributions for location,
	speed, and pause time
	
	for the random waypoint mobility model. We then show how to implement
	the random way-
	
	point mobility model in order to construct more efﬁcient and reliable
	simulations for mobile
	
	ad hoc networks. Simulation results, which verify the correctness
	of our method, are included.
	
	In addition, implementation of our method for the NS-2 simulator is
	available.},
  file = {CSM-MCS-03-04.pdf:CSM-MCS-03-04.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{necula1996,
  author = {George C. Necula and Peter Lee},
  title = {Safe Kernel Extensions Without Run-Time Checking},
  booktitle = {USENIX, 2nd Symposium on Operating Systems Design and Implementation
	(OSDI '96)},
  year = {1996},
  address = {Seattle, Washington},
  month = {October},
  abstract = {This paper describes a mechanism by which an oper-
	
	ating system kernel can determine with certainty
	
	that it is safe to execute a binary supplied by an
	
	untrusted source. The kernel rst de nes a safety
	
	policy and makes it public. Then, using this pol-
	
	icy, an application can provide binaries in a spe-
	
	cial form called proof-carrying code, or simply PCC.
	
	Each PCC binary contains, in addition to the native
	
	code, a formal proof that the code obeys the safety
	
	policy. The kernel can easily validate the proof with-
	
	out using cryptography and without consulting any
	
	external trusted entities. If the validation succeeds,
	
	the code is guaranteed to respect the safety policy
	
	without relying on run-time checks.
	
	 The main practical di culty of PCC is in gener-
	
	ating the safety proofs. In order to gain some prelim-
	
	inary experience with this, we have written several
	
	network packet lters in hand-tuned DEC Alpha as-
	
	sembly language, and then generated PCC binaries
	
	for them using a special prototype assembler. The
	
	PCC binaries can be executed with no run-time over-
	
	head, beyond a one-time cost of 1 to 3 milliseconds
	
	for validating the enclosed proofs. The net result is
	
	that our packet lters are formally guaranteed to be
	
	safe and are faster than packet lters created using
	
	Berkeley Packet Filters, Software Fault Isolation, or
	
	safe languages such as Modula-3.},
  file = {necula.pdf:necula.pdf:PDF},
  owner = {kristjan},
  review = {See also imurdock1.pdf},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{needels2009,
  author = {Needels, Keith and Kwon, Minseok},
  title = {Secure routing in peer-to-peer distributed hash tables},
  booktitle = {{SAC '09}: Proceedings of the 2009 {ACM} symposium on Applied Computing},
  year = {2009},
  pages = {54--58},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Distributed hash tables (DHTs) provide efﬁcient and scalable lookup
	mechanisms for locating data in peer-to-peer (p2p) networks. Several
	issues, however, prevent DHT-based p2p networks from being widely
	deployed – one of which is security. Malicious peers may modify,
	drop, misroute lookup requests, or even collude to deny the availability
	of target data. To address these security concerns, we propose an
	extension to Chord named Sechord. The main idea is that the source
	can determine whether the next hop is valid or invalid by estimating
	how far the next hop is from its ﬁnger pointer. If the next hop is
	too far away from the ﬁnger pointer, especially compared to the average
	distance between two consecutive peers, the source can infer some
	ongoing malicious activities. Our modiﬁcations require no trust between
	two nodes except node join. Moreover, each node utilizes locally
	available information to evaluate hops encountered during the lookup
	routing process for validity. These modiﬁcations have been implemented
	and evaluated in the presence of malicious nodes. Our results show
	that Sechord signiﬁcantly enhances the security of structured p2p
	systems at the expense of slightly increased hop count.},
  doi = {http://doi.acm.org/10.1145/1529282.1529292},
  file = {needels2009.pdf:needels2009.pdf:PDF},
  isbn = {978-1-60558-166-8},
  keywords = {security, DHTs, distributed hash tables, routing, secure routing},
  location = {Honolulu, Hawaii}
}

@ARTICLE{needham1987,
  author = {Needham, R M and Schroeder, M D},
  title = {Authentication revisited},
  journal = {{SIGOPS} Oper. Syst. Rev.},
  year = {1987},
  volume = {21},
  pages = {7--7},
  number = {1},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/24592.24593},
  file = {needham1987.pdf:needham1987.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM}
}

@ARTICLE{needham1978,
  author = {Roger M. Needham and Michael D. Schroeder},
  title = {Using encryption for authentication in large networks of computers},
  journal = {Commun. ACM},
  year = {1978},
  volume = {21},
  pages = {993--999},
  number = {12},
  abstract = {Use of encryption to achieve authenticated communication in computer
	networks is discussed. Example protocols are presented for the establishment
	of authenticated connections, for the management of authenticated
	mail, and for signature verification and document integrity guarantee.
	Both conventional and public-key encryption algorithms are considered
	as the basis for protocols.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/359657.359659},
  file = {needham1978.pdf:needham1978.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM}
}

@ARTICLE{needham1977,
  author = {Needham,, R. M. and Walker,, R. D.H.},
  title = {The Cambridge {CAP} computer and its protection system},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {1977},
  volume = {11},
  pages = {1--10},
  number = {5},
  abstract = {This paper gives an outline of the architecture of the CAP computer
	as it concerns capability-based protection and then gives an account
	of how protected procedures are used in the construction of an operating
	system.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1067625.806541},
  file = {:p1-needham.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM},
  review = {See also wilkes 1979}
}

@TECHREPORT{needham1997,
  author = {Roger M. Needham and David J. Wheeler},
  title = {{TEA} Extensions},
  institution = {Computer Laboratory, University of Cambridge},
  year = {1997},
  file = {needham1997.pdf:needham1997.pdf:PDF},
  keywords = {TEA, XTEA, cryptography, block cipher},
  owner = {kristjan},
  review = {The XTEA definition},
  timestamp = {2010.06.18}
}

@ARTICLE{neuman1994,
  author = {B. Clifford Neuman and Theodore Ts'o},
  title = {Kerberos : An Authentication Service for Computer Networks},
  journal = {{IEEE Communications Magazine}},
  year = {1994},
  month = {September},
  owner = {kristjan},
  timestamp = {2010.07.07}
}

@ARTICLE{newman2003,
  author = {Harvey B. Newman and I. C. Legrand and Philippe Galvez and Ramiro
	Voicu and Catalin Cirstoiu},
  title = {{MonALISA}: A Distributed Monitoring Service Architecture},
  journal = {{CoRR}},
  year = {2003},
  volume = {cs.DC/0306096},
  abstract = {The MonALISA (Monitoring Agents in A Large Integrated Services Architecture)
	system provides a distributed monitoring service. MonALISA is based
	on a scalable Dynamic Distributed Services Architecture which is
	designed to meet the needs of physics collaborations for monitoring
	global Grid systems, and is implemented using JINI/JAVA and WSDL/SOAP
	technologies. The scalability of the system derives from the use
	of multithreaded Station Servers to host a variety of loosely coupled
	self-describing dynamic services, the ability of each service to
	register itself and then to be discovered and used by any other services,
	or clients that require such information, and the ability of all
	services and clients subscribing to a set of events (state changes)
	in the system to be notified automatically. The framework integrates
	several existing monitoring tools and procedures to collect parameters
	describing computational nodes, applications and network performance.
	It has built-in SNMP support and network-performance monitoring algorithms
	that enable it to monitor end-to-end network performance as well
	as the performance and state of site facilities in a Grid. MonALISA
	is currently running around the clock on the US CMS test Grid as
	well as an increasing number of other sites. It is also being used
	to monitor the performance and optimize the interconnections among
	the reflectors in the VRVS system.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://arxiv.org/abs/cs.DC/0306096},
  file = {newman2003.pdf:newman2003.pdf:PDF}
}

@INCOLLECTION{newman2008,
  author = {Mark Newman},
  title = {Mathematics of Networks},
  booktitle = {The New Palgrave Encyclopedia of Economics},
  publisher = {Palgrave Macmillan, Basingstoke},
  year = {2008},
  editor = {L. E. Blume and S. N. Durlauf},
  edition = {2nd.},
  file = {newman2008.pdf:newman2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.22}
}

@INPROCEEDINGS{newsome2004,
  author = {James Newsome and Elaine Shi and Dawn Song and Adrian Perrig},
  title = {The sybil attack in sensor networks: Analysis \& defenses},
  booktitle = {{IPSN} '04: Proceedings of the third international symposium on Information
	processing in sensor networks},
  year = {2004},
  pages = {259--268},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Security is important for many sensor network applications. A particularly
	harmful attack against sensor and ad hoc networks is known as the
	Sybil attack [6], where a node illegitimately claims multiple identities.
	This paper systematically analyzes the threat posed by the Sybil
	attack to wireless sensor networks. We demonstrate that the attack
	can be exceedingly detrimental to many important functions of the
	sensor network such as routing, resource allocation, misbehavior
	detection, etc. We establish a classiﬁcation of diﬀerent types of
	the Sybil attack, which enables us to better understand the threats
	posed by each type, and better design countermeasures against each
	type. We then propose several novel techniques to defend against
	the Sybil attack, and analyze their eﬀectiveness quantitatively.},
  doi = {http://doi.acm.org/10.1145/984622.984660},
  file = {p259-newsome.pdf:p259-newsome.pdf:PDF},
  isbn = {1-58113-846-6},
  location = {Berkeley, California, USA}
}

@MISC{nexus2007,
  author = {Nexus},
  title = {Cross-Site Scripting for Fun and Profit},
  howpublished = {[online] http://www.xssed.com/article/7/Paper\_Cross-Site\_Scripting\_for\_Fun\_and\_Profit/},
  month = {May},
  year = {2007},
  owner = {kristjan},
  review = {Very badly written and short intro to [[xss]]. Obviously written from
	a "hackers" perspective, adds little to other xss intros already
	read. Some examples provided. Rather disappointing.},
  timestamp = {2008.04.11},
  url = {http://www.xssed.com/article/7/Paper_Cross-Site_Scripting_for_Fun_and_Profit/}
}

@INPROCEEDINGS{ng2002,
  author = {T. S. Eugene Ng and Hui Zhang},
  title = {Predicting Internet network distance with coordinates-based approaches},
  booktitle = {{IEEE INFOCOM}},
  year = {2002},
  pages = {170--179},
  abstract = {In this paper, we propose to use coordinates-based mechanisms in a
	peer-to-peer architecture to predict Internet network distance (i.e.
	round-trip propagation and transmission delay). We study two mechanisms.
	The first is a previously proposed scheme, called the triangulated
	heuristic, which is based on relative coordinates that are simply
	the distances from a host to some special network nodes. We propose
	the second mechanism, called Global Network Positioning (GNP), which
	is based on absolute coordinates computed from modeling the Internet
	as a geometric space. Since end hosts maintain their own coordinates,
	these approaches allow end hosts to compute their inter-host distances
	as soon as they discover each other. Moreover coordinates are very
	efficient in summarizing inter-host distances, making these approaches
	very scalable. By performing experiments using measured Internet
	distance data, we show that both coordinates-based schemes are more
	accurate than the existing state of the art system IDMaps, and the
	GNP approach achieves the highest accuracy and robustness among them.},
  file = {ng2002.pdf:ng2002.pdf:PDF}
}

@INPROCEEDINGS{ngai2004,
  author = {Edith C. H. Ngai and Michael R. Lyu},
  title = {Trust- and Clustering-Based Authentication Services in Mobile Ad
	Hoc Networks},
  booktitle = {{ICDCSW}: Proceedings of the 245h International Conference on Distributed
	Computing Workshops},
  year = {2004},
  organization = {{IEEE Computer Society}},
  abstract = {A mobile ad hoc network is a kind of wireless communication network
	that does not rely on a fixed infrastructure and is lack of any centralized
	control. These characteristics make it vulnerable to security attack,
	so protecting the security of the network is essential. Like many
	distributed systems, security in ad hoc networks widely relies on
	the use of key management mechanisms. However, traditional key management
	systems are not appropriate for them. This work aims at providing
	a secure and distributed authentication service in ad hoc networks.
	We propose a secure public key authentication service based on our
	trust model and network model to prevent nodes from obtaining false
	public keys of the others when there are malicious nodes in the network.
	We perform an overall evaluation of our proposed approach by simulations.
	The experimental results indicate clear advantages of our approach
	in providing effective security in mobile ad hoc networks.},
  file = {ngai2004.pdf:ngai2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{ngan2003,
  author = {Tsuen-Wan Ngan and Dan S. Wallach and Peter Druschel},
  title = {Enforcing Fair Sharing of Peer-to-Peer Resources},
  booktitle = {In Proc. IPTPS’03},
  year = {2003},
  file = {ngan2003.pdf:ngan2003.pdf:PDF}
}

@INPROCEEDINGS{nguyen_tuong_2005,
  author = {Anh Nguyen-Tuong and Salvatore Guarnieri and Doug Greene and Jeff
	Shirley and David Evans},
  title = {Automatically hardening Web applications using precise tainting},
  booktitle = {20th IFIP International Information Security Conference},
  year = {2005},
  address = {Chiba, Japan},
  month = {May 30 - June 1},
  abstract = {Most web applications contain security vulnerabilities. The simple
	and natural ways of creating a web application are prone to SQL injection
	attacks and cross-site scripting attacks as well as other less common
	vulnerabilities. In response, many tools have been developed for
	detecting or mitigating common web application vulnerabilities. Existing
	techniques either require effort from the site developer or are prone
	to false positives. This paper presents a fully automated approach
	to securely hardening web applications. It is based on precisely
	tracking taintedness of data and checking specifically for dangerous
	content only in parts of commands and output that came from untrustworthy
	sources. Unlike previous work in which everything that is derived
	from tainted input is tainted, our approach precisely tracks taintedness
	within data values.},
  file = {infosec05.pdf:infosec05.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.22}
}

@INPROCEEDINGS{Nielson2005,
  author = {Seth James Nielson and Scott A. Crosby and Dan S. Wallach},
  title = {A Taxonomy of Rational Attacks},
  booktitle = {4th. {IPTPS}},
  year = {2005},
  month = {February},
  file = {nielson2005.pdf:nielson2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{ning2008,
  author = {Ning, Peng and Liu, An and Du, Wenliang},
  title = {Mitigating {DoS} attacks against broadcast authentication in wireless
	sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2008},
  volume = {4},
  pages = {1--35},
  number = {1},
  abstract = {Broadcast authentication is a critical security service in wireless
	sensor networks. There are two general approaches for broadcast authentication
	in wireless sensor networks: digital signatures and μTESLA-based
	techniques. However, both signature-based and μTESLA-based broadcast
	authentication are vulnerable to Denial of Services (DoS) attacks:
	An attacker can inject bogus broadcast packets to force sensor nodes
	to perform expensive signature verifications (in case of signature-based
	broadcast authentication) or packet forwarding (in case of μTESLA-based
	broadcast authentication), thus exhausting their limited battery
	power. This paper presents an efficient mechanism called message-specific
	puzzle to mitigate such DoS attacks. In addition to signature-based
	or μTESLA-based broadcast authentication, this approach adds a weak
	authenticator in each broadcast packet, which can be efficiently
	verified by a regular sensor node, but takes a computationally powerful
	attacker a substantial amount of time to forge. Upon receiving a
	broadcast packet, each sensor node first verifies the weak authenticator,
	and performs the expensive signature verification (in signature-based
	broadcast authentication) or packet forwarding (in μTESLA-based broadcast
	authentication) only when the weak authenticator is valid. A weak
	authenticator cannot be precomputed without a non-reusable (or short-lived)
	key disclosed only in a valid packet. Even if an attacker has intensive
	computational resources to forge one or more weak authenticators,
	it is difficult to reuse these forged weak authenticators. Thus,
	this weak authentication mechanism substantially increases the difficulty
	of launching successful DoS attacks against signature-based or μTESLA-based
	broadcast authentication. A limitation of this approach is that it
	requires a powerful sender and introduces sender-side delay. This
	article also reports an implementation of the proposed techniques
	on TinyOS, as well as initial experimental evaluation in a network
	of MICAz motes.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1325651.1325652},
  file = {ning2008.pdf:ning2008.pdf:PDF},
  issn = {1550-4859},
  keywords = {sensor network, DoS attack mitigation, multi-hop DoS attack},
  publisher = {ACM}
}

@MISC{Nottingham2005,
  author = {M. Nottingham and R. Sayre},
  title = {{RFC 4287: The Atom Syndication Format}},
  year = {2005},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://www.ietf.org/rfc/rfc4287}
}

@MISC{skipjack-1998,
  author = {{NSA}},
  title = {{SKIPJACK} and {KEA} Algorithm Specifications},
  month = {May},
  year = {1998},
  note = {Version 2},
  file = {skipjack-1998.pdf:skipjack-1998.pdf:PDF},
  keywords = {block cipher, Feistel network},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@INPROCEEDINGS{ntarmors2004,
  author = {Nikos Ntarmos and Peter Triantaﬁllou},
  title = {{AESOP}: Altruism-Endowed Self-Organizing Peers},
  booktitle = {2nd {DBISP2P}},
  year = {2004},
  abstract = {We argue the case for a new paradigm for architecting structured P2P
	overlay networks, coined AESOP. AESOP consists of 3 layers: (i) an
	architecture, PLANES, that ensures signiﬁcant performance speedups,
	assuming knowledge of altruistic peers; (ii) an accounting/auditing
	layer, AltSeAl, that identiﬁes and validates altruistic peers; and
	(iii) SeAledPLANES, a layer that facilitates the coordination/collaboration
	of the previous two components. We brieﬂy present these components
	along with experimental and analytical data of the promised signiﬁcant
	performance gains and the related overhead. In light of these very
	encouraging results, we put this three-layer architecture paradigm
	forth as the way to structure the P2P overlay networks of the future.},
  file = {ntarmors2004.pdf:ntarmors2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@INPROCEEDINGS{o-madadhain-2005,
  author = {Joshua O'Madadhain and Padhraic Smyth},
  title = {{EventRank}: a framework for ranking time-varying networks},
  booktitle = {{LinkKDD} '05: Proceedings of the 3rd international workshop on Link
	discovery},
  year = {2005},
  pages = {9--16},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Node-ranking algorithms for (social) networks do not respect the sequence
	of events from which the network is constructed, but rather measure
	rank on the aggregation of all data. For data sets that relate to
	the flow of information (e.g., email), this loss of information can
	obscure the true relative importances of individuals in the network.
	We present EventRank, a framework for ranking algorithms that respect
	event sequences and provide a natural way of tracking changes in
	ranking over time. We compare the performance of a number of ranking
	algorithms using a large organizational data set consisting of approximately
	1 million emails involving over 600 users, including an evaluation
	of how the email-based ranking correlates with known organizational
	hierarchy.},
  doi = {http://doi.acm.org/10.1145/1134271.1134273},
  file = {o-madadhain-2005.pdf:o-madadhain-2005.pdf:PDF},
  isbn = {1-59593-215-1},
  location = {Chicago, Illinois}
}

@MISC{O'Neil1993,
  author = {Elizabeth J. O'Neil and Patrick E. O'Neil and Gerhard Weikum},
  title = {The LRU-K Page Replacement Algorithm For Database Disk Buffering},
  year = {1993},
  owner = {kristjan},
  pages = {297--306},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/article/oneil93lruk.html}
}

@ONLINE{oreilly2005,
  author = {Tim O'Reilly},
  title = {{What Is Web 2.0. Design Patterns and Business Models for the Next
	Generation of Software}},
  url = {http://www.oreillynet.com/pub/a/oreilly/tim/news/2005/09/30/what-is-web-20.html},
  year = {2005},
  howpublished = {[online] http://www.oreillynet.com/pub/a/oreilly/tim/ news/2005/09/30/what-is-web-20.html},
  month = {September},
  owner = {kristjan},
  timestamp = {2008.02.15}
}

@MISC{obscure2002,
  author = {Obscure},
  title = {Microsoft Passport Account Hijack Attack},
  howpublished = {[online] http://eyeonsecurity.org/papers/passport.pdf},
  month = {July},
  year = {2002},
  owner = {kristjan},
  timestamp = {2008.04.11}
}

@INPROCEEDINGS{oda2008,
  author = {Terri Oda and Glenn Wurster and P. C. {van Oorschot} and Anil Somayaji},
  title = {SOMA: mutual approval for included content in web pages},
  booktitle = {CCS '08: Proceedings of the 15th ACM conference on Computer and communications
	security},
  year = {2008},
  pages = {89--98},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Unrestricted information flows are a key security weakness of current
	web design. Cross-site scripting, cross-site request forgery, and
	other attacks typically require that information be sent or retrieved
	from arbitrary, often malicious, web servers. In this paper we propose
	Same Origin Mutual Approval (SOMA), a new policy for controlling
	information flows that prevents common web vulnerabilities. By requiring
	site operators to specify approved external domains for sending or
	receiving information, and by requiring those external domains to
	also approve interactions, we prevent page content from being retrieved
	from malicious servers and sensitive information from being communicated
	to an attacker. SOMA is compatible with current web applications
	and is incrementally deployable, providing immediate benefits for
	clients and servers that implement it. SOMA has an overhead of one
	additional HTTP request per domain accessed and can be implemented
	with minimal effort by application and web browser developers. To
	evaluate our proposal, we have developed a Firefox SOMA add-on.},
  doi = {http://doi.acm.org/10.1145/1455770.1455783},
  file = {:p89-oda.pdf:PDF},
  isbn = {978-1-59593-810-7},
  location = {Alexandria, Virginia, USA}
}

@INPROCEEDINGS{oh2004,
  author = {Songhwai Oh and Stuart Russell and Shankar Sastry},
  title = {Markov Chain Monte Carlo Data Association for General Multiple-Target
	Tracking Problems},
  booktitle = {{IEEE} International Conference on Decision and Control},
  year = {2004},
  month = {December},
  abstract = {In this paper, we consider the general multiple-
	
	target tracking problem in which an unknown number of
	
	targets appears and disappears at random times and the goal
	
	is to ﬁnd the tracks of targets from noisy observations. We
	
	propose an efﬁcient real-time algorithm that solves the data
	
	association problem and is capable of initiating and terminat-
	
	ing a varying number of tracks. We take the data-oriented,
	
	combinatorial optimization approach to the data association
	
	problem but avoid the enumeration of tracks by applying a
	
	sampling method called Markov chain Monte Carlo (MCMC).
	
	The MCMC data association algorithm can be viewed as a
	
	“deferred logic” method since its decision about forming a
	
	track is based on both current and past observations. At the
	
	same time, it can be viewed as an approximation to the optimal
	
	Bayesian ﬁlter. The algorithm shows remarkable performance
	
	compared to the greedy algorithm and the multiple hypothesis
	
	tracker (MHT) under extreme conditions, such as a large
	
	number of targets in a dense environment, low detection
	
	probabilities, and high false alarm rates.},
  file = {oh2004.pdf:oh2004.pdf:PDF},
  keywords = {sensor network, target tracking, markov chain monte carlo, MCMC},
  owner = {kristjan},
  timestamp = {2010.05.16}
}

@INPROCEEDINGS{okamoto1993,
  author = {Okamoto, Tatsuaki},
  title = {Provably Secure and Practical Identification Schemes and Corresponding
	Signature Schemes},
  booktitle = {{CRYPTO} '92: Proceedings of the 12th Annual International Cryptology
	Conference on Advances in Cryptology},
  year = {1993},
  pages = {31--53},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {okamoto1993.pdf:okamoto1993.pdf:PDF},
  isbn = {3-540-57340-2},
  keywords = {zero-knowledge proof, identification protocol},
  review = {Improvement of the Schnorr scheme.}
}

@MISC{oleshchuk2007,
  author = {Vladimir A. Oleshchuk and Vladimir Zadorozhny},
  title = {Secure Multi-party Computations and Privacy Preservation: Results
	and Open Problems},
  year = {2007},
  abstract = {In this paper we give a brief overview of the research in the area
	of secure multiparty computations (SMC) applied to privacy preservation
	with special focus on the telecommunication systems. We provide classification
	of the proposed approaches in the telecom context.},
  file = {oleshchuk2007.pdf:oleshchuk2007.pdf:PDF},
  keywords = {secure multi-party computation, MPC, SMC},
  review = {A failrly nice high-level overview of SMC -- the major results outlined.
	Applications of SMC to some practical problems discussed.}
}

@INPROCEEDINGS{olfati-saber-2005,
  author = {R. Olfati-Saber},
  title = {Distributed Kalman Filter with Embedded Consensus Filters},
  year = {2005},
  pages = { 8179-8184},
  month = {Dec.},
  abstract = {The problem of distributed Kalman filtering (DKF) for sensor networks
	is one of the most fundamental distributed estimation problems for
	scalable sensor fusion. This paper addresses the DKF problem by reducing
	it to two separate dynamic consensus problems in terms of weighted
	measurements and inverse-covariance matrices. These to data fusion
	problems are solved is a distributed way using low-pass and band-pass
	consensus filters. Consensus filters are distributed algorithms that
	allow calculation of average-consensus of time-varying signals. The
	stability properties of consensus filters is discussed in a companion
	CDC ’05 paper [24]. We show that a central Kalman filter for sensor
	networks can be decomposed into n micro-Kalman filters with inputs
	that are provided by two types of consensus filters. This network
	of micro-Kalman filters collectively are capable to provide an estimate
	of the state of the process (under observation) that is identical
	to the estimate obtained by a central Kalman filter given that all
	nodes agree on two central sums. Later, we demonstrate that our consensus
	filters can approximate these sums and that gives an approximate
	distributed Kalman filtering algorithm. A detailed account of the
	computational and communication architecture of the algorithm is
	provided. Simulation results are presented for a sensor network with
	200 nodes and more than 1000 links.},
  file = {olfati-saber-2005.pdf:olfati-saber-2005.pdf:PDF},
  journal = {Decision and Control, 2005 and 2005 European Control Conference.
	CDC-ECC '05. 44th IEEE Conference on},
  keywords = {null consensus filters , distributed Kalman filter , dynamic average-consensus
	, networked embedded systems , random networks, sensor fusion , sensor
	networks }
}

@ARTICLE{oliveira2007a,
  author = {Oliveira, Leonardo B. and Ferreira, Adrian and Vila\c{c}a, Marco
	A. and Wong, Hao Chi and Bern, Marshall and Dahab, Ricardo and Loureiro,
	Antonio A. F.},
  title = {{SecLEACH} -- On the security of clustered sensor networks},
  journal = {Signal Process.},
  year = {2007},
  volume = {87},
  pages = {2882--2895},
  number = {12},
  abstract = {Clustered sensor networks have recently been shown to increase system
	throughput, decrease system delay, and save energy while performing
	data aggregation. Whereas those with rotating cluster heads, such
	as LEACH (low-energy adaptive clustering hierarchy), have also advantages
	in terms of security, the dynamic nature of their communication makes
	most existing security solutions inadequate for them. In this paper,
	we investigate the problem of adding security to hierarchical (cluster-based)
	sensor networks where clusters are formed dynamically and periodically,
	such as LEACH. For this purpose, we show how random key predistribution,
	widely studied in the context of flat networks, and μTESLA, a building
	block from SPINS, can be both used to secure communications in this
	type of network. We present our solution, and provide a detailed
	analysis of how different values for the various parameters in such
	a system impact a hierarchical network in terms of security and energy
	efficiency. To the best of our knowledge, ours is the first that
	investigates security in hierarchical WSNs with dynamic cluster formation.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.sigpro.2007.05.016},
  file = {oliveira2007a.pdf:oliveira2007a.pdf:PDF},
  issn = {0165-1684},
  keywords = {sensor network, security, clustering, LEACH},
  publisher = {Elsevier North-Holland, Inc.},
  review = {Considers adding security to LEACH -- a protocol for clustered sensor
	networks.}
}

@INPROCEEDINGS{oliveira2005,
  author = {Leonardo B. Oliveira and Hao Chi Wong and Antonio A. Loureiro},
  title = {{LHA-SP}: Secure protocols for hierarchical wireless sensor networks},
  booktitle = {Ninth International Symposium on Integrated Network Management ({IM’05}),
	{IFIP/IEEE}},
  year = {2005},
  pages = {31--44},
  abstract = {Wireless sensor networks (WSNs) are ad hoc networks comprised mainly
	of small sensor
	
	nodes with limited resources, and can be used to monitor areas of
	interest. In this paper, we
	
	propose a solution for securing heterogeneous hierarchical WSNs with
	an arbitrary number
	
	of levels. Our solution relies exclusively on symmetric key schemes,
	is highly distributed,
	
	and takes into account node interaction patterns that are speciﬁc
	to clustered WSNs.},
  file = {oliveira2005.pdf:oliveira2005.pdf:PDF},
  review = {Looks like an older version of oliveira2007}
}

@ARTICLE{oliveira2007,
  author = {Oliveira, Leonardo B. and Wong, Hao Chi and Loureiro, Antonio A.
	F. and Dahab, Ricardo},
  title = {On the design of secure protocols for hierarchical sensor networks},
  journal = {Int. J. Secur. Netw.},
  year = {2007},
  volume = {2},
  pages = {216--227},
  number = {3/4},
  abstract = {Wireless sensor networks (WSNs) are ad hoc networks comprised mainly
	of small sensor nodes with limited resources, and can be used to
	monitor areas of interest. In this paper, we propose a solution for
	securing heterogeneous hierarchical WSNs with an arbitrary number
	of levels. Our solution relies exclusively on symmetric key schemes,
	is highly distributed, and takes into account node interaction patterns
	that are speciﬁc to clustered WSNs.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJSN.2007.013175},
  file = {oliveira2007.pdf:oliveira2007.pdf:PDF},
  issn = {1747-8405},
  keywords = {sensor network, security, key establishment, cluster selection, secure
	aggregation},
  owner = {kristjan},
  publisher = {Inderscience Publishers},
  review = {Present protocols for key establishment and setup of clustered SN.
	Considers an arbitrarily deep hierarchy. Secure communications between
	a sensor and elected clusterhead via simple pairwise encryption and
	MACs. Only consider point-to-point operation, even in CH to sensor
	communications. Reference LEAP on authenticated broadcast.}
}

@ONLINE{ollman_xss_2007,
  author = {Gunter Ollman},
  title = {HTML Code Injection and Cross-site scripting. Understanding the cause
	and effect of CSS (XSS) Vulnerabilities.},
  url = {http://www.technicalinfo.net/papers/CSS.html},
  year = {2007},
  howpublished = {[online] http://www.technicalinfo.net/papers/CSS.html},
  abstract = {As web-based applications have become more sophisticated, the types
	of vulnerabilities are capable of exploiting has rapidly increased.
	A particular class of attacks commonly referred to as “code insertion”
	and often “Cross-Site Scripting” has become increasingly popular.
	Unfortunately, the number of applications vulnerable to these attacks
	is staggering, and the varieties of ways attackers are finding to
	successfully exploit them is on the increase. Analysis of many sites
	has indicated that not only are the majority of sites vulnerable,
	but they are vulnerable to many different methods and much of their
	content is affected.},
  owner = {kristjan},
  review = {This paper provides a good introduction to "Cross-site scripting":xss.},
  timestamp = {2008.04.10}
}

@MISC{owasp_top_ten_2007,
  author = {{Open Web Application Security Project}},
  title = {Top 10 2007},
  month = {September},
  year = {2008},
  file = {Top 10 2007:OWASP_Top_10_2007.pdf:PDF},
  owner = {kristjan},
  project = {phd},
  timestamp = {2008.11.20},
  url = {http://www.owasp.org/index.php/Top_10_2007}
}

@MISC{owasp_top_ten_2004,
  author = {{Open Web Application Security Project}},
  title = {The ten most critical Web application security vulnerabilities},
  howpublished = {[online] http://umn.dl.sourceforge.net/sourceforge/owasp/OWASPTopTen2004.pdf},
  year = {2004},
  file = {OWASPTopTen2004.pdf:OWASPTopTen2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://umn.dl.sourceforge.net/sourceforge/owasp/OWASPTopTen2004.pdf}
}

@MISC{ortalo1996,
  author = {Rodolphe Ortalo},
  title = {Using Deontic Logic for Security Policy Specification},
  year = {1996},
  abstract = {This paper analyses the problem of specifying a security policy for
	organizations. First, various issues related to the problem of an
	adequate and rigorous specification of a security policy are outlined
	in a context where security requirements usually remain informal
	and are difficult to satisfy. Then, it is proposed to use a logical
	language, previously studied in the literature, that seems to exhibit
	the adaptability needed for such tasks. The definition of this formalism
	is provided. We focus on the problem of its practical use and propose
	a graphical approach supported by a tool. A security policy specification
	example is presented to illustrate this approach.},
  file = {ortalo1996.pdf:ortalo1996.pdf:PDF},
  keywords = {security policy specification, deontic logic}
}

@ARTICLE{Ott2005,
  author = {J{''{o}}rg Ott and Dirk Kutscher},
  title = {A Disconnection-Tolerant Transport for Drive-thru Internet Environments},
  journal = {{IEEE INFOCOM}},
  year = {2005},
  volume = {Vol 3.},
  owner = {kristjan},
  page = {1849-1862},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{Ott2004,
  author = {J{\''{o}}rg Ott and Dirk Kutscher},
  title = {Why Seamless? Towards Exploiting WLAN-based Intermittent Connectivity
	on the Road},
  booktitle = {Proceedings of the {TERENA Networking Conference, TNC}},
  year = {2004},
  month = {June},
  location = {Rhodes},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{owasp_xss_2008,
  author = {{OWASP}},
  title = {Cross Site Scripting},
  howpublished = {[online] http://www.owasp.org/index.php/Cross_Site_Scripting},
  month = {March},
  year = {2008},
  owner = {kristjan},
  timestamp = {2008.04.11},
  url = {http://www.owasp.org/index.php/Cross_Site_Scripting}
}

@ARTICLE{ozdemir2008,
  author = {Ozdemir, Suat},
  title = {Functional reputation based reliable data aggregation and transmission
	for wireless sensor networks},
  journal = {Comput. Commun.},
  year = {2008},
  volume = {31},
  pages = {3941--3953},
  number = {17},
  abstract = {In wireless sensor networks, compromised sensor nodes aim to distort
	the integrity of data by sending false data reports, injecting false
	data during data aggregation, and disrupting transmission of aggregated
	data. Previously known trust systems rely on general reputation concept
	to prevent these attacks. However, this paper presents a novel reliable
	data aggregation and transmission protocol, called RDAT, which is
	based on the concept of functional reputation. Protocol RDAT improves
	the reliability of data aggregation and transmission by evaluating
	each type of sensor node action using a respective functional reputation.
	In addition, protocol RDAT employs a fault tolerant Reed-Solomon
	coding scheme based multi path data transmission algorithm to ensure
	the reliable data transmission to the base station. The simulation
	results show that protocol RDAT significantly improves the reliability
	of the data aggregation and transmission in the presence of compromised
	nodes.},
  address = {Newton, MA, USA},
  doi = {http://dx.doi.org/10.1016/j.comcom.2008.07.017},
  issn = {0140-3664},
  publisher = {Butterworth-Heinemann}
}

@INCOLLECTION{ozdemir2007,
  author = {Suat Ozdemir},
  title = {Secure and Reliable Data Aggregation for Wireless Sensor Networks},
  booktitle = {Ubiquitous Computing Systems (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  abstract = {This paper presents a data aggregation protocol that ensures security
	and reliability of aggregated data in the presence of compromised
	sensor nodes. The proposed protocol relies on a novel trust development
	algorithm which is used by data aggregators and sensor nodes to ensure
	the reliability of aggregated data and to select secure and reliable
	paths. Simulation results show that the proposed protocol improves
	the security and reliability of aggregated data significantly.},
  file = {ozdemir2007.pdf:ozdemir2007.pdf:PDF},
  keywords = {sensor networks, security, reputation, beta distribution},
  owner = {kristjan},
  review = {Presents the SELDA protocol for security in sensor networks. Web of
	trust establishment by node interaction -- reputation approach. Reputation
	for availability and integrity enhancement. Probabilistic multi-path
	forwarding using reputation as a metric of trust. Reputation is based
	on mutually observable environment -- eg. sensor nodes in same "area"
	expected to measure similar temperature -- correlated data assumption.
	Disjoint sensor/aggregator architecture.},
  timestamp = {2010.01.21}
}

@INPROCEEDINGS{ozdemir2007a,
  author = {Suat Ozdemir},
  title = {Concealed Data Aggregation in Heterogeneous Sensor Networks using
	Privacy Homomorphism},
  booktitle = {{ICPS'07}: {IEEE} Conference on Pervasive Services},
  year = {2007},
  pages = {165--168},
  address = {Istanbul, Turkey},
  __markedentry = {[kristjan]},
  abstract = {Data aggregation is implemented in wireless sensor networks to reduce
	data redundancy and to summarize relevant and necessary information
	without requiring all pieces of the data. The bene t of data aggregation
	can be maximized by implementing it at every data aggregator on the
	path to the base station. However, data con dentiality requires sensor
	nodes to encrypt their data prior to transmission. Moreover, once
	data is encrypted by a sensor node, it should be decrypted at the
	base station to maintain end-to-end security. This makes the implementation
	of data aggregation very dif cult because data aggregation algorithms
	require encrypted data to be decrypted. Consequently, data aggregation
	and secure communication have con icts in their implementation. To
	achieve data aggregation and secure communication together, this
	paper employs Privacy Homomorphism which offers end-to-end concealment
	of data and ability to operate on ciphertexts. In the proposed protocol,
	the computational overhead imposed by the privacy homomorphic encryption
	functions is tolerated by employing a set of powerful nodes, called
	AGGNODEs.},
  file = {ozdemir2007a.pdf:ozdemir2007a.pdf:PDF},
  owner = {kristjan},
  review = {Concealed data aggregation in sensor networks CDAP -- \cite{ozdemir2009}
	on background. Special set of resource rich sensor nodes AGGNODEs
	used to encrypt (homomorphically). A clustered kind of architecture
	in which sensors send (symmetrically encrypted) data directly to
	an aggreator (clusterhead?) which homomorphically encrypts and forwards
	through a network of aggregators to a base station. 
	
	
	Heterogeneous network -- higher capacity (and to some degree trusted)
	aggregators can homomorphically encrypt. The "mini servers" system
	architecture assumption.
	
	
	Problems: Implicit trust of first hop aggregator. What if it is corrupt?
	Argument that injection of false data by compromised aggregators
	is local and tolerable!},
  timestamp = {2010.05.16}
}

@INCOLLECTION{cam2007,
  author = {Suat Ozdemir and Hasan Cam},
  title = {False Data Detection and Secure Data Aggregation in Wireless Sensor
	Networks},
  booktitle = {Security in Distributed, Grid, Mobile, and Pervasive Computing},
  publisher = {Auerbach Publications},
  year = {2007},
  __markedentry = {[kristjan]},
  owner = {kristjan},
  timestamp = {2010.05.13},
  url = {http://docs.google.com/viewer?a=v&q=cache:RQyKCEvFxRAJ:www.crcnetbase.com/doi/pdf/10.1201/9780849379253.ch7+false+data+detection+and+secure+data+aggregation+in+wireless+sensor+networks&hl=is&gl=is&pid=bl&srcid=ADGEESj7RH6rN_WP-UrJZm3BX-XXZoxf7iPNgStP6lIY3-09HIPEZB1WK7221E9W4fAbwDboRx49wf5_Ph15uqRwkG2uajDwomWIa0YZg6xKYc55lF3CM-UfWkTGrYvvYrTpqoQtJQgj&sig=AHIEtbQ8jddNdy5L2KAdSVRn61sxaE4F9w}
}

@ARTICLE{ozdemir2009,
  author = {Suat Ozdemir and Yang Xiao},
  title = {Secure data aggregation in wireless sensor networks: A comprehensive
	overview},
  journal = {Computer Networks},
  year = {2009},
  volume = {53},
  pages = {2022 - 2037},
  number = {12},
  abstract = {Wireless sensor networks often consists of a large number of low-cost
	sensor nodes that have strictly limited sensing, computation, and
	communication capabilities. Due to resource restricted sensor nodes,
	it is important to minimize the amount of data transmission so that
	the average sensor lifetime and the overall bandwidth utilization
	are improved. Data aggregation is the process of summarizing and
	combining sensor data in order to reduce the amount of data transmission
	in the network. As wireless sensor networks are usually deployed
	in remote and hostile environments to transmit sensitive information,
	sensor nodes are prone to node compromise attacks and security issues
	such as data confidentiality and integrity are extremely important.
	Hence, wireless sensor network protocols, e.g., data aggregation
	protocol, must be designed with security in mind. This paper investigates
	the relationship between security and data aggregation process in
	wireless sensor networks. A taxonomy of secure data aggregation protocols
	is given by surveying the current “state-of-the-art” work in this
	area. In addition, based on the existing research, the open research
	areas and future research directions in secure data aggregation concept
	are provided.},
  doi = {DOI: 10.1016/j.comnet.2009.02.023},
  file = {ozdemir2009.pdf:ozdemir2009.pdf:PDF},
  issn = {1389-1286},
  keywords = {Secure data aggregation, survey, sensor networks, wireless networks},
  review = {An ok survey (B+/A) on aggregation (structured) in general, security
	requirements for aggregaton. Categorizes solutions as 1) ones which
	aggregate plaintext (perhaps hop-by-hop) encrypted and 2) methods
	which operate on encrypted data (homomorphic encryption -- end-to-end
	security). Gives good pointers for future work, e.g. dynamic networks,
	countering compromized aggregators, more advanced homomorphic methods
	(e.g. symmetric key ones for efficiency). Mentions source coding
	as a possible direction -- sounds promising. Hierarchial secure privacy
	homomorphisms non-trivial -- extending current single layer homomorphic
	protocols to multi-layer hierarchial protocols an interesting future
	problem.
	
	
	Note: How about homomorphic encryption in gossip networks??},
  url = {http://www.sciencedirect.com/science/article/B6VRG-4VXB88W-1/2/19d5ff6af92871bd6aff85ac5de4ae8d}
}

@MISC{ozdemir2009a,
  author = {Suat Ozdemir and Yang Xiao},
  title = {Hierarchical Concealed Data Aggregation for Wireless Sensor Networks},
  year = {2009},
  abstract = {In wireless sensor networks, performing data aggregation while preserving
	data conﬁdentiality is a challenging task. Recently, privacy homomorphism
	based secure data aggregation schemes have been proposed to achieve
	seamless integration of data conﬁdentiality and aggregation. If sensor
	data are encrypted with different keys, however, these schemes do
	not allow hierarchical data aggregation, thereby limiting the beneﬁt
	of data aggregation. This paper presents a novel hierarchial concealed
	data aggregation protocol that allows the aggregation of data packets
	which are encrypted with different keys. Hence, regardless of the
	encryption key, data collected from all sensor nodes can be aggregated
	without violating data conﬁdentiality. Moreover, during the decryption
	of aggregated data, the base station is able to classify sensor data
	based on the encryption key.},
  file = {ozdemir2009a.pdf:ozdemir2009a.pdf:PDF},
  keywords = {in-network aggregation, security, concealed data aggregation},
  owner = {kristjan},
  timestamp = {2010.01.18}
}

@ARTICLE{padhye1998,
  author = {Jitendra Padhye and Victor Firoiu and Don Towsley and Jim Kurose},
  title = {Modeling {TCP} throughput: a simple model and its empirical validation},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {1998},
  volume = {28},
  pages = {303--314},
  number = {4},
  abstract = {In this paper we develop a simple analytic characterization of the
	steady state throughput, as a function of loss rate and round trip
	time for a bulk transfer TCP flow, i.e., a flow with an unlimited
	amount of data to send. Unlike the models in [6, 7, 10], our model
	captures not only the behavior of TCP's fast retransmit mechanism
	(which is also considered in [6, 7, 10]) but also the effect of TCP's
	timeout mechanism on throughput. Our measurements suggest that this
	latter behavior is important from a modeling perspective, as almost
	all of our TCP traces contained more time-out events than fast retransmit
	events. Our measurements demonstrate that our model is able to more
	accurately predict TCP throughput and is accurate over a wider range
	of loss rates.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/285243.285291},
  file = {padhye1998.pdf:padhye1998.pdf:PDF},
  issn = {0146-4833},
  keywords = {networks, network analysis, TCP, throughput, network measurements},
  publisher = {ACM}
}

@INPROCEEDINGS{pai2006,
  author = {Hung-Ta Pai and Yunghsiang S. Han},
  title = {Power-Efficient Data Fusion Assurance Using Direct Voting Mechanism
	in Wireless Sensor Networks},
  booktitle = {SUTC '06: Proceedings of the IEEE International Conference on Sensor
	Networks, Ubiquitous, and Trustworthy Computing -Vol 1 (SUTC'06)},
  year = {2006},
  pages = {368--375},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  doi = {http://dx.doi.org/10.1109/SUTC.2006.105},
  isbn = {0-7695-2553-9-01}
}

@ARTICLE{pai2008,
  author = {Pai, Sameer and Meingast, Marci and Roosta, Tanya and Bermudez, Sergio
	and Wicker, Stephen B. and Mulligan, Deirdre K. and Sastry, Shankar},
  title = {Transactional Confidentiality in Sensor Networks},
  journal = {{IEEE Security and Privacy}},
  year = {2008},
  volume = {6},
  pages = {28--35},
  number = {4},
  abstract = {In a sensor network environment, elements such as message rate, message
	size, mote frequency, and message routing can reveal transactional
	data—that is, information about the sensors deployed, frequency of
	events monitored, network topology, parties deploying the network,
	and location of subjects and objects moving through the networked
	space. Whereas the confidentiality of network communications content
	is secured through encryption and authentication techniques, the
	ability of network outsiders and insiders to observe transactional
	data can also compromise network confidentiality. Four types of transactional
	data are typically observable in sensor networks. Measures to limit
	the availability and utility of transactional data are essential
	to preserving confidentiality in sensor networks.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/MSP.2008.107},
  file = {pai2008.pdf:pai2008.pdf:PDF},
  issn = {1540-7993},
  keywords = {sensor network, security, confidentiality},
  publisher = {IEEE Educational Activities Department}
}

@INPROCEEDINGS{pai2007,
  author = {Sameer Pai and Tanya Roosta and Stephen Wicker and S. Shankar Sastry},
  title = {Using Social Network Theory Towards Development Of Wireless Ad hoc
	Network Trust},
  booktitle = {Proceedings of the {IEEE} 21st International Conference on Advanced
	Information Networking and Applications},
  year = {2007},
  month = {June},
  abstract = {The evolution and existence of stable trust relations have been studied
	extensively in the context of social theory. However, reputation
	systems or trust schemes have only been recently used in the domain
	of wireless ad hoc networks. It has been shown that these schemes
	provide positive results as a self-policing mechanism for the routing
	of data in wireless ad hoc network security. This paper develops
	a relationship between the trust concepts in the social network theory
	and wireless ad hoc networks. In addition, the paper maps existing
	trust schemes in wireless ad hoc networks to a long-standing theory
	in social networks. Most importantly, a refined model of trust evaluation
	in social networks is constructed and mapped to a new trust scheme
	for ad hoc networks. The new trust scheme is analyzed and shown to
	outperform existing schemes using scenario and simulation analysis.},
  file = {pai2007.pdf:pai2007.pdf:PDF},
  keywords = {social networks, security, trust establishment},
  url = {http://www.truststc.org/pubs/202.html}
}

@INCOLLECTION{paillier1999,
  author = {Pascal Paillier},
  title = {Public-Key Cryptosystems Based on Composite Degree Residuosity Classes},
  booktitle = {Advances in Cryptology — {EUROCRYPT} ’99},
  publisher = {Springer Berlin / Heidelberg},
  year = {1999},
  volume = {1592/1999},
  abstract = {This paper investigates a novel computational problem, namely the
	Composite Residuosity Class Problem, and its applications to public-key
	cryptography. We propose a new trapdoor mechanism and derive from
	this technique three encryption schemes: a trapdoor permutation and
	two homomorphic probabilistic encryption schemes computationally
	comparable to RSA. Our cryptosystems, based on usual modular arithmetics,
	are provably secure under appropriate assumptions in the standard
	model.},
  file = {paillier1999.pdf:paillier1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.14}
}

@INPROCEEDINGS{palmskog2010,
  author = {Karl Palmskog and Alberto Gonzalez Prieto and Catalin Meirosu and
	Rolf Stadler and Mads Dam},
  title = {Scalable Metadata-Directed Search in a Network of Information},
  booktitle = {{Future Network and MobileSummit}},
  year = {2010},
  abstract = {The information-centric paradigm has been recently proposed for the
	design of future networking systems. A key requirement for realising
	such systems is having mechanisms that provide efficient, scalable
	and accurate information search. In this paper, we present solutions
	for both one-time and continuous searches. Our solution for one-time
	searches is scalable for its search completion time grows sublinearly
	with the system size. In addition, the overhead it introduces is
	evenly distributed. For our solution for continuous searches, we
	discuss its tradeoff between load (efficiency) and timeliness (accuracy).},
  file = {palmskog2010.pdf:palmskog2010.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.03}
}

@ARTICLE{palomo2009,
  author = {Esteban J. Palomo and Enrique Dom\'{i}nguez and Rafael M. Luque and
	Jos\'{e} Mu\~{n}oz},
  title = {An Intrusion Detection System based on Hierarchical Self-Organization},
  journal = {Journal of Information Assurance and Security},
  year = {2009},
  volume = {4},
  pages = {209--216},
  abstract = {An intrusion detection system (IDS) monitors the IP packets flowing
	over the network to capture intrusions or anomalies. One of the techniques
	used for anomaly detection is building statistical models using metrics
	derived from observation of the user's actions. In this paper, a
	neural network model based on self organization is proposed for detecting
	intrusions. The self-organizing map (SOM) has shown to be successful
	for the analysis of high-dimensional input data as in data mining
	applications such as network security. The proposed growing hierarchical
	SOM (GHSOM) addresses the limitations of the SOM related to the static
	architecture of this model. The GHSOM is an artificial neural network
	model with hierarchical architecture composed of independent growing
	SOMs. Randomly selected subsets that contain both attacks and normal
	records from the KDD Cup 1999 benchmark are used for training the
	proposed GHSOM.},
  file = {palomo2009.pdf:palomo2009.pdf:PDF},
  keywords = {Network security, hierarchical self-organization, intrusion detection,
	data clustering.},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INCOLLECTION{palomo2009a,
  author = {Esteban J. Palomo and Enrique Dom\'{i}nguez and Rafael M. Luque and
	Jose Mu\~{n}oz},
  title = {A Self-Organized Multiagent System for Intrusion Detection},
  booktitle = {Agents and Data Mining Interaction (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2009},
  abstract = {This paper describes a multiagent system with capabilities to analyze
	and discover knowledge gathered from distributed agents. These enhanced
	capabilities are obtained through a dynamic self-organizing map and
	a multiagent communication system. The central administrator agent
	dynamically obtains information about the attacks or intrusions from
	the distributed agents and maintains a knowledge pool using a proposed
	growing self-organizing map. The approach integrates traditional
	mathematical and data mining techniques with a multiagent system.
	The proposed system is used to build an intrusion detection system
	(IDS) as a network security application. Finally, experimental results
	are presented to confirm the good performance of the proposed system.},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{Panagakis2007,
  author = {Athanasios Vaios Antonis Panagakis and Ioannis Stavrakakis},
  title = {On the effects of cooperation in DTNs},
  booktitle = {In Proc. of The Second IEEE/CreateNet/ICST International Conference
	on Communication System Software and Middleware (COMSWARE)},
  year = {2007},
  month = {January 7-12},
  file = {panagakis2007.pdf:/home/kristjan/articles/panagakis2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{paola-2006,
  author = {Stefano Di Paola and Giorgio Fedon},
  title = {Subverting {Ajax}. Next generation vulnerabilities in 2.0 web applications},
  booktitle = {{23rd Chaos Communication Congress}},
  year = {2006},
  month = {December},
  abstract = {The ability of modern browsers to use asynchronous requests introduces
	a new type of attack vectors. In particular, an attacker can inject
	client side code to totally subvert the communication flow between
	client and server. In fact, advanced features of Ajax framework build
	up a new transparent layer not controlled by the user. This paper
	will focus on security aspects of Ajax technology and on their influence
	upon privacy issues. Ajax is not only a group of features for web
	developers: it's a new paradigm that allows leveraging the most refined
	client side attacks.},
  file = {1158-Subverting_Ajax.pdf:1158-Subverting_Ajax.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14}
}

@INPROCEEDINGS{papadimitratos2002,
  author = {Panagiotis Papadimitratos and Zygmunt J. Haas},
  title = {Secure Routing for Mobile Ad hoc Networks},
  booktitle = {{SCS Communication Networks and Distributed Systems Modeling and
	Simulation Conference (CNDS 2002)}},
  year = {2002},
  address = {San Antonio, TX},
  month = {January 27-31},
  abstract = {The emergence of the Mobile Ad Hoc Networking (MANET) technology advocates
	self-organized wireless interconnection of communication devices
	that would either extend or operate in concert with the wired networking
	infrastructure or, possibly, evolve to autonomous networks. In either
	case, the proliferation of MANET-based applications depends on a
	multitude of factors, with trustworthiness being one of the primary
	challenges to be met. Despite the existence of well-known security
	mechanisms, additional vulnerabilities and features pertinent to
	this new networking paradigm might render such traditional solutions
	inapplicable. In particular, the absence of a central authorization
	facility in an open and distributed communication environment is
	a major challenge, especially due to the need for cooperative network
	operation. In particular, in MANET, any node may compromise the routing
	protocol functionality by disrupting the route discovery process.
	In this paper, we present a route discovery protocol that mitigates
	the detrimental effects of such malicious behavior, as to provide
	correct connectivity information. Our protocol guarantees that fabricated,
	compromised, or replayed route replies would either be rejected or
	never reach back the querying node. Furthermore, the protocol responsiveness
	is safeguarded under different types of attacks that exploit the
	routing protocol itself. The sole requirement of the proposed scheme
	is the existence of a security association between the node initiating
	the query and the sought destination. Specifically, no assumption
	is made regarding the intermediate nodes, which may exhibit arbitrary
	and malicious behavior. The scheme is robust in the presence of a
	number of non-colluding nodes, and provides accurate routing information
	in a timely manner.},
  file = {papadimitratos2002.pdf:papadimitratos2002.pdf:PDF},
  keywords = {mobile ad-hoc network, secure routing, security},
  owner = {kristjan},
  timestamp = {2009.08.31}
}

@INPROCEEDINGS{papadimitratos2002a,
  author = {Papadimitratos, Panagiotis and Haas, Zygmunt J. and Sirer, Emin G\"{u}n},
  title = {Path set selection in mobile ad hoc networks},
  booktitle = {{MobiHoc} '02: Proceedings of the 3rd {ACM} international symposium
	on Mobile ad hoc networking \& computing},
  year = {2002},
  pages = {1--11},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Topological changes in mobile ad hoc networks frequently render routing
	paths unusable. Such recurrent path failures have detrimental effects
	on the network ability to support QoS-driven services. A promising
	technique for addressing this problem is to use multiple redundant
	paths between the source and the destination. However while multipath
	routing algorithms can tolerate network failures well their failure
	resilience only holds if the paths are selected judiciously. In particular
	the correlation between the failures of the paths in a redundant
	path set should be as small as possible. However selecting an optimal
	path set is an NP-complete problem. Heuristic solutions proposed
	in the literature are either too complex to be performed in real-time
	or too ineffective or both. This paper proposes a multipath routing
	algorithm called Disjoint Pathset Selection Protocol (DPSP) based
	on a novel heuristic that in nearly linear time on average picks
	a set of highly reliable paths. The convergence to a highly reliable
	path set is very fast and the protocol provides flexibility in path
	selection and routing algorithm. Furthermore DPSP is suitable for
	real-time execution with nearly no message exchange overhead and
	with minimal additional storage requirements. This paper presents
	evidence that multipath routing can mask a substantial number of
	failures in the network compared to single path routing protocols
	and that the selection of paths according to DPSP can be beneficial
	for mobile ad hoc networks since it dramatically reduces the rate
	of route discoveries.},
  doi = {http://doi.acm.org/10.1145/513800.513802},
  file = {papadimitratos2002a.pdf:papadimitratos2002a.pdf:PDF},
  isbn = {1-58113-501-7},
  keywords = {path selection},
  location = {Lausanne, Switzerland}
}

@INPROCEEDINGS{Papadopouli2001,
  author = {Maria Papadopouli and Henning Schulzrinne},
  title = {Effects of power conservation, wireless coverage and cooperation
	on data dissemination among mobile devices},
  booktitle = {MobiHoc '01: Proceedings of the 2nd ACM international symposium on
	Mobile ad hoc networking \& computing},
  year = {2001},
  pages = {117--127},
  address = {New York, NY, USA},
  publisher = {ACM Press},
  isbn = {1-58113-428-2},
  location = {Long Beach, CA, USA},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{Papadopouli2001a,
  author = {Maria Papadopouli and Henning Schulzrinne},
  title = {Design and Implementation of a Peer-to-Peer Data Dissemination and
	Prefetching Tool for Mobile Users},
  booktitle = {Proceedings of the First NY Metro Area Networking Workshop},
  year = {2001},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{paperghost-2006,
  author = {Paperghost},
  title = {Myspace Phish Attack Leads Users to Zango Content},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://blog.spywareguide.com/2006/12/myspace_phish_attack_leads_use.html}
}

@INPROCEEDINGS{parekh2007,
  author = {Parekh, Bhavik and Cam, Hasan},
  title = {Minimizing False Alarms on Intrusion Detection for Wireless Sensor
	Networks in Realistic Environments},
  booktitle = {{IEEE MILCOM'07} Military Communications Conference},
  year = {2007},
  pages = {1-7},
  month = {Oct.},
  abstract = {Wireless sensor networks are expected to enhance the efficiency and
	to reduce the cost of target detection in area surveillance systems.
	In order to provide accurate reports for target detection and tracking
	in realistic environments, not only false alarms but also the impact
	of weather, terrain, and ground conditions on sensor readings should
	be taken into account. This paper addresses how to determine a false
	alarm threshold dynamically and efficiently in order to minimize
	the false alarm probability and to maximize the probability that
	no target passes through without being detected. In the proposed
	dynamic threshold scheme, the threshold changes in accordance with
	the false alarm rate. This results in a better detection probability
	and reduces the number of false alarms. The paper proposes to reduce
	the impact of noise by taking a weighted average of different sensing
	units' readings for the same target. The fact that sensing units
	of different types are affected at varying degrees by the environmental
	factors is exploited here. In addition to analytically characterizing
	false alarm rate and the role of reputation values, we provide simulation
	results to show the improvement on the target detection accuracy
	by the proposed scheme. A real world target detection case is considered
	and the false alarm probability is reduced by 25% when compared to
	a single sensor reading and by 17% when compared to an non-weighted
	averaged reading.},
  doi = {10.1109/MILCOM.2007.4455315},
  keywords = {wireless sensor networks, intrusion detection, threshold detection,
	dynamic threshold detection}
}

@INPROCEEDINGS{parno2006,
  author = {Bryan Parno and Mark Luk and Evan Gaustad and Adrian Perrig},
  title = {Secure Sensor Network Routing: A Clean-Slate Approach},
  booktitle = {{CoNEXT} -- 2nd Conference on Future Networking Technologies},
  year = {2006},
  address = {Lisboa, Portugal},
  month = {December},
  file = {parno2006.pdf:parno2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.01}
}

@INPROCEEDINGS{parno2005,
  author = {Parno, B. and Perrig, A. and Gligor, V.},
  title = {Distributed detection of node replication attacks in sensor networks},
  booktitle = {IEEE Symp. Security and Privacy},
  year = {2005},
  pages = {49--63},
  address = {Oakland, CA},
  month = {May},
  abstract = {The low-cost, off-the-shelf hardware components in unshielded sensor-network
	nodes leave them vulnerable to compromise. With little effort, an
	adversary may capture nodes, analyze and replicate them, and surreptitiously
	insert these replicas at strategic locations within the network.
	Such attacks may have severe consequences; they may allow the adversary
	to corrupt network data or even disconnect signiﬁcant parts of the
	network. Previous node replication detection schemes depend primarily
	on centralized mechanisms with single points of failure, or on neighborhood
	voting protocols that fail to detect distributed replications. To
	address these fundamental limitations, we propose two new algorithms
	based on emergent properties [17], i.e., properties that arise only
	through the collective action of multiple nodes. Randomized Multicast
	distributes node location information to randomly-selected witnesses,
	exploiting the birthday paradox to detect replicated nodes, while
	Line-Selected Multicast uses the topology of the network to detect
	replication. Both algorithms provide globally-aware, distributed
	node-replica detection, and Line-Selected Multicast displays particularly
	strong performance characteristics. We show that emergent algorithms
	represent a promising new approach to sensor network security; moreover,
	our results naturally extend to other classes of networks in which
	nodes can be captured, replicated and re-inserted by an adversary.},
  file = {parno2005.pdf:parno2005.pdf:PDF},
  keywords = {wireless networks, ad-hoc networks, security, wormhole attack prevention,
	node clone attack},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@MISC{Pasick2002,
  author = {Adam Pasick},
  title = {{LIVEWIRE} - File-sharing network thrives beneath the radar},
  howpublished = {[online] http://in.tech.yahoo.com/041103/137/2ho4i.html},
  month = {November 4},
  year = {2002},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://in.tech.yahoo.com/041103/137/2ho4i.html}
}

@INPROCEEDINGS{pathak2009,
  author = {Rohit Pathak and Satyadhar Joshi},
  title = {Secure Multi-party Computation Using Virtual Parties for Computation
	on Encrypted Data.},
  booktitle = {Advances in Information Security and Assurance, Third International
	Conference and Workshops},
  year = {2009},
  address = {Seoul, Korea},
  month = {June 25-27},
  file = {pathak2009.pdf:pathak2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@ARTICLE{patt-shamir-2007,
  author = {Patt-Shamir, Boaz},
  title = {A note on efficient aggregate queries in sensor networks},
  journal = {Theor. Comput. Sci.},
  year = {2007},
  volume = {370},
  pages = {254--264},
  number = {1-3},
  abstract = {We consider a scenario where nodes in a sensor network hold numeric
	items, and the task is to evaluate simple functions of the distributed
	data. In this note we present distributed protocols for computing
	the median with sublinear space and communication complexity per
	node. Specifically, we give a deterministic protocol for computing
	median with polylog complexity and a randomized protocol that computes
	an approximate median with polyloglog communication complexity per
	node. On the negative side, we observe that any deterministic protocol
	that counts the number of distinct data items must have linear complexity
	in the worst case.},
  address = {Essex, UK},
  doi = {http://dx.doi.org/10.1016/j.tcs.2006.10.032},
  file = {patt-shamir-2007.pdf:patt-shamir-2007.pdf:PDF},
  issn = {0304-3975},
  publisher = {Elsevier Science Publishers Ltd.}
}

@ARTICLE{paxson2001,
  author = {Vern Paxson},
  title = {An analysis of using reflectors for distributed denial-of-service
	attacks},
  journal = {SIGCOMM Comput. Commun. Rev.},
  year = {2001},
  volume = {31},
  pages = {38--47},
  number = {3},
  abstract = {Attackers can render distributed denial-of-service attacks more difficult
	to defend against by bouncing their flooding traffic off of reflectors;
	that is, by spoofing requests from the victim to a large set of Internet
	servers that will in turn send their combined replies to the victim.
	The resulting dilution of locality in the flooding stream complicates
	the victim's abilities both to isolate the attack traffic in order
	to block it, and to use traceback techniques for locating the source
	of streams of packets with spoofed source addresses, such as ITRACE
	[Be00a], probabilistic packet marking [SWKA00], [SP01], and SPIE
	[S+01]. We discuss a number of possible defenses against reflector
	attacks, finding that most prove impractical, and then assess the
	degree to which different forms of reflector traffic will have characteristic
	signatures that the victim can use to identify and filter out the
	attack traffic. Our analysis indicates that three types of reflectors
	pose particularly significant threats: DNS and Gnutella servers,
	and TCP-based servers (particularly Web servers) running on TCP implementations
	that suffer from predictable initial sequence numbers. We argue in
	conclusion in support of "reverse ITRACE" [Ba00] and for the utility
	of packet traceback techniques that work even for low volume flows,
	such as SPIE.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/505659.505664},
  file = {:p38-paxson.pdf:PDF},
  issn = {0146-4833},
  publisher = {ACM}
}

@ARTICLE{paxson1998,
  author = {Vern Paxson and Jamshid Mahdavi and Andrew Adams and Matt Mathis},
  title = {An Architecture for Large-Scale Internet Measurement},
  journal = {IEEE Communications},
  year = {1998},
  volume = {36},
  pages = {48--54},
  abstract = {Historically, the Internet has been woefully under-measured and under-instrumented.
	The problem is only getting worse with the network's ever-increasing
	size. We discuss the goals and requirements for building a "measurement
	infrastructure " for the Internet, in which a collection of measurement
	"platforms" cooperatively measure the properties of Internet paths
	and clouds by exchanging test traffic among themselves. The key emphasis
	of the architecture, which forms the underpinnings of the National
	Internet Measurement Infrastructure (NIMI) project, is on tackling
	problems related to scale. Consequently, the architecture emphasizes
	decentralized control of measurements; strong authentication and
	security; mechanisms for both maintaining tight administrative control
	over who can perform what measurements using which platforms, and
	delegation of some forms of measurement as a site's measurement policy
	permits; and simple configuration and maintenance of platforms.},
  file = {paxson1998.pdf:paxson1998.pdf:PDF}
}

@BOOK{peleg2000,
  title = {Distributed Computing: A Locality-Sensitive Approach (SIAM Monographs
	on Discrete Mathematics and Applications 5)},
  publisher = {Society for Industrial and Applied Mathematics {SIAM}},
  year = {2000},
  author = {David Peleg},
  abstract = {K},
  owner = {kristjan},
  timestamp = {2009.08.20}
}

@MISC{peng2008,
  author = {Dongsheng Peng and Weidong Liu and Chuang Lin and Zhen Chen and Jiaxing
	Song},
  title = {A Loosely Synchronized Gossip-Based Algorithm for Aggregate Information
	Computation},
  abstract = {Many P2P applications necessitate statistics aggregate computation
	of certain information among all individual peers. In contrast to
	methods of constructing aggregation tree, centralized computing and
	flooding, gossip-based mechanism has the advantages of good robustness
	and moderate communication and computing costs. Most algorithms of
	this type perform aggregate computation recursively on successive
	time slots called rounds. They require rounds to be globally synchronous
	on all the nodes, which complicates the algorithm realization. To
	eliminate the requirement for global round synchronization, we propose
	a loosely synchronized algorithm to compute global statistic average
	based on random event triggering mechanism, and prove that the convergence
	time is . We then propose a robust method to estimate the number
	of peers in the network based on this algorithm. Finally, a framework
	is proposed to generalize the computation of SUM, AVG, MAX, MIN,
	and CNT(N).},
  file = {peng2008.pdf:peng2008.pdf:PDF},
  keywords = {gossip protocol, peer-to-peer networks, aggregate computation, convergence
	time},
  owner = {kristjan},
  timestamp = {2010.05.03}
}

@MISC{Perkins1996,
  author = {C. Perkins},
  title = {RFC 2002: IP Mobility Support},
  year = {1996},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{perlman1985,
  author = {Radia Perlman},
  title = {An algorithm for distributed computation of a spanningtree in an
	extended LAN},
  journal = {{SIGCOMM} Comput. Commun. Rev.},
  year = {1985},
  volume = {15},
  pages = {44--53},
  number = {4},
  abstract = {A protocol and algorithm are given in which bridges in an extended
	Local Area Network of arbitrary topology compute, in a distributed
	fashion, an acyclic spanning subset of the network. The algorithm
	converges in time proportional to the diameter of the extended LAN,
	and requires a very small amount of memory per bridge, and communications
	bandwidth per LAN, independent of the total number of bridges or
	the total number of links in the network. Algorhyme I think that
	I shall never see A graph more lovely than a tree. A tree whose crucial
	property Is loop-free connectivity. A tree which must be sure to
	span So packets can reach every LAN. First the Root must be selected
	By ID it is elected. Least cost paths from Root are traced. In the
	tree these paths are placed. A mesh is made by folks like me Then
	bridges find a spanning tree.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/318951.319004},
  file = {perlman1985.pdf:perlman1985.pdf:PDF},
  issn = {0146-4833},
  keywords = {spanning tree protocol, STP, routing, link layer routing},
  publisher = {ACM}
}

@INPROCEEDINGS{perrig2001,
  author = {A. Perrig and R. Canetti and D. Song and J.D. Tygar},
  title = {Efficient and secure source authentication for multicast},
  booktitle = {{NDSS'01}},
  year = {2001},
  abstract = {One of the main challenges of securing multicast communication is
	source authentication, or enabling receivers of multicast data to
	verify that the received data originated with the claimed source
	and was not modiﬁed en-route. The problem becomes more complex in
	common settings where other receivers of the data are not trusted,
	and where lost packets are not retransmitted.
	
	
	 Several source authentication schemes for multicast have been suggested
	in the past, but none of these schemes is satisfactorily efﬁcient
	in all prominent parameters. We recently proposed a very efﬁcient
	scheme, TESLA, that is based on initial loose time synchronization
	between the sender and the receivers, followed by delayed release
	of keys by the sender.
	
	
	 This paper proposes several substantial modiﬁcations and improvements
	to TESLA. One modiﬁcation allows receivers to authenticate most packets
	as soon as they arrive (whereas TESLA requires buffering packets
	at the receiver side, and provides delayed authentication only).
	Other modiﬁcations improve the scalability of the scheme, reduce
	the space overhead for multiple instances, increase its resistance
	to denial-of-service attacks, and more.},
  file = {perrig2001.pdf:perrig2001.pdf:PDF},
  keywords = {TESLA, multicast source authentication},
  owner = {kristjan},
  timestamp = {2009.12.09}
}

@ARTICLE{perrig2002a,
  author = {Adrian Perrig and Sean Smith and Dawn Song and J. D. Tygar},
  title = {{SAM}: A Flexible and Secure Auction Architecture Using Trusted Hardware},
  journal = {Electronic Journal on E-commerce Tools and Applications},
  year = {2002},
  volume = {1},
  number = {1},
  abstract = {Increasing numbers of economic transactions are conducted through
	on-line auctions. Nevertheless, most current auction implementations
	fail to address important security concerns. In particular, most
	auction systems force buyers and sellers to trust the auctioneer;
	alternative secure systems are inﬂexible and have a high computational
	and/or communication overhead.
	
	
	 To overcome these limitations, we propose a secure auction marketplace
	(SAM) architecture, based on the recently available tool of high-performance,
	programmable secure coprocessors.
	
	
	 Unlike previous schemes, this approach provides a general framework
	that can incorporate arbitrary auction schemes by using different
	evaluation programs, as well as provide complex security properties
	by using the secure coprocessor and our auction protocols.
	
	
	 Our approach features strong security guarantees for the buyers and
	sellers without trusting the auctioneer, precise deﬁnition of the
	information disclosed during and after the auction, and high ﬂexibility
	to adapt to new types of auctions.},
  file = {perrig2001a.pdf:perrig2001a.pdf:PDF},
  keywords = {Secure auction architecture, secure coprocessor, TPM, trusted platform
	module},
  owner = {kristjan},
  timestamp = {2010.01.19}
}

@ARTICLE{perrig2004,
  author = {Adrian Perrig and John Stankovic and David Wagner},
  title = {Security in wireless sensor networks},
  journal = {Commun. ACM},
  year = {2004},
  volume = {47},
  pages = {53--57},
  number = {6},
  abstract = {They are susceptible to a variety of attacks, including node capture,
	physical tampering, and denial of service, while prompting a range
	of fundamental research challenges.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/990680.990707},
  file = {:p53-perrig.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM},
  review = {An accessible introduction to some security issues in sensor networks.
	Some of the issues are not that relevant in infrastructure-based
	aggregation networks, e.g.\ physical attack, node capture, power
	considerations and wireless attacks (like jamming nodes with a high-energy
	radio). Nevertheless, a lot of issues are relevant to this group
	and the paper can at least serve as a basis for issues to be studied.
	It is generally well written.
	
	
	Sensor networks are a special case of aggregation networks: They perform
	in-network processing and reduce great amounts of collected data
	to easily digested aggregates.
	
	
	The authors make an important point: Security should be considered
	at every step; each component of a system must be secured and security
	must be an integral part of system design.
	
	
	Some issues to consider:
	
	\begin{itemize}
	
	\item \textit{Key establishment and trust setup}. Public key cryptography
	difficult in sensor networks because of the computational load required
	and power considerations. No such problems in general for aggregation
	nodes. Random key predistribution protocols may be worth considering
	in the future \cite{eschenauer2002}.
	
	\item \textit{Secrecy and authentication}. Pretty much the same issues
	as above. Public v.s.\ private key cryptography. End-to-end, point-to-point
	and link-layer cryptography.
	
	\item \textit{Privacy}. Here they discuss the socio-political issues
	regarding sensor networks and how the information collected must
	be protected once these networks become prevalent. We should consider
	some of the same issues, including possibly the following: ways to
	anonimyze collected data, protecting local data on each node which
	it does not want to share. My feeling is that privacy issues can
	largely be ignored for our purposes at the present time.
	
	\item \textit{Robustness to communication denial of service.} Denial
	of service should of course be considered in every secure network.
	In the case of sensor networks, some new cvectors of attack exist,
	e.g.\ simply broadcasting a high-energy radio signal to jam the entire
	network. We probably do not have to worry about such issues in general.
	Interesting reference on increasing tolerance to ddos by routing
	around affected area \cite{wood2002}. DoS attacks against individual
	nodes are certainly a concern for our work.
	
	\item \textit{Secure routing} is perhaps not relevant as such to our
	work, but secure building of spanning trees as some similarities,
	right? Routing issues are discussed in \cite{Karlof2003}.
	
	\item \textit{Resilience to node capture} is probably not an issue
	as such for us. There are though some interesting points like using
	state replication and majority voting to detect inconsistencies in
	the network. Can we look at an insertion by a hostile node into an
	aggregation network as a kind of node capture?
	
	\item \textit{Secure group management} should certainly be considered
	in our context.
	
	\item \textit{Intrusion detection} should similarily be considered.
	Most of the currently used methods involve centralized solutions
	(IDS) or hybrids of HIDS/NIDS. Worth considering some form of distributed
	intrusion detection for our work?
	
	\item \textit{Secure data aggregation} is perhaps most important for
	our purposes. We have to trust the data being aggregated, or at least
	have a reasonable level of trust in the results. Random sampling
	(auditing?) of nodes for consistency is described in \cite{przydatek2003}
	and could be helpful for our work.
	
	\end{itemize}
	
	
	In summary, a decent high-level description of sensor network security
	with an accessible list of issues. Fairly few references.}
}

@ARTICLE{perrig2002,
  author = {Adrian Perrig and Robert Szewczyk and J. D. Tygar and Victor Wen
	and David E. Culler},
  title = {{SPINS}: security protocols for sensor networks},
  journal = {{Wirel. Netw.}},
  year = {2002},
  volume = {8},
  pages = {521--534},
  number = {5},
  abstract = {Wireless sensor networks will be widely deployed in the near future.
	While much research has focused on making these networks feasible
	and useful, security has received little attention. We present a
	suite of security protocols optimized for sensor networks: SPINS.
	SPINS has two secure building blocks: SNEP and µTESLA. SNEP includes:
	data conﬁdentiality, two-party data authentication, and evidence
	of data freshness. µTESLA provides authenticated broadcast for severely
	resource-constrained environments. We implemented the above protocols,
	and show that they are practical even on minimal hardware: the performance
	of the protocol suite easily matches the data rate of our network.
	Additionally, we demonstrate that the suite can be used for building
	higher level protocols.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1023/A:1016598314198},
  file = {perrig2002.pdf:perrig2002.pdf:PDF},
  issn = {1022-0038},
  keywords = {sensor network, security, encryption, authentication,, cryptography},
  publisher = {Kluwer Academic Publishers},
  review = {See also perrig2004 where this paper is referenced on bootstrapping
	cryptographic keys through a trusted base station.
	
	
	This paper discusses secure protocols for two-party communications
	and broadcasting. The protocols have very low overhead and are suitable
	for use in sensor networks and other resource constrained environments.
	Symmetric key cryptography is used throughout but the authors claim
	strong security properties, even for broadcast. For less resource
	constrained environments, consider the TESLA protocol by some of
	the same authors for authenticated broadcasting.
	
	
	Protocols:
	
	* SNEP -- confidentiality, two-party data authentication and evidence
	of data freshness.
	
	* mu-tesla -- authenticated broadcast for severely resource constrained
	environments.
	
	
	See also TESLA by perrig \cite{perrig2000}.}
}

@INPROCEEDINGS{perrig2000,
  author = {Perrig, Adrian and Tygar, J. D. and Song, Dawn and Canetti, Ran},
  title = {Efficient Authentication and Signing of Multicast Streams over Lossy
	Channels},
  booktitle = {{SP '00}: Proceedings of the 2000 IEEE Symposium on Security and
	Privacy},
  year = {2000},
  pages = {56},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Multicast stream authentication and signing is an important and challenging
	problem. Applications include the continuous authentication of radio
	and TV Internet broadcasts, and authenticated data distribution by
	satellite. The main challenges are fourfold. First, authenticity
	must be guaranteed even when only the sender of the data is trusted.
	Second, the scheme needs to scale to potentially millions of receivers.
	Third, streamed media distribution can have high packet loss. Finally,
	the system needs to be efficient to support fast packet rates.We
	propose two efficient schemes, TESLA and EMSS, for secure lossy multicast
	streams. TESLA, short for Timed Efficient Stream Loss-tolerant Authentication,
	offers sender authentication, strong loss robustness, high scalability,
	and minimal overhead, at the cost of loose initial time synchronization
	and slightly delayed authentication. EMSS, short for Efficient Multi-chained
	Stream Signature, provides non-repudiation of origin, high loss resistance,
	and low overhead, at the cost of slightly delayed verification.},
  file = {perrig2000.pdf:perrig2000.pdf:PDF},
  isbn = {0-7695-0665-8},
  keywords = {TESLA, multicast source authentication},
  review = {The TESLA multicast authentication protocol.}
}

@MISC{peter2007,
  author = {Steffen Peter and Krzysztof Piotrowski and Peter Langendoerfer},
  title = {On Concealed Data Aggregation for Wireless Sensor Networks},
  year = {2007},
  abstract = {In this paper we discuss algorithms that allow the concealed data
	aggregation (CDA) in wireless sensor networks. We describe and evaluate
	three algorithms that were reported to suit to the WSN scenario.
	As result of the evaluation, where we emphasize the awareness to
	potential attack scenarios, we present a brief overview of strengths
	and weaknesses of the algorithms. Since no algorithm provides all
	desirable goals, we propose two approaches to cope with the problems.
	The first is the successive combination of two algorithms. It increases
	security, while the additional efforts can be minimized by carefully
	selected parameters. For the second approach we face specific weaknesses
	and engineer mechanisms that solve the particular issues. With the
	considered homomorphic message authentication code and a discussion
	of the id-issue we exemplary evaluate the two biggest issues of the
	very promising CMT algorithm.},
  file = {peter2007.pdf:peter2007.pdf:PDF},
  keywords = {in-network aggregation, homomorphic encryption, concealed data aggregation},
  owner = {kristjan},
  review = {The paper addresses security of data in in-network aggregation. No
	end-to-end security (in the classic approaches) and hop by hop encryption
	requires decryption/encryption by each intermediary node. 
	
	
	CDA: Combines end-to-end security and in-network aggregation. Aggregation
	performed on encrypted values, which only the root can decrypt. Reduces
	computaitonal effort in-network since the need to repeatedly decrypt/encrypt
	is removed. Adversaries (within network) are not able to watch the
	values. 
	
	
	CDA based on privacy homomorphisms. Additive PHs used in in-network
	aggregation. Many requre very large messages and computational effort.
	Suitable ones include
	
	* Domingo-Ferrer DFPH \cite{domingo-ferrer-2002} used in WSN by \cite{Girao2005}.
	Note: The authors discuss the vulnerabilities of this protocol against
	known plaintext attacks \cite{wagner2003}.
	
	* CMT stream based PH \cite{castelluccia2005}. Problem: Decryption
	requires the exact same keystream.
	
	* Elliptic-curve ElGamal ECEG. Asymmetric (in contrast to the other
	two). See also \cite{mykletun2006} on this.
	
	
	Vulnerabilities of the PH algorithms:
	
	* DFPH vulnerable to known plaintext attacks \cite{wagner2003}.
	
	* CMT is the only of the three to resist replay attacks
	
	* CMT and ECEG malleable -- an adversary can modify packets without
	detection and w/o knowing the plaintext. 
	
	* CMT the only one to be secure against unauthorized aggregation --
	attacks which combine a (captured?) ciphertext with aggregation packets.
	
	* DFPH and CMT resistant on forged packets as the keys to the encryption
	process are hidden.
	
	* Symmetric key approaches with common keys vulnerable to node capture
	attacks.
	
	
	Peter et.al recommend combining PHs to cancel out weaknesses. Do however
	observe that the CMT appears to be the most promising PH.},
  timestamp = {2010.01.17}
}

@ARTICLE{peter2008,
  author = {Steffen Peter and Dirk Westhoff and Claude Castelluccia},
  title = {A Survey on the Encryption of Convergecast-Traffic with In-Network
	Processing},
  journal = {{IEEE} Transactions on Dependable and Secure Computing},
  year = {2008},
  volume = {99},
  number = {RapidPosts},
  abstract = {We present an overview of end-to-end encryption solutions for convergecast-traffic
	in wireless sensor networks that support in-network processing at
	forwarding intermediate nodes. Other than hop-by-hop based encryption
	approaches, aggregator nodes can perform in-network processing on
	encrypted data. Since it is not required to decrypt the incoming
	ciphers before aggregating substantial advantages are i) neither
	keys nor plaintext is available at aggregating nodes, ii) the overall
	energy consumption of the backbone can be reduced, iii) the system
	is more flexible with respect to changing routes, and finally iv)
	the overall system security increases. We provide a qualitative comparison
	of available approaches, point out their strengths respectively weaknesses
	and investigate opportunities for further research.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TDSC.2008.23},
  file = {peter2008.pdf:peter2008.pdf:PDF},
  issn = {1545-5971},
  keywords = {Sensor networks, Security and Privacy Protection},
  publisher = {IEEE Computer Society}
}

@BOOK{Peterson2003,
  title = {Computer Networks. A systems approach.},
  publisher = {Morgan Kaufman Publishers},
  year = {2003},
  author = {Larry L. Peterson and Bruce S. Davie},
  edition = {Edition 3.},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{petrovic2003,
  author = {Dragan Petrovi\'{c} and Rahul C. Shah and Kannan Ramch and Jan Rabaey},
  title = {Data funneling: routing with aggregation and compression for wireless
	sensor networks},
  booktitle = {{IEEE} Sensor Netwrok Protocols and Applications {SPNA}},
  year = {2003},
  pages = {156--162},
  abstract = {This paper considers the problem of minimizing the amount of communication
	needed to send readings from a set of sensors to a single destination
	in energy constrained wireless networks. Substantial gains can be
	obtained using packet aggregation techniques while routing. The proposed
	routing algorithm, called Data Funneling, allows the network to considerably
	reduce the amount of energy spent on communication setup and control,
	an important concern in low data-rate communication. This is achieved
	by sending only one data stream from a group of sensors to the destination
	instead of having an individual data stream from each sensor to the
	destination. Doing so also reduces the probability of packet collisions
	in the wireless medium because the same amount of information can
	be transmitted by having fewer nodes send longer packets. Additional
	gains can be realized by efficient compression of data. This is achieved
	by losslessly compressing the data by encoding information in the
	ordering of the sensors’ packets. This “coding by ordering ” scheme
	compresses data by suppressing certain readings and encoding their
	values in the ordering of the remaining packets. Using these techniques
	together can more than halve the energy spent in communication.},
  file = {petrovic2003.pdf:petrovic2003.pdf:PDF},
  keywords = {sensor network, distributed aggregation, energy efficiency},
  review = {highly referenced}
}

@ARTICLE{pham1998,
  author = {Vu Anh Pham and Karmouch, A.},
  title = {Mobile software agents: an overview},
  journal = {Communications Magazine, IEEE},
  year = {1998},
  volume = {36},
  pages = {26-37},
  number = {7},
  month = {Jul},
  abstract = {The anticipated increase in popular use of the Internet will create
	more opportunities in distance learning, electronic commerce, and
	multimedia communication, but it will also create more challenges
	in organizing information and facilitating its efficient retrieval.
	From the network perspective, there will be additional challenges
	and problems in meeting bandwidth requirements and network management.
	Many researchers believed that the mobile agent paradigm (mobile
	object) could propose several attractive solutions to deal with such
	challenges and problems. A number of mobile agent systems have been
	designed and implemented in academic institutions and commercial
	firms. However, few applications were found to take advantage of
	the mobile agent. Among the hurdles facing this emerging paradigm
	are concerns about security requirements and efficient resource management.
	This article introduces the core concepts of this emerging paradigm,
	and presents an account of current research efforts in the context
	of telecommunications. The goal is to provide the interested reader
	with a clear background of the opportunities and challenges this
	emerging paradigm brings about, and a descriptive look at some of
	the forerunners that are providing experimental technologies supporting
	this paradigm},
  doi = {10.1109/35.689628},
  issn = {0163-6804},
  keywords = {Internet, computer network management, intelligent networks, security
	of data, software agents, telecommunication computingInternet, bandwidth
	requirements, distance learning, electronic commerce, experimental
	technologies, information retrieval, intelligent network, mobile
	object, mobile software agents, multimedia communication, network
	management, resource management, security, telecommunications},
  owner = {kristjan},
  timestamp = {2009.03.10},
  url = {http://www.comsoc.org/ci/private/1998/jul/Karmouch.html}
}

@INPROCEEDINGS{picconi2006,
  author = {Picconi, Fabio and Ravi, Nishkam and Gruteser, Marco and Iftode,
	Liviu},
  title = {Probabilistic validation of aggregated data in vehicular ad-hoc networks},
  booktitle = {{VANET} '06: Proceedings of the 3rd international workshop on Vehicular
	ad hoc networks},
  year = {2006},
  pages = {76--85},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {Vehicular ad-hoc networks present great opportunity for information
	exchange and equal opportunity for abuse. Validating traffic information
	without imposing significant communication overheads is a hard problem.
	In this paper, we propose a solution for validating aggregated data.
	The main idea is to use random checks to probabilistically catch
	the attacker, and thereby discourage attacks in the network. Our
	solution relies on PKI based authentication and assumes a tamper-proof
	service in each car to carry out certain secure operations such as
	signing and timestamping. We try to keep the set of secure operations
	as small as possible, in accordance with the principle of economy
	of mechanism. We show that our solution provides security without
	significant communication overheads.},
  doi = {http://doi.acm.org/10.1145/1161064.1161077},
  file = {picconi2006.pdf:picconi2006.pdf:PDF},
  isbn = {1-59593-540-1},
  location = {Los Angeles, CA, USA}
}

@MISC{pixley2000,
  author = {Tom Pixley},
  title = {{Document Object Model (DOM) Level 2 Events Specification (Version
	1.0)}},
  howpublished = {http://www.w3.org/TR/DOM-Level-2-Events/},
  year = {2000},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://www.w3.org/TR/DOM-Level-2-Events/}
}

@ARTICLE{poovendran2007,
  author = {Radha Poovendran and Loukas Lazos},
  title = {A graph theoretic framework for preventing the wormhole attack in
	wireless ad hoc networks},
  journal = {Wireless Networks},
  year = {2007},
  volume = {13},
  pages = {27-59},
  number = {1},
  abstract = {Wireless ad hoc networks are envisioned to be randomly deployed in
	versatile and potentially hostile environments. Hence, providing
	secure and uninterrupted communication between the un-tethered network
	nodes becomes a critical problem. In this paper, we investigate the
	wormhole attack in wireless ad hoc networks, an attack that can disrupt
	vital network functions such as routing. In the wormhole attack,
	the adversary establishes a low-latency unidirectional or bi-directional
	link, such as a wired or long-range wireless link, between two points
	in the network that are not within communication range of each other.
	The attacker then records one or more messages at one end of the
	link, tunnels them via the link to the other end, and replays them
	into the network in a timely manner. The wormhole attack is easily
	implemented and particularly challenging to detect, since it does
	not require breach of the authenticity and confidentiality of communication,
	or the compromise of any host. We present a graph theoretic framework
	for modeling wormhole links and derive the necessary and sufficient
	conditions for detecting and defending against wormhole attacks.
	Based on our framework, we show that any candidate solution preventing
	wormholes should construct a communication graph that is a subgraph
	of the geometric graph defined by the radio range of the network
	nodes. Making use of our framework, we propose a cryptographic mechanism
	based on local broadcast keys in order to prevent wormholes. Our
	solution does not need time synchronization or time measurement,
	requires only a small fraction of the nodes to know their location,
	and is decentralized. Hence, it is suitable for networks with the
	most stringent constraints such as sensor networks. Finally, we believe
	our work is the first to provide an analytical evaluation in terms
	of probabilities of the extent to which a method prevents wormholes.},
  file = {poovendran2007.pdf:poovendran2007.pdf:PDF},
  keywords = {Wormhole attack - Security - Wireless ad hoc networks - Geometric
	random graphs},
  owner = {kristjan},
  timestamp = {2010.01.15}
}

@TECHREPORT{prieto2009,
  author = {Alberto Gonzalez Prieto and Rolf Stadler},
  title = {Controlling Performance Trade-offs in Adaptive Network Monitoring},
  institution = {Royal Institute of Technology (KTH)},
  year = {2009},
  number = {IR-EE-LCN-2009-001},
  address = {Stockholm, Sweden},
  abstract = {A key requirement for autonomic (i.e., self-*) management systems
	is a short adaptation time to changes in the networking conditions.
	In this paper, we show that the adaptation time of a distributed
	monitoring protocol can be controlled. We show this for A-GAP, a
	protocol for continuous monitoring of global metrics with controllable
	accuracy. We demonstrate through simulations that, for the case of
	A-GAP, the choice of the topology of the aggregation tree controls
	the trade-off between adaptation time and protocol overhead in steady-state.
	Generally, allowing a larger adaptation time permits reducing the
	protocol overhead. Our results suggest that the adaptation time primarily
	depends on the height of the aggregation tree and that the protocol
	overhead is strongly influenced by the number of internal nodes.
	We outline how A-GAP can be extended to dynamically self-configure
	and to continuously adapt its configuration to changing conditions,
	in order to meet a set of performance objectives, including adaptation
	time, protocol overhead, and estimation accuracy.},
  file = {prieto2009.pdf:prieto2009.pdf:PDF},
  keywords = {Adaptive management, real-time monitoring, large-scale distributed
	systems},
  owner = {kristjan},
  timestamp = {2008.09.04}
}

@ARTICLE{prieto2007,
  author = {Alberto Gonzalez Prieto and Rolf Stadler},
  title = {{A-GAP}: An Adaptive Protocol for Continuous Network Monitoring with
	Accuracy Objectives},
  journal = {{IEEE Trans. on Network and Service Management}},
  year = {2007},
  abstract = {We present A-GAP, a novel protocol for continuous monitoring of network
	state variables, which aims at achieving a given monitoring accuracy
	with minimal overhead. Network state variables are computed from
	device counters using aggregation functions, such as SUM, AVERAGE
	and MAX. The accuracy objective is expressed as the average estimation
	error. A-GAP is decentralized and asynchronous to achieve robustness
	and scalability. It executes on an overlay that interconnects management
	processes on the devices. On this overlay, the protocol maintains
	a spanning tree and updates the network state variables through incremental
	aggregation. Based on a stochastic model, it dynamically configures
	local filters that control whether an update is sent towards the
	root of the tree. We evaluate A-GAP through simulation using real
	traces and two different types of topologies of up to 650 nodes.
	The results show that we can effectively control the trade-off between
	accuracy and protocol overhead, and that the overhead can be reduced
	by almost two orders of magnitude when allowing for small errors.
	The protocol quickly adapts to a node failure and exhibits short
	spikes in the estimation error. Lastly, it can provide an accurate
	estimate of the error distribution in real-time.},
  file = {TRITA-EE_2006_034.pdf:TRITA-EE_2006_034.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.04}
}

@INPROCEEDINGS{provos2003,
  author = {Niels Provos},
  title = {A Virtual Honeypot Framework},
  booktitle = {13th {USENIX} Security Symposium},
  year = {2003},
  pages = {1--14},
  abstract = {A honeypot is a closely monitored network decoy serving several purposes:
	it can distract adversaries from more valuable machines on a network,
	can provide early warning about new attack and exploitation trends,
	or allow in-depth examination of adversaries during and after exploitation
	of a honeypot. Deploying a physical honeypot is often time intensive
	and expensive as di#erent operating systems require specialized hardware
	and every honeypot requires its own physical system. This paper presents
	Honeyd, a framework for virtual honeypots that simulates virtual
	computer systems at the network level. The simulated computer systems
	appear to run on unallocated network addresses. To deceive network
	fingerprinting tools, Honeyd simulates the networking stack of di#erent
	operating systems and can provide arbitrary routing topologies and
	services for an arbitrary number of virtual systems. This paper discusses
	Honeyd's design and shows how the Honeyd framework helps in many
	areas of system security, e.g. detecting and disabling worms, distracting
	adversaries, or preventing the spread of spam email.},
  file = {provos2003.pdf:provos2003.pdf:PDF}
}

@INPROCEEDINGS{przydatek2003,
  author = {Bartosz Przydatek and Dawn Song and Adrian Perrig},
  title = {{SIA: Secure Information Aggregation in Sensor Networks}},
  booktitle = {{SenSys '03: Proceedings of the 1st international conference on Embedded
	networked sensor systems}},
  year = {2003},
  pages = {255--265},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Sensor networks promise viable solutions to many monitoring problems.
	However, the practical deployment of sensor networks faces many challenges
	imposed by real-world demands. Sensor nodes often have limited computation
	and communication resources and battery power. Moreover, in many
	applications sensors are deployed in open environments, and hence
	are vulnerable to physical attacks, potentially compromising the
	sensor’s cryptographic keys. 
	
	One of the basic and indispensable functionalities of sensor networks
	is the ability to answer queries over the data acquired by the sensors.
	The resource constraints and security issues make designing mechanisms
	for information aggregation in large sensor networks particularly
	challenging.
	
	 In this paper, we propose a novel framework for secure information
	aggregation in large sensor networks. In our framework certain nodes
	in the sensor network, called aggregators, help aggregating information
	requested by a query, which substantially reduces the communication
	overhead. By constructing efﬁcient random sampling mechanisms and
	interactive proofs, we enable the user to verify that the answer
	given by the aggregator is a good approximation of the true value
	even when the aggregator and a fraction of the sensor nodes are corrupted.
	In particular, we present efﬁcient protocols for secure computation
	of the median and the average of the measurements, for the estimation
	of the network size, and for ﬁnding the minimum and maximum sensor
	reading. Our protocols require only sublinear communication between
	the aggregator and the user. To the best of our knowledge, this paper
	is the ﬁrst on secure information aggregation in sensor networks
	that can handle a malicious aggregator and sensor nodes.},
  doi = {http://doi.acm.org/10.1145/958491.958521},
  file = {:p255-przydatek.pdf:PDF},
  isbn = {1-58113-707-9},
  location = {Los Angeles, California, USA},
  review = {See ref by perrig2004 on randomly sampling a fraction of the population
	to verify correct behavior. Redundancy to increase resilience? CHECK.
	
	See later journal paper chan2007.
	
	
	Single aggregator model. The objective is to prevent malicious aggregator
	behavior.
	
	Aggregate-commit-prove approach. Cryptographic commitments by leafs
	are combined by aggregator in a Merkle hash tree. The querier (verifier)
	engages in an interactive proof session with the aggregator (prover)
	to probabilistically prove proper behavior.
	
	
	Secure median and other functions (see Wagner for comparison). Mention
	hierarchial aggregation very briefly.}
}

@MISC{online-python,
  author = {{Python Software Foundation}},
  title = {{Python Programming Language -- Official Website}},
  year = {2008},
  owner = {kristjan},
  timestamp = {2008.09.22},
  url = {http://www.python.org/}
}

@ARTICLE{rajagopalan2006,
  author = {Rajagopalan, R. and Varshney, P.K.},
  title = {Data-aggregation techniques in sensor networks: a survey},
  journal = {{Communications Surveys \& Tutorials, IEEE}},
  year = {2006},
  volume = {8},
  pages = {48-63},
  number = {4},
  month = {Quarter },
  abstract = {Wireless sensor networks consist of sensor nodes with sensing and
	communication capabilities. We focus on data-aggregation problems
	in energy constrained sensor networks. The main goal of data-aggregation
	algorithms is to gather and aggregate data in an energy efficient
	manner so that network lifetime is enhanced. In this article we present
	a survey of data-aggregation algorithms in wireless sensor networks.
	We compare and contrast different algorithms on the basis of performance
	measures such as lifetime, latency, and data accuracy. We conclude
	with possible future research directions.},
  doi = {10.1109/COMST.2006.283821},
  file = {rajagopalan2006.pdf:rajagopalan2006.pdf:PDF},
  issn = {1553-877X},
  keywords = {sensor networks, aggregation, survey}
}

@INPROCEEDINGS{ramaswamy2000,
  author = {Sridhar Ramaswamy and Rajeev Rastogi and Kyuseok Shim},
  title = {Efficient algorithms for mining outliers from large data sets},
  booktitle = {SIGMOD '00: Proceedings of the 2000 ACM SIGMOD international conference
	on Management of data},
  year = {2000},
  pages = {427--438},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we propose a novel formulation for distance-based outliers
	that is based on the distance of a point from its kth nearest neighbor.
	We rank each point on the basis of its distance to its kth nearest
	neighbor and declare the top n points in this ranking to be outliers.
	In addition to developing relatively straightforward solutions to
	finding such outliers based on the classical nested-loop join and
	index join algorithms, we develop a highly efficient partition-based
	algorithm for mining outliers. This algorithm first partitions the
	input data set into disjoint subsets, and then prunes entire partitions
	as soon as it is determined that they cannot contain outliers. This
	results in substantial savings in computation. We present the results
	of an extensive experimental study on real-life and synthetic data
	sets. The results from a real-life NBA database highlight and reveal
	several expected and unexpected aspects of the database. The results
	from a study on synthetic data sets demonstrate that the partition-based
	algorithm scales well with respect to both data set size and data
	set dimensionality.},
  doi = {http://doi.acm.org/10.1145/342009.335437},
  file = {p427-ramaswamy.pdf:p427-ramaswamy.pdf:PDF},
  isbn = {1-58113-217-4},
  location = {Dallas, Texas, United States}
}

@PHDTHESIS{rappe2004,
  author = {Rappe},
  title = {Homomorphic cryptosystems and their applications},
  school = {University of Dortmund},
  year = {2004},
  address = {Dortmund, Germany},
  __markedentry = {[kristjan]},
  file = {rappe2004.pdf:rappe2004.pdf:PDF},
  keywords = {security, cryptography, homomorphic encryption, privacy homomorphisms},
  owner = {kristjan},
  review = {Applications of homomorphic crypto to MPC.},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{ratnasamy2001,
  author = {Sylvia Ratnasamy and Paul Francis and Mark Handley and Richard Karp
	and Scott Schenker},
  title = {A scalable content-addressable network},
  booktitle = {{SIGCOMM} '01: Proceedings of the 2001 conference on Applications,
	technologies, architectures, and protocols for computer communications},
  year = {2001},
  pages = {161--172},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Hash tables – which map “keys” onto “values” – are an essential building
	block in modern software systems. We believe a similar functionality
	would be equally valuable to large distributed systems. In this paper,
	we introduce the concept of a Content-Addressable Network (CAN) as
	a distributed infrastructure that provides hash table-like functionality
	on Internet-like scales. The CAN is scalable, fault-tolerant and
	completely self-organizing, and we demonstrate its scalability, robustness
	and low-latency properties through simulation.},
  doi = {http://doi.acm.org/10.1145/383059.383072},
  file = {ratnasamy2001.pdf:ratnasamy2001.pdf:PDF},
  isbn = {1-58113-411-8},
  keywords = {CAN, DHTs, peer-to-peer systems},
  location = {San Diego, California, United States}
}

@INPROCEEDINGS{raya2006,
  author = {Raya, Maxim and Aziz, Adel and Hubaux, Jean-Pierre},
  title = {Efficient secure aggregation in {VANETs}},
  booktitle = {{VANET} '06: Proceedings of the 3rd international workshop on Vehicular
	ad hoc networks},
  year = {2006},
  pages = {67--75},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  abstract = {In VANETs, better communication efficiency can be achieved by sacrificing
	security and vice versa. But VANETs cannot get started without either
	of them. In this paper, we propose a set of mechanisms that can actually
	reconcile these two contradictory requirements. The main idea is
	to use message aggregation and group communication. The first class
	of solutions is based on asymmetric cryptographic primitives, the
	second class uses symmetric ones, and the third one mixes the two.
	We have also evaluated the performance potential of one technique
	and arrived at the conclusion that aggregation in VANETs increases
	not only efficiency but also security.},
  doi = {http://doi.acm.org/10.1145/1161064.1161076},
  file = {raya2006.pdf:raya2006.pdf:PDF},
  isbn = {1-59593-540-1},
  keywords = {VANET, secure aggregation},
  location = {Los Angeles, CA, USA},
  review = {In-network aggregation in terms of VANETs.
	
	
	Concatenated and onion signatures over groups. Assumes majority of
	honest nodes in any given group.}
}

@ARTICLE{reed1998,
  author = {Michael G. Reed and Paul F. Syverson and David M. Goldschlag},
  title = {Anonymous Connections and Onion Routing},
  journal = {{IEEE} Journal on Selected Areas in Communication. Special Issue
	on Copyright and Privacy Protection},
  year = {1998},
  file = {:onion-routing-JSAC-1998.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.09}
}

@ARTICLE{reis2007,
  author = {Charles Reis and John Dunagan and Helen J. Wang and Opher Dubrovsky
	and Saher Esmeir},
  title = {BrowserShield: Vulnerability-driven filtering of dynamic HTML},
  journal = {ACM Trans. Web},
  year = {2007},
  volume = {1},
  pages = {11},
  number = {3},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1281480.1281481},
  file = {reis2007.pdf:reis2007.pdf:PDF},
  issn = {1559-1131},
  publisher = {ACM}
}

@INPROCEEDINGS{reiter1995,
  author = {Reiter, Michael K.},
  title = {The Rampart Toolkit for Building High-Integrity Services},
  booktitle = {Selected Papers from the International Workshop on Theory and Practice
	in Distributed Systems},
  year = {1995},
  pages = {99--110},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {Abstract. Rampart is a toolkit of protocols to facilitate the development
	of high-integrity services, i.e., distributed services that retain
	their availability and correctness despite the malicious penetration
	of some component servers by an attacker. At the core of Rampart
	are new protocols that solve several basic problems in distributed
	computing, including asynchronous group membership, reliable multicast
	(Byzantine agreement), and atomic multicast. Using these protocols,
	Rampart supports the development of high-integrity services via the
	technique of state machine replication, and also extends this technique
	with a new approach to server output voting. In this paper we give
	a brief overview of Rampart, focusing primarily on its protocol architecture.
	We also sketch its performance in our prototype implementation and
	ongoing work.},
  file = {reiter1995.pdf:reiter1995.pdf:PDF},
  isbn = {3-540-60042-6}
}

@MISC{resnick_rfc_2822_2001,
  author = {P. Resnick},
  title = {{RFC 2822}: Internet Message Format},
  month = {April},
  year = {2001},
  abstract = {This standard specifies a syntax for text messages that are sent between
	computer users, within the framework of "electronic mail" messages.
	This standard supersedes the one specified in Request For Comments
	(RFC) 822, "Standard for the Format of ARPA Internet Text Messages",
	updating it to reflect current practice and incorporating incremental
	changes that were specified in other RFCs.},
  owner = {kristjan},
  timestamp = {2009.02.11},
  url = {http://www.faqs.org/rfcs/rfc2822.html}
}

@ARTICLE{resnick2000,
  author = {Paul Resnick and Richard Zeckhauser and Eric Friedman and Ko Kuwabara},
  title = {Reputation Systems: Facilitating Trust in Internet Interactions},
  journal = {Commun. ACM},
  year = {2000},
  volume = {43},
  pages = {45--48},
  file = {resnick2000.pdf:resnick2000.pdf:PDF},
  keywords = {reputation systems, survey},
  owner = {kristjan},
  timestamp = {2010.05.20}
}

@ARTICLE{riaz2008,
  author = {Riaz, Rabia and Naureen, Ayesha and Akram, Attiya and Akbar, Ali
	Hammad and Kim, Ki-Hyung and Farooq Ahmed, H.},
  title = {A unified security framework with three key management schemes for
	wireless sensor networks},
  journal = {Comput. Commun.},
  year = {2008},
  volume = {31},
  pages = {4269--4280},
  number = {18},
  abstract = {Pervasive computing environments find their practical manifestations
	through wireless sensor networks, which sense a relationship amongst
	themselves and the environment. Currently the proposed keying schemes
	for ensuring security, in wireless sensor networks, may be classified
	into public and private keying schemes, or their hybrid. However,
	an investigation in peer work underpins the fact that neither of
	these works relates the key management schemes with the granularity
	of key generation, distribution, renewal, and revocation. In this
	paper, we propose a unified security framework with three key management
	schemes, SACK, SACK-P, and SACK-H that incorporate symmetric key
	cryptography, asymmetric key cryptography and the hybrid, respectively.
	We have evaluated the key management schemes against a broad range
	of metrics such as energy, resource utilization, scalability and
	resilience to node compromises. Our evaluation comprises both analytical
	investigation and experimental validation. The results show that
	though SACK-P is heavy on resources, it provides maximal security
	and offers the best resilience to node compromises. On the contrary,
	SACK is very efficient in terms of storage and communication. Our
	results substantiate a relationship between the level of security
	and resource utilization and form a design benchmark for security
	frameworks.},
  address = {Newton, MA, USA},
  doi = {http://dx.doi.org/10.1016/j.comcom.2008.05.043},
  issn = {0140-3664},
  publisher = {Butterworth-Heinemann}
}

@INCOLLECTION{richardson2003,
  author = {Richardson, M. and Agrawal, R. and Doningos, P.},
  title = {Trust management for the semantic web},
  booktitle = {The SemanticWeb - ISWC 2003},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  volume = {Volume 2870/2003},
  pages = {351-368},
  month = {September},
  file = {richardson2003.pdf:richardson2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@MISC{Rijmen2005,
  author = {Vincent Rijmen and Elisabeth Oswald},
  title = {Update on {SHA-1}},
  howpublished = {{Cryptology ePrint Archive}, Report 2005/010},
  year = {2005},
  note = {\url{http://eprint.iacr.org/}},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@MISC{rivest1992,
  author = {R. Rivest},
  title = {{RFC} 1321: The {MD5} Message-Digest Algorithm},
  month = {April},
  year = {1992},
  abstract = {This document describes the MD5 message-digest algorithm. The algorithm
	takes as input a message of arbitrary length and produces as output
	a 128-bit "fingerprint" or "message digest" of the input. It is conjectured
	that it is computationally infeasible to produce two messages having
	the same message digest, or to produce any message having a given
	prespecified target message digest. The MD5 algorithm is intended
	for digital signature applications, where a large file must be "compressed"
	in a secure manner before being encrypted with a private (secret)
	key under a public-key cryptosystem such as RSA.
	
	
	 The MD5 algorithm is designed to be quite fast on 32-bit machines.
	In addition, the MD5 algorithm does not require any large substitution
	tables; the algorithm can be coded quite compactly.
	
	
	 The MD5 algorithm is an extension of the MD4 message-digest algorithm
	1,2]. MD5 is slightly slower than MD4, but is more "conservative"
	in design. MD5 was designed because it was felt that MD4 was perhaps
	being adopted for use more quickly than justified by the existing
	critical review; because MD4 was designed to be exceptionally fast,
	it is "at the edge" in terms of risking successful cryptanalytic
	attack. MD5 backs off a bit, giving up a little in speed for a much
	greater likelihood of ultimate security. It incorporates some suggestions
	made by various reviewers, and contains additional optimizations.
	The MD5 algorithm is being placed in the public domain for review
	and possible adoption as a standard.
	
	
	 For OSI-based applications, MD5's object identifier is
	
	
	 md5 OBJECT IDENTIFIER ::= iso(1) member-body(2) US(840) rsadsi(113549)
	digestAlgorithm(2) 5
	
	
	 In the X.509 type AlgorithmIdentifier [3], the parameters for MD5
	should have type NULL.},
  owner = {kristjan},
  timestamp = {2009.09.09},
  url = {http://www.faqs.org/rfcs/rfc1321.html}
}

@INCOLLECTION{rivest1978a,
  author = {R. Rivest and L. Adleman and M. Dertouzos},
  title = {On data banks and privacy homomorphisms},
  booktitle = {Foundations of Secure Computation},
  publisher = {Academic Press},
  year = {1978},
  pages = {169–177},
  file = {rivest1978a.pdf:rivest1978a.pdf:PDF},
  owner = {kristjan},
  review = {see sorniotti on background. 
	
	
	Seminal work in homomorphic encryption -- coined the privacy homomorphism
	term (?)
	
	
	Rivest et al considered to have defined privacy homomorphisms in this
	work. 
	
	Later broken by \cite{brickell1987}.
	
	
	See note by blass2008 on most types of comparisons on encrypted data
	being infeasible according to this work.},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{rivest1995,
  author = {Ronald L. Rivest},
  title = {The RC5 Encryption Algorithm},
  year = {1995},
  pages = {86--96},
  publisher = {Springer-Verlag},
  file = {rivest1995.pdf:rivest1995.pdf:PDF},
  keywords = {cryptography, RC5, resource constrained systems}
}

@MISC{rivest1996,
  author = {Ronald L. Rivest and Butler Lampson},
  title = {{SDSI - A Simple Distributed Security Infrastructure}},
  howpublished = {http://people.csail.mit.edu/rivest/sdsi11.html},
  month = {October},
  year = {1996},
  abstract = {We propose a new distributed security infrastructure, called SDSI
	(pronounced ``Sudsy''). SDSI combines a simple public-key infrastructure
	design with a means of defining groups and issuing group-membership
	certificates. SDSI's groups provides simple, clear terminology for
	defining access-control lists and security policies. SDSI's design
	emphasizes linked local name spaces rather than a hierarchical global
	name space.},
  file = {:SDSI.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.10},
  url = {http://people.csail.mit.edu/rivest/sdsi11.html}
}

@ARTICLE{rivest1978,
  author = {Rivest, R. L. and Shamir, A. and Adleman, L.},
  title = {A method for obtaining digital signatures and public-key cryptosystems},
  journal = {Commun. ACM},
  year = {1978},
  volume = {21},
  pages = {120--126},
  number = {2},
  abstract = {An encryption method is presented with the novel property that publicly
	revealing an encryption key does not thereby reveal the corresponding
	decryption key. This has two important consequences: (1) Couriers
	or other secure means are not needed to transmit keys, since a message
	can be enciphered using an encryption key publicly revealed by the
	intended recipient. Only he can decipher the message, since only
	he knows the corresponding decryption key. (2) A message can be "signed"
	using a privately held decryption key. Anyone can verify this signature
	using the corresponding publicly revealed encryption key. Signatures
	cannot be forged, and a signer cannot later deny the validity of
	his signature. This has obvious applications in "electronic mail"
	and "electronic funds transfer" systems. A message is encrypted by
	representing it as a number M, raising M to a publicly specified
	power e, and then taking the remainder when the result is divided
	by the publicly specified product, n, of two large secret prime numbers
	p and q. Decryption is similar; only a different, secret, power d
	is used, where e * d ------l(mod (p - 1) * (q - 1)). The security
	of the system rests in part on the difficulty of factoring the published
	divisor, n.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/359340.359342},
  file = {rivest1978.pdf:rivest1978.pdf:PDF},
  issn = {0001-0782},
  keywords = {cryptography, homomorphic encryption, RSA},
  publisher = {ACM}
}

@ARTICLE{rizzo1997,
  author = {Luigi Rizzo},
  title = {Dummynet: A simple approach to the evaluation of network protocols},
  journal = {ACM Computer Communication Review},
  year = {1997},
  volume = {27},
  pages = {31--41},
  abstract = {Network protocols are usually tested in operational networks or in
	simulated environments. With the former approach it is not easy to
	set and control the various operational parameters such as bandwidth,
	delays, queue sizes. Simulators are easier to control, but they are
	often only an approximate model of the desired setting, especially
	for what regards the various traffic generators (both producers and
	consumers) and their interaction with the protocol itself.
	
	 In this paper we show how a simple, yet exible and accurate network
	simulator -- dummynet -- can be built with minimal modi cations to
	an existing protocol stack, allowing experiments to be run on a standalone
	system. dummynet works by intercepting communications of the protocol
	layer under test and simulating the e ects of nite queues, bandwidth
	limitations and communication delays. It runs in a fully operational
	system, hence allowing the use of real tra c generators and protocol
	implementations, while solving the problem of simulating unusual
	environments. With our tool, doing experiments with network protocols
	is as simple as running the desired set of applications on a workstation.
	
	 A FreeBSD implementation of dummynet, targeted to TCP, is available
	from the author. This implementation is highly portable and compatible
	with other BSD-derived systems, and takes less than 300 lines of
	kernel code.},
  file = {10.1.1.57.2969.pdf:10.1.1.57.2969.pdf:PDF},
  keywords = {Protocol evaluation, TCP/IP, simulation, Dummynet}
}

@INPROCEEDINGS{rodhe2008,
  author = {Rodhe, I. and Rohner, C.},
  title = {{n-LDA}: {n-Layers Data Aggregation in Sensor Networks}},
  booktitle = {{ICDCS '08}. 28th International Conference on Distributed Computing
	Systems Workshops},
  year = {2008},
  pages = {400-405},
  month = {June},
  abstract = {We present a protocol for secure data aggregation in wireless sensor
	networks that offers end-to-end data confidentiality by using homomorphic
	functions and interleaved encryption. Hop-by-hop aggregation in sensor
	networks is an efficient way to save energy. Node compromises in
	hostile environments require protocols for data aggregation where
	the intermediate nodes contribute with their own values to the aggregated
	data without getting access to it. Homomorphic encryption schemes
	allow aggregation on ciphertext and thus can provide end-to-end data
	confidentiality. We propose a layered data aggregation protocol which
	ensures that, in the presence of less than n captured nodes, an attacker
	cannot get access to any aggregated data from the network. When more
	than n nodes are captured, the attacker can only get access to the
	aggregated values received by the captured nodes. Our protocol is
	resilient to node failure and no pre-built tree for data aggregation
	is needed.},
  doi = {10.1109/ICDCS.Workshops.2008.54},
  file = {rodhe2008.pdf:rodhe2008.pdf:PDF},
  issn = {1545-0678},
  keywords = {cryptography, protocols, telecommunication security, wireless sensor
	networksdata confidentiality, homomorphic functions, hop-by-hop aggregation,
	interleaved encryption, n-LDA, n-layers data aggregation, protocols,
	secure data aggregation, wireless sensor networks}
}

@ARTICLE{rogaway2003,
  author = {Rogaway, Phillip and Bellare, Mihir and Black, John},
  title = {{OCB}: A block-cipher mode of operation for efficient authenticated
	encryption},
  journal = {{ACM} Trans. Inf. Syst. Secur.},
  year = {2003},
  volume = {6},
  pages = {365--403},
  number = {3},
  abstract = {We describe a parallelizable block-cipher mode of operation that simultaneously
	provides privacy and authenticity. OCB encrypts-and-authenticates
	a nonempty string M &in; &lcub;0, 1&rcub;* using ⌈&vertbar;M&vertbar;/n⌉
	+ 2 block-cipher invocations, where n is the block length of the
	underlying block cipher. Additional overhead is small. OCB refines
	a scheme, IAPM, suggested by Charanjit Jutla. Desirable properties
	of OCB include the ability to encrypt a bit string of arbitrary length
	into a ciphertext of minimal length, cheap offset calculations, cheap
	key setup, a single underlying cryptographic key, no extended-precision
	addition, a nearly optimal number of block-cipher calls, and no requirement
	for a random IV. We prove OCB secure, quantifying the adversary's
	ability to violate the mode's privacy or authenticity in terms of
	the quality of its block cipher as a pseudorandom permutation (PRP)
	or as a strong PRP, respectively.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/937527.937529},
  file = {rogaway2003.pdf:rogaway2003.pdf:PDF},
  issn = {1094-9224},
  keywords = {authenticated encryption, cryptography},
  publisher = {ACM}
}

@INPROCEEDINGS{roman2006,
  author = {Rodrigo Roman},
  title = {Applying intrusion detection systems to wireless sensor networks},
  booktitle = {in CCNC 2006: Proceeding of the 3rd IEEE Consumer Communications
	and Networking Conference},
  year = {2006},
  pages = {640--644},
  abstract = {The research of Intrusion Detection Systems (IDS) is a mature area
	in wired networks, and has also attracted many attentions in wireless
	ad hoc networks recently. Nevertheless, there is no previous work
	reported in the literature about IDS architectures in wireless sensor
	networks. In this paper, we discuss the general guidelines for applying
	IDS to static sensor networks, and introduce a novel technique to
	optimally watch over the communications of the sensors’ neighborhood
	on certain scenarios.},
  file = {roman2006.pdf:roman2006.pdf:PDF},
  keywords = {sensor networks, intrusion deteciton, IDS, Internet security}
}

@INPROCEEDINGS{roosta2007,
  author = {Tanya Roosta and Sameer Pai and Phoebus Chen and S. Shankar Sastry
	and Stephen Wicker},
  title = {The Inherent Security of Routing Protocols in Ad Hoc and Sensor Networks},
  booktitle = {Proceedings of the 50th Annual IEEE Global Communications Conference
	(IEEE GLOBECOM'07)},
  year = {2007},
  month = {November},
  organization = {IEEE},
  abstract = {Many of the routing protocols that have been designed for wireless
	ad-hoc networks focus on energy-efficiency and guaranteeing high
	throughput in a non-adversarial setting. However, given that ad-hoc
	and sensor networks are deployed and left unattended for long periods
	of time, it is crucial to design secure routing protocols for these
	networks. Over the past few years, attacks on the routing protocols
	have been studied and a number of secure routing protocols have been
	designed for wireless sensor networks. However, there has not been
	a comprehensive study of how these protocols compare in terms of
	achieving security goals and maintaining high throughput. In this
	paper, we focus on the problem of analyzing the inherent security
	of routing protocols with respect to two categories: multi-path and
	single-path routing. Within each category, we focus on deterministic
	vs. probabilistic mechanisms for setting up the routes. We consider
	the scenario in which an adversary has subverted a subset of the
	nodes, and as a result, the paths going through these nodes are compromised.
	We present our findings through simulation results.},
  file = {roosta2007.pdf:roosta2007.pdf:PDF},
  keywords = {sensor networks, security, secure routing},
  review = {Considers the inherent robustness (Roosta calls this security) of
	various single and multi-path ad-hoc routing protocols.
	
	Fairly ok but limited taxonomy of protocols, not very convincing simulation
	results. The findings are (not surprisingly) that multi-path is more
	robust than single path. However, multi-path routing is more energy
	consuming.
	
	Roosta considers active insider attackers which want to remain stealthy.
	Therefore, the attacks considered are random drops of messages and
	modification of contents.
	
	
	Discusses node disjoint vs edge disjoint routing protocols.
	
	
	In summary: Not a very impressive paper, results unclear and graphs
	plain bad. TODO: Follow up with regards to inherent security of aggregation
	protocols, trees, multi-path, gossip??},
  url = {http://www.truststc.org/pubs/327.html}
}

@INPROCEEDINGS{roosta2006,
  author = {Tanya Roosta and Shiuhpyng Shieh and Shankar Sastry},
  title = {taxonomy of Security Attacks in Sensor Networks and Countermeasures},
  booktitle = {First {IEEE} International Conference on System Integration and Reliability
	Improvements},
  year = {2006},
  pages = {13--15},
  address = {Hanoi},
  abstract = {Ad-hoc sensor networks have become common over the past few years
	and the domain of their application is increasing widely. However,
	the security of these networks poses a great challenge due to the
	fact that they consist of tiny wireless devices which have limited
	hardware and energy resources. In addition, these networks are generally
	deployed and then left unattended. These facts coupled together make
	it impractical to directly apply the traditional security mechanisms
	to the sensor network paradigm. Therefore, there is a need to analyze
	and better understand the security requirements of sensor networks.
	This paper provides a comprehensive taxonomy of security attacks
	on sensor networks, and gives solutions for each set of attacks.
	More importantly, it points out the research directions which need
	to be investigated in
	
	the future.},
  file = {roosta2006.pdf:roosta2006.pdf:PDF},
  review = {Pretty good survey on security issues in sensor networks. Very SN
	specific. Categorizes attackers, trust model and security objectives
	briefly. Addresses:
	
	* Physical attacks and countermeasures
	
	* Attacks categorised by the OSI layers -- jamming at physical layer,
	routing protocol subversion, generating MAC layer collisions
	
	* Taffic analysis attacks
	
	* Key management
	
	* Sybil attack (very briefly)
	
	* Reptation related attacks -- mentions Confidant as a watchdog-type
	mechanism.
	
	* In-network processing attacks (very brief and light)
	
	* Time synchronization protocols.}
}

@MISC{rosenberg-turn-2008,
  author = {J. Rosenberg and R. Mahy and P. Matthews},
  title = {Traversal Using Relays around {NAT} ({TURN}): Relay Extensions to
	Session Traversal Utilities for {NAT} ({STUN})},
  howpublished = {Internet-Draft},
  month = {November 30},
  year = {2008},
  owner = {kristjan},
  timestamp = {2009.02.10},
  url = {http://tools.ietf.org/html/draft-ietf-behave-turn-12}
}

@MISC{Rosenberg2002,
  author = {J. Rosenberg and H. Schulzrinne and G. Camarillo and A. Johnston
	and J. Peterson and R. Sparks and M. Handley and E. Schooler},
  title = {{RFC} 3261 - {SIP}: Session Initiation Protocol},
  year = {2002},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{rosenberg-stun-2003,
  author = {J. Rosenberg and J. Weinberger and C. Huitema and R. Mahy},
  title = {{STUN} - Simple Traversal of User Datagram Protocol ({UDP}) Through
	Network Address Translators ({NATs})},
  howpublished = {RFC},
  month = {March},
  year = {2003},
  owner = {kristjan},
  timestamp = {2009.02.10},
  url = {http://www.ietf.org/rfc/rfc3489.txt}
}

@ONLINE{ross2000,
  author = {David Ross and Ivan Brugiolo and John Coates and Michael Roe},
  title = {Cross-site Scripting Overview},
  url = {http://www.megasecurity.org/Info/cross-site_scripting.txt},
  year = {2000},
  comment = {cross-site_scripting.txt},
  howpublished = {[online] http://www.megasecurity.org/Info/cross-site\_scripting.txt},
  month = {February},
  owner = {kristjan},
  review = {Very thorough introduction to the problem of "Cross-site scripting":xss.
	
	Rather old, but still appears to be relevant.
	
	
	The authors discuss several methods of guarding against XSS, including
	filtering of input strings to remove potentially dangerous special
	characters, using the HTTP referer.
	
	
	See also: [[ollman_xss_2007]] references this page and appears to
	use it heavily (although that ref is much more recent!). The examples
	provided in ross2000 are often more thourough.},
  timestamp = {2008.04.11}
}

@ARTICLE{roughan2006,
  author = {Roughan, Matthew and Zhang, Yin},
  title = {Secure distributed data-mining and its application to large-scale
	network measurements},
  journal = {{SIGCOMM} Comput. Commun. Rev.},
  year = {2006},
  volume = {36},
  pages = {7--14},
  number = {1},
  abstract = {The rapid growth of the Internet over the last decade has been startling.
	However, efforts to track its growth have often fallen afoul of bad
	data --- for instance, how much traffic does the Internet now carry?
	The problem is not that the data is technically hard to obtain, or
	that it does not exist, but rather that the data is not shared. Obtaining
	an overall picture requires data from multiple sources, few of whom
	are open to sharing such data, either because it violates privacy
	legislation, or exposes business secrets. Likewise, detection of
	global Internet health problems is hampered by a lack of data sharing.
	The approaches used so far in the Internet, e.g. trusted third parties,
	or data anonymization, have been only partially successful, and are
	not widely adopted.The paper presents a method for performing computations
	on shared data without any participants revealing their secret data.
	For example, one can compute the sum of traffic over a set of service
	providers without any service provider learning the traffic of another.
	The method is simple, scalable, and flexible enough to perform a
	wide range of valuable operations on Internet data.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1111322.1111326},
  file = {roughan2006.pdf:roughan2006.pdf:PDF},
  issn = {0146-4833},
  keywords = {data mining, privacy preserving computaiton.},
  publisher = {ACM}
}

@ARTICLE{roush2003,
  author = {Wade Roush},
  title = {10 Emerging technologies that will change the world -- Sensor Networks},
  journal = {Technology Review},
  year = {2003},
  month = {February},
  file = {roush2003.pdf:roush2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.17}
}

@ARTICLE{rowstron2001a,
  author = {Antony Rowstron and Peter Druschel},
  title = {Storage management and caching in {PAST}, a large-scale, persistent
	peer-to-peer storage utility},
  journal = {{SIGOPS Oper. Syst. Rev.}},
  year = {2001},
  volume = {35},
  pages = {188--201},
  number = {5},
  abstract = {This paper presents and evaluates the storage management and caching
	in PAST, a large-scale peer-to-peer persistent storage utility. PAST
	is based on a self-organizing, Internet-based overlay network of
	storage nodes that cooperatively route file queries, store multiple
	replicas of files, and cache additional copies of popular files.In
	the PAST system, storage nodes and files are each assigned uniformly
	distributed identifiers, and replicas of a file are stored at nodes
	whose identifier matches most closely the file's identifier. This
	statistical assignment of files to storage nodes approximately balances
	the number of files stored on each node. However, non-uniform storage
	node capacities and file sizes require more explicit storage load
	balancing to permit graceful behavior under high global storage utilization;
	likewise, non-uniform popularity of files requires caching to minimize
	fetch distance and to balance the query load.We present and evaluate
	PAST, with an emphasis on its storage management and caching system.
	Extensive trace-driven experiments show that the system minimizes
	fetch distance, that it balances the query load for popular files,
	and that it displays graceful degradation of performance as the global
	storage utilization increases beyond 95%.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/502059.502053},
  file = {rowstron2001a.pdf:rowstron2001a.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM}
}

@INPROCEEDINGS{rowstron2001,
  author = {Antony I. T. Rowstron and Peter Druschel},
  title = {Pastry: Scalable, Decentralized Object Location, and Routing for
	Large-Scale Peer-to-Peer Systems},
  booktitle = {Middleware '01: Proceedings of the IFIP/ACM International Conference
	on Distributed Systems Platforms Heidelberg},
  year = {2001},
  pages = {329--350},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {This paper presents the design and evaluation of Pastry, a scalable,
	distributed object location and routing substrate for wide-area peer-to-peer
	applications. Pastry performs application-level routing and object
	location in a potentially very large overlay network of nodes connected
	via the Internet. It can be used to support a variety of peer-to-peer
	applications, including global data storage, data sharing, group
	communication and naming.
	
	Each node in the Pastry network has a unique identiﬁer (nodeId). When
	presented with a message and a key, a Pastry node efﬁciently routes
	the message to the node with a nodeId that is numerically closest
	to the key, among all currently live Pastry nodes. Each Pastry node
	keeps track of its immediate neighbors in the nodeId space, and notiﬁes
	applications of new node arrivals, node failures and recoveries.
	Pastry takes into account network locality; it seeks to minimize
	the distance messages travel, according to a to scalar proximity
	metric like the number of IP routing hops.
	
	Pastry is completely decentralized, scalable, and self-organizing;
	it automatically adapts to the arrival, departure and failure of
	nodes. Experimental results obtained with a prototype implementation
	on an emulated network of up to 100,000 nodes conﬁrm Pastry’s scalability
	and efﬁciency, its ability to self-organize and adapt to node failures,
	and its good network locality properties.},
  file = {rowstron2001.pdf:rowstron2001.pdf:PDF},
  isbn = {3-540-42800-3}
}

@PHDTHESIS{roy2008a,
  author = {Sankardas Roy},
  title = {Secure Data Aggregation in Wireless Sensor Networks},
  school = {George Mason University},
  year = {2008},
  address = {Fairfax, VA},
  abstract = {Wireless sensor networks have proved to be useful in several applications,
	such as envi-
	
	ronment monitoring and perimeter surveillance. In a large sensor network,
	in-network data
	
	aggregation (i.e., combining partial results at intermediate nodes
	during message routing)
	
	signiﬁcantly reduces the amount of communication and energy consumption.
	Recently, the
	
	research community has proposed a robust aggregation framework called
	synopsis diﬀusion
	
	which combines multi-path routing schemes with duplicate-insensitive
	algorithms to accu-
	
	rately compute aggregates (e.g., Count, Sum) in spite of message losses
	resulting from node
	
	and transmission failures. However, this aggregation framework does
	not address the prob-
	
	lem of false sub-aggregate values contributed by compromised nodes
	resulting in large errors
	
	in the aggregate computed at the base station, which is the root node
	in the aggregation
	
	hierarchy. This is an important problem since sensor networks are
	highly vulnerable to node
	
	compromises due to the unattended nature of sensor nodes and the lack
	of tamper-resistant
	
	hardware.
	
	
	In this dissertation, we make the synopsis diﬀusion approach secure
	against attacks in
	
	which compromised nodes contribute false sub-aggregate values. In
	particular, we present
	
	two classes of algorithms to securely compute Count or Sum. First,
	we propose a lightweight
	
	veriﬁcation algorithm which enables the base station to determine
	if the computed aggregate
	
	includes any false contribution. Second, we present attack-resilient
	computation algorithms
	
	which can be used to compute the true aggregate by ﬁltering out the
	contributions of com-
	
	promised nodes in the aggregation hierarchy. Thorough theoretical
	analysis and extensive
	
	simulation study show that our algorithms outperform other existing
	approaches.
	
	This dissertation also addresses the security issues of in-network
	computation of Median
	
	and presents veriﬁcation algorithms and attack-resilient computation
	algorithms to securely
	
	compute an approximate estimate of this aggregate. To the best of
	our knowledge, prior to
	
	this dissertation there was no other work related to the security
	of in-network computation
	
	of Median. We evaluate the performance and cost of our algorithms
	via both analysis and
	
	simulation. The results show that our approach is scalable and eﬃcient.},
  file = {roy2008a.pdf:roy2008a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.22}
}

@ARTICLE{roy2009,
  author = {Roy, Sankardas and Conti, Mauro and Setia, Sanjeev and Jajodia, Sushil},
  title = {Secure median computation in wireless sensor networks},
  journal = {{Ad Hoc Netw.}},
  year = {2009},
  volume = {7},
  pages = {1448--1462},
  number = {8},
  abstract = {Wireless sensor networks (WSNs) have proven to be useful in many applications,
	such as military surveillance and environment monitoring. To meet
	the severe energy constraints in WSNs, several researchers have proposed
	to use the in-network data aggregation technique (i.e., combining
	partial results at intermediate nodes during message routing), which
	significantly reduces the communication overhead. Given the lack
	of hardware support for tamper-resistance and the unattended nature
	of sensor nodes, sensor network protocols need to be designed with
	security in mind. Recently, researchers proposed algorithms for securely
	computing a few aggregates, such as Sum (the sum of the sensed values),
	Count (number of nodes) and Average. However, to the best of our
	knowledge, there is no prior work which securely computes the Median,
	although the Median is considered to be an important aggregate. The
	contribution of this paper is twofold. We first propose a protocol
	to compute an approximate Median and verify if it has been falsified
	by an adversary. Then, we design an attack-resilient algorithm to
	compute the Median even in the presence of a few compromised nodes.
	We evaluate the performance and cost of our approach via both analysis
	and simulation. Our results show that our approach is scalable and
	efficient.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2009.04.007},
  file = {roy2009.pdf:roy2009.pdf:PDF},
  issn = {1570-8705},
  publisher = {Elsevier Science Publishers B. V.},
  review = {See also roy2008 on same (?) material.
	
	
	Present a sampling algorithm for approximating the median. Security
	increased by an divide-and-conquer protocol. Grouping (geographic,
	id-based and dynamic) is employed along with an attacker locating
	protocol.}
}

@INPROCEEDINGS{roy2008,
  author = {Roy, Sankardas and Conti, Mauro and Setia, Sanjeev and Jajodia, Sushil},
  title = {Securely computing an approximate median in wireless sensor networks},
  booktitle = {{SecureComm} '08: Proceedings of the 4th international conference
	on Security and privacy in communication networks},
  year = {2008},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Wireless Sensor Networks (WSNs) have proven to be useful in many applications,
	such as military surveillance and environment monitoring. To meet
	the severe energy constraints in WSNs, some researchers have proposed
	to use the in-network data aggregation technique (i.e., combining
	partial results at intermediate nodes during message routing), which
	significantly reduces the communication overhead. Given the lack
	of hardware support for tamper resistance and the unattended nature
	of sensor nodes, sensor network protocols need to be designed with
	security in mind. Recently, researchers proposed algorithms for securely
	computing a few aggregates, such as Sum (the sum of the sensed values),
	Count (number of nodes) and Average. However, to the best of our
	knowledge, there is no prior work which securely computes the Median,
	although the Median is considered to be an important aggregate. The
	contribution of this paper is twofold. We first propose a protocol
	to compute an approximate Median and verify if it has been falsified
	by an adversary. Then, we design an attack-resilient algorithm to
	compute the Median even in the presence of a few compromised nodes.
	We evaluate the performance and cost of our approach via both analysis
	and simulation. Our results show that our approach is scalable and
	efficient.},
  doi = {http://doi.acm.org/10.1145/1460877.1460885},
  file = {roy2008.pdf:roy2008.pdf:PDF},
  isbn = {978-1-60558-241-2},
  location = {Istanbul, Turkey},
  owner = {kristjan},
  review = {Same material as roy2009??}
}

@INPROCEEDINGS{roy2006,
  author = {Roy, Sankardas and Setia, Sanjeev and Jajodia, Sushil},
  title = {Attack-resilient hierarchical data aggregation in sensor networks},
  booktitle = {{SASN} '06: Proceedings of the fourth {ACM} workshop on Security
	of ad hoc and sensor networks},
  year = {2006},
  pages = {71--82},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1180345.1180355},
  file = {roy2006.pdf:roy2006.pdf:PDF},
  isbn = {1-59593-554-1},
  keywords = {sensor network, in-network aggregation, synopsis diffusion},
  location = {Alexandria, Virginia, USA},
  review = {See note by yu2009b that the protocol can be rendered unavailable
	by multi-hop flooding attacks.
	
	
	See note by yu2009b on the motivation for synopsis diffusion being
	to reduce the estimation error resulting from message losses in traditional
	protocols such as TAG.}
}

@ARTICLE{Royer1999,
  author = {E. Royer and C. Toh},
  title = {A Review of Current Routing Protocols for Ad-Hoc Mobile Wireless
	Networks},
  journal = {IEEE Personal Communications},
  year = {1999},
  pages = {46-55},
  month = {april},
  file = {royer99review.pdf:royer99review.pdf:PDF},
  owner = {kristjan},
  text = {E.M. Royer and C-K Toh. A Review of Current Routing Protocols for
	Ad-Hoc Mobile Wireless Networks. IEEE Personal Communications, Apr.
	1999.},
  timestamp = {2008.09.19},
  url = {mack.ittc.ku.edu/article/royer99review.html}
}

@MISC{rsa-pkcs5-v2-1999,
  author = {{{RSA} Laboratories}},
  title = {{PKCS} \#5 v2.0: Password-Based Cryptography Standard},
  year = {1999},
  file = {rsa-pkcs5-v2-1999.pdf:rsa-pkcs5-v2-1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.07.26}
}

@MISC{rsnake_xss,
  author = {RSnake},
  title = {XSS (Cross Site Scripting) Cheat Sheet},
  howpublished = {[online] http://ha.ckers.org/xss.html},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://ha.ckers.org/xss.html}
}

@ARTICLE{rubin1998,
  author = {Aviel D. Rubin and Daniel E. {Geer, Jr.}},
  title = {A Survey of Web Security},
  journal = {Computer},
  year = {1998},
  volume = {31},
  pages = {34--41},
  number = {9},
  abstract = {Developing security methods for the Web is a daunting task, in part
	because security concerns arose after the fact. The authors offer
	a survey of Web security issues, focusing on particular areas of
	concern, such as server security, mobile code, data transfer, and
	user privacy.},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/2.708448},
  file = {00708448.pdf:00708448.pdf:PDF},
  issn = {0018-9162},
  publisher = {IEEE Computer Society Press}
}

@MISC{ruderman-same-origin-policy,
  author = {Jesse Ruderman},
  title = {The Same Origin Policy},
  owner = {kristjan},
  timestamp = {2008.09.08},
  url = {http://www.mozilla.org/projects/security/components/same-origin.html}
}

@TECHREPORT{rushby1992,
  author = {John Rushby},
  title = {Noninterference, Transitivity, and Channel-Control Security Policies},
  year = {1992},
  month = {dec},
  abstract = {We consider noninterference formulations of security policies [7]
	in
	
	which the “interferes” relation is intransitive. Such policies provide
	a
	
	formal basis for several real security concerns, such as channel control
	[17,
	
	18], and assured pipelines [4]. We show that the appropriate formulation
	
	of noninterference for the intransitive case is that developed by
	Haigh
	
	and Young for “multidomain security” (MDS) [9, 10]. We construct an
	
	“unwinding theorem” [8] for intransitive polices and show that it
	diﬀers
	
	signiﬁcantly from that of Haigh and Young. We argue that their theorem
	
	is incorrect. A companion report [22] presents a mechanically-checked
	
	formal speciﬁcation and veriﬁcation of our unwinding theorem.
	
	 We consider the relationship between transitive and intransitive
	for-
	
	mulations of security. We show that the standard formulations of non-
	
	interference and unwinding [7, 8] correspond exactly to our intransitive
	
	formulations, specialized to the transitive case. We show that transi-
	
	tive polices are precisely the “multilevel security” (MLS) polices,
	and
	
	that any MLS secure system satisﬁes the conditions of the unwinding
	
	theorem.
	
	 We also consider the relationship between noninterference formula-
	
	tions of security and access control formulations, and we identify
	the
	
	“reference monitor assumptions” that play a crucial role in establishing
	
	the soundness of access control implementations.},
  booktitle = {Technical Report {CSL-92-02}},
  file = {csl-92-2.pdf:csl-92-2.pdf:PDF},
  url = {http://www.csl.sri.com/papers/csl-92-2/}
}

@MISC{s_labs_2006,
  author = {{S. Labs}},
  title = {Detecting, analyzing, and exploiting intranet applications using
	javascript.},
  howpublished = {[whitepaper] http://www.spidynamics.com/spilabs/education/articles/JS-portscan.html},
  month = {July},
  year = {2006},
  owner = {kristjan},
  timestamp = {2008.04.10},
  url = {http://www.spidynamics.com/spilabs/education/articles/JS-portscan.html}
}

@INPROCEEDINGS{sang2006,
  author = {Yingpeng Sang and Hong Shen and Yasushi Inoguchi and Yasuo Tan and
	Naixue Xiong},
  title = {Secure Data Aggregation in Wireless Sensor Networks: A Survey},
  booktitle = {{PDCAT '06: Proceedings of the Seventh International Conference on
	Parallel and Distributed Computing, Applications and Technologies}},
  year = {2006},
  pages = {315--320},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Data aggregation is a widely used technique in wireless sensor networks.
	The security issues, data conﬁdentiality and integrity, in data aggregation
	become vital when the sensor network is deployed in a hostile environment.
	There has been many related work proposed to address these security
	issues. In this paper we survey these work and classify them into
	two cases: hop-by-hop encrypted data aggregation and end-to-end encrypted
	data aggregation. We also propose two general frameworks for the
	two cases respectively. The framework for end-to-end encrypted data
	aggregation has higher computation cost on the sensor nodes, but
	achieves stronger security, in comparison with the framework for
	hop-by-hop encrypted data aggregation.},
  doi = {http://dx.doi.org/10.1109/PDCAT.2006.96},
  file = {:sang2006.pdf:PDF},
  isbn = {0-7695-2736-1},
  keywords = {security, aggregation, wireless sensor network, survey},
  review = {An ok survey on distributed aggregation security -- considers confidentiality
	issues:
	
	Discusses data confidentiality and integrity in secure data aggregation.
	
	* hop-by-hop encryption for confidentiality -- mentions key distribution
	issues
	
	* end-to-end security by homomorphic encryption -- rather weak on
	this but check out refs on CDA.}
}

@INPROCEEDINGS{sanli2004,
  author = {{H. Ozgur} Sanli and Suat Ozdemir and Hasan Cam},
  title = {{SRDA}: Secure Reference-Based Data Aggregation Protocol for Wireless
	Sensor Networks},
  booktitle = {{VTC2004-Fall}: 60th {IEEE} Vehicular Technology Conference},
  year = {2004},
  abstract = {Data aggregation in wireless sensor networks is crucial due to its
	enhancement of bandwidth usage and energy utilization by minimizing
	the transfer of redundant data. This paper presents a secure data
	aggregation protocol, called SRDA, for wireless sensor networks.
	In order to reduce the number of bits transmitted, SRDA requires
	sensor nodes to send differential data instead of raw sensed data.
	Effectiveness of the SRDA is further demonstrated by applying its
	key mechanism to enhance existing data aggregation protocols.
	
	
	 SRDA establishes secure connectivity among sensor nodes by taking
	advantage of deployment estimation and not performing any online
	key distribution. The incremental security requirement due to the
	nature of the data aggregation process is met by an aggregation speciﬁc
	security technique. Simulation results show that SRDA yields signiﬁcant
	savings in the energy consumption while preserving the data security.},
  file = {sanli2004.pdf:sanli2004.pdf:PDF},
  owner = {kristjan},
  review = {Weak.
	
	
	Uses a cluster based WSN. Basic idea: nodes transmit differential
	rather than raw sensed data. Why?
	
	
	Two contributions: 1) a key distribution protocol, based on key pre-distribution
	and 2) an aggregation specific security mechanism for clustered WSN.
	
	
	Key distribution scheme: Assme sensors are distributed over an AxA
	square area, divided into n subsquares. Sensors are deployed in groups,
	using a center of a n-area as deployment point. Assume Gaussian distribution
	-- hence, location/grouping of sensors known with some probability
	-- groups of some size k. Each node is allocated some m symmetric
	keys, shared with some sensors in the group, giving some probability
	of connectivity for each node. This is basically a variation on the
	key pre-distribution scheme. After deployment, nodes start a shared
	key discovery phase and set up communications.
	
	
	For the aggreation phase, the authors observe that the value of the
	information increases with proximity to the base station. Hence,
	they increase the security level gradually as the packets are transmitted
	thhrough higher level cluster heads. Use RC6 and increase its security
	margin with proximity to the base station. Note: still hop-by-hop
	crypto. Not at all clear what the authors hope to accomplish by this
	increase of the security margin -- this will still only guard against
	outsiders, which is adequately done using an uniformly strong symmetric
	crypto algorithm. In conclusion, a fairly dubious result.
	
	
	Transmission phase: Transmit differential data, rather than raw, to
	decrease the size of packets (note: crypto will tend to fix the block
	sizes, so are the gains really that great?). Cluster heads create
	reference entry for nodes -- subtract the reference from the reading
	and send the difference. Note: Seems this opens up possibilities
	of trivial attacks against the integrity of the measurements if insiders
	are assumed.},
  timestamp = {2010.01.17}
}

@INPROCEEDINGS{sanzgiri2002,
  author = {Sanzgiri, Kimaya and Dahill, Bridget and Levine, Brian Neil and Shields,
	Clay and Belding-Royer, Elizabeth M.},
  title = {A Secure Routing Protocol for Ad Hoc Networks},
  booktitle = {{ICNP} '02: Proceedings of the 10th IEEE International Conference
	on Network Protocols},
  year = {2002},
  pages = {78--89},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Most recent ad hoc network research has focused on providing routing
	services without considering security. In this paper, we detail security
	threats against ad hoc routing protocols,specifically examining AODV
	and DSR. In light of these threats, we identify three different environments
	with distinct security requirements. We propose a solution to one,
	the managed-open scenario where no network infrastructure is pre-deployed,
	but a small amount of prior security coordination is expected. Our
	protocol, ARAN, is based on certificates and successfully defeats
	all identified attacks.},
  file = {sanzgiri2002.pdf:sanzgiri2002.pdf:PDF},
  isbn = {0-7695-1856-7},
  keywords = {ad-hoc network, security, secure routing}
}

@INPROCEEDINGS{sarmenta2006,
  author = {Sarmenta, Luis F. G. and van Dijk, Marten and O'Donnell, Charles
	W. and Rhodes, Jonathan and Devadas, Srinivas},
  title = {Virtual monotonic counters and count-limited objects using a {TPM}
	without a trusted {OS}},
  booktitle = {{STC} '06: Proceedings of the first {ACM} workshop on Scalable trusted
	computing},
  year = {2006},
  pages = {27--42},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A trusted monotonic counter is a valuable primitive that enables a
	wide variety of highly scalable offline and decentralized applications
	that would otherwise be prone to replay attacks, including offline
	payment, e-wallets, virtual trusted storage, and digital rights management
	(DRM). In this paper, we show how one can implement a very large
	number of virtual monotonic counters on an untrusted machine with
	a Trusted Platform Module (TPM) or similar device, without relying
	on a trusted OS. We first present a log-based scheme that can be
	implemented with the current version of the TPM (1.2) and used in
	certain applications. We then show how the addition of a few simple
	features to the TPM makes it possible to implement a hash-tree-based
	scheme that not only offers improved performance and scalability
	compared to the log-based scheme, but also makes it possible to implement
	count-limited objects (or ``clobs'' for short) -- i.e., encrypted
	keys, data, and other objects that can only be used when an associated
	virtual monotonic counter is within a certain range. Such count-limited
	objects include n-time use keys, n-out-of-m data blobs, n-copy migratable
	objects, and other variants, which have many potential uses in digital
	rights management (DRM), digital cash, itinerant computing, and other
	application areas.},
  doi = {http://doi.acm.org/10.1145/1179474.1179485},
  file = {sarmenta2006.pdf:sarmenta2006.pdf:PDF},
  isbn = {1-59593-548-7},
  location = {Alexandria, Virginia, USA}
}

@INPROCEEDINGS{sasson2003,
  author = {Yoav Sasson and David Cavin and André Schiper},
  title = {Probabilistic Broadcast for Flooding in Wireless Mobile Ad hoc Networks},
  booktitle = {{IEEE} Wireless Communications and Networking {(WCNC)}},
  year = {2003},
  pages = {1124--1130},
  abstract = {Although far from optimal, flooding is an indispensable message dissemination
	technique for network-wide broadcast within mobile ad hoc networks
	(MANETs). As such, the plain flooding algorithm provokes a high number
	of unnecessary packet rebroadcasts, causing contention, packet collisions
	and ultimately wasting precious limited bandwidth. Studies have been
	undertaken to optimize flooding using a deterministic approach. Because
	of the highly dynamic and mobile characteristics of MANETs, probabilistic
	algorithms may be better suited. We explore the phase transition
	phenomenon observed in percolation theory and random graphs as a
	basis for defining probabilistic flooding algorithms. We consider
	models with and without packet collisions to better understand when
	phase transition occurs. We show through simulation that in cases
	of no collision control, probabilistic flooding greatly enhances
	network performance while significantly reducing broadcast packets
	in dense networks, although phase transition is not observed.},
  file = {tech report:sasson2002.pdf:PDF;sasson2003.pdf:sasson2003.pdf:PDF}
}

@INPROCEEDINGS{sastry2003,
  author = {Naveen Sastry and Umesh Shankar and David Wagner},
  title = {Secure verification of location claims},
  booktitle = {WiSe '03: Proceedings of the 2nd ACM workshop on Wireless security},
  year = {2003},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {With the growing prevalence of sensor and wireless networks comes
	a new demand for location-based access control mechanisms. We introduce
	the concept of secure location veriﬁcation, and we show how it can
	be used for location-based access control. Then, we present the Echo
	protocol, a simple method for secure location veriﬁcation. The Echo
	protocol is extremely lightweight: it does not require time synchronization,
	cryptography, or very precise clocks. Hence, we believe that it is
	well suited for use in small, cheap, mobile devices.},
  doi = {http://doi.acm.org/10.1145/941311.941313},
  file = {sastry2003.pdf:sastry2003.pdf:PDF},
  isbn = {1-58113-769-9},
  location = {San Diego, CA, USA}
}

@ARTICLE{Savage1999,
  author = {Stefan Savage and Neal Cardwell and David Wetherall and Tom Anderson},
  title = {{TCP} congestion control with a misbehaving receiver},
  journal = {ACM SIGCOMM Computer Communication Review},
  year = {1999},
  volume = {29},
  pages = {71-78},
  number = {5},
  month = {October},
  file = {p71-savage.pdf:p71-savage.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@TECHREPORT{saxena2007,
  author = {Mohit Saxena},
  title = {Security in Wireless Sensor Networks - A Layer based Classification},
  institution = {Purdue University},
  year = {2007},
  abstract = {With a widespread growth in the potential applications of Wireless
	Sensor Networks (WSN), the need for reliable security mechanisms
	for them has increased manifold. Security protocols in WSNs, unlike
	the traditional mechanisms, need special efforts and issues to be
	addressed. This is attributed to the inherent computational and communicational
	constraints in these tiny embedded system devices. Another reason
	which distinguishes them from traditional network security mechanisms,
	is their usage in extremely hostile and unattended environments.
	The sensitivity of the data sensed by these devices also pose ever-increasing
	challenges. We present a layer based classification of WSN security
	threats and defenses proposed in the literature, with special focus
	on physical, link and network layer issues.},
  acknowledgement = {I would like to thank Prof. E. Bertino and Ms. Yunhua Koglin for their
	guidance through the course of this survey study.},
  affiliation = {Department of Computer Science},
  file = {saxena2007.pdf:saxena2007.pdf:PDF},
  language = {English},
  school = {Purdue University}
}

@INPROCEEDINGS{saxena2003,
  author = {Nitesh Saxena and Gene Tsudik and Jeong Hyun Yi},
  title = {Admission control in Peer-to-Peer: design and performance evaluation},
  booktitle = {SASN '03: Proceedings of the 1st ACM workshop on Security of ad hoc
	and sensor networks},
  year = {2003},
  pages = {104--113},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Peer-to-Peer (P2P) applications and services are very common in today’s
	computing. The popularity of the P2P paradigm prompts the need for
	specialized security services which makes P2P security an important
	and challenging research topic. Most prior work in P2P security focused
	on authentication, key management and secure communication. However,
	an important pre-requisite for many P2P security services is secure
	admission, or how one becomes a peer in a P2P setting. This issue
	has been heretofore largely untouched.
	
	 This paper builds upon some recent work [11] which constructed a
	peer group admission control framework based on different policies
	and corresponding cryptographic techniques. Our central goal is to
	assess the practicality of these techniques. To this end, we construct
	and evaluate concrete P2P admission mechanisms based on various cryptographic
	techniques. Although our analysis focuses primarily on performance,
	we also consider other important features, such as: anonymity, unlinkability
	and accountability. Among other things, our experimental results
	demonstrate that, unfortunately, advanced cryptographic constructs
	(such as veriﬁable threshold signatures) are not yet ready for prime
	time.},
  doi = {http://doi.acm.org/10.1145/986858.986873},
  file = {:p104-saxena.pdf:PDF},
  isbn = {1-58113-783-4},
  location = {Fairfax, Virginia}
}

@INPROCEEDINGS{scheibelhofer2007,
  author = {Karl Scheibelhofer},
  title = {A Bit-Slice Implementation of the {Whirlpool} Hash Function},
  booktitle = {{CT-RSA}},
  year = {2007},
  file = {scheibelhofer2007.pdf:scheibelhofer2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.16}
}

@ARTICLE{Schmidt2003,
  author = {Terry Schmidt and Anthony Townshend},
  title = {Why Wi-Fi Wants To Be Free},
  journal = {Communications of the ACM},
  year = {2003},
  volume = {46},
  number = {5},
  owner = {kristjan},
  page = {47-52},
  timestamp = {2008.09.19}
}

@ARTICLE{schneider1990,
  author = {Schneider, Fred B.},
  title = {Implementing fault-tolerant services using the state machine approach:
	a tutorial},
  journal = {{ACM Comput. Surv.}},
  year = {1990},
  volume = {22},
  pages = {299--319},
  number = {4},
  abstract = {The state machine approach is a general method for implementing fault-tolerant
	services in distributed systems. This paper reviews the approach
	and describes protocols for two different failure models—Byzantine
	and fail stop. Systems reconfiguration techniques for removing faulty
	components and integrating repaired components are also discussed.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/98163.98167},
  file = {schneider1990.pdf:schneider1990.pdf:PDF},
  issn = {0360-0300},
  publisher = {ACM}
}

@MISC{Schneier2009,
  author = {Bruce Schneier},
  title = {Ever Better Cryptanalytic Results Against {SHA-1}},
  howpublished = {[online] \url{http://www.schneier.com/blog/archives/2009/06/ever_better_cry.html}},
  month = {June},
  year = {2009},
  owner = {kristjan},
  timestamp = {2010.03.02},
  url = {http://www.schneier.com/blog/archives/2009/06/ever_better_cry.html}
}

@MISC{scneier_homomorphic_enc_breakthrough_2009,
  author = {Bruce Schneier},
  title = {Homomorphic Encryption Breakthrough},
  howpublished = {[online] \url{http://www.schneier.com/blog/archives/2009/07/homomorphic_enc.html}},
  month = {July},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.10.19},
  url = {http://www.schneier.com/blog/archives/2009/07/homomorphic_enc.html}
}

@ONLINE{schneier-trends-2005,
  author = {Bruce Schneier},
  title = {Attack Trends: 2004 and 2005},
  url = {http://www.schneier.com/blog/archives/2005/06/attack_trends_2.html},
  year = {2005},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@MISC{Schneier2005,
  author = {Bruce Schneier},
  title = {{SHA-1} Broken},
  howpublished = {[online] \url{http://www.schneier.com/blog/archives/2005/02/sha1_broken.html}},
  month = {February},
  year = {2005},
  owner = {kristjan},
  timestamp = {2010.03.02},
  url = {http://www.schneier.com/blog/archives/2005/02/sha1_broken.html}
}

@INPROCEEDINGS{schneier1997,
  author = {Schneier, Bruce and Whiting, Doug},
  title = {Fast Software Encryption: Designing Encryption Algorithms for Optimal
	Software Speed on the Intel Pentium Processor},
  booktitle = {{FSE} '97: Proceedings of the 4th International Workshop on Fast
	Software Encryption},
  year = {1997},
  pages = {242--259},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {schneier1997.pdf:schneier1997.pdf:PDF},
  isbn = {3-540-63247-6},
  keywords = {cryptographic algorithms, RC4, SEAL, RC5, Blowfish, Khufu, Khafre}
}

@INPROCEEDINGS{schnorr1989,
  author = {Schnorr, Claus-Peter},
  title = {Efficient Identification and Signatures for Smart Cards},
  booktitle = {{CRYPTO} '89: Proceedings of the 9th Annual International Cryptology
	Conference on Advances in Cryptology},
  year = {1989},
  pages = {239--252},
  address = {London, UK},
  publisher = {Springer-Verlag},
  file = {schnorr1989.pdf:schnorr1989.pdf:PDF},
  isbn = {3-540-97317-6},
  keywords = {digital signatures, encryption, smart cards, zero-knowledge proofs}
}

@MISC{schreiber-2004,
  author = {Thomas Schreiber},
  title = {Session Riding. A Widespread Vulnerability in Today's Web Applications},
  howpublished = {whitepaper, SecureNet GmbH},
  month = {December},
  year = {2004},
  file = {Session_Riding.pdf:Session_Riding.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://www.securenet.de/papers/Session_Riding.pdf}
}

@MISC{cgi_sec_css,
  author = {CGI Security},
  title = {The cross-site scripting FAQ},
  howpublished = {http://www.cgisecurity.net/articles/xss\-faq.shtml},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://www.cgisecurity.net/articles/xss-faq.shtml}
}

@MISC{sethi1997,
  author = {Adarshpal S. Sethi and Pramod Kalyanasundaram and Christopher M.
	Sherwin and Dong Zhu},
  title = {A Hierarchical Management Framework for Battlefield Network Management},
  year = {1997},
  file = {sethi1997.pdf:sethi1997.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.09.21}
}

@MISC{SGI,
  author = {SGI},
  title = {Standard Template Library},
  howpublished = {[online] http://www.sgi.com/tech/stl/},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://www.sgi.com/tech/stl/}
}

@INPROCEEDINGS{Shah2003,
  author = {Shah, R.C. and Roy, S. and Jain, S. and Brunette, W.},
  title = {Data MULEs: modeling a three-tier architecture for sparse sensor
	networks},
  booktitle = {Proceedings of the First IEEE. 2003 IEEE International Workshop on
	Sensor Network Protocols and Applications, 2003.},
  year = {2003},
  pages = {30-41},
  abstract = {This paper presents and analyzes an architecture to collect sensor
	data in sparse sensor networks. Our approach exploits the presence
	of mobile entities (called MULEs) present in the environment. MULEs
	pick up data from the sensors when in close range, buffer it, and
	drop off the data to wired access points. This can lead to substantial
	power savings at the sensors as they only have to transmit over a
	short range. This paper focuses on a simple analytical model for
	understanding performance as system parameters are scaled. Our model
	assumes two-dimensional random walk for mobility and incorporates
	key system variables such as number of MULEs, sensors and access
	points. The performance metrics observed are the data success rate
	(the fraction of generated data that reaches the access points) and
	the required buffer capacities on the sensors and the MULEs. The
	modeling along with simulation results can be used for further analysis
	and provide certain guidelines for deployment of such systems.},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INCOLLECTION{shamir1984,
  author = {Adi Shamir},
  title = {Identity-Based Cryptosystems and Signature Schemes},
  booktitle = {Advances in Cryptology: Proceedings of {CRYPTO} 84},
  year = {1984},
  series = {Lecture Notes in Computer Science},
  pages = {47--53},
  file = {shamir1984.pdf:shamir1984.pdf:PDF},
  keywords = {cryptography, identity based encryption},
  owner = {kristjan},
  review = {See http://en.wikipedia.org/wiki/ID-based_encryption on general background
	to identity based encryption.
	
	
	Shamir's paper first implementation of identity based (email address)
	crypto -- email address public key.},
  timestamp = {2010.05.16}
}

@ARTICLE{shamir1979,
  author = {Adi Shamir},
  title = {How to share a secret},
  journal = {Commun. ACM},
  year = {1979},
  volume = {22},
  pages = {612--613},
  number = {11},
  abstract = {In this paper we show how to divide data D into n
	
	pieces in such a way that D is easily reconstructable
	
	from any k pieces, but even complete knowledge of
	
	k - 1 pieces reveals absolutely no information about D.
	
	This technique enables the construction of robust key
	
	management schemes for cryptographic systems that
	
	can function securely and reliably even when misfor-
	
	tunes destroy half the pieces and security breaches ex-
	
	pose all but one of the remaining pieces.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/359168.359176},
  file = {p612-shamir.pdf:p612-shamir.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM}
}

@INCOLLECTION{shaneck2005,
  author = {Mark Shaneck and Karthikeyan Mahadevan and Vishal Kher and Yongdae
	Kim},
  title = {Remote Software-Based Attestation for Wireless Sensors},
  booktitle = {Security and Privacy in Ad-hoc and Sensor Networks},
  publisher = {Springer Berlin / Heidelberg},
  year = {2005},
  volume = {3813/2005},
  abstract = {Wireless sensor networks are envisioned to be deployed in mission-critical
	applications. Detecting a compromised sensor, whose memory contents
	have been tampered, is crucial in these settings, as the attacker
	can reprogram the sensor to act on his behalf. In the case of sensors,
	the task of verifying the integrity of memory contents is difficult
	as physical access to the sensors is often infeasible. In this paper,
	we propose a software-based approach to verify the integrity of the
	memory contents of the sensors over the network without requiring
	physical contact with the sensor. We describe the building blocks
	that can be used to build a program for attestation purposes, and
	build our attestation program based on these primitives. The success
	of our approach is not dependent on accurate measurements of the
	execution time of the attestation program. Further, we do not require
	any additional hardware support for performing remote attestation.
	Our attestation procedure is designed to detect even small memory
	changes and is designed to be resistant against modifications by
	the attacker.},
  keywords = {sensor network, software-based attestation},
  owner = {kristjan},
  review = {Use later as ref for tamper proofing along with TPM and similar. See
	roosta2006 on background.},
  timestamp = {2010.05.16}
}

@INPROCEEDINGS{shanmugasundaram2003,
  author = {K. Shanmugasundaram and N. Memon and A. Savant and H. Bronnimann},
  title = {ForNet: A distributed forensics network},
  booktitle = {Second International Workshop on Mathematical Methods, Models and
	Architectures for Computer Networks Security},
  year = {2003},
  address = {St. Petersburg, Russia},
  abstract = {This paper introduces ForNet, a distributed network logging mechanism
	to aid digital forensics over wide area networks. We describe the
	need for such a system, review related work, present the architecture
	of the system, and discuss key research issues.},
  file = {shanmugasundaram2003.pdf:shanmugasundaram2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ARTICLE{shannon2004,
  author = {Colleen Shannon and David Moore},
  title = {The Spread of the Witty Worm},
  journal = {IEEE Security and Privacy},
  year = {2004},
  volume = {2},
  pages = {46--50},
  number = {4},
  abstract = {An up close examination of the Witty worm, the first widely propagated
	Internet worm to carry a destructive payload.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/MSP.2004.59},
  file = {shannon2004.pdf:shannon2004.pdf:PDF},
  issn = {1540-7993},
  publisher = {IEEE Educational Activities Department}
}

@ARTICLE{shannon2002,
  author = {Colleen Shannon and David Moore and K. C. Claffy},
  title = {Beyond folklore: observations on fragmented traffic},
  journal = {{IEEE/ACM Trans. Netw.}},
  year = {2002},
  volume = {10},
  pages = {709--720},
  number = {6},
  abstract = {Fragmented IP traffic is a poorly understood component of the overall
	mix of traffic on the Internet. Many assertions about the nature
	and extent of fragmented traffic are anecdotal rather than empirical.
	In this paper we examine the causes and attributes of measured fragment
	traffic, in particular, the effects of NFS, streaming media, networked
	video games, tunneled traffic, and the prevalence of packet fragmentation
	due to improperly configured machines.To understand the prevalence,
	causes, and effects of fragmented IP traffic, we have collected and
	analyzed seven multiday traces from four sources. These sources include
	a university commodity access link, two highly aggregated commercial
	exchange points, and a local NAP. Although there is no practical
	method of ascertaining whether any data provide a representative
	sample of all Internet traffic, we include data sources that cover
	several different types of WANs with traffic from commercial entities,
	educational and research institutions, and large government facilities.The
	dominant causes of fragmentation are streaming media and tunneled
	traffic. Although rumored to be the main impetus for IP packet fragmentation,
	NFS is not among the top ten causes.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TNET.2002.805028},
  file = {shannon2002.pdf:shannon2002.pdf:PDF},
  issn = {1063-6692},
  keywords = {networks, network analysis, traces, IP fragmentation},
  publisher = {IEEE Press}
}

@ARTICLE{sharif2007,
  author = {Monirul Sharif and Kapil Singh and Jonathon Giffin and Wenke Lee},
  title = {Understanding Precision in Host Based Intrusion Detection},
  journal = {Lecture Notes in Computer Science},
  year = {2007},
  volume = {Volume 4637/2007},
  pages = {21-41},
  abstract = {Many host-based anomaly detection systems monitor process execution
	at the granularity of system calls. Other recently proposed schemes
	instead verify the destinations of control-flow transfers to prevent
	the execution of attack code. This paper formally analyzes and compares
	real systems based on these two anomaly detection philosophies in
	terms of their attack detection capabilities, and proves and disproves
	several intuitions. We prove that for any system-call sequence model,
	under the same (static or dynamic) program analysis technique, there
	always exists a more precise control-flow sequence based model. While
	hybrid approaches combining system calls and control flows intuitively
	seem advantageous, especially when binary analysis constructs incomplete
	models, we prove that they have no fundamental advantage over simpler
	control-flow models. Finally, we utilize the ideas in our framework
	to make external monitoring feasible at the precise control-flow
	level. Our experiments show that external control-flow monitoring
	imposes performance overhead comparable to previous system call based
	approaches while detecting synthetic and real world attacks as effectively
	as an inlined monitor.},
  file = {sharif2007.pdf:sharif2007.pdf:PDF},
  keywords = {networks, network secrurity, intrusion detection, HIDS},
  owner = {kristjan},
  timestamp = {2008.03.14}
}

@ARTICLE{shatdal1995,
  author = {Ambuj Shatdal and Jeffrey F. Naughton},
  title = {Adaptive parallel aggregation algorithms},
  journal = {SIGMOD Rec.},
  year = {1995},
  volume = {24},
  pages = {104--114},
  number = {2},
  abstract = {Aggregation and duplicate removal are common in SQL queries. However,
	in the parallel query processing literature, aggregate processing
	has received surprisingly little attention; furthermore, for each
	of the traditional parallel aggregation algorithms, there is a range
	of grouping selectivities where the algorithm performs poorly. In
	this work, we propose new algorithms that dynamically adapt, at query
	evaluation time, in response to observed grouping selectivities.
	Performance analysis via analytical modeling and an implementation
	on a workstation-cluster shows that the proposed algorithms are able
	to perform well for all grouping selectivities. Finally, we study
	the effect of data skew and show that for certain data sets the proposed
	algorithms can even outperform the best of traditional approaches.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/568271.223801},
  file = {shatdal1995.pdf:shatdal1995.pdf:PDF},
  issn = {0163-5808},
  publisher = {ACM}
}

@INPROCEEDINGS{sheng2008,
  author = {Bo Sheng and Qun Li},
  title = {Veriﬁable Privacy-Preserving Range Query in Two-tiered Sensor Networks},
  booktitle = {{IEEE INFOCOM}},
  year = {2008},
  abstract = {We consider a sensor network that is not fully trusted and ask the
	question how we preserve privacy for the collected data and how we
	verify the data reply from the network. We explore the problem in
	the context of a network augmented with storage nodes and target
	at range query. We use bucketing scheme to mix the data for a range,
	use message encryption for data integrity, and employ encoding numbers
	to prevent the storage nodes from dropping data.},
  file = {sheng2008.PDF:sheng2008.PDF:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@ARTICLE{sherif2002,
  author = {Joseph S. Sherif and Tommy G. Dearmond},
  title = {Intrusion detection: Systems and models},
  journal = {{WET} {ICE} 2002. Proceedings. Eleventh {IEEE} International Workshops
	on Enabling Technologies: Infrastructure for Collaborative Enterprises},
  year = {2002},
  pages = { 115-133},
  abstract = {Organizations more ofien than not lack comprehensive security policies
	and are not adequately prepared to protect their systems against
	intrusions. This paper puts forward a review of state of the art
	and state of the applicability of intrusion detection systems, and
	models. The paper also presents a classification of literature pertaining
	to intrusion detection.},
  doi = {10.1109/ENABL.2002.1029998},
  file = {02-1439.pdf:02-1439.pdf:PDF},
  issn = {1080-1383 },
  keywords = {computer crimeintrusion detection models, intrusion detection systems,
	security policies}
}

@ARTICLE{shi2004,
  author = {Elaine Shi and Adrian Perrig},
  title = {Designing Secure Sensor Networks},
  journal = {{IEEE} Wirel. Netw.},
  year = {2004},
  month = {December},
  abstract = {Sensor networks are expected to play an essential role in the upcoming
	age of pervasive computing. Due to their constraints in computation,
	memory, and power resources, their susceptibility to physical capture,
	and use of wireless communications, security is a challenge in these
	networks. The scale of deployments of wireless sensor networks require
	careful decisions and trade-offs among various security measures.
	The authors discuss these issues and consider mechanisms to achieve
	secure communication in these networks.},
  file = {shi2004.pdf:shi2004.pdf:PDF},
  owner = {kristjan},
  review = {A good survey paper on security issues in sensor networks. Discusses
	adversarial and trust models and some attacks. Mostly summarizes
	work I read before. Little on stealthy attacks. Closes by discussing
	some promising research directions, eg. code attestation.},
  timestamp = {2010.01.17}
}

@ARTICLE{shin2007,
  author = {Shin, Kwang Sik and Jung, Jin Ha and Cheon, Jin Young and Choi, Sang
	Bang},
  title = {Real-time network monitoring scheme based on SNMP for dynamic information},
  journal = {{J. Netw. Comput. Appl.}},
  year = {2007},
  volume = {30},
  pages = {331--353},
  number = {1},
  abstract = {An efficient and automated network management is required in large
	and complex networks since it is very difficult to manage them only
	with human effort. In response to this need, the Simple Network Management
	Protocol (SNMP) has been developed and adopted as the de facto standard.
	Some management information changes with time and the management
	station needs to monitor its value in real time. In such a case,
	polling is generally used in the SNMP because the management station
	can query agents periodically. However, the polling scheme needs
	both request and response messages for management information every
	time, which results in network traffic increase. In this paper, we
	suggest a real-time network monitoring method for dynamic information
	to reduce the network traffic in SNMP-based network management. In
	the proposed strategy, each agent first decides its own monitoring
	period. Then, the manager collects them and approves each agent's
	period without modification or adjusts it based on the total traffic
	generated by monitoring messages. After receiving a response message
	containing the monitoring period from the management station, each
	agent sends management information periodically without the request
	of management station. To evaluate the performance of the proposed
	real-time monitoring method, we implemented it and compared the network
	traffic and monitoring quality of the proposed scheme with the general
	polling method.},
  address = {London, UK, UK},
  doi = {http://dx.doi.org/10.1016/j.jnca.2005.07.002},
  file = {shin2007.pdf:shin2007.pdf:PDF},
  issn = {1084-8045},
  publisher = {Academic Press Ltd.}
}

@TECHREPORT{shneidman2004,
  author = {Shneidman, Jeffrey and Parkes, David C.},
  title = {Specification faithfulness in networks with rational nodes},
  year = {2004},
  address = {New York, NY, USA},
  abstract = {It is useful to prove that an implementation correctly follows a specification.
	But even with a provably correct implementation, given a choice,
	would a node choose to follow it? This paper explores how to create
	distributed system specifications that will be faithfully implemented
	in networks with rational nodes, so that no node will choose to deviate.
	Given a strategyproof centralized mechanism, and given a network
	of nodes modeled as having rational-manipulation faults, we provide
	a proof technique to establish the incentive-, communication-, and
	algorithm-compatibility properties that guarantee that participating
	nodes are faithful to a suggested specification. As a case study,
	we apply our methods to extend the strategyproof interdomain routing
	mechanism proposed by Feigenbaum, Papadimitriou, Sami, and Shenker
	(FPSS) [7], defining a faithful implementation.},
  booktitle = {PODC '04: Proceedings of the twenty-third annual ACM symposium on
	Principles of distributed computing},
  doi = {http://doi.acm.org/10.1145/1011767.1011781},
  file = {shneidman2004.pdf:shneidman2004.pdf:PDF},
  isbn = {1-58113-802-4},
  location = {St. John's, Newfoundland, Canada},
  pages = {88--97},
  publisher = {ACM}
}

@INPROCEEDINGS{shrivastava2004,
  author = {Shrivastava, Nisheeth and Buragohain, Chiranjeeb and Agrawal, Divyakant
	and Suri, Subhash},
  title = {Medians and beyond: new aggregation techniques for sensor networks},
  booktitle = {{SenSys} '04: Proceedings of the 2nd international conference on
	Embedded networked sensor systems},
  year = {2004},
  pages = {239--249},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Wireless sensor networks offer the potential to span and monitor large
	geographical areas inexpensively. Sensors, however, have significant
	power constraint (battery life), making communication very expensive.
	Another important issue in the context of sensor-based information
	systems is that individual sensor readings are inherently unreliable.
	In order to address these two aspects, sensor database systems like
	TinyDB and Cougar enable in-network data aggregation to reduce the
	communication cost and improve reliability. The existing data aggregation
	techniques, however, are limited to relatively simple types of queries
	such as SUM, COUNT, AVG, and MIN/MAX. In this paper we propose a
	data aggregation scheme that significantly extends the class of queries
	that can be answered using sensor networks. These queries include
	(approximate) quantiles, such as the median, the most frequent data
	values, such as the <i>consensus</i> value, a histogram of the data
	distribution, as well as range queries. In our scheme, each sensor
	aggregates the data it has received from other sensors into a fixed
	(user specified) size message. We provide strict theoretical guarantees
	on the approximation quality of the queries in terms of the message
	size. We evaluate the performance of our aggregation scheme by simulation
	and demonstrate its accuracy, scalability and low resource utilization
	for highly variable input data sets.},
  doi = {http://doi.acm.org/10.1145/1031495.1031524},
  file = {shrivastava2004.pdf:shrivastava2004.pdf:PDF},
  isbn = {1-58113-879-2},
  keywords = {sensor networks, wireless networks, peer-to-peer systems, secure in-network
	aggregation},
  location = {Baltimore, MD, USA},
  review = {Approximate computation of medians and histograms.}
}

@PHDTHESIS{simpson2007,
  author = {Charles Robert {Simpson, Jr.}},
  title = {Analysis of Passive End-to-End Network Performance Measurements},
  school = {Georgia Institute of Technology},
  year = {2007},
  month = {May},
  abstract = {As the use of networks is increasingly becoming an important part
	of daily life, the measurement and analysis of these networks is
	becoming important as well. This dissertation ﬁrst introduces a network
	measurement infrastructure designed to collect these measurements
	from end-hosts on the Internet. Then, utilizing these measurements,
	studies are made on the behavior of the network and network users
	as well as the security issues aﬀecting the Internet. Finally, the
	public release of the collected data is discussed.
	
	 The NETI@home network measurement infrastructure is a distributed
	approach to passively gathering end-to-end network performance measurements.
	The client is designed to run on virtually any machine connected
	to the Internet and measurements are reported to a server located
	at the Georgia Institute of Technology. This tool gives researchers
	much needed data on the end-to-end performance of the Internet, as
	measured by end-users. NETI@home’s basic approach is to sniﬀ packets
	sent from and received by the host and infer performance metrics
	based on these observed packets. NETI@home users are able to select
	a privacy level that determines what types of data are gathered,
	and what is not reported. NETI@home is designed to be an unobtrusive
	software system that runs quietly in the background with little or
	no intervention by the user, and using few resources.
	
	 We conduct a ﬂow-based comparison of honeynet traﬃc, representing
	malicious traﬃc, and NETI@home traﬃc, representing typical end-user
	traﬃc. We present a cumulative distribution function of the number
	of packets for a TCP ﬂow and learn that a large portion of these
	ﬂows in both datasets are failed and potentially malicious connection
	attempts. Next, we look at a histogram of TCP port activity over
	large time scales to gain insight into port scanning and worm activity.
	One key observation is that new worms can linger on for more than
	a year after the initial release date. We go on to look at activity
	relative to the IP address space and observe that the sources of
	malicious traﬃc are spread across the allocated range. Finally, we
	discuss other security-related observations including suspicious
	use of ICMP packets and attacks on our own NETI@home server. 
	
	 We present some observations and conclusions based on the behavior
	of the network and networking protocols, from the unique perspective
	of the end-user. An analysis of hop counts, based on observed TTL
	values, is presented. The frequency and use of network address translation
	(NAT) and the private IP address space are studied. Finally, several
	other options and ﬂags of various protocols are analyzed to determine
	their adoption and use by the Internet community.
	
	 The simulation of computer networks requires accurate models of user
	behavior. To this end, we present empirical models of end-user network
	traﬃc derived from the analysis of NETI@home data. There are two
	forms of models presented. The ﬁrst models traﬃc for a speciﬁc TCP
	or UDP port. The second models all TCP or UDP traﬃc for an end-user.
	These models are meant to be network-independent and contain aspects
	such as bytes sent, bytes received, and user think time. The empirical
	models derived in this study can then be used to enable more realistic
	simulations of computer networks and are implemented in GTNetS.
	
	 Finally, we further discuss our approaches to anonymizing the dataset
	and how these anonymized data and their associated analysis tools
	will be distributed.},
  file = {:simpson-phd.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.24}
}

@MISC{simpson2006proposal,
  author = {Charles Robert {Simpson, Jr.}},
  title = {Analysis Of Passive End-To-End Network Performance Measurements},
  month = {December},
  year = {2006},
  file = {simpson2006proposal.pdf:simpson2006proposal.pdf:PDF},
  keywords = {networks, network measurement and analysis, NETI@home, phd proposal},
  owner = {kristjan},
  review = {Phd proposal},
  timestamp = {2009.08.17}
}

@MASTERSTHESIS{simpson2004a,
  author = {Charles Robert {Simpson, Jr.}},
  title = {A Distributed Approach to Passively Gathering End-to-End Network
	Performance Measurements},
  school = {Georgia Institute of Technology},
  year = {2004},
  month = {May},
  abstract = {NETI@home is an open-source software package that collects network
	performance statistics from end-systems. It has been written for
	and tested on the Windows, Solaris, and Linux operating systems,
	with testing for other operating systems to be completed soon. NETI@home
	is designed to run on end-user machines and collect various statistics
	about Internet performance. These statistics are then sent to a server
	at the Georgia Institute of Technology, where they are collected
	and made publicly available. This tool gives researchers much needed
	data on the end-to-end performance of the Internet, as measured by
	end-users. NETI@home’s basic approach is to sniﬀ packets sent from
	and received by the host and infer performance metrics based on these
	observed packets. NETI@home users are able to select a privacy level
	that determines what types of data are gathered, and what is not
	reported. NETI@home is designed to be an unobtrusive software system
	that runs quietly in the background with little or no intervention
	by the user, and using few resources.},
  file = {:simpson_charles_r_200405_mast.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.24}
}

@INPROCEEDINGS{simpson2006,
  author = {Charles Robert {Simpson, Jr.} and Dheeraj Reddy and George F. Riley},
  title = {Empirical Models of {TCP} and {UDP} End-User Network Traffic From
	{NETI@home} Data Analysis},
  booktitle = {20th {ACM}/{IEEE}/{SCS} Workshop on Principles of Advanced and Distributed
	Simulation ({PADS} 2006)},
  year = {2006},
  pages = {166--174},
  month = {May},
  note = {Best Paper Nominee},
  abstract = {The simulation of computer networks requires accurate models of user
	behavior. To this end, we present empirical models of end–user network
	trafﬁc derived from the analysis of NETI@home data. There are two
	forms of models presented. The ﬁrst models trafﬁc for a speciﬁc TCP
	or UDP port. The second models all TCP or UDP trafﬁc for an end–user.
	These models are meant to be network–independent and contain aspects
	such as bytes sent, bytes received, and user think time. The empirical
	models derived in this study can then be used to enable more realistic
	simulations of computer networks.},
  file = {csimpson-empirical.pdf:csimpson-empirical.pdf:PDF},
  keywords = {NETI@home
	
	end-to-end monitoring},
  location = {Singapore},
  project = {phd}
}

@INPROCEEDINGS{simpson2004,
  author = {Charles Robert {Simpson, Jr.} and George F. Riley},
  title = {{NETI@home}: A Distributed Approach to Collecting End-to-End Network
	Performance Measurements},
  booktitle = {{PAM 2004 - A workshop on Passive and Active Measurements}},
  year = {2004},
  month = {April},
  abstract = {NETI@home is an open-source software package that collects network
	performance statistics from end-systems. It has been written for
	and tested on the Windows, Solaris, and Linux operating systems,
	with testing for other operating systems to be completed soon. NETI@home
	is designed to run on end-user machines and collects various statistics
	about Internet performance. These statistics are then sent to a server
	at the Georgia Institute of Technology, where they are collected
	and made publicly available. This tool gives researchers much needed
	data on the end-to-end performance of the Internet, as measured by
	end-users. Our basic approach is to sniﬀ packets sent from and received
	by the host and infer performance metrics based on these observed
	packets. NETI@home users are able to select a privacy level that
	determines what types of data are gathered, and what is not reported.
	NETI@home is designed to be an unobtrusive software system that runs
	quietly in the background with little or no intervention by the user,
	and using few resources.},
  file = {:neti_pam_2004.pdf:PDF},
  keywords = {NETI@home
	
	end-to-end monitoring},
  location = {Antibes Juan-les-Pins, France}
}

@ARTICLE{simpson2008,
  author = {Charles Robert {Simpson, Jr} and Dheeraj Reddy and George F Riley},
  title = {Empirical Models of End-User Network Behavior from NETI@home Data
	Analysis},
  journal = {Simulation},
  year = {2008},
  volume = {84},
  pages = {557--571},
  number = {10-11},
  abstract = {The simulation of computer networks requires accurate models of user
	behavior. To this end, we present empirical models of end-user network
	traffic derived from the analysis of NETI@home (NET-work Intelligence
	at home) data. There are two forms of models presented. The first
	models traffic for a specific Transmission Control Protocol (TCP)
	or User Datagram Protocol (UDP) port. The second models all TCP or
	UDP traffic for an end-user. These models are meant to be network-independent
	and contain aspects such as bytes sent, bytes received, and user
	think time. The empirical models derived in this study can then be
	used to enable more realistic simulations of computer networks and
	are implemented in the Georgia Tech Network Simulator (GTNetS).},
  address = {San Diego, CA, USA},
  doi = {http://dx.doi.org/10.1177/0037549708099041},
  file = {:simpson2008.pdf:PDF},
  issn = {0037-5497},
  keywords = {simulation, internet measurement, network traffic models
	
	NETI@home},
  owner = {kristjan},
  publisher = {Society for Computer Simulation International},
  timestamp = {2008.12.05}
}

@ARTICLE{singh2006,
  author = {Atul Singh and Petros Maniatis and Timothy Roscoe and Peter Druschel},
  title = {Using queries for distributed monitoring and forensics},
  journal = {SIGOPS Oper. Syst. Rev.},
  year = {2006},
  volume = {40},
  pages = {389--402},
  number = {4},
  abstract = {Distributed systems are hard to build, proﬁle, debug, and test. Monitoring
	a distributed system – to detect and analyze bugs, test for regressions,
	identify fault-tolerance problems or security compromises – can be
	difﬁcult and error-prone. In this paper we argue that declarative
	development of distributed systems is well suited to tackle these
	tasks. We present an application logging, monitoring, and debugging
	facility that we have built on top of the P2 system, comprising an
	introspection model, an execution tracing component, and a distributed
	query processor. We use this facility to demonstrate a range of on-line
	distributed diagnosis tools that range from simple, local state assertions
	to sophisticated global property detectors on consistent snapshots.
	These tools are small, simple, and can be deployed piecemeal on-line
	at any point during a system’s life cycle. Our evaluation suggests
	that the overhead of our approach to improving and monitoring running
	distributed systems continuously is well in tune with its beneﬁts.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1218063.1217973},
  file = {p2-eurosys06.pdf:p2-eurosys06.pdf:PDF},
  issn = {0163-5980},
  publisher = {ACM}
}

@INPROCEEDINGS{sion2004,
  author = {Sion, Radu and Atallah, Mikhail and Prabhakar, Sunil},
  title = {Resilient rights protection for sensor streams},
  booktitle = {VLDB '04: Proceedings of the Thirtieth international conference on
	Very large data bases},
  year = {2004},
  pages = {732--743},
  publisher = {VLDB Endowment},
  abstract = {Today's world of increasingly dynamic computing environments naturally
	results in more and more data being available as fast streams. Applications
	such as stock market analysis, environmental sensing, web clicks
	and intrusion detection are just a few of the examples where valuable
	data is streamed. Often, streaming information is offered on the
	basis of a non-exclusive, single-use customer license. One major
	concern, especially given the digital nature of the valuable stream,
	is the ability to easily record and potentially "re-play" parts of
	it in the future. If there is value associated with such future re-plays,
	it could constitute enough incentive for a malicious customer (Mallory)
	to duplicate segments of such recorded data, subsequently re-selling
	them for profit. Being able to protect against such infringements
	becomes a necessity.
	
	
	In this paper we introduce the issue of rights protection for discrete
	streaming data through watermarking. This is a novel problem with
	many associated challenges including: operating in a finite window,
	single-pass, (possibly) high-speed streaming model, surviving natural
	domain specific transforms and attacks (e.g.extreme sparse sampling
	and summarizations), while at the same time keeping data alterations
	within allowable bounds. We propose a solution and analyze its resilience
	to various types of attacks as well as some of the important expected
	domain-specific transforms, such as sampling and summarization. We
	implement a proof of concept software (wms.*) and perform experiments
	on real sensor data from the NASA Infrared Telescope Facility at
	the University of Hawaii, to assess encoding resilience levels in
	practice. Our solution proves to be well suited for this new domain.
	For example, we can recover an over 97% confidence watermark from
	a highly down-sampled (e.g. less than 8%) stream or survive stream
	summarization (e.g. 20%) and random alteration attacks with very
	high confidence levels, often above 99%.},
  file = {sion2004.pdf:sion2004.pdf:PDF},
  isbn = {0-12-088469-0},
  keywords = {watermarking, rights protection, sensor network, sensor stream},
  location = {Toronto, Canada},
  review = {Low impact -- citation count 5. Cited by albath2007. Provides a way
	to identify original owner of a datastream (not quite the integrity
	protection application). No privacy guarantees.}
}

@MISC{sirivianos2007,
  author = {Michael Sirivianos and Dirk Westhoff and Frederik Armknecht and Joao
	Girao},
  title = {Non-Manipulable Aggregator Node Election Protocols for Wireless Sensor
	Networks},
  year = {2007},
  abstract = {Aggregator nodes commonly have the ability to read, corrupt or disrupt
	the ﬂow of information produced by a Wireless Sensor Network (WSN).
	Despite this fact, existing aggregator node election schemes do not
	address an adversary that strives to inﬂuence the election process
	towards candidate nodes that it controls. We discuss the requirements
	that need to be fulﬁlled by a non-manipulable aggregator node election
	protocol. We conclude that these requirements can be satisﬁed by
	a distributed random number generator function in which no node is
	able to determine the output of the function. We provide and compare
	three protocols that instantiate such function.},
  file = {sirivianos2007.pdf:sirivianos2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{sit2002,
  author = {Emil Sit and Robert Morris},
  title = {Security Considerations for Peer-to-Peer Distributed Hash Tables},
  booktitle = {{IPTPS} '01: Revised Papers from the First International Workshop
	on Peer-to-Peer Systems},
  year = {2002},
  pages = {261--269},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {Recent peer-to-peer research has focused on providing efﬁcient hash
	lookup systems that can be used to build more complexsystems. These
	systems have good properties when their algorithms are executed correctly
	but have not generally considered how to handle misbehaving nodes.
	This paper looks at what sorts of security problems are inherent
	in large peer-to-peer systems based on distributed hash lookup systems.
	We examine the types of problems that such systems might face, drawing
	examples from existing systems, and propose some design principles
	for detecting and preventing these problems.},
  file = {:sit2002.pdf:PDF},
  isbn = {3-540-44179-4},
  keywords = {networks, security, peer-to-peer systems, DHTs, distributed hash tables,
	overview},
  review = {Sit and Morris consider security in distributed hash-tables, a special
	case of peer-to-peer networks. Hence, a fair number of issues in
	common with p2p aggregation networks. This is an overview paper of
	security issues, of course primarily with regards to DHTs. Identify
	two broad classes of attacks: 1) those which cause the system to
	return incorrect data and 2) those which prevent participants from
	finding data. The authors focus on the latter issue, as they maintain
	the first can be countered by self certifying path names \cite{fu2002}.
	
	
	The authors describe DHTs shortly, e.g.\ CHORD \cite{stoica2003},
	PASTRY \cite{rowstron2001} and CAN \cite{ratnasamy2001}. Then move
	on to describe the adversary model -- participants in the network
	which do not follow the protocol correctly. This can certainly be
	an issue in aggregation networks so presumably a similar set of issues
	apply. A malicious node in this model can only receive packets addressed
	to itself -- cannot overhear packets for other nodes. The authors
	then move on to describe attacks and defences. 
	
	
	The following design principles are proposed to being able to observe
	and audit operations in DHTs:
	
	\begin{itemize}
	
	\item Define verifiable system invariants and verify them.
	
	\item Allow the querier to observe the lookup progress.
	
	\item Assign keys to nodes in a verifiable way.
	
	\item Server selection in routing can be abused.
	
	\item Cross-check routing tables using random queries.
	
	\item Avoid single points of responsibility.
	
	\end{itemize}
	
	Some of these principles can be applied for construction of aggregation
	networks, as will be further noted in the following discussion.
	
	
	\textbf{Attacks}
	
	
	Authors maintain that verifyability underlies all detection techniques
	-- detection of violations of invariants is the first line of defense.
	
	
	\textbf{Routing attacks}
	
	
	Routing attacks are perhaps not relevant for our work, but like previously
	observed, may be similar to attacks agains the tree construction
	algorithm. The way to detect such attacks is identified by the authors
	as defining verifiable system invariants and providing nodes with
	verification mechanism to check those invariants.
	
	
	Attacks here include incorrect lookup routing, which can be reduced
	in severity by allowing the querier to observe the lookup process.
	The system should also assign keys to nodes in a verifiable way.
	I'm not sure exactly how to correlate this to distributed aggregation.
	Still, the principle of verifiability should hold for aggregation
	networks in general.
	
	
	Incorrect routing updates may correlate to attacks against the tree
	maintenance algorithm in the aggregation network case.
	
	
	P2p networks in general vulnerable to partition -- need to bootstrap
	into the system by contacting an existing node. A malicious node
	may send the new node to a parallel network, subverting the original
	network and/or compromizing its effectiveness. Malicious nodes can
	thus use a parallel network to learn about individual nodes and observe
	the protocol. The authors recommend having new nodes bootstrap from
	a trusted source, out of band to the main network. In our case, this
	could perhaps be a trusted authentication node? The authors warn
	against building trust on node participation, but state that public
	keys may help. Cross checking by \textit{random queries} is proposed
	to let nodes to check overall network consistency once they have
	joined the network in a trustworthy manner. The authors repeatedly
	(and rightfully so!) warn against trusting an IP address as a form
	of identity (the same can of course be said about MAC addresses).
	
	
	\textbf{Storage and retrieval attacks}
	
	
	DHTs are vulnerable against malicious nodes denying or misrepresenting
	requested information, while otherwise participating in the network
	in a legitimate manner. The solution to this is replication of data
	s.t.\ no single node is responsible for any piece of data. Avoid
	single points of responsibility. In our case, replication and multiple
	paths can surely be of benefit to ensure consistency. Same general
	principle.
	
	
	\textbf{Miscellaneous attacks}
	
	
	An attack can be more difficult to detect if nodes show good behaviour
	towards parts of the network while doing bad things to the rest.
	This is certainly applicable to aggregation networks -- a node may
	appear to be participating fully, but lie about its findings or make
	itself appear as a leaf (cutting off its children). Redundant paths
	may help for this -- establish multiple (braided?) paths between
	root and each child node and thus remove the possibility of any single
	node to cut off knowledge of subtrees.
	
	
	Denial of service against individual nodes is certainly an issue for
	aggregation networks. An attack against the root would be devastating
	and probably difficult to prevent/stop without pruning the whole
	offending branch.
	
	
	Rapid joins and leaves are bad for aggregation trees as well as DHTs
	if a lot of maintenance has to be done by other members. Rapid churn
	is a fact of life in many p2p systems as noted by \citeA{krishnamurthy2001},
	though probably not for most aggregation networks (?).
	
	
	Unsolicited messages are also defined as a threat. In the DHT context,
	this can be a forged result for an iterative query. In the case of
	aggregation trees, this is probably closest to the case discussed
	previously of a node falsifying results from its children.}
}

@INPROCEEDINGS{slagell2005,
  author = {Adam Slagell and William Yurcik},
  title = {Sharing Computer Network Logs for Security and Privacy: A Motivation
	for New Methodologies of Anonymization},
  booktitle = {{Proceedings of SECOVAL: The Workshop on the Value of Security through
	Collaboration}},
  year = {2005},
  pages = {80--89},
  abstract = {Logs are one of the most fundamental resources to any security professional.
	It is widely recognized by the government and industry that it is
	both beneficial and desirable to share logs for the purpose of security
	research. However, the sharing is not happening or not to the degree
	or magnitude that is desired. Organizations are reluctant to share
	logs because of the risk from exposing sensitive information to potential
	attackers. In this paper we survey current attempts at sharing logs
	and current log anonymization tools. We further define the problem
	and describe a roadmap to solve the issues that have to date inhibited
	large scale log sharing.},
  file = {slagell2005.pdf:slagell2005.pdf:PDF}
}

@INPROCEEDINGS{slijepcevic2002,
  author = {Sasha Slijepcevic and Vlasios Tsiatsis and Scott Zimbeck and Miodrag
	Potkonjak and Mani B. Srivastava},
  title = {On Communication Security in Wireless Ad-Hoc Sensor Networks},
  booktitle = {{IEEE} International Conference on Enabling Technologies: Infrastructure
	for Collaborative Enterprises ({WETICE'02})},
  year = {2002},
  pages = {139--144},
  address = {Pittsburg, Pennsylvania, USA},
  abstract = {Networks of wireless microsensors for monitoring physical environments
	have emerged as an important new application area for the wireless
	technology. Key attributes of these new types of networked systems
	are the severely constrained computational and energy resources,
	and an ad hoc operational environment. This paper is a study of the
	communication security aspects of these networks. Resource limitations
	and specific architecture of sensor networks call for customized
	security mechanisms. Our approach is to classify the types of data
	existing in sensor networks, and identify possible communication
	security threats according to this classification. We propose a communication
	security framework where for each type of data we define a corresponding
	security mechanism. By employing this multitiered security architecture
	where each mechanism has different resource requirements we allow
	for efficient resource management that is essential for wireless
	sensor networks.},
  file = {slijepcevic2002.pdf:slijepcevic2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.07.01}
}

@INPROCEEDINGS{Smaragdakis1999,
  author = {Yannis Smaragdakis and Scott Kaplan and Paul R. Wilson},
  title = {EELRU: Simple and Effective Adaptive Page Replacement},
  booktitle = {ACM SIGMETRICS International Conference on Measurement and Modeling
	of Computer Systems},
  year = {1999},
  pages = {122-133},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/smaragdakis99eelru.html}
}

@MISC{Smarandache-linear-congruences,
  author = {Florentin Smarandache},
  title = {Algorithms for Solving Linear Congruences and Systems Of Linear Congruences},
  file = {Smarandache-linear-congruences.pdf:Smarandache-linear-congruences.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.02.14}
}

@INPROCEEDINGS{smith2001,
  author = {F. Donelson Smith and Félix Hernández Campos and Kevin Jeffay and
	David Ott},
  title = {What TCP/IP Protocol Headers Can Tell Us About the Web},
  booktitle = {ACM SIGMETRICS},
  year = {2001},
  pages = {245-256},
  address = {Cambridge, MA},
  month = {June},
  abstract = {We report the results of a large-scale empirical study of web traffic.
	Our study is based on over 500 GB of TCP/IP protocol-header traces
	collected in 1999 and 2000 (approximately one year apart) from the
	high-speed link connecting a large university to its Internet service
	provider. We also use a set of smaller traces from the NLANR repository
	taken at approximately the same times for comparison. The principal
	results from this study are: (1) empirical data suitable for constructing
	traffic generating models of contemporary web traffic, (2) new characterizations
	of TCP connection usage showing the effects of HTTP protocol improvement,
	notably persistent connections (e.g., about 50% of web objects are
	now transferred on persistent connections), and (3) new characterizations
	of web usage and content structure that reflect the influences of
	"banner ads," server load balancing, and content distribution. A
	novel aspect of this study is to demonstrate that a relatively light-weight
	methodology based on passive tracing of only TCP/IP headers and off-line
	analysis tools can provide timely, high quality data about web traffic.
	We hope this will encourage more researchers to undertake ongoing
	data collection programs and provide the research community with
	data about the rapidly evolving characteristics of web traffic.},
  file = {:SMITH-SIGMETRICS-01.pdf:PDF},
  keywords = {networks, network measurements and analysis, web usage analysis},
  owner = {kristjan},
  timestamp = {2009.01.16}
}

@INPROCEEDINGS{Sollazzo2007,
  author = {Giuseppe Sollazzo and Mirco Musolesi and Cecilia Mascolo},
  title = {TACO-DTN: A Time-Aware COntent-based dissemination system for Delay
	Tolerant Networks},
  booktitle = {Proceedings of the First International Workshop on Mobile Opportunistic
	Networking (Mobiopp)},
  year = {2007},
  address = {Puerto Rico},
  month = {June},
  file = {mobiopp_beppe.pdf:/home/kristjan/articles/mobiopp_beppe.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{sommers2004,
  author = {Joel Sommers and Hyungsuk Kim and Paul Barford},
  title = {Harpoon: a flow-level traffic generator for router and network tests},
  booktitle = {{SIGMETRICS} '04/Performance '04: Proceedings of the joint international
	conference on Measurement and modeling of computer systems},
  year = {2004},
  pages = {392--392},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We describe Harpoon, a new application-independent tool for generating
	representative packet traffic at the IP flow level. Harpoon is a
	configurable tool for creating TCP and UDP packet flows that have
	the same byte, packet, temporal, and spatial characteristics as measured
	at routers in live environments. We validate Harpoon using traces
	collected from a live router and then demonstrate its capabilities
	in a series of router performance benchmark tests.},
  doi = {http://doi.acm.org/10.1145/1005686.1005733},
  file = {sommers2004.pdf:sommers2004.pdf:PDF},
  isbn = {1-58113-873-3},
  keywords = {networks, traffic generation, IP flows generation},
  location = {New York, NY, USA}
}

@MISC{rfc-4494-song-2006,
  author = {JH. Song and R. Poovendran and J. Lee},
  title = {{RFC}-4494: The {AES-CMAC-96} Algorithm and Its Use with {IPsec}},
  month = {June},
  year = {2006},
  owner = {kristjan},
  timestamp = {2010.09.03},
  url = {http://tools.ietf.org/html/rfc4494}
}

@MISC{rfc-4493-2006,
  author = {JH. Song and R. Poovendran and J. Lee and T. Iwata},
  title = {{RFC} 4493: The {AES-CMAC} Algorithm},
  month = {June},
  year = {2006},
  owner = {kristjan},
  timestamp = {2010.09.02},
  url = {http://tools.ietf.org/html/rfc4493}
}

@ARTICLE{song2005,
  author = {Shanshan Song and Kai Hwang and Runfang Zhou and Yu-Kwong Kwok},
  title = {Trusted P2P Transactions with Fuzzy Reputation Aggregation},
  journal = {IEEE Internet Computing},
  year = {2005},
  volume = {9},
  pages = {24--34},
  number = {6},
  abstract = {Internet commerce and online commodity exchanges suffer from distrust
	among sellers and buyers, who are often strangers to each other.
	The authors present a new P2P reputation system based on fuzzy logic
	inferences, which can better handle uncertainty, fuzziness, and incomplete
	information in peer trust reports.This system aggregates peer reputations
	with affordable message overhead. By testing the system using eBay
	transaction data in the public domain, the authors seek to demonstrate
	the efficacy and robustness of two P2P reputation systems¿FuzzyTrust
	and EigenTrust¿at establishing trust among the peers in P2P applications.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/MIC.2005.136},
  file = {:song2005.pdf:PDF},
  issn = {1089-7801},
  publisher = {IEEE Educational Activities Department}
}

@MISC{soref-2003,
  author = {Josh Soref},
  title = {{DNS}: Spoofing and Pinning.},
  month = {September},
  year = {2003},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://viper.haque.net/~timeless/blog/11/}
}

@ARTICLE{sorniotti2007,
  author = {Alesandro Sorniotti and Laurent Gomez and Konrad Wrona and Lorenzo
	Odorico},
  title = {Secure and Trusted in-network Data Processing in Wireless Sensor
	Networks: a survey},
  journal = {Journal of Information Assurance and Security},
  year = {2007},
  volume = {2},
  pages = {189-199},
  abstract = {In-network data processing in wireless sensor networks (WSN) is a
	rapidly emerging research topic. The distributed processing could
	have several advantages for wireless sensor networks. First of all,
	in WSN computation is typically much less energy consuming than communication.
	Secondly, in-network processing enables WSN to provide more complex
	services to application layer, and not only data gathering functionality.
	However, in addition to computational overhead, in-network data processing
	introduces also many challenging security issues. Most of them are
	still open and require development of innovative security mechanisms.
	In this article we survey the current research related to security
	of in-network data processing in wireless sensor networks and highlight
	the directions, which are most promising in our opinion.},
  file = {sorniotti2007.pdf:sorniotti2007.pdf:PDF},
  keywords = {security, aggregation, wireless sensor network, survey, elliptic curves
	cryptography, bilinear pairings, privacy homomorphisms, reputation,
	trust, secure aggregation},
  owner = {kristjan},
  review = {A decent survey paper on issues related to secure aggregation. Fairly
	light on actual secure aggregation. Better on background and techniques.
	
	Good on crypto: ECC, bilinear pairings, PH. Also discusses trust and
	reputation.
	
	
	Bilinear parings over elliptic curves: can implement oracles for the
	DDH problem, yet keep the CDH problem hard.
	
	
	Mentions identity based cryptography briefly in his background on
	techniques.
	
	
	Interesting background discussion on subjective logic -- leave for
	later. Subjective logic discussed in conjunction with reputation
	and particularily the beta probability density function.},
  timestamp = {2010.01.15}
}

@MISC{Sotirov2008,
  author = {Alexander Sotirov and Marc Stevens and Jacob Appelbaum and Arjen
	Lenstra and David Molnar and Dag Arne Osvik and Benne de Weger},
  title = {{MD5} considered harmful today},
  howpublished = {[online] \url{http://www.win.tue.nl/hashclash/rogue-ca}},
  month = {December},
  year = {2008},
  owner = {kristjan},
  timestamp = {2010.03.02},
  url = {http://www.win.tue.nl/hashclash/rogue-ca/}
}

@TECHREPORT{specht2003,
  author = {Stephen Specht and Ruby Lee},
  title = {Taxonomies of Distributed Denial of Service Networks, Attacks, Tools,
	and Countermeasures},
  institution = {Department of Electrical Engineering, Princeton Architecture Laboratory
	for Multimedia and Security, Princeton},
  year = {2003},
  number = {Technical Report CE-L2003-03},
  month = {May},
  file = {:specht2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@ONLINE{online_spitzner_honeynets,
  author = {L. Spitzner},
  title = {Know Your Enemy: Honeynets},
  url = {http://www.honeynet.org/papers/honeynet/},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@TECHREPORT{Sridhara,
  author = {Vinay Sridhara and Stephan Bohacek},
  title = {Realistic Propagation Simulation of Urban Mesh Networks},
  institution = {University of Delaware},
  abstract = {Simulation plays an important role in the veriﬁcation of mobile wireless
	networking protocols. Recently several
	
	cities have either begun deploying or are completing plans to deploy
	large-scale urban mesh networks (LUMNets).
	
	On the other hand, the networking research community has little expertise
	in simulating such networks. While
	
	the protocols are simulated reasonably realistically, the propagation
	of wireless transmissions and the mobility of
	
	nodes are not. Today, simulations typically model propagation with
	either the free-space model or a "two-ray"
	
	model that includes a ground reﬂection. Such models are only valid
	in open space where there are no hills and
	
	no buildings. Since wireless signals at the frequencies used for mobile
	wireless networking are partly reﬂected off
	
	of buildings and partly is transmitted into the building, the presence
	of buildings greatly inﬂuences propagation.
	
	Consequently, the open-space propagation models are inaccurate in
	outdoor urban areas. Indoors, the open-space
	
	models are not even applicable. This paper presents guidelines for
	simulating propagation in such urban settings.
	
	Furthermore, extensive background discussion on propagation is also
	included. The techniques for propagation are
	
	validated against propagation measurements. The techniques discussed
	are implemented in a suite of tools that are
	
	compatible with protocol simulators and are freely available for use.},
  file = {PropagationTechRep.pdf:PropagationTechRep.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@MISC{srisuresh-rfc-5128-2008,
  author = {P. Srisuresh and B. Ford and D. Kegel},
  title = {{RFC 5128}: State of Peer-to-Peer ({P2P}) Communication across Network
	Address Translators ({NATs})},
  month = {March},
  year = {2008},
  abstract = {This memo documents the various methods known to be in use by applications
	to establish direct communication in the presence of Network Address
	Translators (NATs) at the current time. Although this memo is intended
	to be mainly descriptive, the Security Considerations section makes
	some purely advisory recommendations about how to deal with security
	vulnerabilities the applications could inadvertently create when
	using the methods described. This memo covers NAT traversal approaches
	used by both TCP- and UDP-based applications. This memo is not an
	endorsement of the methods described, but merely an attempt to capture
	them in a document.},
  owner = {kristjan},
  timestamp = {2009.02.10},
  url = {http://tools.ietf.org/html/rfc5128}
}

@PHDTHESIS{mudhakar2007,
  author = {Mudhakar Srivatsa},
  title = {Security Architecture And Protocols For Overlay Network Services},
  school = {Georgia Institute of Technology},
  year = {2007},
  month = {August},
  abstract = {Conventional wisdom suggests that in order to build a secure system,
	security must be an integral component in the system design. However,
	cost considerations drive most system designers to channel their
	efforts on the system's performance, scalability and usability. With
	little or no emphasis on security, such systems are vulnerable to
	a wide range of attacks that can potentially compromise confidentiality,
	integrity and availability of sensitive data. It is often cumbersome
	to redesign and implement massive systems with security as one of
	the primary design goals. This thesis advocates a proactive approach
	that cleanly retrofits security solutions into existing system architectures.
	The first step in this approach is to identify security threats,
	vulnerabilities and potential attacks on a system or an application.
	The second step is to develop security tools in the form of customizable
	and configurable plug-ins that address these security issues and
	minimally modify existing system code, while preserving its performance
	and scalability metrics. This thesis uses overlay network applications
	to shepherd through and address challenges involved in supporting
	security in large scale distributed systems. In particular, the focus
	is on two popular applications: publish/subscribe networks and VoIP
	networks. Our work on VoIP networks has for the first time identified
	and formalized caller identification attacks on VoIP networks. We
	have identified two attacks: a triangulation based timing attack
	on the VoIP network's route set up protocol and a flow analysis attack
	on the VoIP network's voice session protocol. These attacks allow
	an external observer (adversary) to uniquely (nearly) identify the
	true caller (and receiver) with high probability. Our work on the
	publish/subscribe networks has resulted in the development of an
	unified framework for handling event confidentiality, integrity,
	access control and DoS attacks, while incurring small overhead on
	the system. We have proposed a key isomorphism paradigm to preserve
	the confidentiality of events on publish/subscribe networks while
	permitting scalable content-based matching and routing. Our work
	on overlay network security has resulted in a novel information hiding
	technique on overlay networks. Our solution represents the first
	attempt to transparently hide the location of data items on an overlay
	network.},
  file = {mudhakar2007.pdf:mudhakar2007.pdf:PDF},
  owner = {kristjan},
  review = {Overlay networks used to retrofit existing systems with enhanced security.},
  timestamp = {2009.09.02}
}

@INPROCEEDINGS{srivatsa2004,
  author = {Srivatsa, Mudhakar and Liu, Ling},
  title = {Vulnerabilities and Security Threats in Structured Overlay Networks:
	A Quantitative Analysis},
  booktitle = {{ACSAC '04: Proceedings of the 20th Annual Computer Security Applications
	Conference}},
  year = {2004},
  pages = {252--261},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {A number of recent applications have been built on distributed hash
	tables (DHTs) based overlay networks. Almost all DHT-based schemes
	employ a tight deterministic data placement and ID mapping schemes.
	This feature on one hand provides assurance on location of data if
	it exists, within a bounded number of hops, and on the other hand,
	opens doors for malicious nodes to lodge attacks that can potentially
	thwart the functionality of the overlay network. This paper studies
	several serious security threats in DHT-based systems through two
	targeted attacks at the overlay network's protocol layer. The first
	attack explores the routing anomalies that can be caused by malicious
	nodes returning incorrect lookup routes. The second attack targets
	the ID mapping scheme. We disclose that the malicious nodes can target
	any specific data item in the system; and corrupt/modify the data
	item to its favor. For each of these attacks, we provide quantitative
	analysis to estimate the extent of damage that can be caused by the
	attack; followed by experimental validation and defenses to guard
	the overlay networks from such attacks.},
  doi = {http://dx.doi.org/10.1109/CSAC.2004.50},
  isbn = {0-7695-2252-1}
}

@INPROCEEDINGS{stadler2008,
  author = {Rolf Stadler and Mads Dam and Alberto Gonzalez and Fetahi Wuhib},
  title = {Decentralized real-time monitoring of network-wide aggregates},
  booktitle = {{LADIS '08: Proceedings of the 2nd Workshop on Large-Scale Distributed
	Systems and Middleware}},
  year = {2008},
  pages = {1--6},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The traditional monitoring paradigm of network and systems management,
	characterized by a central entity polling individual devices, is
	not adequate for today's large-scale networked systems whose states
	and configurations are highly dynamic. We outline principles for
	monitoring such new systems and stress the need for protocols that
	continuously monitor network-wide aggregates. To keep the overhead
	at acceptable levels, such protocols must be tunable, e.g., allow
	controlling the trade-off between accuracy and overhead. We describe
	and compare two of our efforts in developing protocols for decentralized
	monitoring of aggregates; one is based on spanning trees, the other
	on gossiping.},
  doi = {http://doi.acm.org/10.1145/1529974.1529984},
  file = {stadler2008.pdf:stadler2008.pdf:PDF},
  isbn = {978-1-60558-296-2},
  location = {Yorktown Heights, New York}
}

@INPROCEEDINGS{stajano1999,
  author = {Frank Stajano and Ross Anderson},
  title = {The resurrecting duckling: Security issues for ad-hoc wireless networks},
  booktitle = {7th International Workshop on Security Protocols},
  year = {1999},
  pages = {172--194},
  address = {Cambridge, England},
  publisher = {Springer-Verlag},
  abstract = {In the near future, many personal electronic devices will be able
	to communicate with each other over a short range wireless channel.
	We investigate the principal security issues for such an environment.
	Our discussion is based on the concrete example of a thermometer
	that makes its readings available to other nodes over the air. Some
	lessons learned from this example appear to be quite general to ad-hoc
	networks, and rather diﬀerent from what we have come to expect in
	more conventional systems: denial of service, the goals of authentication,
	and the problems of naming all need re-examination. We present the
	resurrecting duckling security policy model, which describes secure
	transient association of a device with multiple serialised owners.},
  file = {stajano1999.pdf:stajano1999.pdf:PDF}
}

@BOOK{Stallings2005,
  title = {Wireless Communications \& Networks},
  publisher = {Pearson Prentice Hall},
  year = {2005},
  author = {William Stallings},
  edition = {2},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{stamm-2008,
  author = {Sid Stamm and Zulfikar Ramzan and Markus Jakobsson},
  title = {Drive-by pharming},
  journal = {Lecture Notes in Computer Science. Information and Communications
	Security.},
  year = {2008},
  pages = {495-506},
  file = {stamm-drive-by-pharming.pdf:stamm-drive-by-pharming.pdf:PDF},
  owner = {kristjan},
  publisher = {Springer Berlin / Heidelberg},
  timestamp = {2008.11.14}
}

@INPROCEEDINGS{Stann2003,
  author = {Fred Stann and John Heidemann},
  title = {{RMST}: Reliable Data Transport in Sensor Networks},
  booktitle = {Proceedings of the First International Workshop on Sensor Net Protocols
	and Applications},
  year = {2003},
  pages = {102--112},
  address = {Anchorage, Alaska, USA},
  month = {April},
  publisher = {{IEEE}},
  abstract = {Reliable data transport in wireless sensor networks is a multifaceted
	problem influenced by the physical, MAC, network, and transport layers.
	Because sensor networks are subject to strict resource constraints
	and are deployed by single organizations, they encourage revisiting
	traditional layering and are less bound by standardized placement
	of services such as reliability. This paper presents analysis and
	experiments resulting in specific recommendations for implementing
	reliable data transport in sensor nets. To explore reliability at
	the transport layer, we present RMST (Reliable Multi-Segment Transport),
	a new transport layer for Directed Diffusion. RMST provides guaranteed
	delivery and fragmentation/reassembly for applications that require
	them. RMST is a selective NACK-based protocol that can be configured
	for in-network caching and repair.},
  file = {Stann2003.pdf:Stann2003.pdf:PDF},
  keywords = {sensor networks, reliable transport layer, RMST, PDSQ},
  myorganization = {USC/Information Sciences Institute},
  pdfurl = {http://www.isi.edu/~johnh/PAPERS/Stann03a.pdf},
  url = {http://www.isi.edu/~johnh/PAPERS/Stann03a.html}
}

@ARTICLE{steiner2007,
  author = {Moritz Steiner and Taoufik En-Najjary and Ernst W. Biersack},
  title = {Exploiting {KAD}: possible uses and misuses},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {2007},
  volume = {37},
  pages = {65--70},
  number = {5},
  abstract = {Peer-to-peer systems have seen a tremendous growth in the last few
	years and peer-to-peer traffic makes a major fraction of the total
	traffic seen in the Internet. The dominating application for peer-to-peer
	is file sharing. Some of the most popular peer-to-peer systems for
	file sharing have been Napster, FastTrack, BitTorrent, and eDonkey,
	each one counting a million or more users at their peak time.
	
	
	We got interested in kad since it is the only DHT that has been part
	of very popular peer-to-peer system with several million simultaneous
	users. As we have been studying kad over the course of the last 18
	months we have been both, fascinated and frightened by the possibilities
	kad offers. Mounting a Sybil attack is very easy in kad and allows
	to compromise the privacy of kad users, to compromise the correct
	operation of the key lookup and to mount DDOS with very little resources.
	
	
	In this paper, we will relate some of our findings and point out how
	kad can be used and misused.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1290168.1290176},
  file = {steiner2007.pdf:steiner2007.pdf:PDF},
  issn = {0146-4833},
  publisher = {ACM}
}

@ARTICLE{stephenson1989,
  author = {Karen Stephenson and Marvin Zelen},
  title = {Rethinking Centrality: Methods and Examples},
  journal = {Social Networks},
  year = {1989},
  volume = {1},
  number = {37},
  file = {stephenson1989.pdf:stephenson1989.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.04.22}
}

@BOOK{Stevens1994,
  title = {{TCP/IP Illustrated, Volume 1, The Protocols}},
  publisher = {Addison-Wesley},
  year = {1994},
  author = {W. Richard Stevens},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@BOOK{stinson2006,
  title = {Cryptography -- Theory and Practice},
  publisher = {Chapman \& Hall/CRC},
  year = {2006},
  editor = {Kenneth H. Rosen},
  author = {Douglas R. Stinson},
  owner = {kristjan},
  timestamp = {2010.03.16}
}

@INCOLLECTION{stinson2007,
  author = {Elizabeth Stinson and John C. Mitchell},
  title = {Characterizing Bots\' Remote Control Behavior},
  booktitle = {Detection of Intrusions and Malware, and Vulnerability Assessment},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {Volume 4579/2007},
  series = {Lecture Notes in Computer Science},
  pages = {89-108},
  file = {:stinson2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@ARTICLE{stoica2003,
  author = {Ion Stoica and Robert Morris and David Liben-Nowell and David R Karger
	and M. Frans Kaashoek and Frank Dabek and Hari Balakrishnan},
  title = {Chord: a scalable peer-to-peer lookup protocol for internet applications},
  journal = {IEEE/ACM Trans. Netw.},
  year = {2003},
  volume = {11},
  pages = {17--32},
  number = {1},
  abstract = {A fundamental problem that confronts peer-to-peer applications is
	the efficient location of the node that stores a desired data item.
	This paper presents Chord, a distributed lookup protocol that addresses
	this problem. Chord provides support for just one operation: given
	a key, it maps the key onto a node. Data location can be easily implemented
	on top of Chord by associating a key with each data item, and storing
	the key/data pair at the node to which the key maps. Chord adapts
	efficiently as nodes join and leave the system, and can answer queries
	even if the system is continuously changing. Results from theoretical
	analysis and simulations show that Chord is scalable: Communication
	cost and the state maintained by each node scale logarithmically
	with the number of Chord nodes.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TNET.2002.808407},
  file = {stoica2003.pdf:stoica2003.pdf:PDF},
  issn = {1063-6692},
  publisher = {IEEE Press}
}

@ARTICLE{stonebraker2005,
  author = {Michael Stonebraker and U\v{g}ur \c{C}etintemel and Stan Zdonik},
  title = {The 8 requirements of real-time stream processing},
  journal = {SIGMOD Rec.},
  year = {2005},
  volume = {34},
  pages = {42--47},
  number = {4},
  abstract = {Applications that require real-time processing of high-volume data
	steams are pushing the limits of traditional data processing infrastructures.
	These stream-based applications include market feed processing and
	electronic trading on Wall Street, network and infrastructure monitoring,
	fraud detection, and command and control in military environments.
	Furthermore, as the "sea change" caused by cheap micro-sensor technology
	takes hold, we expect to see everything of material significance
	on the planet get "sensor-tagged" and report its state or location
	in real time. This sensorization of the real world will lead to a
	"green field" of novel monitoring and control applications with high-volume
	and low-latency processing requirements.Recently, several technologies
	have emerged---including off-the-shelf stream processing engines---specifically
	to address the challenges of processing high-volume, real-time data
	without requiring the use of custom code. At the same time, some
	existing software technologies, such as main memory DBMSs and rule
	engines, are also being "repurposed" by marketing departments to
	address these applications.In this paper, we outline eight requirements
	that a system software should meet to excel at a variety of real-time
	stream processing applications. Our goal is to provide high-level
	guidance to information technologists so that they will know what
	to look for when evaluation alternative stream processing solutions.
	As such, this paper serves a purpose comparable to the requirements
	papers in relational DBMSs and on-line analytical processing. We
	also briefly review alternative system software technologies in the
	context of our requirements.The paper attempts to be vendor neutral,
	so no specific commercial products are mentioned.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1107499.1107504},
  file = {borealis-icde05.pdf:borealis-icde05.pdf:PDF},
  issn = {0163-5808},
  publisher = {ACM},
  timestamp = {2008.03.06}
}

@MISC{stuttard-2007,
  author = {Dafydd Stuttard},
  title = {{DNS} pinning and web proxies},
  howpublished = {Whitepaper, NGSSoftware Insight Security Research},
  year = {2007},
  file = {DnsPinningAndWebProxies.pdf:DnsPinningAndWebProxies.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14}
}

@ARTICLE{Stutzbach2005,
  author = {Daniel Stutzbach and Daniel Zappala and Reza Rejaie},
  title = {The Scalability of Swarming Peer-to-Peer Content Delivery},
  journal = {Lecture Notes in Computer Science},
  year = {2005},
  volume = {3462/2005},
  pages = {15-26},
  abstract = {Most web sites are unable to serve content to a large num-
	
	ber of users due to the inherent limitations of client-server ﬁle
	transfer.
	
	Recent peer-to-peer content delivery protocols have demonstrated the
	
	feasibility of spreading this load among the clients themselves, giving
	
	small web sites the possibility of serving large audiences with very
	low
	
	cost. In this paper we use a simulation-based performance evaluation
	to
	
	study the fundamental question of the scalability of swarming peer-to-
	
	peer content delivery. Our results demonstrate the superior scalability
	of
	
	swarming with respect to load, ﬁle size, block size, and client bandwidth.},
  file = {stutzbach2005.pdf:stutzbach2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@TECHREPORT{Stutzbach2004,
  author = {Daniel Stutzbach and Daniel Zappala and Reza Rejaie},
  title = {Swarming: Scalable Content Delivery for the Masses},
  institution = {UNIVERSITY OF OREGON,},
  year = {2004},
  number = {CIS-TR-2004-1},
  file = {swarming-tech04.pdf:swarming-tech04.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{sun2007c,
  author = {Bo Sun and Nilam Chand and Kui Wu and Yang Xiao},
  title = {Change-Point Monitoring for Secure In-Network Aggregation in Wireless
	Sensor Networks},
  booktitle = {{GLOBECOM'07}: Proceedings of the Global Communications Conference},
  year = {2007},
  pages = {936-940},
  address = {Washington, DC, USA},
  month = {November},
  abstract = {Secure in-network aggregation in wireless sensor networks is a necessary
	and challenging task. In this paper, based on an extended Kalman
	filter which can facilitate us to set up a normal range of the neighbor's
	future transmitted aggregated values, we further apply an algorithm
	of combining cumulative summation and generalized likelihood ratio,
	which can utilize the cumulative sum of the deviations between measured
	values and estimated values, and derive a normal range which is more
	sensitive to attacks. We conduct experiments and simulations to evaluate
	our proposed local detection mechanisms under different aggregation
	functions.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://dx.doi.org/10.1109/GLOCOM.2007.180},
  file = {sun2007c.pdf:sun2007c.pdf:PDF},
  keywords = {sensor networks, in-network aggregation, security, secure aggregation,
	intrusion detection}
}

@INPROCEEDINGS{sun2007b,
  author = {Bo Sun and Xing Jin and Kui Wu and Yang Xiao},
  title = {Integration of Secure In-Network Aggregation and System Monitoring
	for Wireless Sensor Networks},
  booktitle = {{IEEE} International Conference on Communications, {ICC '07}},
  year = {2007},
  pages = {1466-1471},
  month = {June},
  abstract = {Secure in-network aggregation in wireless sensor networks (WSNs) is
	a necessary and challenging task. In this paper, we address this
	research problem from an intrusion detection perspective. We propose
	that system monitoring modules, which provide one of the most important
	functionalities for WSNs, should be integrated with intrusion detection
	modules. Under this architecture, we first propose an extended Kalman
	filter (EKF) based mechanism to detect false injected data. Specifically,
	by monitoring behaviors of nodes' neighbors and using EKF to predict
	their future state (the real in-network aggregated value), we aim
	at setting up the normal range of neighbors' future transmitted aggregated
	values. We illustrate how we use EKF to create effective local detection
	mechanisms. Using different aggregation functions (average, sum,
	max, and min), we analyze how to obtain the threshold in theory.
	We then illustrate how our proposed local detection approach can
	work together with the system monitoring module to differentiate
	between malicious events and emergency events. We conduct simulations
	to evaluate performance of local detection mechanisms, including
	false positive rate and detection rate, under different aggregation
	functions.},
  doi = {10.1109/ICC.2007.246},
  file = {sun2007b.pdf:sun2007b.pdf:PDF},
  keywords = {Kalman filters, filtering theory, nonlinear filters, telecommunication
	security, wireless sensor networksextended Kalman filter, in-network
	aggregation security, intrusion detection, system monitoring, system
	monitoring module, wireless sensor networks}
}

@ARTICLE{sun2008,
  author = {Sun, Bo and Xiao, Yang and Li, Chung Chih and Chen, Hsiao-Hwa and
	Yang, T. Andrew},
  title = {Security co-existence of wireless sensor networks and {RFID} for
	pervasive computing},
  journal = {{Comput. Commun.}},
  year = {2008},
  volume = {31},
  pages = {4294--4303},
  number = {18},
  abstract = {Recent advances in wireless networks and embedded systems have created
	a new class of pervasive systems such as Wireless Sensor Networks
	(WSNs) and Radio Frequency IDentification (RFID) systems. WSNs and
	RFID systems provide promising solutions for a wide variety of applications,
	particularly in pervasive computing. However, security and privacy
	concerns have raised serious challenges on these systems. These concerns
	have become more apparent when WSNs and RFID systems co-exist. In
	this article, we first briefly introduce WSNs and RFID systems. We
	then present their security concerns and related solutions. Finally,
	we propose a Linear Congruential Generator (LCG) based lightweight
	block cipher that can meet security co-existence requirements of
	WSNs and RFID systems for pervasive computing.},
  address = {Newton, MA, USA},
  doi = {http://dx.doi.org/10.1016/j.comcom.2008.05.035},
  file = {sun2008.pdf:sun2008.pdf:PDF},
  issn = {0140-3664},
  keywords = {sensor networks, crypto algorithm},
  owner = {kristjan},
  publisher = {Butterworth-Heinemann}
}

@ARTICLE{sun2006,
  author = {Kun Sun and Pai Peng and Peng Ning and Cliff Wang},
  title = {Secure Distributed Cluster Formation in Wireless Sensor Networks},
  journal = {Computer Security Applications Conference, Annual},
  year = {2006},
  volume = {0},
  pages = {131-140},
  abstract = {In wireless sensor networks, clustering sensor nodes into small groups
	is an effective technique to achieve scalability, self-organization,
	power saving, channel access, routing, etc. A number of cluster formation
	protocols have been proposed recently. However, most existing protocols
	assume benign environments, and are vulnerable to attacks from malicious
	nodes. In this paper, we propose a secure distributed cluster formation
	protocol to organize sensor networks into mutually disjoint cliques.
	Our protocol has the following properties: (1) normal nodes are divided
	into mutually disjoint cliques; (2) all the normal nodes in each
	clique agree on the same clique memberships; (3) while external attackers
	can be prevented from participating in the cluster formation process,
	inside attackers that do not follow the protocol semantics can be
	identified and removed from the network; (4) the communication overhead
	is moderate; (5) the protocol is fully distributed.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ACSAC.2006.46},
  file = {sun2006.pdf:sun2006.pdf:PDF},
  issn = {1063-9527},
  keywords = {sensor network, wireless network, cluster formation algorithm},
  publisher = {IEEE Computer Society}
}

@TECHREPORT{sun2007,
  author = {Xin Sun and Ruben Torres and Sanjay Rao},
  title = {Preventing {DDoS} Attacks with {P2P} Systems through Robust Membership
	Management},
  institution = {Purdue University},
  year = {2007},
  number = {TR-EE-07-13},
  address = {West Lafayette, IN},
  abstract = {We show that malicious nodes in a peer-to-peer system may impact the
	external Internet environment, by causing large-scale distributed
	denial of service attacks on nodes not even part of the overlay system.
	This is in contrast to attacks that disrupt the normal functioning,
	and performance of the overlay system itself. We formulate several
	principles critical to the design of membership management protocols
	robust to such attacks. We show that (i) pull-based mechanisms are
	preferable to push-based mechanisms; (ii) it is critical to validate
	membership information received by a node, and even simple probe-based
	techniques can be quite effective; (iii) validating information by
	requiring corroboration from multiple sources can provide good security
	properties with insigniﬁcant performance penalties; and (iv) it is
	important to bound the number of distinct logical identiﬁer (e.g.
	IDs in a DHT) corresponding to the same physical identiﬁer (e.g.,
	IP address), which a participating node is unable to validate. We
	demonstrate the importance of these principles in the context of
	the Kad system for ﬁle distribution, and ESM system for video broadcasting.
	To our knowledge, this is the ﬁrst systematic study of issues in
	the design of membership management algorithms in peer-to-peer systems
	so they may be robust to attacks exploiting them for DDoS attacks
	on external nodes.},
  file = {:TR-EE-07-13.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@ARTICLE{sun2007a,
  author = {Sun, Xin and Torres, Ruben and Rao, Sanjay},
  title = {{DDoS} Attacks by Subverting Membership Management in {P2P} Systems},
  journal = {Secure Network Protocols, 2007. NPSec 2007. 3rd IEEE Workshop on},
  year = {2007},
  pages = {1-6},
  month = {Oct.},
  abstract = {We show that malicious participants in a peer-to-peer system can subvert
	its membership management mechanisms to create large-scale DDoS attacks
	on nodes not even part of the overlay system. The attacks exploit
	many fundamental design choices made by peer-to-peer system designers
	such as (i) use of push-based mechanisms; (ii) use of distinct logical
	identifier (e.g. IDs in a DHT) corresponding to the same physical
	identifier (e.g., IP address), typically to handle hosts behind NATs;
	and (iii) inadequate or poorly designed mechanisms to validate membership
	information. We demonstrate the significance of the attacks in the
	context of mature and extensively deployed peer-to-peer systems with
	representative and contrasting membership management algorithms -
	DHT-based Kad and gossip-based ESM.},
  doi = {10.1109/NPSEC.2007.4371618},
  file = {sun2007a.pdf:sun2007a.pdf:PDF},
  review = {see also tech report sun2007}
}

@ONLINE{surf-2006,
  author = {Moran Surf and Amichai Shulman},
  title = {How Safe is it Out There?},
  url = {http://www.imperva.com/resources/adc/how_safe_is_it.html},
  year = {2006},
  file = {:WP_How-Safe-Is-It_1006r2LK.pdf:PDF},
  keywords = {web application security},
  owner = {kristjan},
  project = {phd},
  timestamp = {2008.11.20}
}

@MISC{sykes-2007,
  author = {Jon Sykes},
  title = {Practical {CSRF} and {JSON} Security},
  month = {March},
  year = {2007},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://jpsykes.com/47/practical-csrf-and-json-security}
}

@INPROCEEDINGS{syverson1997,
  author = {Paul F. Syverson and David M. Goldschlag and Michael G. Reed},
  title = {Anonymous Connections and Onion Routing},
  booktitle = {{IEEE} Symposium on Security and Privacy},
  year = {1997},
  pages = {44},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  file = {10.1.1.47.639.pdf:10.1.1.47.639.pdf:PDF}
}

@ONLINE{szabo1999,
  author = {Nick Szabo},
  title = {The God Protocols},
  url = {http://szabo.best.vwh.net/msc.html},
  year = {1999},
  howpublished = {[online] http://szabo.best.vwh.net/msc.html},
  owner = {kristjan},
  review = {A high level overview of multi-party computation.},
  timestamp = {2010.01.21}
}

@INPROCEEDINGS{taban2008,
  author = {Gelareh Taban and Virgil D. Gligor},
  title = {Efficient Handling of Adversary Attacks in Aggregation Applications},
  booktitle = {Computer Security - {ESORICS 2008}},
  year = {2008},
  abstract = {Current approaches to handling adversary attacks against data aggregation
	in sensor networks either aim exclusively at the detection of aggregate
	data corruption or provide rather inefficient ways to identify the
	nodes captured by an adversary. In contrast, we propose a distributed
	algorithm for efficient identification of captured nodes over a constant
	number of rounds, for an arbitrary number of captured nodes. We formulate
	our problem as a combinatorial group testing problem and show that
	this formulation leads not only to efficient identification of captured
	nodes but also to a precise cost-based characterization of when in-network
	aggregation retains its assumed benefits in a sensor network operating
	under persistent attacks.},
  file = {taban2008.pdf:taban2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.26}
}

@INPROCEEDINGS{Tan2002,
  author = {Kymie M. C. Tan and Roy A. Maxion},
  title = {Why 6? Defining the Operational Limits of Stide, an Anomaly-Based
	Intrusion Detector},
  booktitle = {In Proceedings of the IEEE Symposium on Security and Privacy},
  year = {2002},
  pages = {188--202},
  abstract = {The detection of masqueraders and novel attacks are two of the more
	difficult problems facing intrusion detection systems. While anomaly-based
	intrusion detection approaches appear to be among the most promising
	techniques for dealing with these problems, con dence in the detection
	results requires precise knowledge of the detector's characteristics.
	These include identifying conditions under which the detector fails,
	as well as those in which it works well.
	
	One of the best-known anomaly detectors that has been applied to intrusion
	detection is stide1. Developed at the University of New Mexico, stide
	aims to detect attacks that exploit processes that run with root
	privileges. The
	
	original work on stide presented empirical results indicating that
	sequences of length six and above were required for e ective intrusion
	detection. This paper presents an evaluation framework that maps
	out stide's effective
	
	operating space, and identi es the conditions that contribute to detection
	strength, blindness or weakness. A theoretical justi cation for why
	sequence lengths six and above were e ective is given, and the consequences
	of a
	
	di erent choice on detector performance is explained. In addition,
	we give results of our investigation, which characterizes regions
	of the anomaly space in which stide is capable of anomaly detection
	and those in which it is not. We believe that relating detector properties
	of this kind to manifestations of intrusive activities is necessary
	if e ective anomaly-based intrusion detection systems are to be built
	and deployed.},
  file = {10.1.1.24.989.pdf:10.1.1.24.989.pdf:PDF}
}

@BOOK{Tanenbaum1997,
  title = {Operating Systems: Design and Implementation (Second Edition)},
  publisher = {Prentice-Hall},
  year = {1997},
  author = {Tanenbaum, Andrew S.},
  address = {New Jersey},
  edition = {Second edition},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{tang2005,
  author = {Chunqiang Tang and Rong N. Chang and Christopher Ward},
  title = {{GoCast}: Gossip-enhanced Overlay Multicast for Fast and Dependable
	Group Communication},
  booktitle = {{DSN}},
  year = {2005},
  pages = {140--149},
  publisher = {IEEE Computer Society},
  abstract = {We study dependable group communication for large-scale and delay-sensitive
	mission critical applications. The goal is to design a protocol that
	imposes low loads on bottleneck network links and provides both stable
	throughput and fast delivery of multicast messages even in the presence
	of frequent node and link failures. To this end, we propose our GoCast
	protocol. GoCast builds a resilient overlay network that is proximity
	aware and has balanced node degrees. Multicast messages propagate
	rapidly through an efficient tree embedded in the overlay. In the
	background, nodes exchange message summaries (gossips) with their
	overlay neighbors and pick up missing messages due to disruptions
	in the tree-based multicast. Our simulation based on real Internet
	data shows that, compared with a traditional gossip-based multicast
	protocol, GoCast can reduce the delivery delay of multicast messages
	by a factor of 8.9 when no node fails or a factor of 2.3 when 20%
	nodes fail.},
  file = {tang2005.pdf:tang2005.pdf:PDF},
  keywords = {gossip protocol, overlay network construction}
}

@BOOK{tel2000,
  title = {Introduction to Distributed Algorithms},
  publisher = {Cambridge University Press},
  year = {2000},
  author = {G. Tel},
  edition = {2nd Edition},
  owner = {kristjan},
  timestamp = {2009.03.10}
}

@ARTICLE{teng1990,
  author = {Henry S. Teng and Kaihu Chen},
  title = {Adaptive Real-Time Anomaly Detection Using Inductively Generated
	Sequential Patterns},
  journal = {{IEEE Symposium on Security and Privacy}},
  year = {1990},
  volume = {00},
  pages = {278},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/RISP.1990.63857},
  issn = {1540-7993},
  publisher = {IEEE Computer Society}
}

@MISC{teo2009,
  author = {Sui-Guan Teo and Mufeed Al-Mashrafi and Leonie Simpson and Ed Dawson},
  title = {Analysis of Authenticated Encryption Stream Ciphers},
  year = {2009},
  abstract = {Authenticated Encryption (AE) is the cryptographic process of providing
	simultaneous confidentiality and integrity protection to messages.
	AE is potentially more efficient than applying a two-step process
	of providing confidentiality for a message by encrypting the message
	and in a separate pass, providing integrity protection by generating
	a Message Authentication Code (MAC) tag. This paper presents results
	on the analysis of three AE stream ciphers submitted to the recently
	completed eSTREAM competition. We classify the ciphers based on the
	methods the ciphers use to provide authenticated encryption and discuss
	possible methods for mounting attacks on these ciphers.},
  file = {teo2009.pdf:teo2009.pdf:PDF},
  keywords = {Authenticated Encryption, Message Authentication Codes, Stream Cipher},
  owner = {kristjan},
  timestamp = {2010.06.29}
}

@ARTICLE{thompson1997,
  author = {Kevin Thompson and Gregory J. Miller and Rick Wilder},
  title = {Wide-area Internet traffic patterns and characteristics},
  journal = {IEEE Network},
  year = {1997},
  volume = {11},
  pages = {10--23},
  abstract = {The Internet is rapidly growing in number of users, traffic levels,
	and topological complexity. At the same time it is increasingly driven
	by economic competition. These developments render the characterization
	of network usage and workloads more difficult, and yet more critical.
	Few recent studies have been published reporting Internet backbone
	traffic usage and characteristics. At MCI, we have implemented a
	high-performance, low-cost monitoring system that can capture traffic
	and perform analyses. We have deployed this monitoring tool on OC-3
	trunks within internetMCI’s backbone and also within the NSF-sponsored
	vBNS. This paper presents observations on the patterns and characteristics
	of wide-area Internet traffic, as recorded by MCI’s OC-3 traffic
	monitors. We report on measurements from two OC-3 trunks in MCI’s
	commercial Internet backbone over two time ranges (24-hour and 7-day)
	in the presence of up to 240,000 flows. We reveal the characteristics
	of the traffic in terms of packet sizes, flow duration, volume, and
	percentage composition by protocol and application, as well as patterns
	seen over the two time scales.},
  file = {thompson1997.pdf:thompson1997.pdf:PDF}
}

@ARTICLE{thottan2003,
  author = {M. Thottan and C. Ji},
  title = {{Anomaly detection in IP networks}},
  journal = {IEEE Transactions on Signal Processing},
  year = {2003},
  volume = {51},
  pages = {2191-2204},
  month = aug,
  abstract = {Network anomaly detection is a vibrant research area. Researchers
	have approached this problem using various techniques such as artificial
	intelligence, machine learning, and state machine modeling. In this
	paper, we first review these anomaly detection methods and then describe
	in detail a statistical signal processing technique based on abrupt
	change detection. We show that this signal processing technique is
	effective at detecting several network anomalies. Case studies from
	real network data that demonstrate the power of the signal processing
	approach to network anomaly detection are presented. The application
	of signal processing techniques to this area is still in its infancy,
	and we believe that it has great potential to enhance the field,
	and thereby improve the reliability of IP networks.},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl = {http://adsabs.harvard.edu/abs/2003ITSP...51.2191T},
  doi = {10.1109/TSP.2003.814797},
  file = {thottan2003.pdf:thottan2003.pdf:PDF}
}

@INPROCEEDINGS{tian2004,
  author = {Zhihong Tian and Binxing Fang and Xiaochun Yun},
  title = {Defending Against Flash Crowds and Malicious Traffic Attacks with
	An Auction-Based Method},
  booktitle = {{WI '04: Proceedings of the 2004 IEEE/WIC/ACM International Conference
	on Web Intelligence}},
  year = {2004},
  pages = {24--28},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Flash crowd events (FCEs) and malicious traffic including DDoS and
	worm attacks present a real threat to the stability of Web services.
	In this paper, we design a practical defense system that can provide
	some needed relief from the two types of events and protect the availability
	of Web services. A novel method of dynamic bandwidth arbitration
	using Generalized Vickrey auction based on microeconomics is proposed.
	By adopting this approach, not only the availability of Web services
	is improved but also the total utility of users can be maximized.
	Initial simulations have shown that this mechanism is promising direction
	to control both FCEs and malicious traffic. The presentation in this
	paper is a first step towards a more rigorous evaluation.},
  doi = {http://dx.doi.org/10.1109/WI.2004.50},
  file = {tian2004.pdf:tian2004.pdf:PDF},
  isbn = {0-7695-2100-2}
}

@ONLINE{topf2001,
  author = {Jochen Topf},
  title = {The HTML Form Protocol Attack},
  url = {http://www.remote.org/jochen/sec/hfpa/},
  year = {2001},
  abstract = {This paper describes how some HTML browsers can be tricked through
	
	the use of HTML forms into sending more or less arbitrary data to
	any
	
	TCP port. This can be used to send commands to servers using ASCII
	
	based protocols like SMTP, NNTP, POP3, IMAP, IRC, and others. By
	
	sending HTML email to unsuspecting users or using a trojan HTML page,
	
	an attacker might be able to send mail or post Usenet News through
	
	servers normally not accessible to him. In special cases an attacker
	might
	
	be able to do other harm, e.g. deleting mail from a POP3 mailbox.},
  file = {:hfpa.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{toueg1984,
  author = {Toueg, Sam},
  title = {Randomized Byzantine Agreements},
  booktitle = {{PODC} '84: Proceedings of the third annual {ACM} symposium on Principles
	of distributed computing},
  year = {1984},
  pages = {163--178},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Randomized algorithms for reaching Byzantine Agreement were recently
	proposed in [Rabi83]. With these algorithms, agreement is reached
	within an expected number of phases that is a small constant independent
	of the number of processes n and the number of faulty processes t.
	The algorithms in [Rabi83] tolerate up to [(n-1)/10] faulty processes
	in asynchronous systems, and up to [(n-1)/4] faulty processes in
	synchronous systems. In this paper, using the same computation model
	as in [Rabi83], we describe algorithms that overcome up to [(n-1)/3]
	faulty processes in asynchronous systems, and up to [(n-1)/2] faulty
	processes in synchronous systems. With both proposed algorithms,
	agreement is reached within an expected number of phases that is
	a small constant independent of n and t, but the communication complexity
	is higher than in [Rabi83]. It is also shown that no Byzantine Agreement
	algorithm can overcome more than [(n-1)/3] faulty processes in asynchronous
	authenticated systems, and hence the asynchronous algorithm proposed
	here is optimal in this respect.},
  doi = {http://doi.acm.org/10.1145/800222.806744},
  file = {toueg1984.pdf:toueg1984.pdf:PDF},
  isbn = {0-89791-143-1},
  keywords = {byzantine consensus, randomized algorithm},
  location = {Vancouver, British Columbia, Canada}
}

@INPROCEEDINGS{trappe2005,
  author = {Trappe, Wade and Zhang, Yanyong and Nath, Badri},
  title = {{MIAMI}: methods and infrastructure for the assurance of measurement
	information},
  booktitle = {{DMSN} '05: Proceedings of the 2nd international workshop on Data
	management for sensor networks},
  year = {2005},
  pages = {11--17},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Adversaries do not need to attack traditional security services to
	affect the operation of a sensor network, but may deliberately perturb
	the measurement environment, the measurement method, or the measurement
	infrastructure. These types of attacks, which are attacks on the
	process of measurement(PoM attacks), are unique to sensor networks
	and cannot be addressed through the usual security methods. Hence,
	to complement traditional security services, defense mechanisms are
	needed to protect the sensor network from PoM attacks. This paper
	lays out a framework for assuring the validity of measurement data
	in sensor networks. This framework, which we call the Methods and
	Infrastructure for the Assurance of Measurement Information (MIAMI),
	is centered around the development of the PoM monitor. The PoM monitor
	is responsible for preventing corrupted measurement data from ever
	reaching core sensor services. We map out several mechanisms for
	that might be useful for building the PoM monitor on sensor nodes,
	and examine how it would operate by applying the techniques to the
	detection of wireless interference in a sensor network.},
  doi = {http://doi.acm.org/10.1145/1080885.1080888},
  file = {trappe2005.pdf:trappe2005.pdf:PDF},
  isbn = {1-59593-206-2},
  keywords = {Resilient aggregation, PoM, process of measurement},
  location = {Trondheim, Norway},
  review = {Consider PoM -- process of measurement -- attacks on sensor networks.
	These are attacks in which the sensor node or its environment is
	modified to show wrong readings. Examples: modifying spring in temperature
	sensor and tightening spindle in a anemometer. This is in essence
	physical attacks against the measurement mechanism -- the environment/sensor
	border.
	
	
	PoM monitors are located on each protected node. An adversary corrupting
	the node software can therefore trivially bypass the PoM. However,
	the adversarial modeling moves the corruption into the physical environment/sensor
	border. 
	
	Examples considered are e.g. modifying spring in temperature sensor
	or tightening spindle in an anenometer.
	
	
	
	They propose a policy-based classification and enforcement framework,
	analogous to reference monitors from traditional computer security.
	A classifier checks the consistency of input data with policies and
	semantic knowledge of the environment. An enforcer applies policies
	and filtering, according to the classification. The filtering can
	consist of dropping, cleansing and tagging suspected data.
	
	
	Policies include
	
	* Sanity checks on input data, such as reasonable upper temperature
	bound. N-dimensional consistency space.
	
	* allowable ranges for measurements, such as temperature range [low,high]
	
	* temporal consistency checks -- gathering of sequences in time and
	employing past measruments to judge the quality of the current one.
	
	* multimodal -- consistency checks involving other observable phenomena.
	Examples include correlating location, temperature and luminosity
	
	
	Show a case study involving a jammed region.}
}

@TECHREPORT{traynor2006,
  author = {Patrick Traynor and Raju Kumar and Heesook Choi and Guohong Cao and
	Sencun Zhu and Thomas {La Porta}},
  title = {Efficient Hybrid Security Mechanisms for Heterogeneous Sensor Networks},
  institution = {Pennsylvania State University},
  year = {2006},
  number = {NAS-TR-0044-2006},
  __markedentry = {[kristjan]},
  abstract = {Many applications that make use of sensor networks require secure
	communication. Because asymmetric-key solutions are difficult to
	implement in such a resource-constrained environment, symmetric-key
	methods coupled with a priori key distribution schemes have been
	proposed to achieve the goals of data secrecy and integrity. These
	approaches typically assume that all nodess are similar in terms
	of capabilities, and hence deploy the same number of keys in all
	sensors in a network to provide the aforementioned protections. In
	this paper, we demonstrate that a probabilistic unbalanced distribution
	of keys throughout the network that leverages the existence of a
	small percentage of more capable sensor nodes can not only provide
	an equal level of security but also reduce the consequences of node
	compromise. To fully characterize the effects of the unbalanced key
	management system, we develop, implement and measure the performance
	of a complimentary suite of key establishment protocols known as
	LIGER. Using their pre-deployed keys, nodes operating in isolation
	from external networks can securely and efficiently establish keys
	with each other. Should resources such as a backhaul link to a key
	distribution center (KDC) become available, networks implementing
	LIGER automatically incorporate and benefit from such facilities.
	Detailed experiments demonstrate that the unbalanced distribution
	in combination with the multi-modal LIGER suite offers a robust and
	practical solution to the security needs in sensor networks.},
  file = {traynor2006.pdf:traynor2006.pdf:PDF},
  keywords = {sensor network, security, symmetric key, asymmetric capabilities,
	key distribution, PKI},
  owner = {kristjan},
  review = {Key distribution exploiting a probabilistic distribution of more capable
	nodes. Two protocols (and a hybrid presented). One uses random pre
	key distribution (similar to Gligor) and the other uses available
	infrastructure support. Both protocols take advantage of a fraction
	of more capable nodes -- "miniservers" in the sensor network. A hybrid
	protocol LIGER uses the stand-alone random distribution but takes
	advantage of infrastructure support (connection to a PKI or the like)
	when available.},
  timestamp = {2010.05.02}
}

@ONLINE{trusted-platform-module,
  author = {{Trusted Computing Group}},
  title = {{Trusted Platform Module Specifications}},
  url = {https://www.trustedcomputinggroup.org/specs/TPM},
  year = {2010},
  howpublished = {https://www.trustedcomputinggroup.org/specs/TPM},
  keywords = {trusted platform module, TPM},
  owner = {kristjan},
  timestamp = {2010.01.11}
}

@MISC{tsirtsis-rfc-2766-2000,
  author = {G. Tsirtsis and P. Srisuresh},
  title = {{RFC 2766}: Network Address Translation - Protocol Translation ({NAT-PT})},
  month = {February},
  year = {2000},
  owner = {kristjan},
  timestamp = {2009.02.10},
  url = {http://www.ietf.org/rfc/rfc2766.txt}
}

@ARTICLE{tsudik1992,
  author = {Tsudik, Gene},
  title = {Message authentication with one-way hash functions},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {1992},
  volume = {22},
  pages = {29--38},
  number = {5},
  abstract = {Fast message integrity and authentication services are much desired
	in today's high-speed network protocols. Current message authentication
	techniques are mostly encryption-based which is undesirable for several
	reasons. In this brief paper, we introduce encryption-free message
	authentication based entirely on fast one-way hash functions. Two
	methods are presented and their strength is analyzed. The security
	of the proposed methods is based on the strength of the underlying
	one-way hash function.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/141809.141812},
  file = {tsudik1992.pdf:tsudik1992.pdf:PDF},
  issn = {0146-4833},
  publisher = {ACM}
}

@MASTERSTHESIS{tu2006,
  author = {Zhiqi Tu},
  title = {Enhancements of the Non-linear Knapsack Cryptosystem},
  school = {University of Canterbury},
  year = {2006},
  file = {tu2006.pdf:tu2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@PHDTHESIS{tunstall2006,
  author = {Michael Tunstall},
  title = {Secure Cryptographic Algorithm Implementation On Embedded Platforms},
  school = {University of London},
  year = {2006},
  file = {tunstall2006.pdf:tunstall2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.04.12}
}

@MISC{us-dod-orangebook-85,
  author = {{U.S. Department of Defense}},
  title = {Trusted Computer System Evaluation Criteria (Orange Book)},
  month = {December},
  year = {1985},
  file = {dod85.pdf:dod85.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@ARTICLE{upadhyayula2007,
  author = {S. Upadhyayula and S.K.S. Gupta},
  title = {Spanning tree based algorithms for low latency and energy efficient
	data aggregation enhanced convergecast ({DAC}) in wireless sensor
	networks},
  journal = {Ad Hoc Netw.},
  year = {2007},
  volume = {5},
  pages = {626--648},
  number = {5},
  abstract = {Many wireless sensor networks (WSNs) employ battery-powered sensor
	nodes. Communication in such networks is very taxing on its scarce
	energy resources. Convergecast - process of routing data from many
	sources to a sink - is commonly performed operation in WSNs. Data
	aggregation is a frequently used energy-conversing technique in WSNs.
	The rationale is to reduce volume of communicated data by using in-network
	processing capability at sensor nodes. In this paper, we address
	the problem of performing the operation of data aggregation enhanced
	convergecast (DAC) in an energy and latency efficient manner. We
	assume that all the nodes in the network have a data item and there
	is an a priori known application dependent data compression factor
	(or compression factor), @c, that approximates the useful fraction
	of the total data collected. The paper first presents two DAC tree
	construction algorithms. One is a variant of the Minimum Spanning
	Tree (MST) algorithm and the other is a variant of the Single Source
	Shortest Path Spanning Tree (SPT) algorithm. These two algorithms
	serve as a motivation for our Combined algorithm (COM) which generalized
	the SPT and MST based algorithm. The COM algorithm tries to construct
	an energy optimal DAC tree for any fixed value of @a (=1-@c), the
	data growth factor. The nodes of these trees are scheduled for collision-free
	communication using a channel allocation algorithm. To achieve low
	latency, these algorithms use the @b-constraint, which puts a soft
	limit on the maximum number of children a node can have in a DAC
	tree. The DAC tree obtained from energy minimizing phase of tree
	construction algorithms is re-structured using the @b-constraint
	(in the latency minimizing phase) to reduce latency (at the expense
	of increasing energy cost). The effectiveness of these algorithms
	is evaluated by using energy efficiency, latency and network lifetime
	as metrics. With these metrics, the algorithms' performance is compared
	with an existing data aggregation technique. From the experimental
	results, for a given network density and data compression factor
	@c at intermediate nodes, one can choose an appropriate algorithm
	depending upon whether the primary goal is to minimize the latency
	or the energy consumption.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.adhoc.2006.04.004},
  file = {upadhyayula2007.pdf:upadhyayula2007.pdf:PDF},
  issn = {1570-8705},
  publisher = {Elsevier Science Publishers B. V.}
}

@ARTICLE{urdaneta2009,
  author = {Guido Urdaneta and Guillaume Pierre and Maarten van Steen},
  title = {A Survey of {DHT} Security Techniques},
  journal = {{ACM Computing Surveys}},
  year = {2009},
  note = {\url{http://www.globule.org/publi/SDST_acmcs2009.html}, to appear},
  abstract = {Peer-to-peer networks based on Distributed Hash Tables (DHTs) have
	received considerable attention ever since their introduction in
	2001. Unfortunately, DHT-based systems have shown to be notoriously
	diﬃcult to protect against security attacks. Various reports have
	been published that discuss or classify general security issues,
	but so far a comprehensive survey describing the various proposed
	defenses has been lacking. In this paper, we present an overview
	of techniques reported in the literature for making DHT-based systems
	resistant to the three most important attacks that can be launched
	by malicious nodes participating in the DHT: (1) the Sybil attack,
	(2) the Eclipse attack, and (3) routing and storage attacks. We review
	the advantages and disadvantages of the proposed solutions and in
	doing so, conﬁrm how diﬃcult it is to secure DHT-based systems in
	an adversarial environment.},
  file = {urdaneta2009.pdf:urdaneta2009.pdf:PDF},
  keywords = {networks, security, DHTs, distributed hash tables, survey}
}

@ARTICLE{vaccaro1989,
  author = {Vaccaro, H.S. and Liepins, G.E.},
  title = {Detection of anomalous computer session activity},
  journal = {Security and Privacy, 1989. Proceedings., 1989 IEEE Symposium on},
  year = {1989},
  pages = {280-289},
  month = {1-3 May},
  abstract = {The authors discusses Wisdom and Sense (W&S), a computer security
	anomaly detection system. W&S is statistically based. It automatically
	generates rules from historical data and, in terms of those rules,
	identifies computer transactions that are at variance with historically
	established usage patterns. Issues addressed include how W&S generates
	rules from a necessarily small sample of all possible transactions,
	how W&S deals with inherently categorical data, and how W&S assists
	system security officers in their review of audit logs. Preliminary
	results with W&S show that the software does periodically detect
	anomalies of high interest even in data though to be free of such
	events},
  doi = {10.1109/SECPRI.1989.36302},
  file = {00036302.pdf:00036302.pdf:PDF},
  keywords = {DP management, security of dataWisdom and Sense, anomalous computer
	session activity, audit logs, categorical data, historical data,
	rules, system security officers, usage patterns}
}

@TECHREPORT{Vahdat2000,
  author = {Amin Vahdat and David Becker},
  title = {Epidemic Routing for Partially-Connected Ad Hoc Networks},
  institution = {Duke University},
  year = {2000},
  number = {CS-200006},
  month = {April},
  abstract = {Mobile ad hoc routing protocols allow nodes with wireless adaptors
	to communicate with one an-
	
	other without any pre-existing network infrastructure. Existing ad
	hoc routing protocols, while robust to
	
	rapidly changing network topology, assume the presence of a connected
	path from source to destination.
	
	Given power limitations, the advent of short-range wireless networks,
	and the wide physical conditions
	
	over which ad hoc networks must be deployed, in some scenarios it
	is likely that this assumption is
	
	invalid. In this work, we develop techniques to deliver messages in
	the case where there is never a
	
	connected path from source to destination or when a network partition
	exists at the time a message is
	
	originated. To this end, we introduce Epidemic Routing, where random
	pair-wise exchanges of mes-
	
	sages among mobile hosts ensure eventual message delivery. The goals
	of Epidemic Routing are to:
	
	i) maximize message delivery rate, ii) minimize message latency, and
	iii) minimize the total resources
	
	consumed in message delivery. Through an implementation in the Monarch
	simulator, we show that
	
	Epidemic Routing achieves eventual delivery of 100% of messages with
	reasonable aggregate resource
	
	consumption in a number of interesting scenarios.},
  file = {adhocepidemics_vahdat_2000.pdf:/home/kristjan/articles/adhocepidemics_vahdat_2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@TECHREPORT{vaidyanathan2004,
  author = {Karthikeyan Vaidyanathan and Sayantan Sur and Sundeep Narravula and
	Prasun Sinha},
  title = {Data Aggregation Techinques in Sensor Networks},
  institution = {Ohio State University},
  year = {2004},
  number = {OSU-CISRC-11/04-TR60},
  abstract = {Advancement in computing technology has led to the production of wireless
	sensors capable of observing and reporting various real world phenomena
	in a time sensitive manner. However such systems suﬀer from band-width,
	energy and throughput constraints which limit the amount of information
	transfered from end-to-end. Data aggregation is a known technique
	addressed to alleviate these problems but are limited due to their
	lack of adaptation to dynamic network topologies and unpredictable
	traﬃc patterns. In this project, we propose three novel data aggregation
	schemes; in-network data aggregation, grid-based data aggregation
	and hybrid data aggregation, which increases throughput, decreases
	congestion and saves energy. Our simulation results show that the
	end-to-end transmission delay is reduced by a factor of 2.3, the
	throughput increases by a factor of 2.4 under heavy load conditions
	and the energy dissipated is reduced by a factor of 2.2. We conclude
	our evaluation by proposing an hybrid aggregation scheme through
	which sensor nodes can dynamically change from one aggregation technique
	to the other in an unpredictable environment and adapt to dynamic
	changes in the network.},
  file = {vaidyanathan2004.pdf:vaidyanathan2004.pdf:PDF},
  keywords = {sensor network, aggregation, in-network aggregation},
  owner = {kristjan},
  review = {WEAK. Present some very basic aggregation methods. Contribution unclear.},
  timestamp = {2010.01.17}
}

@ARTICLE{van-renesse-2003,
  author = {Van Renesse, Robbert and Birman, Kenneth P. and Vogels, Werner},
  title = {Astrolabe: A robust and scalable technology for distributed system
	monitoring, management, and data mining},
  journal = {{ACM Trans. Comput. Syst.}},
  year = {2003},
  volume = {21},
  pages = {164--206},
  number = {2},
  abstract = {Scalable management and self-organizational capabilities are emerging
	as central requirements for a generation of large-scale, highly dynamic,
	distributed applications. We have developed an entirely new distributed
	information management system called Astrolabe. Astrolabe collects
	large-scale system state, permitting rapid updates and providing
	on-the-fly attribute aggregation. This latter capability permits
	an application to locate a resource, and also offers a scalable way
	to track system state as it evolves over time. The combination of
	features makes it possible to solve a wide variety of management
	and self-configuration problems. This paper describes the design
	of the system with a focus upon its scalability. After describing
	the Astrolabe service, we present examples of the use of Astrolabe
	for locating resources, publish-subscribe, and distributed synchronization
	in large systems. Astrolabe is implemented using a peer-to-peer protocol,
	and uses a restricted form of mobile code based on the SQL query
	language for aggregation. This protocol gives rise to a novel consistency
	model. Astrolabe addresses several security considerations using
	a built-in PKI. The scalability of the system is evaluated using
	both simulation and experiments; these confirm that Astrolabe could
	scale to thousands and perhaps millions of nodes, with information
	propagation delays in the tens of seconds.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/762483.762485},
  file = {van-renesse-2003.pdf:van-renesse-2003.pdf:PDF},
  issn = {0734-2071},
  keywords = {in-network aggregation, astrolabe},
  publisher = {ACM},
  review = {See also van_renesse_2003. Astrolabe uses a combined approach of hierarchy
	of domains and epidemic aggregation within domains.}
}

@TECHREPORT{van-renesse-1998,
  author = {{Van Renesse}, Robbert and Minsky, Yaron and Hayden, Mark},
  title = {A Gossip-Style Failure Detection Service},
  institution = {Cornell University},
  year = {1998},
  address = {Ithaca, NY, USA},
  abstract = {Failure Detection is valuable for system management, replication,
	load balancing, and other distributed services. To date, Failure
	Detection Services scale badly in the number of members that are
	being monitored. This paper describes a new protocol based on gossiping
	that does scale well and provides timely detection. We analyze the
	protocol, and then extend it to discover and leverage the underlying
	network topology for much improved resource utilization. We then
	combine it with another protocol, based on broadcast, that is used
	to handle partition failures.},
  file = {van-renesse-1998.pdf:van-renesse-1998.pdf:PDF},
  publisher = {Cornell University},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Acornellcs%3ACORNELLCS%3ATR98-1687}
}

@ARTICLE{vaquero2009,
  author = {Luis M. Vaquero and Luis Rodero-Merino and Juan Caceres and Maik
	Lindner},
  title = {A Break in the Clouds: Towards a Cloud Definition},
  journal = {{ACM SIGCOMM Computer Communication Review}},
  year = {2009},
  volume = {39},
  pages = {50-55},
  number = {1},
  abstract = {This paper discusses the concept of Cloud Computing to
	
	achieve a complete deﬁnition of what a Cloud is, using the
	
	main characteristics typically associated with this paradigm
	
	in the literature. More than 20 deﬁnitions have been studied
	
	allowing for the extraction of a consensus deﬁnition as well
	
	as a minimum deﬁnition containing the essential characteris-
	
	tics. This paper pays much attention to the Grid paradigm,
	
	as it is often confused with Cloud technologies. We also de-
	
	scribe the relationships and distinctions between the Grid
	
	and Cloud approaches.},
  file = {:p50-v39n1l-vaqueroA.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.11}
}

@INPROCEEDINGS{Varga2001,
  author = {Varga, Andras},
  title = {The {OMNeT++} discrete event simulation system},
  booktitle = {{European Simulation Multiconference (ESM'2001)}},
  year = {2001},
  month = {June},
  abstract = {The paper introduces OMNeT++, a C++-based discrete event simulation
	package primarily targeted at simulating computer networks and other
	distributed systems. OMNeT++ is fully programmable and modular, and
	it was designed from the ground up to support modeling very large
	networks built from reusable model components. Large emphasis was
	placed also on easy traceability and debuggability of simulation
	models: one can execute the simulation under a powerful graphical
	user interface, which makes the internals of a simulation model fully
	visible to the person running the simulation: it displays the network
	graphics, animates the message flow and lets the user peek into objects
	and variables within the model. These features make OMNeT++ a good
	candidate for both research and educational purposes. The OMNeT++
	simulation engine can be easily embedded into larger applications.
	OMNeT++ is open-source, free for non-profit use, and it has a fairly
	large user community},
  citeulike-article-id = {1005962},
  file = {esm2001-meth48.pdf:/home/kristjan/articles/esm2001-meth48.pdf:PDF},
  keywords = {omnet simulation},
  owner = {kristjan},
  priority = {2},
  timestamp = {2008.09.19},
  url = {http://www.omnetpp.org/download/docs/papers/esm2001-meth48.pdf}
}

@PHDTHESIS{vigfusson-2010,
  author = {{\'{Y}}mir Vigf\'{u}sson},
  title = {Affinity in Distributed Systems},
  school = {Cornell University},
  year = {2010},
  abstract = {In this dissertation we address shortcomings of two important group
	communication layers, IP Multicast and gossip based message dissemination,
	both of which have scalability issues when the number of groups grows.
	
	
	We propose a transparent and backward-compatible layer called Dr.
	Multicast to allow data center administrators to enable IPMC for
	large numbers of groups without causing stability issues. Dr. Multicast
	optimizes IPMC resources by grouping together similar groups in terms
	of membership to minimize redundant transmissions as well as cost
	of ﬁltering unwanted messages.
	
	
	We then argue that when nodes belong to multiple groups, gossip based
	communication loses its appealing property of using ﬁxed amount of
	bandwidth. We propose a platform called GO (for Gossip Objects) that
	bounds the node’s bandwidth use to a customizable limit, prohibiting
	applications from joining groups that would cause the limit to be
	exceeded. 
	
	
	Both systems incorporate optimizations that are based on group similarity
	or afﬁnity. We explore group afﬁnity in real data-sets from social
	networks and a trace from an industrial setting. We present new models
	to characterize overlaps between groups, and discuss our results
	in the context of Dr. Multicast and GO.
	
	
	The chapters on Dr. Multicast and GO are self-contained, extended
	versions of papers that appeared respectively in the ACM Hot Topics
	in Networks (Hot-Nets) Workshop 2008 [85] and the International Peer-to-Peer
	(P2P) Conference 2009 [87].},
  file = {vigfusson-2010.pdf:vigfusson-2010.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.04}
}

@ARTICLE{vigna1999,
  author = {Giovanni Vigna and Richard A. Kemmerer},
  title = {NetSTAT: a network-based intrusion detection system},
  journal = {J. Comput. Secur.},
  year = {1999},
  volume = {7},
  pages = {37--71},
  number = {1},
  abstract = {Network-based attacks are becoming more common and sophisticated.
	For this reason, intrusion detection systems are now shifting their
	focus from the hosts and their operating systems to the network itself.
	Network-based intrusion detection is challenging because network
	auditing produces large amounts of data, and different events related
	to a single intrusion may be visible in different places on the network.
	This paper presents a new approach that applies the State Transition
	Analysis Technique (STAT) to network intrusion detection. Network-based
	intrusions are modeled using state transition diagrams in which states
	and transitions are characterized in a networked environment. The
	target network environment itself is represented using a model based
	on hypergraphs. By using a formal model of both the network to be
	protected and the attacks to be detected the approach is able to
	determine which network events have to be monitored and where they
	can be monitored, providing automatic support for configuration and
	placement of intrusion detection components.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  file = {vigna1999.pdf:vigna1999.pdf:PDF},
  issn = {0926-227X},
  publisher = {IOS Press}
}

@INPROCEEDINGS{vishwanath2006,
  author = {Kashi Venkatesh Vishwanath and Amin Vahdat},
  title = {Realistic and responsive network traffic generation},
  booktitle = {SIGCOMM '06: Proceedings of the 2006 conference on Applications,
	technologies, architectures, and protocols for computer communications},
  year = {2006},
  pages = {111--122},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1159913.1159928},
  file = {:p111-vishwanath.pdf:PDF},
  isbn = {1-59593-308-5},
  location = {Pisa, Italy}
}

@ARTICLE{vogels2003,
  author = {Vogels, Werner and van Renesse, Robbert and Birman, Ken},
  title = {The power of epidemics: robust communication for large-scale distributed
	systems},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {2003},
  volume = {33},
  pages = {131--135},
  number = {1},
  abstract = {Building very large computing systems is extremely challenging, given
	the lack of robust scalable communication technologies. This threatens
	a new generation of mission-critical but very large computing systems.
	Fortunately, a new generation of "gossip-based" or epidemic communication
	primitives can overcome a number of these scalability problems, offering
	robustness and reliability even in the most demanding settings. Epidemic
	protocols emulate the spread of an infection in a crowded population,
	and are both reliable and stable under forms of stress that will
	disable most traditional protocols. This paper describes some of
	the common problems that arise in scalable group communication systems
	and how epidemic techniques have been used to successfully address
	these problems.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/774763.774784},
  file = {vogels2003.pdf:vogels2003.pdf:PDF},
  issn = {0146-4833},
  keywords = {epidemic protocols, gossiping, multicast},
  publisher = {ACM}
}

@INPROCEEDINGS{vogt2004,
  author = {Harald Vogt},
  title = {Exploring Message Authentication in Sensor Networks},
  booktitle = {In Proc. of European Workshop on Security of Ad Hoc and Sensor Networks
	(ESAS), LNCS},
  year = {2004},
  publisher = {Springer-Verlag},
  __markedentry = {[kristjan]},
  abstract = {This paper explores the design space for message authentication in
	sensor networks. Several types of authentication are put into relation:
	end-to-end, hop-to-hop, and physical and virtual multipath authentication.
	While end-to-end authentication provides the highest and most general
	security level, it may be too costly or impractical to implement.
	On the other end of the security scale, hop-to-hop authentication
	can be implemented with little eﬀort but provides security only to
	a highly restricted attacker. Multipath authentication provides an
	intermediate security level that may be appropriate for many applications
	of sensor networks, trading energy for security guarantees. Virtual
	multi-paths oﬀer an improvement, reducing energy demands while retaining
	crucial security properties of physical multipaths.},
  file = {vogt2004.pdf:vogt2004.pdf:PDF},
  review = {cited by albath2007 (actually appears to be not remotely connected
	to the material of that paper).}
}

@INPROCEEDINGS{vogt-xss-2007,
  author = {Philipp Vogt and Florian Nentwich and Nenad Jovanovic and Engin Kirda
	and Christopher Kruegel and Giovanni Vigna},
  title = {Cross-Site Scripting Prevention with Dynamic Data Tainting and Static
	Analysis},
  booktitle = {14th Annual Network and Distributed System Security Symposium (NDSS
	2007)},
  year = {2007},
  address = {San Diego, CA},
  month = {February},
  file = {vogt-xss.pdf:vogt-xss.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.11.14}
}

@ARTICLE{vorobiev2006,
  author = {Artem Vorobiev and Jun Han},
  title = {Security Attack Ontology for Web Services},
  journal = {skg},
  year = {2006},
  volume = {0},
  pages = {42},
  abstract = {Web services (WS) have become a significant part of the Web because
	of such attractive features as simple to use, platform independence,
	and XML/SOAP support. However, these features make WS vulnerable
	to many new and inherited old security threats. Semantic WS, which
	are capable of publishing semantic data about their functional and
	nonfunctional properties, add even more security issues. Now, it
	becomes easier to attack WS because their semantic data is publicly
	available. To register and prevent these attacks, especially distributed
	attacks, new distributed firewalls and intrusion detection systems
	(F/IDS) have to be applied. However, these F/IDS can be developed
	by different vendors and they do not have the way to cooperate with
	each other. This problem can be solved if various F/IDS share a common
	vocabulary, which can be based on ontologies, to allow them to interact
	with each other. In this paper, we describe WS security threats and
	state that they have to be analysed and classified systematically
	in order to allow the development of better distributed defensive
	mechanisms for WS using F/IDS. We choose ontologies and OWL/OWL-S
	over taxonomies because ontologies allow different parties to evolve
	and share a common understanding of information which can be reasoned
	and analysed automatically. We develop the security attack ontology
	for WS and illustrate the benefits of using it with an example.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SKG.2006.85},
  file = {04023894.pdf:04023894.pdf:PDF},
  isbn = {0-7695-2673-X},
  publisher = {IEEE Computer Society}
}

@MASTERSTHESIS{Wacha2007,
  author = {Clemens Wacha},
  title = {Wireless Ad-Hoc Podcasting with Handhelds},
  school = {Swiss Federal Institute of Technology Zurich (ETH)},
  year = {2007},
  month = {April},
  file = {MA-2007-05.pdf:/home/kristjan/articles/MA-2007-05.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{wagner2005,
  author = {Arno Wagner and Bernhard Plattner},
  title = {Entropy Based Worm and Anomaly Detection in Fast IP Networks},
  booktitle = {{WETICE '05: Proceedings of the 14th IEEE International Workshops
	on Enabling Technologies: Infrastructure for Collaborative Enterprise}},
  year = {2005},
  pages = {172--177},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Detecting massive network events like worm outbreaks in fast IP networks,
	such as Internet backbones, is hard. One problem is that the amount
	of traffic data does not allow real-time analysis of details. Another
	problem is that the specific characteristics of these events are
	not known in advance. There is a need for analysis methods that are
	real-time capable and can handle large amounts of traffic data. We
	have developed an entropy-based approach, that determines and reports
	entropy contents of traffic parameters such as IP addresses. Changes
	in the entropy content indicate a massive network event. We give
	analyses on two Internet worms as proof-of-concept. While our primary
	focus is detection of fast worms, our approach should also be able
	to detect other network events. We discuss implementation alternatives
	and give benchmark results. We also show that our approach scales
	very well.},
  doi = {http://dx.doi.org/10.1109/WETICE.2005.35},
  isbn = {0-7695-2362-5}
}

@INPROCEEDINGS{wagner2004,
  author = {David Wagner},
  title = {Resilient aggregation in sensor networks},
  booktitle = {{SASN} '04: Proceedings of the 2nd {ACM} workshop on Security of
	ad hoc and sensor networks},
  year = {2004},
  pages = {78--87},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper studies security for data aggregation in sensor networks.
	Current aggregation schemes were designed without security in mind
	and there are easy attacks against them. We examine several approaches
	for making these aggregation schemes more resilient against certain
	attacks, and we propose a mathematical framework for formally evaluating
	their security.},
  doi = {http://doi.acm.org/10.1145/1029102.1029116},
  file = {wagner2004.pdf:wagner2004.pdf:PDF},
  isbn = {1-58113-972-1},
  location = {Washington DC, USA},
  review = {\shortciteA{wagner2004} discusses the resiliency of aggregation functions
	in the setting of a single aggregator model. He abstracts the computation
	of the aggregate away from the protocol. The conclusion is that some
	of the most widely used functions in the literature, sum, average,
	maximum and minimum, are inherently insecure with regards to an attackers
	abilty to influence the final result, regardless of the protocol
	being used. \citeauthor{wagner2004} gives a formal basis for the
	conclusion by applying robust statistics and estimation theory. Some
	methods of increasing the resiliency of aggregation functions are
	given. Interestingly, the method used by \shortciteA{chan2006} (truncation)
	is deemed unsatisfactory, since it exhibits poor dynamic range. Trimming
	-- excluding a fraction of the highest and lowest results -- is a
	better method statistically speaking, but not clear how to achiece
	such results in systems employing in-network aggregation. In-network
	aggregation is infact identified as an open problem in this regard.
	
	
	Wagner coined the term "resilient aggregation" to refer to techniques
	which make it hard for an adversary to produce significant distortion
	in the aggregation result.
	
	
	Discussion on MPC -- first I have seen in relation to aggregation:
	
	"It is known that any functionality that can be computed with the
	help of a trusted third party can also be computed without it, using
	generic multi-party computation"
	
	...
	
	With regards to aggregation, we can ask the following question:
	
	"Which functionalities f can be meaningfully computed by a protocol
	for secure multi-party computation, when some parties might behave
	maliciously by submitting bogus inputs?"
	
	The question is fundamentally different from the usual task of secure
	MPC -- to demonstrate that computable with a trusted 3rd party can
	also be can be computed (usually in a privacy preserving setting)
	without a trusted 3rd party. 
	
	The fundamental problem in aggregation is that inputs can be modified
	-- we are in an integrity preserving setting with active attackers.
	
	
	
	The main contribution is a mathematical theory of aggregetion in statistical
	terms. Quantifies exactly the inherent resilience of the common scalar
	aggregation funcitons.}
}

@INCOLLECTION{wagner2003,
  author = {David Wagner},
  title = {Cryptanalysis of an Algebraic Privacy Homomorphism},
  booktitle = {Information Security (Lecture Notes in Computer Science)},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  volume = {2851/2003},
  pages = {234-239},
  month = {December},
  abstract = {We use linear algebra to show that an algebraic privacy homomorphism
	proposed by Domingo-Ferrer is insecure for some parameter settings.},
  file = {wagner2003.ps:wagner2003.ps:PostScript},
  owner = {kristjan},
  review = {Shows Domingo-Ferrers PH to be vulnerable to known plaintext attacks.},
  timestamp = {2010.01.17}
}

@ARTICLE{wagner2001,
  author = {Wagner, D. and Dean, R.},
  title = {Intrusion detection via static analysis},
  journal = {Security and Privacy, 2001. S\&P 2001. Proceedings. 2001 IEEE Symposium
	on},
  year = {2001},
  pages = {156-168},
  doi = {10.1109/SECPRI.2001.924296},
  keywords = {network operating systems, program diagnostics, security of datacomputer
	security, corrupted code, false alarms, host-based intrusion detection
	system, intrusion detection, mobile code, programming languages,
	static analysis, typical application behavior},
  owner = {kristjan},
  timestamp = {2008.03.14}
}

@INPROCEEDINGS{walsh2006,
  author = {Kevin Walsh and Emin G\"{u}n Sirer},
  title = {Experience with an object reputation system for peer-to-peer filesharing},
  booktitle = {NSDI'06: Proceedings of the 3rd conference on Networked Systems Design
	\& Implementation},
  year = {2006},
  pages = {1--1},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {In this paper, we describe Credence, a decentralized object reputation
	and ranking system for large-scale peer-to-peer filesharing networks.
	Credence counteracts pollution in these networks by allowing honest
	peers to assess the authenticity of online content through secure
	tabulation and management of endorsements from other peers. Our system
	enables peers to learn relationships even in the absence of direct
	observations or interactions through a novel, flow-based trust computation
	to discover trustworthy peers. We have deployed Credence as an overlay
	on top of the Gnutella filesharing network, with more than 10,000
	downloads of our client software to date. We describe the system
	design, our experience with its deployment, and results from a long-term
	study of the trust network built by users. Data from the live deployment
	shows that Credence's flow-based trust computation enables users
	to avoid undesirable content. Honest Credence clients can identify
	three quarters of the decoys encountered when querying the Gnutella
	network.},
  file = {walsh2006.pdf:walsh2006.pdf:PDF},
  location = {San Jose, CA}
}

@INCOLLECTION{walters2006,
  author = {John~Paul Walters and Zhengqiang Liang and Weisong Shi and Vipin
	Chaudhary},
  title = {Wireless Sensor Network Security: A Survey},
  booktitle = {Security in Distributed, Grid, and Pervasive Computing},
  publisher = {Auerbach Publications, CRC Press},
  year = {2006},
  chapter = {17},
  abstract = {As wireless sensor networks continue to grow, so does the need for
	effective security mechanisms. Because sensor networks may interact
	with sensitive data and/or operate in hostile unattended environments,
	it is imperative that these security concerns be addressed from the
	beginning of the system design. However, due to inherent resource
	and computing constraints, security in sensor networks poses different
	challenges than traditional network/computer security. There is currently
	enormous research potential in the field of wireless sensor network
	security. Thus, familiarity with the current research in this field
	will benefit researchers greatly. With this in mind, we survey the
	major topics in wireless sensor network security, and present the
	obstacles and the requirements in the sensor security, classify many
	of the current attacks, and finally list their corresponding defensive
	measures.},
  file = {walters2006.pdf:walters2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.01.15}
}

@BOOK{waltz1990,
  title = {Multisensor Data Fusion},
  publisher = {Artech House, Inc.},
  year = {1990},
  author = {Waltz, Edward L. and Llinas, James},
  address = {Norwood, MA, USA},
  note = {Foreword By-White, Franklin E.},
  isbn = {0890062773},
  keywords = {aggregation, data fusion}
}

@ARTICLE{wan2004,
  author = {Wan, Chieh-Yih and Campbell, Andrew T. and Krishnamurthy, Lakshman},
  title = {Reliable transport for sensor networks: PSFQ - Pump slowly fetch
	quickly paradigm},
  journal = {Wireless Sensor Networks},
  year = {2004},
  pages = {153--182},
  abstract = {We propose PSFQ (Pump Slowly, Fetch Quickly), a reliable transport
	protocol suitable for a new class of reliable data applications emerging
	in wireless sensor networks. For example, currently sensor networks
	tend to be application specific and are typically hard-wired to perform
	a specific task efficiently at low cost; however, there is an emerging
	need to be able to re-task or reprogram groups of sensors in wireless
	sensor networks on the fly (e.g., during disaster recovery). Due
	to the application-specific nature of sensor networks, it is difficult
	to design a single monolithic transport system that can be optimized
	for every application. PSFQ takes a different approach and supports
	a simple, robust and scalable transport that is customizable to meet
	the needs of different reliable data applications. To our knowledge
	there has been little work on the design of an efficient reliable
	transport protocol for wireless sensor networks, even though some
	techniques found in IP networks have some relevance to the solution
	space, such as, the body of work on reliable multicast. We present
	the design and implementation of PSFQ, and evaluate the protocol
	using the ns-2 simulator and an experimental wireless sensor testbed
	based on Berkeley motes. We show through simulation and experimentation
	that PSFQ can out perform existing related techniques (e.g., an idealized
	SRM scheme) and is highly responsive to the various error conditions
	experienced in wireless sensor networks, respectively.},
  address = {Norwell, MA, USA},
  book = {Wireless sensor networks},
  file = {wan2004.pdf:wan2004.pdf:PDF},
  isbn = {1-4020-7883-8},
  keywords = {sensor network, reliable transport},
  publisher = {Kluwer Academic Publishers}
}

@ARTICLE{wang2007,
  author = {Da-Wei Wang and Churn-Jung Liau and Tsan-sheng Hsu},
  title = {An epistemic framework for privacy protection in database linking},
  journal = {{Data Knowl. Eng.}},
  year = {2007},
  volume = {61},
  pages = {176--205},
  number = {1},
  abstract = {In this paper, we present an epistemic framework for privacy protection
	in the database linking context, whereby the user's knowledge and
	the individuals' confidential information are represented by propositional
	sentences. In the framework, the concept of safety is rigorously
	defined, and an effective approach for testing the safety of released
	data is provided. It is shown that some generalization operations
	can be applied to original data to make it less specific so that
	the release of generalized data does not violate privacy. Two kinds
	of generalization operation are considered: attribute-oriented generalization
	(AOG) and cell-oriented generalization (COG). AOG is more restrictive,
	but a bottom-up search algorithm can be used to find the maximally
	informative AOG that satisfies the safety requirement. We investigate
	the properties of AOG that can be used to improve the search efficiency.
	COG, on the other hand, is more flexible. However, it necessitates
	searching through the whole space, so its computational complexity
	is much higher. Although graph theory can be used to simplify the
	search procedure, heuristic methods are needed to improve its efficiency.
	Easy extensibility is one of the main advantages of our framework.
	It is shown that the framework can be extended to accommodate probabilistic
	inference attacks and alternative protection techniques.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.datak.2006.05.004},
  file = {wang2007.pdf:wang2007.pdf:PDF},
  issn = {0169-023X},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{wang2008,
  author = {Hongfa Wang},
  title = {A Robust Mechanism for Wireless Sensor Network Security},
  booktitle = {Wireless Communications, Networking and Mobile Computing, 2008. WiCOM
	'08. 4th International Conference on},
  year = {2008},
  pages = {1-4},
  month = {Oct.},
  abstract = {This paper mainly proposes a new robust and energy-efficient solution
	for secure operation of wireless sensor networks. It motivates a
	new paradigm where security is based upon using parameterized frequency
	hopping and cryptographic keys in a unified framework to provide
	differential security services for wireless sensor networks.},
  doi = {10.1109/WiCom.2008.923},
  file = {wang2008.pdf:wang2008.pdf:PDF},
  keywords = {cryptography, frequency hop communication, wireless sensor networks,
	cryptographic keys, parameterized frequency hopping, wireless sensor
	network security}
}

@ARTICLE{wang2006b,
  author = {Haodong Wang and Bo Sheng and Qun Li},
  title = {Elliptic curve cryptography-based access control in sensor networks},
  journal = {Int. J. Security and Networks},
  year = {2006},
  volume = {1},
  pages = {127-137},
  abstract = {Access control in sensor networks is used to authorise and grant users
	the right to access the network and data collected by sensors. Different
	users have different access right due to the access restriction implicated
	by the data security and conﬁdentiality. Even though symmetric-key
	scheme, which has been investigated extensively for sensor networks,
	can fulﬁl the requirement, public-key cryptography is more ﬂexible
	and simple rendering a clean interface for the security component.
	Against the popular belief that a public key scheme is not practical
	for sensor networks, this paper describes a public-key implementation
	of access control in a sensor network. We detail the implementation
	of Elliptic Curve Cryptography (ECC) over primary ﬁeld, a public-key
	cryptography scheme, on TelosB, which is the latest sensor network
	platform. We evaluate the performance of our implementation and compare
	with other implementations we have ported to TelosB.},
  file = {wang2006b.pdf:wang2006b.pdf:PDF},
  keywords = {elliptic curve crypto, ECC, sensor networks, public key crypto, access
	control}
}

@INPROCEEDINGS{wang2002,
  author = {H. Wang and D. Zhang and K.G. Shin},
  title = {Detecting {SYN} flooding attacks},
  booktitle = {{IEEE INFOCOM}},
  year = {2002},
  abstract = {We propose a simple and robust mechanism for detecting SYN ﬂooding
	attacks. Instead of monitoring the ongoing trafﬁc at the front end
	(like ﬁrewall or proxy) or a victim server itself, we detect the
	SYN ﬂooding attacks at leaf routers that connect end hosts to the
	Internet. The simplicity of our detection mechanism lies in its statelessness
	and low computation overhead, which make the detection mechanism
	itself immune to ﬂooding attacks. Our detection mechanism is based
	on the protocol behavior of TCP SYN–FIN (RST) pairs, and is an instance
	of the Sequential Change Point Detection [1]. To make the detection
	mechanism insensitive to site and access pattern, a non-parametric
	Cumulative Sum (CUSUM) method [4] is applied, thus making the detection
	mechanism much more generally applicable and its deployment much
	easier. The efﬁcacy of this detection mechanism is validated by trace-driven
	simulations. The evaluation results show that the detection mechanism
	has short detection latency and high detection accuracy. Moreover,
	due to its proximity to the ﬂooding sources, our mechanism not only
	sets alarms upon detection of ongoing SYN ﬂooding attacks, but also
	reveals the location of the ﬂooding sources without resorting to
	expensive IP traceback.},
  file = {wang2002.pdf:wang2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.06.26}
}

@TECHREPORT{wang2009,
  author = {Helen J. Wang and Chris Grier and Alexander Moshchuk and Samuel T.
	King and Piali Choudhury and Herman Venter},
  title = {The Multi-Principal OS Construction of the Gazelle Web Browser},
  institution = {Microsoft Research},
  year = {2009},
  number = {MSR-TR-2009-16},
  abstract = {Web browsers originated as applications that people used to view static
	web sites sequentially. As
	
	web sites evolved into dynamic web applications composing content
	from various web sites, browsers
	
	have become multi-principal operating environments with resources
	shared among mutually distrusting
	
	web site principals. Nevertheless, no existing browsers, including
	new architectures like IE 8, Google
	
	Chrome, and OP, have a multi-principal operating system construction
	that gives a browser-based OS the
	
	exclusive control to manage the protection of all system resources
	among web site principals.
	
	 In this paper, we introduce Gazelle, a secure web browser constructed
	as a multi-principal OS.
	
	Gazelle’s Browser Kernel is an operating system that exclusively manages
	resource protection and shar-
	
	ing across web site principals. This construction exposes intricate
	design issues that no previous work
	
	has identiﬁed, such as legacy protection of cross-origin script source,
	and cross-principal, cross-process
	
	display and events protection. We elaborate on these issues and provide
	comprehensive solutions.
	
	 Our prototype implementation and evaluation experience indicates
	that it is realistic to turn an ex-
	
	isting browser into a multi-principal OS that yields signiﬁcantly
	stronger security and robustness with
	
	acceptable performance. Our security policies pose some incompatibility,
	the cost of which requires
	
	further investigation.},
  file = {:msr-gazelle-browser.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.02}
}

@INPROCEEDINGS{wang-2004,
  author = {Helen J. Wang and Chuanxiong Guo and Daniel R. Simon and Alf Zugenmaier},
  title = {Shield: vulnerability-driven network filters for preventing known
	vulnerability exploits},
  booktitle = {SIGCOMM '04: Proceedings of the 2004 conference on Applications,
	technologies, architectures, and protocols for computer communications},
  year = {2004},
  pages = {193--204},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1015467.1015489},
  file = {p193-wang.pdf:p193-wang.pdf:PDF},
  isbn = {1-58113-862-8},
  location = {Portland, Oregon, USA}
}

@INPROCEEDINGS{wang2007a,
  author = {Wang, Ronghua and Du, Wenliang and Ning, Peng},
  title = {Containing denial-of-service attacks in broadcast authentication
	in sensor networks},
  booktitle = {{MobiHoc} '07: Proceedings of the 8th {ACM} international symposium
	on Mobile ad hoc networking and computing},
  year = {2007},
  pages = {71--79},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Broadcast authentication is an important application in sensor networks.
	Public Key Cryptography (PKC) is desirable for this application,
	but due to the resource constraints on sensor nodes, these operations
	are expensive, which means sensor networks using PKC are susceptible
	to Denial of Service (DoS) attacks: attackers keep broadcasting bogus
	messages, which will incur extra costs, thus exhaust the energy of
	the honest nodes. In addition, the long time to verify each message
	using PKC increases the response time of the nodes; it is impractical
	for the nodes to validate each incoming message before forwarding
	i.
	
	
	In this paper we discuss this type of DoS attacks, in which the goal
	of the adversary is to exhaust the energy of the sensor nodes and
	to increase their response time to broadcast messages. We then present
	a dynamic window scheme, where sensor nodes determine whether first
	to verify a message or first to forward the message by themselves.
	This is made possible with the information such as how far this node
	is away from the malicious attacker, and how many hops the incoming
	message has passed. We compare the performance of the proposed scheme
	with other schemes, and show that it can contain the damage of DoS
	attacks to only a small portion of the sensor nodes.},
  doi = {http://doi.acm.org/10.1145/1288107.1288118},
  file = {wang2007a.pdf:wang2007a.pdf:PDF},
  isbn = {978-1-59593-684-4},
  keywords = {sensor network, multi-hop DoS attack},
  location = {Montreal, Quebec, Canada}
}

@MISC{Wang2004,
  author = {Xiaoyun Wang and Dengguo Feng and Xuejia Lai and Hongbo Yu},
  title = {Collisions for Hash Functions {MD4}, {MD5}, {HAVAL}-128 and {RIPEMD}},
  year = {2004},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{wang2005b,
  author = {Xiaoyun Wang and Yiqun Lisa Yin and Hongbo Yu},
  title = {Finding Collisions in the Full SHA-1},
  booktitle = {In Proceedings of Crypto},
  year = {2005},
  pages = {17--36},
  publisher = {Springer},
  abstract = {In this paper, we present new collision search attacks on the hash
	function SHA-1. We show that collisions of SHA-1 can be found with
	complexity less than 2 69 hash operations. This is the first attack
	on the full 80-step SHA-1 with complexity less than the 2 80 theoretical
	bound. Keywords: Hash functions, collision search attacks, SHA-1,
	SHA-0. 1},
  file = {wang2005a.pdf:wang2005a.pdf:PDF}
}

@INPROCEEDINGS{Wang2005a,
  author = {Xiaoyun Wang and Hongbo Yu},
  title = {How to Break {MD5} and Other Hash Functions},
  booktitle = {{EUROCRYPT}},
  year = {2005},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@ARTICLE{wang2006a,
  author = {Yong Wang and Garhan Attebury and Byrav Ramamurthy},
  title = {A survey of security issues in wireless sensor networks},
  journal = {{IEEE} Communications Surveys \& Tutorials},
  year = {2006},
  volume = {8},
  pages = {2--23},
  abstract = {Wireless Sensor Networks (WSNs) are used in many applications in military,
	ecological, and health-related areas. These applications often include
	the monitoring of sensitive information such as enemy movement on
	the battlefield or the location of personnel in a building. Security
	is therefore important in WSNs. However, WSNs suffer from many constraints,
	including low computation capability, small memory, limited energy
	resources, susceptibility to physical capture, and the use of insecure
	wireless communication channels. These constraints make security
	in WSNs a challenge. In this article we present a survey of security
	issues in WSNs. First we outline the constraints, security requirements,
	and attacks with their corresponding countermeasures in WSNs. We
	then present a holistic view of security issues. These issues are
	classified into five categories: cryptography, key management, secure
	routing, secure data aggregation, and intrusion detection. Along
	the way we highlight the advantages and disadvantages of various
	WSN security protocols and further compare and evaluate these protocols
	based on each of these five categories. We also point out the open
	research issues in each subarea and conclude with possible future
	research directions on security in WSNs.},
  file = {wang2006a.pdf:wang2006a.pdf:PDF}
}

@TECHREPORT{wang2005,
  author = {Yi-Min Wang and Doug Beck and Xuxian Jiang and Roussi Roussev},
  title = {Automated Web Patrol with Strider HoneyMonkeys: Finding Web Sites
	That Exploit Browser Vulnerabilities},
  institution = {Microsoft Research},
  year = {2005},
  number = {MSR-TR-2005-72},
  month = {July},
  file = {:TR-2005-72.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{wang2006,
  author = {Yi-Min Wang and Doug Beck and Xuxian Jiang and Roussi Roussev and
	Chad Verbowski and Shuo Chen and Sam King},
  title = {Automated Web Patrol with Strider HoneyMonkeys: Finding Web Sites
	That Exploit Browser Vulnerabilities},
  booktitle = {13th Annual Network and Distributed System Security Symposium (NDSS
	'06)},
  year = {2006},
  month = {February},
  file = {:honeymonkeys.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.16}
}

@INPROCEEDINGS{wang2003,
  author = {Yao Wang and Julita Vassileva},
  title = {Trust and Reputation Model in Peer-to-Peer Networks},
  booktitle = {IEEE Conference on P2P Computing},
  year = {2003},
  abstract = {It is important to enable peers to represent and update their trust
	in other peers in open networks for sharing files, and especially
	services. In this paper, we propose a Bayesian network-based trust
	model and a method for building reputation based on recommendations
	in peer-to-peer networks. Since trust is multi-faceted, peers need
	to develop differentiated trust in different aspects of other peers’
	capability. The peer’s needs are different in different situations.
	Depending on the situation, a peer may need to consider its trust
	in a specific aspect of another peer’s capability or in multiple
	aspects. Bayesian networks provide a flexible method to present differentiated
	trust and combine different aspects of trust. The evaluation of the
	model using a simulation shows that the system where peers communicate
	their experiences (recommendations) outperforms the system where
	peers do not share recommendations with each other and that a differentiated
	trust adds to the performance in terms of percentage of successful
	interactions.},
  file = {:wang2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.17}
}

@BOOK{wasserman1994,
  title = {Social Network Analysis},
  publisher = {Cambridge University Press},
  year = {1994},
  author = {Wasserman, S. and Faust, K.},
  owner = {kristjan},
  timestamp = {2009.04.01}
}

@ARTICLE{watfa2009,
  author = {Watfa, Mohamed K. and El\&\#45;Ghali, Marwa and Halabi, Hiba},
  title = {A hybrid security protocol for sensor networks},
  journal = {Int. J. Commun. Netw. Distrib. Syst.},
  year = {2009},
  volume = {3},
  pages = {116--145},
  number = {2},
  __markedentry = {[kristjan]},
  abstract = {Sensor nodes used to transmit sensitive data, especially in military
	applications, require securing the data transmitted through the WSNs
	to maintain the confidentiality of the data and authenticate the
	participating sensor nodes. Since sensor nodes suffer from limited
	resources, in memory storage, computing power, energy capabilities
	and transmission rates, available network security protocols are
	inadequate. Symmetric algorithms cannot provide the same degree of
	security as public key algorithms, leading us to devise a new algorithm
	SHESP that uses public keys within the limitations of sensor nodes.
	This paper presents a way to utilise existing public key algorithms
	such as RSA, Diffie-Hellmann and elliptic curve in the field of WSN
	security by dividing the network into clusters. Our algorithm supplies
	data confidentiality, node authentication and data integrity while
	remaining within acceptable memory, time and energy constraints.
	We provide theoretical and experimental evidence to validate our
	algorithms. Results reveal significant improvement in data availability,
	data confidentiality and authenticity while reducing the communication
	and computation overhead.},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  doi = {http://dx.doi.org/10.1504/IJCNDS.2009.026822},
  issn = {1754-3916},
  publisher = {Inderscience Publishers},
  review = {Consider data integrity and authenticity by applying public key crypto
	on sensor nodes in a clustered scheme. Claim that symmetric crypto
	cannot give same guarantees as asymmetric which seems contrary to
	accepted views on strength of encryption algorithms. Missing pdf
	-- may be worth looking at.}
}

@INPROCEEDINGS{watro2004,
  author = {Watro, Ronald and Kong, Derrick and Cuti, Sue-fen and Gardiner, Charles
	and Lynn, Charles and Kruus, Peter},
  title = {{TinyPK}: securing sensor networks with public key technology},
  booktitle = {{SASN} '04: Proceedings of the 2nd {ACM} workshop on Security of
	ad hoc and sensor networks},
  year = {2004},
  pages = {59--64},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Wireless networks of miniaturized, low-power sensor/actuator devices
	are poised to become widely used in commercial and military environments.
	The communication security problems for these networks are exacerbated
	by the limited power and energy of the sensor devices. In this paper,
	we describe the design and implementation of public-key-(PK)-based
	protocols that allow authentication and key agreement between a sensor
	network and a third party as well as between two sensor networks.
	Our work is novel in that PK technology was commonly believed to
	be too inefficient for use on low-power devices. As part of our solution,
	we exploit the efficiency of public operations in the RSA cryptosystem
	and design protocols that place the computationally expensive operations
	on the parties external to the sensor network, when possible. Our
	protocols have been implemented on UC Berkeley MICA2 motes using
	the TinyOS development environment.},
  doi = {http://doi.acm.org/10.1145/1029102.1029113},
  file = {watro2004.pdf:watro2004.pdf:PDF},
  isbn = {1-58113-972-1},
  keywords = {sensor networks, wireless networks, security mechanisms, public key
	cryptography},
  location = {Washington DC, USA}
}

@ARTICLE{watts1998,
  author = {Watts, D.J. and Strogatz, S.H.},
  title = {Collective dynamics of "small-world" networks},
  journal = {Nature},
  year = {1998},
  volume = {393},
  number = {6684},
  abstract = {Networks of coupled dynamical systems have been used to model biological
	oscillators1–4, Josephson junction arrays5,6, excitable media7, neural
	networks8–10, spatial games11, genetic control networks12 and many
	other self-organizing systems. Ordinarily, the connection topology
	is assumed to be either completely regular or completely random.
	But many biological, technological and social networks lie somewhere
	between these two extremes. Here we explore simple models of networks
	that can be tuned through this middle ground: regular networks ‘rewired’
	to introduce increasing amounts of disorder. We ﬁnd that these systems
	can be highly clustered, like regular lattices, yet have small characteristic
	path lengths, like random graphs. We call them ‘small-world’ networks,
	by analogy with the small-world phenomenon13,14 (popularly known
	as six degrees of separation15). The neural network of the worm Caenorhabditis
	elegans, the power grid of the western United States, and the collaboration
	graph of ﬁlm actors are shown to be small-world networks. Models
	of dynamical systems with small-world coupling display enhanced signal-propagation
	speed, computational power, and synchronizability. In particular,
	infectious diseases spread more easily in small-world networks than
	in regular lattices.},
  file = {watts1998.pdf:watts1998.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@ARTICLE{wawrzoniak2004,
  author = {Mike Wawrzoniak and Larry Peterson and Timothy Roscoe},
  title = {Sophia: an Information Plane for networked systems},
  journal = {SIGCOMM Comput. Commun. Rev.},
  year = {2004},
  volume = {34},
  pages = {15--20},
  number = {1},
  abstract = {This paper motivates and describes an example network Information
	Plane, called Sophia, currently deployed on PlanetLab. Sophia is
	a distributed system that collects, stores, propagates, aggregates,
	and reacts to observations about the network's current conditions.
	Sophia's approach is novel: it can be viewed as a multi-user distributed
	expression evaluator in which sensors and actuators form the ground
	terms, and statements take on the complete expressiveness of a logic
	language like Prolog. This paper argues that this approach has several
	advantages in managing and controlling a complex, federated, and
	evolving network: (1) a declarative logic language provides a natural
	way to express the kinds of statements that are common to this application
	domain, through temporal and positional logic rules, facts and expressions;
	and (2) distributed evaluation of such logic expressions provides
	many opportunities for performance optimization yielding an efficient
	system.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/972374.972378},
  file = {p15-wawrzoniak.pdf:p15-wawrzoniak.pdf:PDF},
  issn = {0146-4833},
  publisher = {ACM}
}

@ARTICLE{waxman1988,
  author = {Bernard M. Waxman},
  title = {Routing of multipoint connections},
  journal = {Selected Areas in Communications, IEEE Journal on},
  year = {1988},
  abstract = {The author addresses the problem of routing connections in a large-scale
	packet-switched network supporting multipoint communications. He
	gives a formal definition of several versions of the multipoint problem,
	including both static and dynamic versions. He looks at the Steiner
	tree problem as an example of the static problem and considers the
	experimental performance of two approximation algorithms for this
	problem. A weighted greedy algorithm is considered for a version
	of the dynamic problem which allows endpoints to come and go during
	the life of a connection. One of the static algorithms serves as
	a reference to measure the performance of the proposed weighted greedy
	algorithm in a series of experiments},
  address = {Los Alamitos, CA, USA},
  book = {Broadband switching: architectures, protocols, design, and analysis},
  isbn = {0-8186-8926-9},
  publisher = {IEEE Computer Society Press},
  review = {See thesis by Osnat Mokryn. Waxman provides one of the first attempts
	to model the Internet as a complex network. Uses a slightly modified
	Erdos-Renyi model.}
}

@INPROCEEDINGS{weaver2003,
  author = {Nicholas Weaver and Vern Paxson and Stuart Staniford and Robert Cunningham},
  title = {A taxonomy of computer worms},
  booktitle = {WORM '03: Proceedings of the 2003 ACM workshop on Rapid malcode},
  year = {2003},
  pages = {11--18},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {To understand the threat posed by computer worms, it is necessary
	to understand the classes of worms, the attackers who may employ
	them, and the potential payloads. This paper describes a preliminary
	taxonomy based on worm target discovery and selection strategies,
	worm carrier mechanisms, worm activation, possible payloads, and
	plausible attackers who would employ a worm.},
  doi = {http://doi.acm.org/10.1145/948187.948190},
  file = {:p11-weaver.pdf:PDF},
  isbn = {1-58113-785-0},
  location = {Washington, DC, USA}
}

@INPROCEEDINGS{weaver2004,
  author = {Nicholas Weaver and Stuart Staniford and Vern Paxson},
  title = {Very fast containment of scanning worms},
  booktitle = {SSYM'04: Proceedings of the 13th conference on USENIX Security Symposium},
  year = {2004},
  pages = {3--3},
  address = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  abstract = {Computer worms - malicious, self-propagating programs - represent
	a significant threat to large networks. One possible defense, containment,
	seeks to limit a worm's spread by isolating it in a small subsection
	of the network. In this work we develop containment algorithms suitable
	for deployment in high-speed, low-cost network hardware. We show
	that these techniques can stop a scanning host after fewer than 10
	scans with a very low false-positive rate. We also augment this approach
	by devising mechanisms for cooperation that enable multiple containment
	devices to more effectively detect and respond to an emerging infection.
	Finally, we discuss ways that a worm can attempt to bypass containment
	techniques in general, and ours in particular.},
  file = {:GuangSen_containment.pdf:PDF},
  location = {San Diego, CA}
}

@ARTICLE{weigle2006,
  author = {Michele C. Weigle and Prashanth Adurthi and F\'{e}lix Hern\'{a}ndez-Campos
	and Kevin Jeffay and F. Donelson Smith},
  title = {Tmix: a tool for generating realistic TCP application workloads in
	ns-2},
  journal = {{SIGCOMM Comput. Commun. Rev.}},
  year = {2006},
  volume = {36},
  pages = {65--76},
  number = {3},
  abstract = {In order to perform realistic network simulations, one needs a traffic
	generator that is capable of generating realistic synthetic traffic
	in a closed-loop fashion that "looks like" traffic found on an actual
	network. We describe such a traffic generation system for the widely
	used ns-2 simulator. The system takes as input a packet header trace
	taken from a network link of interest. The trace is "reverse compiled"
	into a source-level characterization of each TCP connection present
	in the trace. The characterization, called a connection vector, is
	then used as input to an ns module called tmix that emulates the
	socket-level behavior of the source application that created the
	corresponding connection in the trace. This emulation faithfully
	reproduces the essential pattern of socket reads and writes that
	the original application performed without knowledge of what the
	original application actually was. When combined with a network path
	emulation component we have constructed called DelayBox, the resulting
	traffic generated in the simulation is statistically representative
	of the traffic measured on the real link. This approach to synthetic
	traffic generation allows one to automatically repro-duce in ns the
	full range of TCP connections found on an arbitrary link. Thus with
	our tools, researchers no longer need make arbitrary decisions on
	how traffic is generated in simulations and can instead easily generate
	TCP traffic that represents the use of a net-work by the full mix
	of applications measured on actual network links of interest. The
	method is evaluated by applying it to packet header traces taken
	from campus and wide-area networks and comparing the statistical
	properties of traffic on the measured links with traffic generated
	by tmix in ns.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1140086.1140094},
  issn = {0146-4833},
  keywords = {networks, traffic generation, simulation, ns-2, TCP traffic},
  publisher = {ACM}
}

@ARTICLE{weigle2005,
  author = {Michele C. Weigle and Kevin Jeffay and F. Donelson Smith},
  title = {Delay-based early congestion detection and adaptation in TCP: impact
	on web performance},
  journal = {Computer Communications},
  year = {2005},
  volume = {28},
  pages = {837 - 850},
  number = {8},
  abstract = {Concerns over the scalability of TCP's end-to-end approach to congestion
	control and its AIMD congestion adaptation have led to proposals
	for router-based congestion control, specifically, active queue management
	(AQM). In this paper we present an end-to-end alternative to AQM—a
	new congestion detection and reaction mechanism for TCP based on
	measurements of one-way transit times of TCP segments within a TCP
	connection. Our design, called Sync-TCP, places timestamps in TCP
	headers, measures variation in one-way transit times, and uses these
	measurements as a form of early congestion notification. We demonstrate
	empirically that: (1) Sync-TCP provides better throughput and HTTP
	response-time performance than TCP Reno, (2) Sync-TCP provides better
	early congestion detection and reaction than the Adaptive Random
	Early Detection with Explicit Congestion Notification AQM mechanism,
	(3) Sync-TCP's congestion detection and adaptation mechanisms are
	robust against clock drift, (4) Sync-TCP is an incrementally deployable
	protocol—Sync-TCP connections can co-exist with TCP Reno connections
	in a network, and (5) the performance of TCP Reno connections are
	improved with the addition of even a small percentage of Sync-TCP
	connections.},
  doi = {DOI: 10.1016/j.comcom.2004.11.011},
  file = {weigle2005.pdf:weigle2005.pdf:PDF},
  issn = {0140-3664},
  keywords = {networking, Congestion control, simulations},
  url = {http://www.sciencedirect.com/science/article/B6TYP-4F082CH-2/2/d36f2ef1c86645dd7b494b7f36e1c67b}
}

@ARTICLE{weiser1999,
  author = {Weiser, Mark},
  title = {The computer for the 21st century},
  journal = {{SIGMOBILE} Mob. Comput. Commun. Rev.},
  year = {1999},
  volume = {3},
  pages = {3--11},
  number = {3},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/329124.329126},
  file = {weiser1999.pdf:weiser1999.pdf:PDF},
  issn = {1559-1662},
  keywords = {ubiquitous computing},
  publisher = {ACM},
  review = {The (?) original definition of ubiquitous computing. Good visionary
	description of the field.}
}

@ARTICLE{westhoff2006,
  author = {Dirk Westhoff and Joao Girao and Mithun Acharya},
  title = {Concealed Data Aggregation for Reverse Multicast Traffic in Sensor
	Networks: Encryption, Key Distribution, and Routing Adaptation},
  journal = {{IEEE} Transactions on Mobile Computing},
  year = {2006},
  volume = {5},
  pages = {1417-1431},
  abstract = {Routing in wireless sensor networks is different from that in commonsense
	mobile ad-hoc networks. It mainly needs to support reverse multicast
	traffic to one particular destination in a multihop manner. For such
	a communication pattern, end-to-end encryption is a challenging problem.
	To save the overall energy resources of the network, sensed data
	needs to be consolidated and aggregated on its way to the final destination.
	We present an approach that 1) conceals sensed data end-to-end by
	2) still providing efficient and flexible in-network data aggregation.
	The aggregating intermediate nodes are not required to operate on
	the sensed plaintext data. We apply a particular class of encryption
	transformations and discuss techniques for computing the aggregation
	functions "average” and "movement detection.” We show that the approach
	is feasible for the class of "going down” routing protocols. We consider
	the risk of corrupted sensor nodes by proposing a key predistribution
	algorithm that limits an attacker's gain and show how key predistribution
	and a key-ID sensitive "going down” routing protocol help increase
	the robustness and reliability of the connected backbone.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TMC.2006.144},
  file = {westhoff2006.pdf:westhoff2006.pdf:PDF},
  issn = {1536-1233},
  publisher = {IEEE Computer Society},
  review = {See also CDA, concealed data aggregation papers by girao and mykletun.
	See discussion by ozdemir2009.
	
	
	Considers confidentiality. Integrity and authenticity out of scope.
	Mechanism: end-to-end encryption via privacy homomorphisms. Elliptic
	curve crypto.
	
	
	concealed data aggregation (CDA) for reverse multicast traffic. Considers
	confidentiality via privacy homomorphisms. No integrity or authenticity
	considered. Disjoint sensor/aggregator architecture since aggregators
	need a special symmetric shared key with base station. Uses Domingo-Ferrer
	cryptosystem.}
}

@INCOLLECTION{wheeler1995,
  author = {David J. Wheeler and Roger M. Needham},
  title = {{TEA}: a tiny encryption algorithm},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer},
  year = {1995},
  volume = {1008},
  abstract = {We give a short routine which is based on a Feistel iteration and
	uses a large number of rounds to get security with simplicity.},
  file = {wheeler1995.pdf:wheeler1995.pdf:PDF},
  keywords = {encryption, resource constrained devices, TEA},
  owner = {kristjan},
  timestamp = {2010.05.23}
}

@MISC{o_wi_cross_site_scripting,
  author = {Wikipedia},
  title = {Cross-site scripting},
  howpublished = {[online] http://en.wikipedia.org/wiki/Cross-site\_scripting},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://en.wikipedia.org/wiki/Cross-site\_scripting}
}

@MISC{o_wi_ecmascript,
  author = {Wikipedia},
  title = {{ECMAScript}},
  howpublished = {[online] http://en.wikipedia.org/wiki/ECMAScript},
  owner = {kristjan},
  timestamp = {2008.02.18},
  url = {http://en.wikipedia.org/wiki/ECMAScript}
}

@MISC{o_wi_javascript,
  author = {Wikipedia},
  title = {{JavaScript}},
  howpublished = {[online] http://en.wikipedia.org/wiki/JavaScript},
  owner = {kristjan},
  timestamp = {2008.02.18},
  url = {http://en.wikipedia.org/wiki/JavaScript}
}

@MISC{o_wi_same_origin_policy,
  author = {Wikipedia},
  title = {Same origin policy},
  howpublished = {[online] http://en.wikipedia.org/wiki/Same\_origin\_policy},
  owner = {kristjan},
  timestamp = {2008.02.19},
  url = {http://en.wikipedia.org/wiki/Same_origin_policy}
}

@OTHER{Wikipedia,
  author = {Wikipedia},
  date_accessed = {march 28, 2006},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {IEEE 802.11},
  url = {http://en.wikipedia.org/wiki/802.11}
}

@MISC{Wikipediaa,
  author = {Wikipedia},
  title = {Zipf's Law},
  howpublished = {Online},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Zipf%27s_law}
}

@MISC{Wikipediab,
  author = {Wikipedia},
  title = {Weighted Fair Queuing},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Weighted_fair_queuing}
}

@MISC{Wikipediac,
  author = {Wikipedia},
  title = {Universally Unique Identifier},
  howpublished = {[online] http://en.wikipedia.org/wiki/UUID},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/UUID}
}

@MISC{Wikipediad,
  author = {Wikipedia},
  title = {Slashdot effect},
  howpublished = {[online] http://en.wikipedia.org/wiki/Slashdot\_effect},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Slashdot_effect}
}

@MISC{Wikipediae,
  author = {Wikipedia},
  title = {RSS},
  howpublished = {[online] http://en.wikipedia.org/wiki/RSS},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/RSS}
}

@MISC{Wikipediaf,
  author = {Wikipedia},
  title = {Podcast},
  howpublished = {[online] http://en.wikipedia.org/wiki/Podcasting},
  date_accessed = {23.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Podcasting}
}

@MISC{Wikipediag,
  author = {Wikipedia},
  title = {OSI model},
  howpublished = {[online] http://en.wikipedia.org/wiki/OSI\_model},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/OSI_model}
}

@MISC{Wikipediah,
  author = {Wikipedia},
  title = {Mesh networking},
  howpublished = {[online] http://en.wikipedia.org/wiki/Mesh_network},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Mesh_network}
}

@MISC{Wikipediai,
  author = {Wikipedia},
  title = {Mobile ad-hoc network},
  howpublished = {[online] http://en.wikipedia.org/wiki/Mobile\_ad-hoc\_network},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Mobile_ad-hoc_network}
}

@MISC{Wikipediaj,
  author = {Wikipedia},
  title = {Kazaa},
  howpublished = {[online] http://en.wikipedia.org/wiki/Kazaa},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Kazaa}
}

@MISC{Wikipediak,
  author = {Wikipedia},
  title = {Joint Tactical Radio System},
  howpublished = {[online] http://en.wikipedia.org/wiki/JTRS},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/JTRS}
}

@MISC{Wikipedial,
  author = {Wikipedia},
  title = {ISM band},
  howpublished = {[online] http://en.wikipedia.org/wiki/ISM\_band},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/ISM_band}
}

@MISC{Wikipediam,
  author = {Wikipedia},
  title = {Hotspot (Wi-Fi)},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Hotspot_%28Wi-Fi%29}
}

@MISC{Wikipedian,
  author = {Wikipedia},
  title = {General Packet Radio Service},
  howpublished = {Online},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/GPRS}
}

@MISC{Wikipediao,
  author = {Wikipedia},
  title = {Gnutellafr},
  howpublished = {[online] http://en.wikipedia.org/wiki/Gnutella},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Gnutella}
}

@MISC{Wikipediap,
  author = {Wikipedia},
  title = {Flash crowds},
  howpublished = {[online] http://en.wikipedia.org/wiki/Flash\_Crowd},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Flash_Crowd}
}

@MISC{Wikipediaq,
  author = {Wikipedia},
  title = {Enhanced Data Rates for GSM Evolution},
  howpublished = {Online},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/EDGE}
}

@OTHER{Wikipediar,
  author = {Wikipedia},
  date_accessed = {26.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Diameter},
  url = {http://en.wikipedia.org/wiki/DIAMETER}
}

@MISC{Wikipedias,
  author = {Wikipedia},
  title = {Common Object Request Broker Architecture},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/CORBA}
}

@MISC{Wikipediat,
  author = {Wikipedia},
  title = {Component Object Model},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Component_object_model}
}

@MISC{Wikipediau,
  author = {Wikipedia},
  title = {Bluetooth},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Bluetooth}
}

@MISC{Wikipediav,
  author = {Wikipedia},
  title = {Application programming interface},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/API}
}

@MISC{Wikipediaw,
  author = {Wikipedia},
  title = {3G},
  howpublished = {Online},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/3G}
}

@OTHER{Wikipedia2007,
  author = {Wikipedia},
  date_accessed = {26.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {WiMAX},
  url = {http://en.wikipedia.org/wiki/WiMAX},
  year = {2007}
}

@OTHER{Wikipedia2007a,
  author = {Wikipedia},
  date_accessed = {26.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Radius (Remote Dialin Authentication, authorization and accounting
	protocol)},
  url = {http://en.wikipedia.org/wiki/RADIUS},
  year = {2007}
}

@OTHER{Wikipedia2007b,
  author = {Wikipedia},
  date_accessed = {26.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Point-to-point protocol},
  url = {http://en.wikipedia.org/wiki/Point-to-Point\_Protocol},
  year = {2007}
}

@OTHER{Wikipedia2007c,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Page replacement algorithm},
  url = {http://en.wikipedia.org/wiki/Page\_replacement\_algorithm},
  year = {2007}
}

@OTHER{Wikipedia2007d,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Locality of reference},
  url = {http://en.wikipedia.org/wiki/Locality\_of\_reference},
  year = {2007}
}

@OTHER{Wikipedia2007e,
  author = {Wikipedia},
  date_accessed = {23.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Internet Group Management Protocol},
  url = {http://en.wikipedia.org/wiki/IGMP},
  year = {2007}
}

@OTHER{Wikipedia2007f,
  author = {Wikipedia},
  date_accessed = {15.01.2006},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Heuristic},
  url = {http://en.wikipedia.org/wiki/Heuristic},
  year = {2007}
}

@OTHER{Wikipedia2007g,
  author = {Wikipedia},
  date_accessed = {23.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Content Delivery Network},
  url = {http://en.wikipedia.org/wiki/Content\_Delivery\_Network},
  year = {2007}
}

@OTHER{Wikipedia2007h,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Cache},
  url = {http://en.wikipedia.org/wiki/Caching},
  year = {2007}
}

@OTHER{Wikipedia2007i,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Cache algorithms},
  url = {http://en.wikipedia.org/wiki/Cache\_algorithms},
  year = {2007}
}

@OTHER{Wikipedia2007j,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Lazlo Belady},
  url = {http://en.wikipedia.org/wiki/Laszlo\_Belady},
  year = {2007}
}

@OTHER{Wikipedia2007k,
  author = {Wikipedia},
  date_accessed = {26.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {ATOM},
  url = {http://en.wikipedia.org/wiki/Atom\_standard},
  year = {2007}
}

@OTHER{Wikipedia2007l,
  author = {Wikipedia},
  date_accessed = {23.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Address Resolution Protocol},
  url = {http://en.wikipedia.org/wiki/Address\_Resolution\_Protocol},
  year = {2007}
}

@OTHER{Wikipedia2007m,
  author = {Wikipedia},
  date_accessed = {15.01.2007},
  owner = {kristjan},
  timestamp = {2008.09.19},
  title = {Adaptive Replacement Cache},
  url = {http://en.wikipedia.org/wiki/Adaptive\_Replacement\_Cache},
  year = {2007}
}

@PHDTHESIS{wikstrom2005,
  author = {Douglas Wikstr\"{o}m},
  title = {On the Security of Mix-Nets and Hierarchical Group Signatures},
  school = {Royal Institute of Technology (Kungliga Tekniska h\"{o}gskolan).
	Stockholm. Sweden.},
  year = {2005},
  abstract = {In this thesis we investigate two separate cryptographic notions:
	mix-nets and hier-
	
	archical group signatures. The former notion was introduced by Chaum
	(1981). The latter
	
	notion is introduced in this thesis, but it generalizes the notion
	of group signatures which
	
	was introduced by Chaum and Heyst (1991).
	
	
	Numerous proposals for mix-nets are given in the literature, but these
	are presented
	
	with informal security arguments or at best partial proofs. We illustrate
	the need for a
	
	rigorous treatment of the security mix-nets by giving several practical
	attacks against a
	
	construction of Golle et al. (2002). Then we provide the ﬁrst deﬁnition
	of security of
	
	a mix-net in the universally composable security framework (UC-framework)
	introduced
	
	by Canetti (2001). We construct two distinct eﬃcient mix-nets that
	are provably secure
	
	under standard assumptions in the UC-framework against an adversary
	that corrupts any
	
	minority of the mix-servers and any set of senders. The ﬁrst construction
	is based on the
	
	El Gamal cryptosystem (1985) and is secure against a static adversary,
	i.e., an adversary
	
	that decides which parties to corrupt before the execution of the
	protocol. This is the ﬁrst
	
	eﬃcient UC-secure mix-net in the literature and the ﬁrst sender veriﬁable
	mix-net that is
	
	robust. The second construction is based on the Paillier cryptosystem
	(1999) and secure
	
	against an adaptive adversary, i.e., an adversary that decides which
	parties to corrupt
	
	during the execution of the protocol. This is the ﬁrst eﬃcient adaptively
	secure mix-net
	
	in any model. An important subprotocol in the above constructions
	is a zero-knowledge
	
	proof of knowledge of a witness that a party behaves as expected.
	There are two known
	
	approaches for constructing such a protocol given by Neﬀ (2002) and
	Furukawa and Sako
	
	(2002) respectively. We present a third independent approach.
	
	
	We introduce the notion of hierarchical group signatures. This is
	a generalization of
	
	group signatures. There are several group managers, and the signers
	and group managers
	
	are organized in a tree in which the signers are the leaves and the
	group managers are
	
	internal nodes. Given a signature, a group manager learns if it is
	an ancestor of the signer,
	
	and if so to which of its immediate subtrees the signer belongs, but
	it learns nothing else.
	
	Thus, the identity of the signer is revealed in a hierarchical way.
	We provide a deﬁnition
	
	of security of hierarchical group signatures and give two provably
	secure constructions.
	
	The ﬁrst construction is secure under general assumptions. It is impractical
	and of purely
	
	theoretical interest. The second construction is provably secure under
	standard complexity
	
	assumptions and almost practical.},
  file = {wikstrom2005.pdf:wikstrom2005.pdf:PDF},
  keywords = {UC, universal composability, security protocol composition, cryptography,
	mix-net},
  owner = {kristjan},
  timestamp = {2010.03.14}
}

@INCOLLECTION{wikstrom2004,
  author = {Douglas Wikstr\"{o}m},
  title = {A Universally Composable Mix-Net},
  booktitle = {Theory of Cryptography},
  publisher = {Springer Berlin / Heidelberg},
  year = {2004},
  volume = {2951/2004},
  abstract = {A mix-net is a cryptographic protocol executed by a set of mix-servers
	that provides anonymity for a group of senders. The main application
	is electronic voting.
	
	Numerous mix-net constructions and stand-alone definitions of security
	are proposed in the literature, but only partial proofs of security
	are given for most constructions and no construction has been proved
	secure with regards to any kind of composition.
	
	
	We define an ideal mix-net in the universally composable security
	framework of Canetti [6]. Then we describe a mix-net based on Feldman
	[13] and using similar ideas as Desmedt and Kurosawa [10], and prove
	that it securely realizes the ideal mix-net with respect to static
	adversaries that corrupt a minority of the mix-servers and arbitrarily
	many senders.
	
	
	The mix-net executes in a hybrid model with access to ideal distributed
	key generation, but apart from that our only assumption is the existence
	of a group in which the Decision Diffie-Hellman Problem is hard.
	
	
	If there are relatively few mix-servers or a strong majority of honest
	mix-servers our construction is practical.},
  file = {wikstrom2004.pdf:wikstrom2004.pdf:PDF},
  keywords = {UC, universal composability, security protocol composition, cryptography,
	mix-net},
  owner = {kristjan},
  timestamp = {2010.03.03}
}

@BOOK{wilkes1979,
  title = {The Cambridge {CAP} Computer and its Operating System},
  publisher = {Elsevier North Holland},
  year = {1979},
  author = {M. V. Wilkes and R. M. Needham},
  file = {:cap.pdf:PDF},
  owner = {kristjan},
  review = {See also needham1977},
  timestamp = {2009.02.27}
}

@MISC{williams2004,
  author = {Amrit T. Williams and Jay Heiser},
  title = {Protect Your PCs and Servers From the Botnet Threat},
  howpublished = {Gartner Research, ID Number: G00124737},
  month = {December},
  year = {2004},
  file = {:GartnerTheBotnetThreat.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@ARTICLE{willinger-1998,
  author = {Walter Willinger and Vern Paxson and Murad S. Taqqu},
  title = {Self-similarity and heavy tails: structural modeling of network traffic},
  year = {1998},
  pages = {27--53},
  abstract = {High-resolution traffic measurements from modern communications networks
	provide unique opportunities for developing and validating mathematical
	models for aggregate traffic. To exploit these opportunities, we
	emphasize the need for structural models that take into account specific
	physical features of the underlying communication network structure.
	This approach is in sharp contrast to the traditional black box modeling
	methodology from time series analysis that ignores, in general, specific
	physical structures. We demonstrate, in particular, how the proposed
	structural modeling approach provides a direct link between the observed
	self-similarity characteristic of measured aggregate network traffic,
	and the strong empirical evidence in favor of heavy-tailed, infinite
	variance phenomena at the level of individual network connections.
	1.},
  address = {Cambridge, MA, USA},
  book = {A practical guide to heavy tails: statistical techniques and applications},
  file = {:10.1.1.54.7996.pdf:PDF},
  isbn = {0-8176-3951-9},
  publisher = {Birkhauser Boston Inc.}
}

@ARTICLE{woo2004,
  author = {Woo, Alec and Madden, Sam and Govindan, Ramesh},
  title = {Networking support for query processing in sensor networks},
  journal = {{Commun. ACM}},
  year = {2004},
  volume = {47},
  pages = {47--52},
  number = {6},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/990680.990706},
  file = {woo2004.pdf:woo2004.pdf:PDF},
  issn = {0001-0782},
  owner = {kristjan},
  publisher = {ACM}
}

@ARTICLE{wood2002,
  author = {Anthony D. Wood and John A. Stankovic},
  title = {Denial of Service in Sensor Networks},
  journal = {Computer},
  year = {2002},
  volume = {35},
  pages = {54--62},
  number = {10},
  abstract = {Unless their developers take security into account at design time,
	sensor networks and the protocols they depend on will remain vulnerable
	to denial of service attacks.},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/MC.2002.1039518},
  file = {wood2002.pdf:wood2002.pdf:PDF},
  issn = {0018-9162},
  publisher = {IEEE Computer Society Press},
  review = {Referenced by perrig2004 on routing around areas affected by DDoS
	attack.}
}

@INPROCEEDINGS{wood2003,
  author = {Anthony D. Wood and John A. Stankovic and Sang H. Son},
  title = {{JAM}: A Jammed-Area Mapping Service for Sensor Networks},
  booktitle = {24th {IEEE} Real-Time Systems Symposium},
  year = {2003},
  pages = {286--297},
  abstract = {Preventing denial-of-service attacks in wireless sensor networks is
	di#cult primarily because of the limited resources available to network
	nodes and the ease with which attacks are perpetrated. Rather than
	jeopardize design requirements which call for simple, inexpensive,
	mass-producible devices, we propose a coping strategy that detects
	and maps jammed regions. We describe a mapping protocol for nodes
	that surround a jammer which allows network applications to reason
	about the region as an entity, rather than as a collection of broken
	links and congested nodes. This solution is enabled by a set of design
	principles: loose group semantics, eager eavesdropping, supremacy
	of local information, robustness to packet loss and failure, and
	early use of results. Performance results show that regions can be
	mapped in 1 -- 5 seconds, fast enough for real-time response. With
	a moderately connected network, the protocol is robust to failure
	rates as high as 25 percent.},
  file = {wood2003.pdf:wood2003.pdf:PDF},
  keywords = {sensor network, denial-of-service, DoS, jamming detection},
  review = {Referenced by roosta2006 on availability attacks.}
}

@ARTICLE{wu2007,
  author = {Kui Wu and Dennis Dreef and Bo Sun and Yang Xiao},
  title = {Secure data aggregation without persistent cryptographic operations
	in wireless sensor networks},
  journal = {{Ad Hoc Networks}},
  year = {2007},
  volume = {5},
  pages = {100 - 111},
  number = {1},
  note = {Security Issues in Sensor and Ad Hoc Networks},
  abstract = {In-network data aggregation is an essential operation to reduce energy
	consumption in large-scale wireless sensor networks. With data aggregation,
	however, raw data items are invisible to the base station and thus
	the authenticity of the aggregated data is hard to guarantee. A compromised
	sensor node may forge an aggregation value and mislead the base station
	into trusting a false reading. Due to the stringent constraints of
	energy supply and computing capability on sensor nodes, it is challenging
	to detect a compromised sensor node and keep it from cheating, since
	expensive cryptographic operations are unsuitable for tiny sensor
	devices. This paper proposes a secure aggregation tree (SAT) to detect
	and prevent cheating. Our method is essentially different from other
	existing solutions in that it does not require any cryptographic
	operations when all sensor nodes work honestly. The detection of
	cheating is based on the topological constraints in the aggregation
	tree. We also propose a weighted voting scheme to determine a misbehaving
	node and a secure local recovery scheme to avoid using the misbehaving
	node.},
  doi = {DOI: 10.1016/j.adhoc.2006.05.009},
  file = {wu2007.pdf:wu2007.pdf:PDF},
  issn = {1570-8705},
  keywords = {Cheating detection, secure in-network aggregation, secure aggregation
	tree, sensor networks, wireless networks},
  review = {The authors address security of in-network aggregagion in sensor networks.
	Address misbehavior by aggregators (analogus to CPS) but do so without
	use of cryptographic functions (during the detection stage). This
	provides a very simple and light-weight protocol.
	
	
	Network assumptions: 
	
	Nodes cannot impersonate neighbors (due to the fact that nodes can
	listen to their neighbors transmissions -- broadcast medium). 
	
	Neighbors have mechanisms to encrypt/decrypt and authenticate messages
	(pairwise). Cite \cite{karlof2004}, \cite{perrig2002}, \cite{watro2007}
	on suitable key distribution protocols. Crypto is though only needed
	when misbehaviour is detected.
	
	
	Construction of secure aggregation tree:
	
	The authors propose to construct the tree so that every child node
	can monitor the behavior of its parent. They maintain that this is
	sufficient to prevent misbehavior by non-leafs. A parent and children
	in such a tree should form a clique. Nodes know their one and two
	hop neighbors. A distributed tree construction algorithm is described,
	initiated by the root node (sink). 
	
	Cheating detection similar to watchdog introduced by \cite{marti2000}
	-- nodes listen to the channel to see if the parent forwarded correctly
	(note: of course this does not work with multi-channel or spread
	spectrum radios). In the clique approach, nodes can overhear all
	messages sent by siblings (in clique) and those sent by the father.
	Note: Encryption (pairwise) would break this -- homomorphic encryption
	schemes probably too.
	
	Nodes detecting misbehavor raise alerts -- indicating potential compromise.
	Weighted voting used to make file (distributed) decision to exclude
	the misbehaving node. Secure communications are used during the voting
	phase. Nodes confirmed as misbehaving in a detection-confirmation
	message are a) ignored if children of the receiving node b) routed
	around in the case the misbehaving node is a parent of the receiver.
	
	
	
	The authors discuss the criteron for raising alerts based on widely
	used aggregation functions -- mean, min, max.
	
	
	The authors evaluate the efficiency of the proposal using a simulation
	study. There is no comparison with other known secure aggregation
	functions.
	
	
	Note: Several adversaries can occupy an entire group (or sufficiently
	large fraction to control vote) and either provide false results
	with impunity or exclude the honest peers.},
  url = {http://www.sciencedirect.com/science/article/B7576-4K7X875-5/2/dd6a9f51dced7629f3bc1fd4b1799709}
}

@INPROCEEDINGS{wu1997,
  author = {Thomas Wu},
  title = {The Secure Remote Password Protocol},
  booktitle = {Internet Society Symposium on Network and Distributed System Security},
  year = {1997},
  abstract = {This paper presents a new password authentication and key-exchange
	protocol suitable for authenticating users and exchanging keys over
	an untrusted network. The new protocol resists dictionary attacks
	mounted by either passive or active network intruders, allowing,
	in principle, even weak passphrases to be used safely. It also o
	ers perfect forward secrecy, which protects past sessions and passwords
	against future compromises. Finally, user passwords are stored in
	a form that is not plaintext-equivalent to the password itself, so
	an attacker who captures the password database cannot use it directly
	to compromise security and gain immediate access to the host. This
	new protocol combines techniques of zero-knowledge proofs with asymmetric
	key exchange protocols and o ers signi cantly improved performance
	over comparably strong extended methods that resist stolen-veri er
	attacks such as Augmented EKE or B-SPEKE.},
  file = {wu1997.pdf:wu1997.pdf:PDF},
  keywords = {password authentication, key exchange, zero knowledge password proof},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@ARTICLE{wuhib2008,
  author = {Fetahi Wuhib and Mads Dam and Rolf Stadler},
  title = {Decentralized Detection of Global Threshold Crossings Using Aggregation
	Trees},
  journal = {Computer Networks},
  year = {2008},
  volume = {52},
  pages = {1745--1761},
  number = {9},
  month = feb,
  abstract = {The timely detection that a monitored variable has crossed a given
	threshold is a fundamental requirement for many network management
	applications. A challenge is the detection of threshold crossing
	of network-wide variables, which are computed from device counters
	across the network, using aggregation functions such as SUM, MAX
	and AVERAGE. This paper contains a detailed description and a comprehensive
	evaluation of TCA-GAP, a protocol for detecting threshold crossings
	of network-wide aggregates in a distributed way. Elements of its
	design include tree-based incremental aggregation for estimating
	the value of aggregates, a local hysteresis mechanism to reduce overhead
	and dynamic recomputation of local thresholds to ensure correctness.
	The protocol is evaluated through extensive simulation using real
	traces in scenarios with network sizes up to 5232 nodes. From the
	measurements, we conclude that the protocol is efficient in the sense
	that the overhead is negligible when the aggregate is far from the
	threshold. It is scalable as the protocol overhead is independent
	of the system size for the network sizes and scenario configurations
	considered. We demonstrate that the local hysteresis parameter can
	be used to control the tradeoff between protocol overhead and detection
	delay. We further report on results on how node failures impact overhead
	and detection quality of the protocol.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.comnet.2008.02.015},
  file = {IR-EE-LCN_2008_008.pdf:IR-EE-LCN_2008_008.pdf:PDF},
  issn = {1389-1286},
  keywords = {decentralized network management, threshold crossing alerts, real-time
	monitoring, tree-based aggregation protocols},
  publisher = {Elsevier North-Holland, Inc.}
}

@INPROCEEDINGS{wuhib2008b,
  author = {Fetahi Wuhib and Mads Dam and Rolf Stadler and Alexander Clemm},
  title = {Robust Monitoring of Network-wide Aggregates through Gossiping},
  booktitle = {{10th IFIP/IEEE International Symposium on Integrated Management
	(IM 2007)}},
  year = {2007},
  address = {Munich, Germany},
  month = {May},
  note = {2008},
  abstract = {We examine the use of gossip protocols for continuous monitoring of
	network-wide aggregates. Aggregates are computed from local management
	variables using functions such as AVERAGE, MIN, MAX, or SUM. A particular
	challenge is to develop a gossip-based aggregation protocol that
	is robust against node failures. In this paper, we present G-GAP,
	a gossip protocol for continuous monitoring of aggregates, which
	is robust against discontiguous failures (i.e., under the constraint
	that neighboring nodes do not fail within a short period of each
	other). We formally prove this property, and we evaluate the protocol
	through simulation using real traces. The simulation results suggest
	that the design goals for this protocol have been met. For instance,
	the tradeoff between estimation accuracy and protocol overhead can
	be controlled, and a high estimation accuracy (below some 5% error
	in our measurements) is achieved by the protocol, even for large
	networks and frequent node failures. Further, we perform a comparative
	assessment of G-GAP against a tree-based aggregation protocol using
	simulation. Surprisingly, we find that the tree-based aggregation
	protocol consistently outperforms the gossip protocol for comparative
	overhead, both in terms of accuracy and robustness.},
  file = {IR-EE-LCN_2007_001.pdf:IR-EE-LCN_2007_001.pdf:PDF},
  keywords = {gossip protocol, epidemic protocol, robust aggregation, decentralized
	monitoring},
  owner = {kristjan},
  timestamp = {2008.09.04}
}

@INPROCEEDINGS{wuhib2005,
  author = {Fetahi Wuhib and Mads Dam and Rolf Stadler and Alexander Clemm},
  title = {Decentralized computation of threshold crossing alerts},
  booktitle = {DSOM 2005: 16th IFIP/IEEE International Workshop on Distributed Systems:
	Operations and management},
  year = {2005},
  volume = {LNCS 2775},
  pages = {220-232},
  month = {October},
  abstract = {Threshold crossing alerts (TCAs) indicate to a management system that
	a management variable, associated with the state, performance or
	health of the network, has crossed a certain threshold. The timely
	detection of TCAs is essential to proactive management. This paper
	focuses on detecting TCAs for network-level variables, which are
	computed from device-level variables using aggregation functions,
	such as SUM, MAX, or AVERAGE. It introduces TCA-GAP, a novel protocol
	for producing network-wide TCAs in a scalable and robust manner.
	The protocol maintains a spanning tree and uses local thresholds,
	which adapt to changes in network state and topology, by allowing
	nodes to trade un-used “threshold space”. Scalability is achieved
	through computing the thresholds locally and through distributing
	the aggregation process across all nodes. Fault-tolerance is achieved
	by a mechanism that reconstructs the spanning tree after node addition,
	removal or failure. Simulation results on an ISP topology show that
	the protocol successfully concentrates trafﬁc overhead to periods
	where the aggregate is close to the given threshold.},
  file = {wuhib2005.pdf:wuhib2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.05.14}
}

@TECHREPORT{wuhib_tr_2008,
  author = {Fetahi Wuhib and Rolf Stadler},
  title = {Adaptive Real-time Monitoring in Mobile Wireless Networks},
  institution = {Royal Institute of Technology (KTH)},
  year = {2008},
  month = jan,
  abstract = {While real-time monitoring is an essential function for many management
	tasks, few results have been reported to date in the context of MANETs
	(Mobile Ad-hoc NETworks). In this work, we compare the performance
	of tree-based and gossip-based aggregation protocols in a MANET environment,
	for the purpose of continuous, real-time monitoring. The fact that
	gossip protocols do not maintain a spanning tree, like tree-based
	protocols do, suggested to us that gossip-based protocols perform
	much better than tree-based protocols in a MANET environment. To
	make the comparison, we adapt a tree-based aggregation protocol (GAP)
	and a gossip-based aggregation protocol (G-GAP), both of which have
	been developed for fixed networks, for operation in MANETs. We report
	on comparative simulation studies, performed in NS-2, with two major
	findings. First, the gossip-based aggregation protocol is very sensitive
	to message loss. If this issue is not addressed properly, the tree-based
	aggregation protocol outperforms the gossip-based protocol in estimation
	accuracy by orders of magnitude, in the scenarios investigated. Second,
	our studies suggest that in a resource-constrained environment characterized
	by high node mobility and large size, a gossip protocol potentially
	performs significantly better than a tree-based protocol.},
  file = {TRITA-EE_2008_005.pdf:TRITA-EE_2008_005.pdf:PDF},
  keywords = {real-time monitoring, MANET, distributed aggregation, tree-based protocols,
	gossip-based protocol}
}

@TECHREPORT{wuhib_tr_2007,
  author = {Fetahi Wuhib and Rolf Stadler},
  title = {M-{GAP}--A New Pattern for Cfengine and Other Distributed Software},
  institution = {Royal Institute of Technology (KTH)},
  year = {2007},
  number = {TRITA-EE 2007:044},
  month = jul,
  abstract = {Aggregation had been identified as an important component in the management
	of distributed systems, and as such, a number of distributed aggregation
	protocols are proposed by others[1][2][3] and also by us[4][5][6].
	Some of our protocols include the Echo Pattern, the Generic Aggregation
	Protocol (GAP) and Gossip Generic Aggregation Protocol (G-GAP). The
	echo pattern is a distributed polling protocol while both GAP and
	G-GAP are protocols for continuous monitoring of network-wide aggregates.
	In this work we present two other protocols, multi-GAP (M-GAP) and
	pull-based multi-GAP (PM-GAP), which are extensions of the GAP protocol
	where the estimate of the aggregate is available on all nodes (vs.
	the estimate being available at the root node in GAP). First, we
	present M-GAP, a push-based protocol where the estimate of the aggregate
	is available on all nodes. Then we present PM-GAP which is M-GAP
	modified in such a way that the interaction between nodes is pull
	and not push, which is the communication paradigm in cfengine[8].},
  file = {TRITA-EE_2007_044.pdf:TRITA-EE_2007_044.pdf:PDF}
}

@TECHREPORT{wuhib2009,
  author = {Fetahi Wuhib and Rolf Stadler and Mads Dam},
  title = {Gossiping for Threshold Detection},
  institution = {Royal Institute of Technology},
  year = {2009},
  number = {IR-EE-LCN-2009-006},
  address = {Stockholm, Sweden},
  abstract = {We investigate the use of gossip protocols to detect threshold crossings
	of network-wide aggregates. Aggregates are computed from local device
	variables using functions such as SUM, AVERAGE, COUNT, MAX and MIN.
	The process of aggregation and detection is performed using a standard
	gossiping scheme. A key design element is to let nodes dynamically
	adjust their neighbor interaction rates according to the distance
	between the nodes’ local estimate of the global aggregate and the
	threshold itself. We show that this allows considerable savings in
	communication overhead. In particular, the overhead becomes negligible
	when the aggregate is sufﬁciently far above or far below the threshold.
	We present evaluation results from simulation studies regarding protocol
	efﬁciency, quality of threshold detection, scalability, and controllability.},
  file = {wuhib2009.pdf:wuhib2009.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.04}
}

@INPROCEEDINGS{xie2007,
  author = {Haiyong Xie and Yang Richard Yang},
  title = {A Measurement-based Study of the Skype Peer-to-Peer VoIP Performance},
  booktitle = {Proceedings of the 6th International Workshop on Peer-to-Peer Systems
	(IPTPS '07)},
  year = {2007},
  month = {February},
  file = {xie2007.pdf:xie2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.10}
}

@INCOLLECTION{xie2008,
  author = {Haiyong Xie and Yang Richard Yang and Avi Silberschatz},
  title = {Towards an ISP-Compliant, Peer-Friendly Design for Peer-to-Peer Networks},
  booktitle = {NETWORKING 2008 Ad Hoc and Sensor Networks, Wireless Networks, Next
	Generation Internet},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  volume = {4982/2008},
  pages = {375-384},
  abstract = {Peer-to-peer (P2P) applications are consuming a significant fraction
	of the total bandwidth of Internet service providers (ISPs). This
	has become a financial burden to ISPs and if not well addressed may
	lead ISPs to block or put strict rate limits on P2P traffic. In this
	paper, we propose a new framework, PCP, for designing P2P applications
	to smoothly fit into the global Internet. In our framework, an ISP
	decides on how much of its bandwidth is to be allocated to P2P clients,
	and P2P clients inside the network adopt a peer-friendly algorithm
	to fairly share the bandwidth. Using the widely-used percentile-based
	charging model and real traffic traces, we show that an ISP can allocate
	a large amount of bandwidth dedicated to P2P, without increasing
	its financial cost. We also show that P2P clients can use the algorithm
	to fairly share the allocated bandwidth.},
  file = {:xie2008.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.10}
}

@ARTICLE{xie2005,
  author = {Yinglian Xie and Sekar, V. and Maltz, D.A. and Reiter, M.K. and Hui
	Zhang},
  title = {Worm origin identification using random moonwalks},
  journal = {{IEEE} Symposium on Security and Privacy},
  year = {2005},
  pages = { 242-256},
  month = {8-11 May},
  abstract = {We propose a novel technique that can determine both the host responsible
	for originating a propagating worm attack and the set of attack ﬂows
	that make up the initial stages of the attack tree via which the
	worm infected successive generations of victims. We argue that knowledge
	of both is important for combating worms: knowledge of the origin
	supports law enforcement, and knowledge of the causal ﬂows that advance
	the attack supports diagnosis of how network defenses were breached.
	Our technique exploits the “wide tree” shape of a worm propagation
	emanating from the source by performing random “moonwalks” backward
	in time along paths of ﬂows. Correlating the repeated walks reveals
	the initial causal ﬂows, thereby aiding in identifying the source.
	Using analysis, simulation, and experiments with real world traces,
	we show how the technique works against both today’s fast propagating
	worms and stealthy worms that attempt to hide their attack ﬂows among
	background trafﬁc.},
  doi = {10.1109/SP.2005.23},
  file = {oakland05.pdf:oakland05.pdf:PDF},
  issn = {1081-6011 },
  keywords = {invasive software, randomised algorithms, tree data structures, attack
	flows, attack tree, background traffic, fast propagating worms, host
	identification, initial causal flows, law enforcement, network diagnosis,
	propagating worm attack, random moonwalks, repeated walks, stealthy
	worms, wide tree shape, worm origin identification, worm propagation},
  owner = {kristjan},
  timestamp = {2008.03.19}
}

@INCOLLECTION{xie2007a,
  author = {Yi Xie and Shun-Zheng Yu},
  title = {Detecting Shrew {HTTP} Flood Attacks for Flash Crowds},
  booktitle = {{Computational Science – ICCS 2007}},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {4487/2007},
  pages = {640-647},
  abstract = {Countering network attacks is becoming ever more challenging. Web-based
	vulnerabilities represent a substantial portion of the security exposures
	of computer networks. In order to detect a new Web-based assault
	named shrew Distributed Denial of Service attacks based on HTTP flood,
	Principle Component Analysis and Independent Component Analysis are
	applied to abstract the multivariate observation vector. A novel
	anomaly detector based on hidden semi-Markov model is proposed. Experiment
	results based on real traffic trace and emulated attacks show, the
	scheme can be used effectively to implement the detection of the
	shrew HTTP flood attacks embedded in the normal flash crowd of large-scale
	Website; and the detection is not dependent on the intensity of attack
	traffic.},
  file = {xie2007a.pdf:xie2007a.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.18}
}

@INPROCEEDINGS{xu2005,
  author = {Dingbang Xu and Peng Ning},
  title = {Privacy-preserving alert correlation: a concept hierarchy based approach},
  booktitle = {21st Annual Computer Security Applications Conference},
  year = {2005},
  abstract = {With the increasing security threats from infrastructure attacks such
	as worms and distributed denial of service attacks, it is clear that
	the cooperation among different organizations is necessary to defend
	against these attacks. However, organizations' privacy concerns for
	the incident and security alert data require that sensitive data
	be sanitized before they are shared with other organizations. Such
	sanitization process usually has negative impacts on intrusion analysis
	(such as alert correlation). To balance the privacy requirements
	and the need for intrusion analysis, we propose a privacy-preserving
	alert correlation approach based on concept hierarchies. Our approach
	consists of two phases. The first phase is entropy guided alert sanitization,
	where sensitive alert attributes are generalized to high-level concepts
	to introduce uncertainty into the dataset with partial semantics.
	To balance the privacy and the usability of alert data, we propose
	to guide the alert sanitization process with the entropy or differential
	entropy of sanitized attributes. The second phase is sanitized alert
	correlation. We focus on defining similarity functions between sanitized
	attributes and building attack scenarios from sanitized alerts. Our
	preliminary experimental results demonstrate the effectiveness of
	the proposed techniques.},
  file = {xu2005.pdf:xu2005.pdf:PDF},
  keywords = {alert correlation},
  owner = {kristjan},
  timestamp = {2009.08.24}
}

@ARTICLE{xu2003,
  author = {Jun Xu and Wooyong Lee},
  title = {Sustaining Availability of Web Services under Distributed Denial
	of Service Attacks},
  journal = {{IEEE Transactions on Computers}},
  year = {2003},
  abstract = {The recent tide of Distributed Denial of Service (DDoS) attacks against
	high-profile web sites demonstrate how devastating DDoS attacks are,
	and how defenseless the Internet is under such attacks. We design
	a practical DDoS defense system that can protect the availability
	of web services during severe DDoS attacks. The basic idea behind
	our system is to isolate and protect legitimate traffic from huge
	volume of DDoS traffic when an attack occurs. Traffic that needs
	to be protected can be recognized and protected using efficient cryptographic
	techniques. Therefore, by provisioning adequate resource (e.g., bandwidth)
	to legitimate traffic separated by this process, we are able to provide
	adequate service to a large percentage of clients during DDoS attacks.
	The worst-case performance of the system is evaluated based on a
	novel game theoretical framework, which characterizes the natural
	adversarial relationship between a DDoS adversary and the proposed
	system. We also conduct a simulation study to verify a key assumption
	used in the game-theoretical analysis and to study the system dynamics
	during an attack.},
  file = {xu2003.pdf:xu2003.pdf:PDF},
  keywords = {networks, security, DDoS, DDoS defense, simulation, game theory}
}

@INPROCEEDINGS{xu2001,
  author = {Xu, Ya and Heidemann, John and Estrin, Deborah},
  title = {Geography-informed energy conservation for Ad Hoc routing},
  booktitle = {{MobiCom '01: Proceedings of the 7th annual international conference
	on Mobile computing and networking}},
  year = {2001},
  pages = {70--84},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We introduce a geographical adaptive fidelity (GAF) algorithm that
	reduces energy consumption in ad hoc wireless networks. GAF conserves
	energy by identifying nodes that are equivalent from a routing perspective
	and then turning off unnecessary nodes, keeping a constant level
	of routing fidelity. GAF moderates this policy using application-
	and system-level information; nodes that source or sink data remain
	on and intermediate nodes monitor and balance energy use. GAF is
	independent of the underlying ad hoc routing protocol; we simulate
	GAF over unmodified AODV and DSR. Analysis and simulation studies
	of GAF show that it can consume 40% to 60% less energy than an unmodified
	ad hoc routing protocol. Moreover, simulations of GAP suggest that
	network lifetime increases proportionally to node density; in one
	example, a four-fold increase in node density leads to network lifetime
	increase for 3 to 6 times (depending on the mobility pattern). More
	generally, GAF is an example of adaptive fidelity, a technique proposed
	for extending the lifetime of self-configuring systems by exploiting
	redundancy to conserve energy while maintaining application fidelity.},
  doi = {http://doi.acm.org/10.1145/381677.381685},
  file = {xu2001.pdf:xu2001.pdf:PDF},
  isbn = {1-58113-422-3},
  location = {Rome, Italy}
}

@MISC{xylitol2008,
  author = {Xylitol},
  title = {Cross Site Scripting - Attack and Defense Guide},
  howpublished = {[online] http://www.xssed.com/article/15/Paper\_Cross\_Site\_Scripting\_-\_Attack\_and\_Defense\_Guide},
  month = {February},
  year = {2008},
  owner = {kristjan},
  review = {A very short guide to some XSS attacks. Appears to be written from
	an attackers perspective (as may be deduced from the authors handle).
	Some of the topics discussed:
	
	
	* How to grab a cookie
	
	
	* A very light treatment on how to prevent XSS
	
	
	* Defacing websites using XSS methods
	
	
	* Bypassing filtering which is intended to prevent XSS (appears to
	be a fairly complete guide - xylitol is apparently more of an attacker
	than a defender).
	
	
	* Flash attacks using the getURL method.
	
	
	* XSS upload by embedding code in a GIF image.
	
	
	* Phishing by XSS
	
	
	
	Some code examples are provided (those thested appear to be blocked
	by recent software).},
  timestamp = {2008.04.11},
  url = {http://www.xssed.com/article/15/Paper_Cross_Site_Scripting_-_Attack_and_Defense_Guide/}
}

@INPROCEEDINGS{yalagandula2004,
  author = {Praveen Yalagandula and Mike Dahlin},
  title = {A scalable distributed information management system},
  booktitle = {{SIGCOMM} '04: Proceedings of the 2004 conference on Applications,
	technologies, architectures, and protocols for computer communications},
  year = {2004},
  pages = {379--390},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We present a Scalable Distributed Information Management System (SDIMS)
	that aggregates information about large-scale networked systems and
	that can serve as a basic building block for a broad range of large-scale
	distributed applications by providing detailed views of nearby information
	and summary views of global information. To serve as a basic building
	block, a SDIMS should have four properties: scalability to many nodes
	and attributes, flexibility to accommodate a broad range of applications,
	administrative isolation for security and availability, and robustness
	to node and network failures. We design, implement and evaluate a
	SDIMS that (1) leverages Distributed Hash Tables (DHT) to create
	scalable aggregation trees, (2) provides flexibility through a simple
	API that lets applications control propagation of reads and writes,
	(3) provides administrative isolation through simple extensions to
	current DHT algorithms, and (4) achieves robustness to node and network
	reconfigurations through lazy reaggregation, on-demand reaggregation,
	and tunable spatial replication. Through extensive simulations and
	micro-benchmark experiments, we observe that our system is an order
	of magnitude more scalable than existing approaches, achieves isolation
	properties at the cost of modestly increased read latency in comparison
	to flat DHTs, and gracefully handles failures.},
  doi = {http://doi.acm.org/10.1145/1015467.1015509},
  file = {p379-yalagandula.pdf:p379-yalagandula.pdf:PDF},
  isbn = {1-58113-862-8},
  location = {Portland, Oregon, USA}
}

@INPROCEEDINGS{yang2005a,
  author = {Yang, Hao and Ye, Fan and Yuan, Yuan and Lu, Songwu and Arbaugh,
	William},
  title = {Toward resilient security in wireless sensor networks},
  booktitle = {{MobiHoc} '05: Proceedings of the 6th {ACM} international symposium
	on Mobile ad hoc networking and computing},
  year = {2005},
  pages = {34--45},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Node compromise poses severe security threats in wireless sensor networks.
	Unfortunately, existing security designs can address only a small,
	fixed threshold number of compromised nodes; the security protection
	completely breaks down when the threshold is exceeded. In this paper,
	we seek to overcome the threshold limitation and achieve resiliency
	against an increasing number of compromised nodes. To this end, we
	propose a novel location-based approach in which the secret keys
	are bound to geographic locations, and each node stores a few keys
	based on its own location. The location-binding property constrains
	the scope for which individual keys can be (mis)used, thus limiting
	the damages caused by a collection of compromised nodes. We illustrate
	this approach through the problem of report fabrication attacks,
	in which the compromised nodes forge non-existent events. We evaluate
	our design through extensive analysis, implementation and simulations,
	and demonstrate its graceful performance degradation in the presence
	of an increasing number of compromised nodes.},
  doi = {http://doi.acm.org/10.1145/1062689.1062696},
  file = {yang2005a.pdf:yang2005a.pdf:PDF},
  isbn = {1-59593-004-3},
  keywords = {sensor network, security},
  location = {Urbana-Champaign, IL, USA}
}

@INPROCEEDINGS{yang2000,
  author = {J. Yang and P. Ning and X.S. Wang and S. Jajodia},
  title = {{CARDS}: A distributed system for detecting coordinated attacks},
  booktitle = {{SEC}},
  year = {2000},
  pages = {171--180},
  abstract = {A major research problem in intrusion detection is the efﬁcient Detection
	of
	
	coordinated attacks over large networks. Issues to be resolved include
	determin-
	
	ing what data should be collected, which portion of the data should
	be analyzed,
	
	where the analysis of the data should take place, and how to correlate
	multi-source
	
	information. This paper proposes the architecture of a Coordinated
	Attack Re-
	
	sponse & Detection System (CARDS). CARDS uses a signature-based model
	
	for resolving these issues. It consists of signature managers, monitors,
	and direc-
	
	tory services. The system collects data in a ﬂexible, distributed
	manner, and the
	
	detection process is decentralized among various monitors and is event-driven.
	
	The paper also discusses related implementation issues.},
  file = {yang2000.pdf:yang2000.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.06.26}
}

@INCOLLECTION{yang2005,
  author = {Mao Yang and Zheng Zhang and Xiaoming Li and Yafei Dai},
  title = {An Empirical Study of Free-Riding Behavior in the Maze P2P File-Sharing
	System},
  booktitle = {Peer-to-Peer Systems IV IPTPS 2005},
  publisher = {Springer Berlin / Heidelberg},
  year = {2005},
  volume = {Volume 3640/2005},
  series = {Lecture Notes in Computer Science},
  pages = {182 – 192},
  abstract = {Maze is a P2P file-sharing system with an active and large user base.
	It is developed, deployed and operated by an academic research team.
	As such, it offers ample opportunities to conduct experiments to
	under-stand user behavior. Embedded in Maze is a set of incentive
	policies designed to encourage sharing and contribution. This paper
	presents an in-depth analysis of the effectiveness of the incentive
	policies and how users react to them. We found that in general the
	policies have been effective. But they also encourage the more selfish
	users to cheat by whitewashing their ac-counts as a variation of
	Sybil attack. We examine multiple factors that may contribute to
	the free-riding behavior. Our conclusions are that upload speed,
	NAT and amount of shared files are not the problems, and selfish
	behavior is demonstrated more by shorter online time. Since free-riders
	are also avid consumers of popular files, we suggest a two-pronged
	approach to reduce free-riding further: mechanisms to direct queries
	to sources that would otherwise be free-riders, and policies to encourage
	users make their resources more available.},
  file = {yang2005.pdf:yang2005.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.03.31}
}

@INCOLLECTION{yang2010,
  author = {Yanjiang Yang and Robert H. Deng and Jianying Zhou and Ying Qiu},
  title = {Achieving Better Privacy Protection in Wireless Sensor Networks Using
	Trusted Computing},
  booktitle = {Information Security Practice and Experience},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  series = {Lecture Notes in Computer Science},
  abstract = {A wireless sensor network (WSN) is an ad-hoc wireless network composed
	of small sensor nodes deployed in large numbers. Sensor nodes are
	usually severely resource limited and power constrained. Security
	enforcement in WSNs is thus a challenging task. In this paper we
	propose a clustered heterogeneous architecture for WSNs, where high-end
	cluster heads are incorporated, and they are further equipped with
	trusted computing technology (TC). As such, the cluster heads act
	as trusted parties, and are expected to help effectively address
	privacy issues in WSNs. As concrete examples, we discuss in details
	how user query privacy and source location privacy can be better
	protected.},
  file = {yang2010.pdf:yang2010.pdf:PDF},
  keywords = {Wireless sensor network, attestation, TC, TPM, Trusted platform module},
  owner = {kristjan},
  timestamp = {2010.04.13}
}

@INPROCEEDINGS{yang2007,
  author = {Yang, Yi and Wang, Xinran and Zhu, Sencun and Cao, Guohong},
  title = {Distributed Software-based Attestation for Node Compromise Detection
	in Sensor Networks},
  booktitle = {{SRDS} '07: Proceedings of the 26th {IEEE} International Symposium
	on Reliable Distributed Systems},
  year = {2007},
  pages = {219--230},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {ensors that operate in an unattended, harsh or hostile environment
	are vulnerable to compromises because their low costs preclude the
	use of expensive tamper-resistant hardware. Thus, an adversary may
	reprogram them with malicious code to launch various insider attacks.
	Based on verifying the genuineness of the running program, we propose
	two distributed software-based attestation schemes that are well
	tailored for sensor networks. These schemes are based on a pseudorandom
	noise generation mechanism and a lightweight block-based pseudorandom
	memory traversal algorithm. Each node is loaded with pseudorandom
	noise in its empty program memory before deployment, and later on
	multiple neighbors of a suspicious node collaborate to verify the
	integrity of the code running on this node in a distributed manner.
	Our analysis and simulation show that these schemes achieve high
	detection rate even when multiple compromised neighbors collude in
	an attestation process.},
  file = {yang2007.pdf:yang2007.pdf:PDF},
  isbn = {0-7695-2995-X},
  keywords = {sensor network, security, code attestation}
}

@INPROCEEDINGS{yang2006,
  author = {Yi Yang and Xinran Wang and Sencun Zhu and Guohong Cao},
  title = {{SDAP}: A secure hop-by-Hop data aggregation protocol for sensor
	networks},
  booktitle = {{MobiHoc '06}},
  year = {2006},
  pages = {356--367},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Hop-by-hop data aggregation is a very important technique for reducing
	the communication overhead and energy expenditure of sensor nodes
	during the process of data collection in a sensor network. However,
	because individual sensor readings are lost in the per-hop aggregation
	process, compromised nodes in the network may forge false values
	as the aggregation results of other nodes, tricking the base station
	into accepting spurious aggregation results. Here a fundamental challenge
	is: how can the base station obtain a good approximation of the fusion
	result when a fraction of sensor nodes are compromised.To answer
	this challenge, we propose SDAP, a Secure Hop-by-hop Data Aggregation
	Protocol for sensor networks. The design of SDAP is based on the
	principles of divide-and-conquer and commit-and-attest. First, SDAP
	uses a novel probabilistic grouping technique to dynamically partition
	the nodes in a tree topology into multiple logical groups (subtrees)
	of similar sizes. A commitment-based hop-by-hop aggregation is performed
	in each group to generate a group aggregate. The base station then
	identifies the suspicious groups based on the set of group aggregates.
	Finally, each group under suspect participates in an attestation
	process to prove the correctness of its group aggregate. Our analysis
	and simulations show that SDAP can achieve the level of efficiency
	close to an ordinary hop-by-hop aggregation protocol while providing
	certain assurance on the trustworthiness of the aggregation result.
	Moreover, SDAP is a general-purpose secure aggregation protocol applicable
	to multiple aggregation functions.},
  doi = {http://doi.acm.org/10.1145/1132905.1132944},
  file = {yang2006.pdf:yang2006.pdf:PDF},
  isbn = {1-59593-368-9},
  keywords = {secure aggregation, sensor networks, wireless networks},
  location = {Florence, Italy},
  review = {The authors consider the problem of securing the aggregate against
	malicious nodes.
	
	
	Based on the principles of divide-and-conquer and commit-and-attest.
	The authors start from the basis of a spanning-tree network. Identify
	that the nature of the in-network aggregation (they use the term
	hop-by-hop aggregation) introduces data tampering vulnerabilities.
	Data aggregation is a lossy process from the viewpoint of information
	theory -- the individual readings are lost due to the aggregation
	process. Impossible (the authors claim) to verify the correctness
	of the readings from the standpoint of the querier. Confidence in
	final value means sacrificing the efficiency of the in-network aggregation
	-- essentially degenerating to the centralized aggregation case.
	
	
	Divide-and-conquer: The network is dynamically subdivided into several
	subtrees (non-overlapping) using a probabilistic grouping method.
	Fewer nodes under a high-level node in a logical subtree means that
	the threat is reduced as compared to a spanning tree where a bad
	high-level node can have a devastating effect .
	
	
	commit-and-attest: A group commits to its aggregate value, ensuring
	the group cannot deny it at a later time. 
	
	The BS selects suspicious groups based on an outlier detection mechanism.
	Outliers are selected for further checking -- attestation. The group
	aggregate is discarded if the group fails to support its original
	commitment under attestation. An advantage of SDAP is that outliers
	are probed and attested but not rejected out of hand as they may
	sometimes be of as much interest as "normal" values. Zero false positives.
	
	
	Network assumptions: Secure broadcast mechansim (mu-TESLA) and a trusted
	BS. individual secret keys shared between BS and individual nodes.
	Also unique pairwise key for each neighbor pair of nodes. Reference
	\cite{liu2003}, LEAP \cite{zhu2006}, \cite{zhang2005} on pairwise
	keys.
	
	
	Deal with data modification attacks which they classify as value changing
	and count changing attacks -- do not consider local data injection.
	
	
	Query phase:
	
	The BS broadcasts a packet containing the query function and a nonce.
	
	
	Aggregation:
	
	Nodes identify their parents from the query broadcast phase. Group
	leaders are selected usign a probabilistic procedure involving the
	nonce. Potential problem (?): Subtrees may be irregular, but may
	not be a problem if each is small enough. The randomized procedure
	for leader selection helps to defend against adversaries positioning
	themselves as leaders. Potential problem (?): What if an adversary
	manipulates the protocol to be a leader each time? May however be
	the leader of a very small group. 
	
	Group leader sets a flag indicating that a packet should not be aggregated
	further -- after that the packet is simply routed to the root, encrypted
	end-to-end.
	
	MAC over the aggregate is computed by intermediary aggregators --
	MACs of child contributions XORed together in the parents aggregate
	MAC. Individual nodes store their contributions for the round until
	attestation is over.
	
	Nodes maintain a forwarding path based on leader id and nonce when
	forwarding completed aggregation packets -- this is used later under
	attestation -- TODO: Can this be exploited to reroute the message
	to a malicious node?
	
	
	Verification:
	
	The verification phase starts once all aggregation messages from group
	leaders have arrived (how is this actually determined since the groups
	are dynamically constructed for each query?). The BS decrypts the
	incoming package and verifies against the known format and allowable
	data range. The BS also verifies if the leader is legitimate by recreating
	the probabilistic inequality. Invalid packets are dropped (Note:
	May constitute a DoS attack on the network, although easy to identify
	the perpetrator).
	
	Now, the BS needs to determine if the group value is legitimate w.
	respect to individual node contributions. Grubbs test used to detect
	outliers in group aggregates. Attestation requests are sent to suspicious
	groups. The attestation mechanism is tricky since the BS only knows
	the (reported) leader, not the group membership. An attestation request
	includes the nonce and a new attestation nonce. BS begins by routing
	the attestation request towards the group leader. The group leader
	forms an attestation path towards the leads using a weighted probabilistic
	procedure. Siblings included (vey much like the off-path vertices
	of CPS). Individual nodes encrypt their contributions and route toward
	the BS, which can reconstruct the computation.
	
	The authors also discuss using multiple attestation paths, each with
	different seeds. The depth-first approach described first can be
	modified -- for example using a breath first search with limited
	depth.
	
	The authors also consider individual node validation which only works
	for topologies in which neighbors should have similar measurements.
	The BS can compare readings of neighbors which are expected to have
	similar readings and reject abnormal ones.
	
	
	The authors provide a convincing discussion on security and efficiency
	of their solution.}
}

@INPROCEEDINGS{yao1982,
  author = {Yao, Andrew C.},
  title = {Protocols for secure computations},
  booktitle = {{SFCS '82: Proceedings of the 23rd Annual Symposium on Foundations
	of Computer Science}},
  year = {1982},
  pages = {160--164},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  doi = {http://dx.doi.org/10.1109/SFCS.1982.88},
  file = {yao1982.pdf:yao1982.pdf:PDF}
}

@INPROCEEDINGS{yao2003,
  author = {Yong Yao and Johannes Gehrke},
  title = {Query Processing for Sensor Networks},
  booktitle = {First Conference on Innovative Data Systems Research {CIDR}},
  year = {2003},
  address = {San Fransisco, CA},
  abstract = {Hardware for sensor nodes that combine physical sensors, actuators,
	embedded processors, and communication components has advanced signiﬁcantly
	over the last decade, and made the large-scale deployment of such
	sensors a reality. Applications range from monitoring applications
	such as inventory maintenance over health care to military applications.
	In this paper, we evaluate the design of a query layer for sensor
	networks. The query layer accepts queries in a declarative language
	that are then optimized to generate eﬃcient query execution plans
	with in-network processing which can signiﬁcantly reduce resource
	requirements. We examine the main architectural components of such
	a query layer, concentrating on in-network aggregation, interaction
	of in-network aggregation with the wireless routing protocol, and
	distributed query processing. Initial simulation experiments with
	the ns-2 network simulator show the tradeoﬀs of our system.},
  file = {yao2003.pdf:yao2003.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.10.06}
}

@ARTICLE{yao2002,
  author = {Yao, Yong and Gehrke, Johannes},
  title = {The cougar approach to in-network query processing in sensor networks},
  journal = {{SIGMOD Rec.}},
  year = {2002},
  volume = {31},
  pages = {9--18},
  number = {3},
  abstract = {The widespread distribution and availability of small-scale sensors,
	actuators, and embedded processors is transforming the physical world
	into a computing platform. One such example is a sensor network consisting
	of a large number of sensor nodes that combine physical sensing capabilities
	such as temperature, light, or seismic sensors with networking and
	computation capabilities. Applications range from environmental control,
	warehouse inventory, and health care to military environments. Existing
	sensor networks assume that the sensors are preprogrammed and send
	data to a central frontend where the data is aggregated and stored
	for offline querying and analysis. This approach has two major drawbacks.
	First, the user cannot change the behavior of the system on the fly.
	Second, conservation of battery power is a major design factor, but
	a central system cannot make use of in-network programming, which
	trades costly communication for cheap local computation.In this paper,
	we introduce the Cougar approach to tasking sensor networks through
	declarative queries. Given a user query, a query optimizer generates
	an efficient query plan for in-network query processing, which can
	vastly reduce resource usage and thus extend the lifetime of a sensor
	network. In addition, since queries are asked in a declarative language,
	the user is shielded from the physical characteristics of the network.
	We give a short overview of sensor networks, propose a natural architecture
	for a data management system for sensor networks, and describe open
	research problems in this area.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/601858.601861},
  file = {yao2002.pdf:yao2002.pdf:PDF},
  issn = {0163-5808},
  owner = {kristjan},
  publisher = {ACM}
}

@INCOLLECTION{yasuda2007,
  author = {Kan Yasuda},
  title = {{"Sandwich"} Is Indeed Secure: How to Authenticate a Message with
	Just One Hashing},
  booktitle = {Information Security and Privacy},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {4586/2007},
  series = {Lecture Notes in Computer Science},
  abstract = {This paper shows that the classical “Sandwich” method, which prepends
	and appends a key to a message and then hashes the data using Merkle-Damgård
	iteration, does indeed provide a secure Message Authentication Code
	(MAC). The Sandwich construction offers a single-key MAC which can
	use the existing Merkle-Damgård implementation of hash functions
	as is, without direct access to the compression function. Hence the
	Sandwich approach gives us an alternative for HMAC particularly in
	a situation where message size is small and high performance is required,
	because the Sandwich scheme is more efficient than HMAC: it consumes
	only two blocks of “waste” rather than three as in HMAC, and it calls
	the hash function only once, whereas HMAC requires two invocations
	of hash function. The security result of the Sandwich method is similar
	to that of HMAC; namely, we prove that the Sandwich construction
	yields a PRF(Pseudo-Random Functions)-based MAC, provided that the
	underlying compression function satisfies PRF properties. In theory,
	the security reduction of the Sandwich scheme is roughly equivalent
	to that of HMAC, but in practice the requirements on the underlying
	compression function look quite different. Also, the security of
	the Sandwich construction heavily relies on the filling and padding
	methods to the data, and we show several ways of optimizing them
	without losing a formal proof of security.},
  file = {yasuda2007.pdf:yasuda2007.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.03.15}
}

@ARTICLE{ye2005,
  author = {Fan Ye and Luo, H. and Songwu Lu and Lixia Zhang},
  title = {Statistical en-route filtering of injected false data in sensor networks},
  journal = {{IEEE} Journal on Selected Areas in Communications},
  year = {2005},
  volume = {23},
  pages = {839 - 850},
  number = {4},
  abstract = {In a large-scale sensor network individual sensors are subject to
	security compromises. A compromised node can be used to inject bogus
	sensing reports. If undetected, these bogus reports would be forwarded
	to the data collection point (i.e., the sink). Such attacks by compromised
	nodes can result in not only false alarms but also the depletion
	of the finite amount of energy in a battery powered network. In this
	paper, we present a statistical en-route filtering (SEF) mechanism
	to detect and drop false reports during the forwarding process. Assuming
	that the same event can be detected by multiple sensors, in SEF each
	of the detecting sensors generates a keyed message authentication
	code (MAC) and multiple MACs are attached to the event report. As
	the report is forwarded, each node along the way verifies the correctness
	of the MAC's probabilistically and drops those with invalid MACs.
	SEF exploits the network scale to filter out false reports through
	collective decision-making by multiple detecting nodes and collective
	false detection by multiple forwarding nodes. We have evaluated SEF's
	feasibility and performance through analysis, simulation, and implementation.
	Our results show that SEF can be implemented efficiently in sensor
	nodes as small as Mica2. It can drop up to 70% of bogus reports injected
	by a compromised node within five hops, and reduce energy consumption
	by 65% or more in many cases.},
  file = {ye2005.pdf:ye2005.pdf:PDF},
  keywords = {sensor networks, secure aggregation, statistical filtering},
  owner = {kristjan},
  review = {Considers countermeasures against false local data injection, e.g.
	by captured sensor nodes, in a flat network topology. Provides protection
	against insider attackers that inject false events into the system
	-- false positives attacks. False negatives (removal or corruption
	of events not considered).
	
	
	HInges on the assumption that multiple nodes will witness the same
	event. Multiple nodes collectively endorse an event report (some
	stimulus or event generated rather infrequently in the sensor field)
	by generating and attaching MACs. Reports with insufficient number
	of MACs are dropped. The message is forwarded over multiple hops
	towards the sink (no aggregation in transit, apparently). Forwarding
	nodes probabilistically check the attached MACs and drop false reports
	(trivial vector for availability attack??). The sink can further
	verify the report by inspecting the MACs.
	
	
	A stimulus is observed by several nodes. One is elected as center-of-stimulus
	(CoS) and serves as an aggregator for the stimulus -- produces a
	summary report on behalf of the group. The summary report (signed
	by the group) are routed over multiple hops towards the (trusted)
	sink. The en-route verification potentially saves power due to early
	dropping of illegitimate reports (but again, the weak point of trivial
	dropping of valid reports -- does this fall under the false negatives
	that the authors conveniently ignore?!).
	
	
	After CoS election, nodes randomly select a key K from their installed
	keys and generates a MAC. The MAC and the key index (i,M_i) is then
	sent to the CoS. MACs are classified according to key partitions
	-- MACs generated by keys in same partition are called a MAC category.
	The CoS randomly chooses a MAC from each category and attaches the
	(i,M_i) tuple to the report. Exactly a threshold T categories must
	be represented in a valid report. Reports with more than one MAC
	per category are considered invalid.
	
	
	An en-route node verifies that T distinct categories are represented
	and then checks if it holds one of the key indexes. The node then
	validates the corresponding MAC. The sink holds all keys and can
	validate the entire MAC set.
	
	
	NOTE: Sending multiple MACs is a weak point in resource constrained
	environment. Would a threshold signature scheme a la SecureDAV be
	a possibility here? The authors propose to use a Bloom filter and
	some adjustments of the scheme to save bandwidth.
	
	
	Reference canetti1999 on use of multiple MACs for source authentication
	in multicast.},
  timestamp = {2010.01.18}
}

@INPROCEEDINGS{ye2000,
  author = {Nong Ye},
  title = {A Markov Chain Model of Temporal Behaviour for Anomaly Detection},
  booktitle = {{IEEE} Workshop on Information Assurance and Security},
  year = {2000},
  address = {United States Military Academy, West Point, NY},
  month = {6-7 June},
  file = {WA1_1.pdf:WA1_1.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.03.03}
}

@INPROCEEDINGS{yedidia2000,
  author = {Jonathan Yedidia and William T. Freeman and Yair Weiss},
  title = {Generalized Belief Propagation},
  booktitle = {In NIPS 13},
  year = {2000},
  pages = {689--695},
  publisher = {MIT Press},
  abstract = {Belief propagation (BP) was only supposed to work for tree-like networks
	but works surprisingly well in many applications involving networks
	with loops, including turbo codes. However, there has been little
	understanding of the algorithm or the nature of the solutions it
	nds for general graphs. We show that BP can only converge to a stationary
	point of an approximate free energy, known as the Bethe free energy
	in statistical physics. This result characterizes BP xed-points and
	makes connections with variational approaches to approximate inference.
	More importantly, our analysis lets us build on the progress made
	in statistical physics since Bethe's approximation was introduced
	in 1935. Kikuchi and others have shown how to construct more accurate
	free energy approximations, of which Bethe's approximation is the
	simplest. Exploiting the insights from our analysis, we derive generalized
	belief propagation (GBP) versions of these Kikuchi approximations.
	These new message passing algorithms can be signi cantly more accurate
	than ordinary BP, at an adjustable increase in complexity. We illustrate
	such a new GBP algorithm on a grid Markov network and show that it
	gives much more accurate marginal probabilities than those found
	using ordinary BP.},
  file = {yedidia2000.pdf:yedidia2000.pdf:PDF}
}

@TECHREPORT{yedidia2002,
  author = {Jonathan S. Yedidia and William T. Freeman and Yair Weiss},
  title = {Understanding Belief Propagation and its Generalizations},
  institution = {Mitsubishi Electric Research Laboratories},
  year = {2002},
  number = {TR-2001-22},
  month = {January},
  abstract = {“Inference” problems arise in statistical physics, computer vision,
	error-correcting coding theory, and AI. We explain the principles
	behind the belief propagation (BP) algorithm, which is an efﬁcient
	way to solve inference problems based on passing local messages.
	We develop a uniﬁed approach, with examples, notation, and graphical
	models borrowed from the relevant disciplines.
	
	 We explain the close connection between the BP algorithm and the
	Bethe approximation of statistical physics. In particular, we show
	that BP can only converge to a ﬁxed point that is also a stationary
	point of the Bethe approximation to the free energy. This result
	helps expain the successes of the BP algorithm, and enables connections
	to be made with variational approaches to approximate inference.
	
	 The connection of BP with the Bethe approximation also suggests a
	way to construct new message passing algorithms based on improvements
	to Bethe’s approximation introduced by Kikuchi and others. The new
	generalized belief propagation (GBP) algorithms are signiﬁcantly
	more accurate than ordinary BP for some problems. We illustrate how
	to construct GBP algorithms with a detailed example.},
  file = {yedidia2002.pdf:yedidia2002.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.05.12}
}

@TECHREPORT{yedidia2001b,
  author = {Jonathan S. Yedidia and William T. Freeman and Yair Weiss},
  title = {Characterization of belief propagation and its generalizations},
  institution = {Mitsubishi Electric Research Laboratories},
  year = {2001},
  number = {TR2001-15},
  month = {March},
  abstract = {Graphical models are used in many scientiﬁc disciplines, including
	statistical physics, machine learning, and error-correcting coding.
	One typically seeks the marginal probability of selected variables
	(nodes of the graph) given observations at other variables. Belief
	propagation (BP) is a fast marginalization method, based on passing
	local messages. Designed for singly-connected graphs, BP nonetheless
	works well in many applications involving graphs with loops, for
	reasons that were not well understood. We characterize the BP solutions,
	showing that BP can only converge to a stationary point of an approximate
	free energy, known as the Bethe free energy in statistical physics.
	This understanding lets us for construct new message-passing algorithms
	based on improvements to Bethe´ approximation introduced by Kikuchi
	and others. The new generalized belief propagation (GBP) algorithms
	are much more accurate than ordinary BP for some problems, and permit
	solutions to Kikuchi approximations for otherwise intractable inhomogeneous
	systems. We illustrate GBP with a spin-glass example and an error-correcting
	code, showing dramatically improved estimates of local magnetizations
	and decoding performance using GBP.},
  file = {yedidia2001b.pdf:yedidia2001b.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.05.27}
}

@ARTICLE{yee2007,
  author = {Yee, Chan Gaik and Shin, Wong Hui and Rao, G.S.V.R.K.},
  title = {An Adaptive Intrusion Detection and Prevention (ID/IP) Framework
	for Web Services},
  journal = {Convergence Information Technology, 2007. International Conference
	on},
  year = {2007},
  pages = {528-534},
  month = {21-23 November},
  doi = {10.1109/ICCIT.2007.4420313},
  file = {04420313.pdf:04420313.pdf:PDF}
}

@INPROCEEDINGS{yegneswaran2004,
  author = {Vinod Yegneswaran and Paul Barford and Somesh Jha},
  title = {Global Intrusion Detection in the {DOMINO} Overlay System},
  booktitle = {{11th Annual Network and Distributed System Security Symposium (NDSS)}},
  year = {2004},
  month = {February},
  abstract = {Sharing data between widely distributed intrusion detection systems
	offers the possibility of signiﬁcant improvements in speed and accuracy
	over isolated systems. In this paper, we describe and evaluate DOMINO
	(Distributed Overlay for Monitoring InterNet Outbreaks); an architecture
	for a distributed intrusion detection system that fosters collaboration
	among heterogeneous nodes organized as an overlay network. The overlay
	design enables DOMINO to be heterogeneous, scalable, and robust to
	attacks and failures. An important component of DOMINO’s design is
	the use of active-sink nodes which respond to and measure connections
	to unused IP addresses. This enables efﬁcient detection of attacks
	from spoofed IP sources, reduces false positives, enables attack
	classiﬁcation and production of timely blacklists.
	
	 We evaluate the capabilities and performance of DOMINO using a large
	set of intrusion logs collected from over 1600 providers across the
	Internet. Our analysis demonstrates the signiﬁcant marginal beneﬁt
	obtained from
	
	distributed intrusion data sources coordinated through a system like
	DOMINO. We also evaluate how to conﬁgure DOMINO in order to maximize
	performance gains from the perspectives of blacklist length, blacklist
	freshness and IP proximity. We perform a retrospective analysis on
	the 2002 SQL-Snake and 2003 SQL-Slammer epidemics that highlights
	how information exchange through DOMINO would have reduced the reaction
	time and false-alarm rates during outbreaks. Finally, we provide
	preliminary results from our prototype active-sink deployment that
	illustrates the limited variability in the sink trafﬁc and the feasibility
	of efﬁcient classiﬁcation and discrimination of attack types.},
  file = {yegneswaran2004.pdf:yegneswaran2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ARTICLE{yick2008,
  author = {Jennifer Yick and Biswanath Mukherjee and Dipak Ghosal},
  title = {Wireless sensor network survey},
  journal = {Computer Networks},
  year = {2008},
  volume = {52},
  pages = {2292 - 2330},
  number = {12},
  abstract = {A wireless sensor network (WSN) has important applications such as
	remote environmental monitoring and target tracking. This has been
	enabled by the availability, particularly in recent years, of sensors
	that are smaller, cheaper, and intelligent. These sensors are equipped
	with wireless interfaces with which they can communicate with one
	another to form a network. The design of a WSN depends significantly
	on the application, and it must consider factors such as the environment,
	the application’s design objectives, cost, hardware, and system constraints.
	The goal of our survey is to present a comprehensive review of the
	recent literature since the publication of [I.F. Akyildiz, W. Su,
	Y. Sankarasubramaniam, E. Cayirci, A survey on sensor networks, IEEE
	Communications Magazine, 2002]. Following a top-down approach, we
	give an overview of several new applications and then review the
	literature on various aspects of WSNs. We classify the problems into
	three different categories: (1) internal platform and underlying
	operating system, (2) communication protocol stack, and (3) network
	services, provisioning, and deployment. We review the major development
	in these three categories and outline new challenges.},
  doi = {DOI: 10.1016/j.comnet.2008.04.002},
  issn = {1389-1286},
  keywords = {Wireless sensor network, survey},
  review = {Pretty good survey on sensor networks.},
  url = {http://www.sciencedirect.com/science/article/B6VRG-4S8TBBT-1/2/b242d2fd1f6d2cf5c6fce0a24c4cb029}
}

@ARTICLE{yook2001,
  author = {S. H. Yook and H. Jeong and A.-L. Barab\'{a}si},
  title = {Weighted Evolving Networks},
  journal = {{Physical Review Letters}},
  year = {2001},
  volume = {86},
  number = {25},
  month = {June},
  abstract = {Many biological, ecological, and economic systems are best described
	by weighted networks, as the nodes interact with each other with
	varying strength. However, most evolving network models studied so
	far are binary, the link strength being either 0 or 1. In this paper
	we introduce and investigate the scaling properties of a class of
	models which assign weights to the links as the network evolves.
	The combined numerical and analytical approach indicates that asymptotically
	the total weight distribution converges to the scaling behavior of
	the connectivity distribution, but this convergence is hampered by
	strong logarithmic corrections.},
  file = {yook2001.pdf:yook2001.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@ARTICLE{younis2004,
  author = {Ossama Younis and Sonia Fahmy},
  title = {Distributed Clustering in Ad-hoc Sensor Networks: A Hybrid, Energy-Efficient
	Approach},
  journal = {{IEEE} Trans. Mobile Comput.},
  year = {2004},
  volume = {3},
  pages = {366-379},
  number = {4},
  abstract = {Prolonged network lifetime, scalability, and load balancing are important
	requirements for many ad-hoc sensor network applications. Clustering
	sensor nodes is an effective technique for achieving these goals.
	In this work, we propose a new energy-efficient approach for clustering
	nodes in adhoc sensor networks. Based on this approach, we present
	a protocol, HEED (Hybrid Energy-Efficient Distributed clustering),
	that periodically selects cluster heads according to a hybrid of
	their residual energy and a secondary parameter, such as node proximity
	to its neighbors or node degree. HEED does not make any assumptions
	about the distribution or density of nodes, or about node capabilities,
	e.g., location-awareness. The clustering process terminates in O(1)
	iterations, and does not depend on the network topology or size.
	The protocol incurs low overhead in terms of processing cycles and
	messages exchanged. It also achieves fairly uniform cluster head
	distribution across the network. A careful selection of the secondary
	clustering parameter can balance load among cluster heads. Our simulation
	results demonstrate that HEED outperforms weight-based clustering
	protocols in terms of several cluster characteristics. We also apply
	our approach to a simple application to demonstrate its effectiveness
	in prolonging the network lifetime and supporting data aggregation.},
  file = {conference paper:younis2004-infocom.pdf:PDF;younis2004.pdf:younis2004.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.05.12}
}

@INPROCEEDINGS{yu2007,
  author = {Dachuan Yu and Ajay Chander and Nayeem Islam and Igor Serikov},
  title = {JavaScript instrumentation for browser security},
  booktitle = {POPL '07: Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium
	on Principles of programming languages},
  year = {2007},
  pages = {237--249},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {It is well recognized that JavaScript can be exploited to launch browser-based
	security attacks. We propose to battle such attacks using program
	instrumentation. Untrusted JavaScript code goes through a rewriting
	process which identiﬁes relevant operations, modiﬁes questionable
	behaviors, and prompts the user (a web page viewer) for decisions
	on how to proceed when appropriate. Our solution is parametric with
	respect to the security policy—the policy is implemented separately
	from the rewriting, and the same rewriting process is carried out
	regardless of which policy is in use. Besides providing a rigorous
	account of the correctness of our solution, we also discuss practical
	issues including policy management and prototype experiments. A useful
	by-product of our work is an operational semantics of a core subset
	of JavaScript, where code embedded in (HTML) documents may generate
	further document pieces (with new code embedded) at runtime, yielding
	a form of self-modifying code.},
  doi = {http://doi.acm.org/10.1145/1190216.1190252},
  file = {p237-yu.pdf:p237-yu.pdf:PDF},
  isbn = {1-59593-575-4},
  location = {Nice, France}
}

@INPROCEEDINGS{yu2009b,
  author = {Haifeng Yu},
  title = {Secure and highly-available aggregation queries in large-scale sensor
	networks via set sampling},
  booktitle = {{IPSN '09}: Proceedings of the 2009 International Conference on Information
	Processing in Sensor Networks},
  year = {2009},
  pages = {1--12},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[kristjan]},
  abstract = {Wireless sensor networks are often queried for aggregates such as
	predicate count, sum, and average. In untrusted environments, sensors
	may potentially be compromised. Existing approaches for securely
	answering aggregation queries in untrusted sensor networks can detect
	whether the aggregation result is corrupted by an attacker. However,
	the attacker (controlling the compromised sensors) can keep corrupting
	the result, rendering the system unavailable. This paper aims to
	enable aggregation queries to tolerate instead of just detecting
	the adversary. To this end, we propose a novel tree sampling algorithm
	that directly uses sampling to answer aggregation queries. It leverages
	a novel set sampling technique to overcome a key and well-known obstacle
	in sampling — traditional sampling technique is only effective when
	the predicate count or sum is large. Set sampling can efficiently
	sample a set of sensors together, and determine whether any sensor
	in the set satisfies the predicate (but not how many). With set sampling
	as a building block, tree sampling can provably generate a correct
	answer despite adversarial interference, while without the drawbacks
	of traditional sampling techniques.},
  file = {yu2009b.pdf:yu2009b.pdf:PDF},
  isbn = {978-1-4244-5108-1},
  keywords = {set sampling, sensor network,},
  owner = {kristjan},
  review = {The paper presents a tree-sampling (derived from set-sampling) technique
	to tolerate, rather than detect an adversary. Gives an (epsilon,delta)
	approximation of the aggregate -- within (1+epsilon) multiplicative
	factor and correct with a probability at least 1-delta.
	
	
	The auther acknowledges the usual suspects in the prior secure aggregation
	results -- CPS etc. Notes that they generally make strong restrictive
	assumptions on the network. In particular, notes that the CPS (which
	gives provable guarantees on correctness of the aggregate) cannot
	tolerate malicious users, rather only detect. A single malicious
	user can keep on corrupting the aggregate. Notes similar limitations
	with roy2006 and nath2009 (SECOA).
	
	
	A binary tree is used for the sampling -- the tree is a local data
	structure maintained by the base station -- no relation to the underlying
	graph. Tree reduces linear communications overhead to logarithmic.
	
	
	See node on multi-hop jamming.
	
	
	Comparison of in-network aggregation and set sampling: Each sample
	only involves a single sensor reading and easy to secure, e.g. by
	a MAC.
	
	
	Communications complexity of tree sampling comparable to Roy2006 (detection
	only protocol) and to the protocol of Garofalakis.
	
	
	Supports predicate count and generalizes to sum and average. Assume
	inputs are integers [1.m] -- truncated inputs.
	
	
	Root distributes sample predicates -- nodes holding a key K respond
	by flooding towards the root.
	
	
	Each node holds log n keys -- see discussion on the sampling tree.
	Base station broadcasts (authenticated) <predicate, N, H(MAC(K,N))>
	-- nodes check if they hold K by hashing a MAC of the nonce N. Interesting
	way of concealing the key, All nodes know H(MAC(K,N)) without being
	able to recreate MAC(K,N) without the key. Nodes holding K and satisfying
	the predicate reply by local broadcasting. A honsest sensor receivign
	the broadcast forwards if it holds H(MAC(K,N)) in memory and then
	erases the fingerprint. This prevents multi-hop flooding attacks.}
}

@INPROCEEDINGS{yu2007b,
  author = {Yu, Haifeng},
  title = {{DoS}-resilient secure aggregation queries in sensor networks},
  booktitle = {{PODC} '07: Proceedings of the twenty-sixth annual {ACM} symposium
	on Principles of distributed computing},
  year = {2007},
  pages = {394--395},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[kristjan]},
  doi = {http://doi.acm.org/10.1145/1281100.1281190},
  file = {yu2007b.pdf:yu2007b.pdf:PDF},
  isbn = {978-1-59593-616-5},
  location = {Portland, Oregon, USA},
  review = {A two page paper -- brief announcement. This is the Yu of SybilLimit/SybilGuard
	so probably worth reading.}
}

@INPROCEEDINGS{yu2008,
  author = {Haifeng Yu and P.B. Gibbons and M. Kaminsky and Feng Xiao},
  title = {{SybilLimit}: A Near-Optimal Social Network Defense against Sybil
	Attacks},
  booktitle = {{IEEE Symposium on Security and Privacy}},
  year = {2008},
  pages = {3-17},
  month = {May},
  abstract = {Decentralized distributed systems such as peer-to-peer systems are
	particularly vulnerable to sybil attacks, where a malicious user
	pretends to have multiple identities (called sybil nodes). Without
	a trusted central authority, defending against sybil attacks is quite
	challenging. Among the small number of decentralized approaches,
	our recent SybilGuard protocol [H. Yu et al., 2006] leverages a key
	insight on social networks to bound the number of sybil nodes accepted.
	Although its direction is promising, SybilGuard can allow a large
	number of sybil nodes to be accepted. Furthermore, SybilGuard assumes
	that social networks are fast mixing, which has never been confirmed
	in the real world. This paper presents the novel SybilLimit protocol
	that leverages the same insight as SybilGuard but offers dramatically
	improved and near-optimal guarantees. The number of sybil nodes accepted
	is reduced by a factor of ominus(radicn), or around 200 times in
	our experiments for a million-node system. We further prove that
	SybilLimit's guarantee is at most a log n factor away from optimal,
	when considering approaches based on fast-mixing social networks.
	Finally, based on three large-scale real-world social networks, we
	provide the first evidence that real-world social networks are indeed
	fast mixing. This validates the fundamental assumption behind SybilLimit's
	and SybilGuard's approach.},
  doi = {10.1109/SP.2008.13},
  file = {yu2008.pdf:yu2008.pdf:PDF},
  issn = {1081-6011},
  keywords = {distributed processing, peer-to-peer computing, protocols, security
	of dataSybilGuard protocol, SybilLimit protocol, decentralized distributed
	system, fast mixing social network, malicious user, million-node
	system, multiple identity, near-optimal social network defense, peer-to-peer
	system, sybil attack, sybil nodes},
  owner = {kristjan},
  timestamp = {2009.03.20}
}

@ARTICLE{yu2008a,
  author = {Haifeng Yu and Michael Kaminsky and Phillip B. Gibbons and Abraham
	D. Flaxman},
  title = {{SybilGuard}: defending against sybil attacks via social networks},
  journal = {{IEEE/ACM Trans. Netw.}},
  year = {2008},
  volume = {16},
  pages = {576--589},
  number = {3},
  abstract = {Peer-to-peer and other decentralized, distributed systems are known
	to be particularly vulnerable to sybil attacks. In a sybil attack,
	a malicious user obtains multiple fake identities and pretends to
	be multiple, distinct nodes in the system. By controlling a large
	fraction of the nodes in the system, the malicious user is able to
	"out vote" the honest users in collaborative tasks such as Byzantine
	failure defenses. This paper presents SybilGuard, a novel protocol
	for limiting the corruptive influences of sybil attacks. Our protocol
	is based on the "social network" among user identities, where an
	edge between two identities indicates a human-established trust relationship.
	Malicious users can create many identities but few trust relationships.
	Thus, there is a disproportionately small "cut" in the graph between
	the sybil nodes and the honest nodes. SybilGuard exploits this property
	to bound the number of identities a malicious user can create. We
	show the effectiveness of SybilGuard both analytically and experimentally.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TNET.2008.923723},
  file = {yu2008a.pdf:yu2008a.pdf:PDF},
  issn = {1063-6692},
  publisher = {IEEE Press}
}

@INPROCEEDINGS{yu2009a,
  author = {Jie Yu and Chengfang Fang and Liming Lu and Zhoujun Li},
  title = {A Lightweight Mechanism to Mitigate Application Layer {{DDoS}} Attacks},
  booktitle = {{ICST INFOSCALE'09}},
  year = {2009},
  abstract = {Application layer DDoS attacks, to which network layer solutions is
	not applicable as attackers are indistinguishable based on packets
	or protocols, prevent legitimate users from accessing services. In
	this paper, we propose Trust Management Helmet (TMH ) as a partial
	solution to this problem, which is a lightweight mitigation mechanism
	that uses trust to diﬀerentiate legitimate users and attackers. Its
	key insight is that a server should give priority to protecting the
	connectivity of good users during application layer DDoS attacks,
	instead of identifying all the attack requests. The trust to clients
	is evaluated based on their visiting history, and used to schedule
	the service to their requests. We introduce license, for user identiﬁcation
	(even beyond NATs) and storing the trust information at clients.
	The license is cryptographically secured against forgery or replay
	attacks. We realize this mitigation mechanism and implement it as
	a Java package and use it for simulation. Through simulation, we
	show that TMH is eﬀective in mitigating session ﬂooding attack: even
	with 20 times number of attackers, more than 99% of the sessions
	from legitimate users are accepted with TMH ; whereas less than 18%
	are accepted without it.},
  file = {yu2009a.pdf:yu2009a.pdf:PDF},
  keywords = {networks, security, ddos mitigation},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@INPROCEEDINGS{yu2007a,
  author = {Jie Yu and Zhoujun Li and Huowang Chen and Xiaoming Chen},
  title = {A Detection and Offense Mechanism to Defend Against Application Layer
	{DDoS} Attacks},
  booktitle = {{ICNS'07}},
  year = {2007},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@INPROCEEDINGS{yu2008b,
  author = {Jie Yu and Zhoujun Li and Xiaoming Chen},
  title = {Misusing Kad protocol to perform {DDoS} attacks},
  booktitle = {{IEEE ISPA'08}},
  year = {2008},
  abstract = {Kademlia-based DHT has been deployed in many P2P applications and
	it is reported that there are millions of simultaneous users in Kad
	network. For such a protocol that significantly involves so many
	peers, its robustness and security must be evaluated carefully. In
	this paper, we analyze the Kademlia protocol and identify several
	potential vulnerabilities. We classify potential attacks as three
	types: asymmetric attack, routing table reflection attack and index
	reflection attack. A limited real-world experiment was run on eMule
	and the results show that these attacks tie up bandwidth and TCP
	connection resources of victim. We analyze the results of our experiment
	in three aspects: the effect of DDoS attacks by misusing Kad in eMule,
	the comparison between asymmetric attack and routing table reflection
	attack, and the distribution of attacks. More large-scale DDoS attack
	can be performed by means of a little more effort. We introduce some
	methods to amplify the performance of attack and some strategies
	to evade detection. Finally, we further discuss several solutions
	for these DDoS attacks.},
  file = {yu2008b.pdf:yu2008b.pdf:PDF},
  keywords = {networks, security, protocols, Kademlia, peer-to-peer systems},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@INPROCEEDINGS{yu2009,
  author = {Jie Yu and Liming Lu and Zhoujun Li},
  title = {{KadCache: Employing Kad to Mitigate Flash Crowds and Application
	Layer DDoS Attacks against Web Servers}},
  booktitle = {{ACM SIGCOMM'09 Poster Session}},
  year = {2009},
  abstract = {Flash crowds or application layer DDoS attacks can severely degrade
	the availability of websites. Peer-to-peer (P2P) networks have been
	exploited to amplify DDoS attacks, but we believe their available
	resource, such as distributed storage and network bandwidth, can
	be used to mitigate both ﬂash crowds and DDoS attacks. In this poster,
	we propose a server initiated approach to employing the P2P network
	as a distributed web cache, so that the workload directed to web
	servers can be reduced. The experiment using Kad demonstrates the
	feasibility and robustness of our approach. The latency is comparable
	to normal direct access to web servers, and the web contents cached
	in Kad remain reachable despite of the dynamic departure of peers.},
  file = {yu2009.pdf:yu2009.pdf:PDF},
  keywords = {networks, security, ddos, flash crowd},
  owner = {kristjan},
  timestamp = {2009.08.17}
}

@ARTICLE{yuyu2008,
  author = {Yu Yu and Jussipekka Leiwo and Benjamin Premkumar},
  title = {A Study on the Security of Privacy Homomorphism},
  journal = {International Journal of Network Security},
  year = {2008},
  volume = {6},
  pages = {470-475},
  number = {1},
  month = {Jan.},
  __markedentry = {[kristjan]},
  abstract = {Informally, Privacy Homomorphism (PH) refers to encryption schemes
	with a homomorphic property allowing to obtain Ek (a + b) or Ek (a
	× b) from ciphertexts Ek (a) and Ek (b) without the knowledge of
	the decryption key. Privacy homomorphisms, especially algebraic ones,
	have a wide range of applications in information security due to
	the homomorphic property. In this paper, we correct a misunderstanding
	regarding the security of additive PH, give a deﬁnition for eﬃcient
	PH, and discuss the security of algebraic PH in the black-box model
	to show that any PH is at most semantically secure under non-adaptive
	chosen-ciphertext attacks (i.e. IND-CCA1 secure), which also implies
	that we can simulate an IND-CCA1 secure algebraic PH with a small
	amount of hardware.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ITNG.2006.19},
  file = {yuyu2008.pdf:yuyu2008.pdf:PDF},
  isbn = {0-7695-2497-4},
  keywords = {cryptography, privacy homomorphism, cryptanalysis},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{yuval1997,
  author = {Yuval, Gideon},
  title = {Reinventing the Travois: Encryption/{MAC} in 30 {ROM} Bytes},
  booktitle = {FSE '97: Proceedings of the 4th International Workshop on Fast Software
	Encryption},
  year = {1997},
  pages = {205--209},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {By using a large number of round, we hope to be able to scrounge an
	Sbox out of nowhere, in an environment for which even TEA and the
	SAFERs are gross overdesign.},
  file = {yuval1997.pdf:yuval1997.pdf:PDF},
  isbn = {3-540-63247-6},
  review = {See for later on work regarding crypto on small devices.}
}

@MISC{zaninotti-2007,
  author = {Thiago Zaninotti and Amit Klein},
  title = {Apache HTTPd "Expect" Header Handling Client-Side Cross Site Scripting
	Vulnerability},
  month = {July},
  year = {2006},
  owner = {kristjan},
  timestamp = {2008.11.14},
  url = {http://www.frsirt.com/english/advisories/2006/2963}
}

@INPROCEEDINGS{zegura1996,
  author = {Zegura, Ellen W. and Calvert, Kenneth L. and Bhattacharjee, Samrat},
  title = {How to model an internetwork},
  booktitle = {{IEEE INFOCOM}},
  year = {1996},
  abstract = {Graphs are commonly used to model the structure of internetworks,
	for the study of problems ranging from routing to resource reservation.
	A variety of graph models are found in the literature, including
	regular topologies such as rings or stars, \well-known" topologies
	such as the original ARPAnet, and randomly generated topologies.
	Less common is any discussion of how closely these models correlate
	with real network topologies. We consider the problem of efficiently
	generating graph models that accurately reflect the topological properties
	of real internetworks. We compare properties of graphs generated
	using various methods with those of real internets. We also propose
	efficient methods for generating topologies with particular properties,
	including a Transit-Stub model that correlates well with Internet
	structure. Improved models for internetwork structure have the potential
	to impact the signi cance of simulation studies of internetworking
	solutions, providing basis for the validity of the conclusions.},
  file = {zegura1996.pdf:zegura1996.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@ARTICLE{zhang2008a,
  author = {Zhang, Qing and Yu, Ting and Ning, Peng},
  title = {A Framework for Identifying Compromised Nodes in Wireless Sensor
	Networks},
  journal = {{ACM Trans. Inf. Syst. Secur.}},
  year = {2008},
  volume = {11},
  pages = {1--37},
  number = {3},
  abstract = {Sensor networks are often subject to physical attacks. Once a node's
	cryptographic key is compromised, an attacker may completely impersonate
	it and introduce arbitrary false information into the network. Basic
	cryptographic mechanisms are often not effective in this situation.
	Most techniques to address this problem focus on detecting and tolerating
	false information introduced by compromised nodes. They cannot pinpoint
	exactly where the false information is introduced and who is responsible
	for it.
	
	
	In this article, we propose an application-independent framework for
	accurately identifying compromised sensor nodes. The framework provides
	an appropriate abstraction of application-specific detection mechanisms
	and models the unique properties of sensor networks. Based on the
	framework, we develop alert reasoning algorithms to identify compromised
	nodes. The algorithm assumes that compromised nodes may collude at
	will. We show that our algorithm is optimal in the sense that it
	identifies the largest number of compromised nodes without introducing
	false positives. We evaluate the effectiveness of the designed algorithm
	through comprehensive experiments.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1341731.1341733},
  file = {zhang2008a.pdf:zhang2008a.pdf:PDF},
  issn = {1094-9224},
  keywords = {sensor networks, intrusion detection},
  publisher = {ACM},
  review = {Sensor network intrusion detection and identification of compromised
	nodes. Two appraches -- 1) detect/tolerate malicious behavior (CPS
	and others) and 2) application specific alerting based on mutually
	observable phenomena. Authors provide a generic framework for the
	latter -- not clear how extensive the contribution is beyond that.}
}

@INPROCEEDINGS{zhang2005a,
  author = {Wensheng Zhang and Guohong Cao},
  title = {Group rekeying for filtering false data in sensor networks: a predistribution
	and local collaboration-based approach},
  booktitle = {{INFOCOM} 2005. 24th Annual Joint Conference of the {IEEE} Computer
	and Communications Societies. Proceedings {IEEE}},
  year = {2005},
  volume = {1},
  pages = { 503-514 vol. 1},
  month = {March},
  abstract = {When a sensor network is deployed in hostile environments, the adversary
	may compromise some sensor nodes, and use the compromised nodes to
	inject false sensing reports or modify the reports sent by other
	nodes. In order to defend against the attacks with low cost, researchers
	have proposed symmetric group key-based en-route filtering schemes,
	such as SEF [F. Ye et al., March 2004] and I-LHAP [S. Zhu et al.,
	2004]. However, if the adversary has compromised a large number of
	nodes, many group keys can be captured, and the filtering schemes
	may become ineffective or even useless. To deal with node compromise,
	the compromised nodes should be identified and the innocent nodes
	should update their group keys. Some existing intruder identification
	schemes can be used to identify the compromised nodes, but most existing
	group rekeying schemes are not suitable for sensor networks since
	they have large overhead and are not scalable. To address the problem,
	we propose a family of predistribution and local collaboration-based
	group rekeying (PCGR) schemes. These schemes are designed based on
	the ideas that future group keys can be preloaded to the sensor nodes
	before deployment, and neighbors can collaborate to protect and appropriately
	use the preloaded keys. Extensive analyses and simulations are conducted
	to evaluate the proposed schemes, and the results show that the proposed
	schemes can achieve a good level of security, outperform most previous
	group rekeying schemes, and significantly improve the effectiveness
	of filtering false data.},
  doi = {10.1109/INFCOM.2005.1497918},
  file = {zhang2005a.pdf:zhang2005a.pdf:PDF},
  issn = {0743-166X },
  keywords = { data communication, filtering theory, telecommunication networks,
	telecommunication security, wireless sensor networks compromised
	node, false data filtering, intruder identification scheme, key-based
	en-route filtering scheme, local collaboration-based approach, network
	security, predistribution and local collaboration-based group rekeying
	scheme, sensor network}
}

@INPROCEEDINGS{zhang2006,
  author = {Wei Zhang and Das, S.K. and Yonghe Liu},
  title = {A Trust Based Framework for Secure Data Aggregation in Wireless Sensor
	Networks},
  booktitle = {{SECON '06}: 3rd Annual IEEE Communications Society Conference on
	Sensor and Ad Hoc Communications and Networks},
  year = {2006},
  pages = {60--69},
  abstract = {In unattended and hostile environments, node compromise can become
	a disastrous threat to wireless sensor networks and introduce uncertainty
	in the aggregation results. A compromised node often tends to completely
	reveal its secrets to the adversary which in turn renders purely
	cryptography-based approaches vulnerable. How to secure the information
	aggregation process against compromised-node attacks and quantify
	the uncertainty existing in the aggregation results has become an
	important research issue. In this paper, we address this problem
	by proposing a trust based framework, which is rooted in sound statistics
	and some other distinct and yet closely coupled techniques. The trustworthiness
	(reputation) of each individual sensor node is evaluated by using
	an information theoretic concept, Kullback-Leibler (KL) distance,
	to identify the compromised nodes through an unsupervised learning
	algorithm. Upon aggregating, an opinion, a metric of the degree of
	belief, is generated to represent the uncertainty in the aggregation
	result. As the result is being disseminated and assembled through
	the routes to the sink, this opinion will be propagated and regulated
	by Josang's belief model. Following this model, the uncertainty within
	the data and aggregation results can be effectively quantified throughout
	the network. Simulation results demonstrate that our trust based
	framework provides a powerful mechanism for detecting compromised
	nodes and reasoning about the uncertainty in the network. It further
	can purge false data to accomplish robust aggregation in the presence
	of multiple compromised nodes},
  file = {zhang2006.pdf:zhang2006.pdf:PDF},
  keywords = {sensor network, trust establishment, secure data aggregation},
  owner = {kristjan},
  review = {Uses subjective logic. Discussed by Sorniotti.},
  timestamp = {2010.01.17}
}

@ARTICLE{zhang2008,
  author = {Wei Zhang and Yonghe Liu and Sajal K. Das and Pradip De},
  title = {Secure data aggregation in wireless sensor networks: A watermark
	based authentication supportive approach},
  journal = {Pervasive and Mobile Computing},
  year = {2008},
  volume = {4},
  pages = {658 - 680},
  number = {5},
  abstract = {In-network processing presents a critical challenge for data authentication
	in wireless sensor networks (WSNs). Current schemes relying on Message
	Authentication Code (MAC) cannot provide natural support for this
	operation since even a slight modification to the data invalidates
	the MAC. Although some recent works propose using privacy homomorphism
	to support in-network processing, they can only work for some specific
	query-based aggregation functions, e.g. SUM, average, etc. In this
	paper, based on digital watermarking, we propose an end-to-end, statistical
	approach for data authentication that provides inherent support for
	in-network processing. In this scheme, authentication information
	is modulated as watermark and superposed on the sensory data at the
	sensor nodes. The watermarked data can be aggregated by the intermediate
	nodes without incurring any en route checking. Upon reception of
	the sensory data, the data sink is able to authenticate the data
	by validating the watermark, thereby detecting whether the data has
	been illegitimately altered. In this way, the aggregation–survivable
	authentication information is only added at the sources and checked
	by the data sink, without any involvement of intermediate nodes.
	Furthermore, the simple operation of watermark embedding and complex
	operation of watermark detection provide a natural solution of function
	partitioning between the resource limited sensor nodes and the resource
	abundant data sink. In addition, the watermark can be embedded in
	both spatial and temporal domains to provide the flexibility between
	the detection time and detection granularity. The simulation results
	show that the proposed scheme can successfully authenticate the sensory
	data with high confidence.},
  doi = {DOI: 10.1016/j.pmcj.2008.05.005},
  file = {zhang2008.pdf:zhang2008.pdf:PDF},
  issn = {1574-1192},
  keywords = {Wireless sensor networks; Data aggregation; Authentication; Watermarking},
  review = {The authors propose to secure distribtued aggregation against malicious
	aggregators by imposing a digital watermark on measurement results
	and using statistical methods on the querying platform to verify
	the existince of the watermark and that it has not been tampered
	with. The watermark is unique to each measurement node and known
	to it and the trusted querier (e.g. a root node). Watermarking a
	measurement at a sensing node is a low cost operation but the statistical
	processing needed to verify the existence of the watermark a relatively
	expensive operation. The authors assume that this is justified --
	that the querier has sufficient resources available to run such an
	operation. 
	
	
	Sounds like a decent idea and certainly minimizes messaging -- the
	bare minimum of one message per leg is needed for each aggregation
	round.},
  url = {http://www.sciencedirect.com/science/article/B7MF1-4SKB3MD-1/2/b73948dcaa3eb63a2c21d09041882625}
}

@INPROCEEDINGS{zhang2005,
  author = {Zhang, Wensheng and Song, Hui and Zhu, Sencun and Cao, Guohong},
  title = {Least privilege and privilege deprivation: towards tolerating mobile
	sink compromises in wireless sensor networks},
  booktitle = {{MobiHoc '05}: Proceedings of the 6th {ACM} international symposium
	on Mobile ad hoc networking and computing},
  year = {2005},
  pages = {378--389},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Mobile sinks are needed in many sensor network applications for efficient
	data collection, data querying, localized sensor reprogramming, identifying
	and revoking compromised sensors, and other network maintenance.
	Employing mobile sinks however raises a new security challenge: if
	a mobile sink is given too many privileges, it will become very attractive
	for attack and compromise. Using a compromised mobile sink, an adversary
	may easily bring down or even take over the sensor network. Thus,
	security mechanisms that can tolerate mobile sink compromises are
	essential. In this paper, based on the principle of least privilege,
	we first propose several efficient schemes to restrict the privilege
	of a mobile sink without impeding its capability of carrying out
	any authorized operations for an assigned task. To further reduce
	the possible damages caused by a compromised mobile sink, we then
	propose efficient message forwarding schemes for depriving the privilege
	assigned to a compromised mobile sink immediately after its compromise
	has been detected. Through detailed analysis and simulations, we
	show that our schemes are secure and efficient, and are highly practical
	for sensor networks consisting of the current generation of sensors.},
  doi = {http://doi.acm.org/10.1145/1062689.1062737},
  file = {zhang2005.pdf:zhang2005.pdf:PDF},
  isbn = {1-59593-004-3},
  keywords = {sensor networks, security, key management, key distribution},
  location = {Urbana-Champaign, IL, USA},
  review = {Deals with securing mobile sinks and how to remove their privileges
	once compromise has been discovered.}
}

@INPROCEEDINGS{zhang2003,
  author = {Zheng Zhang and Shu-Ming Shi and Jing Zhu},
  title = {{SOMO}: Self-Organized Metadata Overlay for Resource Management in
	{P2P DHT}},
  booktitle = {{IPTPS}},
  year = {2003},
  abstract = {In this paper, we first describe the concept of data overlay, which
	is a mechanism to implement arbitrary data structure on top of any
	structured P2P DHT. With this abstraction, we developed a highly
	scalable, efficient and robust infrastructure, called SOMO, to perform
	resource management for P2P DHT. It does so by gathering and disseminating
	system metadata in O(logN) time with a selforganizing and self-healing
	data overlay. Our preliminary results of using SOMO to balance routing
	traffic with node capacities in a prefix-based overlay have demonstrated
	the utility of data overlay as well as the potential of SOMO.},
  file = {zhang2003.pdf:zhang2003.pdf:PDF},
  review = {See citation by bawa2003.
	
	
	Discuss a metadata overlay on top of a DHT. The data overlay is tree-based.
	The authors discuss a rudimentary aggregation and dissemination mechanism
	over the virtual tree. In aggregation, nodes periodically query their
	children for data, resulting in log latencies on the global view.
	Dissemination messages can be piggybacked on the requiests for added
	efficiency.
	
	
	The authors attempt to use the underlying DTH in essence as a robust
	transport layer. The self-healing properties of the DHT and periodic
	reconstruction algorithms on the meta-data overlay maintain relations
	in the tree. This approach can be considered as an alternative to
	the more typical routing or flooding based tree construction algorithms.
	Interesting approach in many aspects but not well developed in the
	paper. In particular, would be interesting to consider the performance
	of a routing based protocol against this one.}
}

@ARTICLE{zhao2004,
  author = {Ben Y. Zhao and Ling Huang and Jeremy Stribling and Sean C. Rhea
	and Anthony D. Joseph and John D. Kubiatowicz},
  title = {Tapestry: A Resilient Global-scale Overlay for Service Deployment},
  journal = {{IEEE} Journal on Selected Areas In Communications},
  year = {2004},
  volume = {22},
  number = {1},
  month = {January},
  abstract = {We present Tapestry, a peer-to-peer overlay routing infrastructure
	offering efﬁcient, scalable, location-independent routing of messages
	directly to nearby copies of an object or service using only localized
	resources. Tapestry supports a generic Decentralized Object Location
	and Routing (DOLR) API using a self-repairing, soft-state based routing
	layer. This paper presents the Tapestry architecture, algorithms,
	and implementation. It explores the behavior of a Tapestry deployment
	on PlanetLab, a global testbed of approximately 100 machines. Experimental
	results show that Tapestry exhibits stable behavior and performance
	as an overlay, despite the instability of the underlying network
	layers. Several widely-distributed applications have been implemented
	on Tapestry, illustrating its utility as a deployment infrastructure.},
  file = {zhao2004.pdf:zhao2004.pdf:PDF},
  keywords = {Tapestry, DHT, distributed hash tables},
  owner = {kristjan},
  timestamp = {2010.03.20}
}

@TECHREPORT{zhao2001,
  author = {Ben Y. Zhao and John D. Kubiatowicz and Anthony D. Joseph},
  title = {Tapestry: An Infrastructure for Fault-tolerant Wide-area Location
	and Routing},
  institution = {University of California, Berkeley},
  year = {2001},
  number = {UCB/CSD-01-1141},
  address = {Berkeley, CA, USA},
  month = {April},
  abstract = {In today’s chaotic network, data and services are mobile and replicated
	widely for availability, durability, and locality. Components within
	this infrastructure interact in rich and complex ways, greatly stressing
	traditional approaches to name service and routing. This paper explores
	an alternative to traditional approaches called Tapestry. Tapestry
	is an overlay location and routing infrastructure that provides location-independent
	routing of messages directly to the closest copy of an object or
	service using only point-to-point links and without centralized resources.
	The routing and directory information within this infrastructure
	is purely soft state and easily repaired. Tapestry is self-administering,
	fault-tolerant, and resilient under load. This paper presents the
	architecture and algorithms of Tapestry and explores their advantages
	through a number of experiments.},
  file = {zhao2001.pdf:zhao2001.pdf:PDF},
  publisher = {University of California at Berkeley},
  source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aucb%3AUCB%2F%2FCSD-01-1141}
}

@INPROCEEDINGS{zhao2003,
  author = {Zhao, Jerry and Govindan, Ramesh},
  title = {Understanding packet delivery performance in dense wireless sensor
	networks},
  booktitle = {{SenSys} '03: Proceedings of the 1st international conference on
	Embedded networked sensor systems},
  year = {2003},
  pages = {1--13},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Wireless sensor networks promise fine-grain monitoring in a wide variety
	of environments. Many of these environments (e.g., indoor environments
	or habitats) can be harsh for wireless communication. From a networking
	perspective, the most basic aspect of wireless communication is the
	packet delivery performance: the spatio-temporal characteristics
	of packet loss, and its environmental dependence. These factors will
	deeply impact the performance of data acquisition from these networks.In
	this paper, we report on a systematic medium-scale (up to sixty nodes)
	measurement of packet delivery in three different environments: an
	indoor office building, a habitat with moderate foliage, and an open
	parking lot. Our findings have interesting implications for the design
	and evaluation of routing and medium-access protocols for sensor
	networks.},
  doi = {http://doi.acm.org/10.1145/958491.958493},
  file = {zhao2003.pdf:zhao2003.pdf:PDF},
  isbn = {1-58113-707-9},
  location = {Los Angeles, California, USA}
}

@INPROCEEDINGS{zhao2003a,
  author = {Yonggang Jerry Zhao and Ramesh Govindan and Deborah Estrin},
  title = {Computing Aggregates for Monitoring Wireless Sensor Networks},
  booktitle = {The First IEEE International Workshop on Sensor Network Protocols
	and Applications (SNPA 03)},
  year = {2003},
  address = {Anchorage, AK, USA},
  month = {May 11},
  abstract = {Wireless sensor networks involve very large numbers of small, low-power,
	wireless devices. Given their unattended nature, and their potential
	applications in harsh environments, we need a monitoring infrastructure
	that indicates system failures and resource depletion. In this paper,
	we briefly describe an architecture for sensor network monitoring,
	then focus on one aspect of this architecture: continuously computing
	aggregates (sum, average, count) of network properties (loss rates,
	energy-levels etc., packet counts). Our contributions are two-fold.
	First, we propose a novel tree construction algorithm that enables
	energy-efficient computation of some classes of aggregates. Second,
	we show through actual implementation and experiments that wireless
	communication artifacts in even relatively benign environments can
	significantly impact the computation of these aggregate properties.
	In some cases, without careful attention to detail, the relative
	error in the computed aggregates can be as much as 50%. However,
	by carefully discarding links with heavy packet loss and asymmetry,
	we can improve accuracy by an order of magnitude.},
  file = {zhao2003a.pdf:zhao2003a.pdf:PDF},
  url = {039}
}

@ARTICLE{zhou1999,
  author = {Lidong Zhou and Zygmunt J. Haas},
  title = {Securing ad hoc networks},
  journal = {{IEEE Network Magazine}},
  year = {1999},
  volume = {13},
  pages = {24--30},
  abstract = {Ad hoc networks are a new wireless networking paradigm for mobile
	hosts. Unlike traditional mobile wireless networks, ad hoc networks
	do not rely on any ﬁxed infrastructure. Instead, hosts rely on each
	other to keep the network connected. The military tactical and other
	security-sensitive operations are still the main applications of
	ad hoc networks, although there is a trend to adopt ad hoc networks
	for commercial uses due to their unique properties. One main challenge
	in design of these networks is their vulnerability to security attacks.
	In this paper, we study the threats an ad hoc network faces and the
	security goals to be achieved. We identify the new challenges and
	opportunities posed by this new networking environment and explore
	new approaches to secure its communication. In particular, we take
	advantage of the inherent redundancy in ad hoc networks — multiple
	routes between nodes — to defend routing against denial of service
	attacks. We also use replication and new cryptographic schemes, such
	as threshold cryptography, to build a highly secure and highly available
	key management service, which forms the core of our security framework.},
  file = {zhou1999.pdf:zhou1999.pdf:PDF},
  keywords = {ad-hoc network, security, sensor networks, key management, threshold
	signatures},
  review = {See ref by hu2003 on use of threshold cryptography for management
	of keys.}
}

@INCOLLECTION{zhou2009,
  author = {Shi Zhou},
  title = {Power Law Modelling of Internet Topology},
  booktitle = {Complex Sciences},
  publisher = {Springer Berlin Heidelberg},
  year = {2009},
  volume = {5},
  pages = {2090-2098},
  abstract = {In recent years there have been tremendous efforts to measure, characterise
	and model the internet topology. We discuss why the power law degree
	distribution is not an artifact but an integral property of the internet.
	On the other hand we argue that while it is one of the properties
	that fundamentally characterise the global internet structure, other
	properties should also be considered to obtain a full description
	of the network. We review the power law modelling of the internet
	topology and provide a critical look at the contribution of such
	research to the Internet engineering.},
  keywords = {Internet, topology, power-laws, network modelling, scale-free networks},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@ARTICLE{zhou2006,
  author = {S. Zhou},
  title = {Characterising and modelling the internet topology — The rich-club
	phenomenon and the PFP model},
  journal = {BT Technology Journal},
  year = {2006},
  volume = {24},
  pages = {108-115},
  number = {3},
  abstract = {It is vital to obtain a good description of the Internet topology
	because structure fundamentally affects function. This paper reviews
	two recent achievements on characterising and modelling the Internet
	topology at the autonomous systems level, including a newly discovered
	structure, called the rich-club phenomenon, and one of the most successful
	Internet topology generators to date, the positive-feedback preference
	(PFP) model. The discovery of the rich-club phenomenon is significant
	because an appreciation of this hierarchy structure is essential
	for a proper examination of the global Internet properties, such
	as routing efficiency, network flexibility and robustness. The PFP
	model accurately reproduces the largest set of important topology
	characteristics of the Internet. The model can be used for more realistic
	simulation studies of the Internet. The model also provides novel
	insights into the underlying rules that govern the Internet evolution.},
  file = {zhou2006.pdf:zhou2006.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.08.26}
}

@INPROCEEDINGS{Zhou2001,
  author = {Yuanyuan Zhou and James Philbin and Kai Li},
  title = {The Multi-Queue Replacement Algorithm for Second Level Buffer Caches},
  booktitle = {In Proc. of the USENIX Ann. Technical Conf.,},
  year = {2001},
  pages = {91--104},
  month = {June},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {citeseer.ist.psu.edu/zhou01multiqueue.html}
}

@MISC{rfc-4556-2006,
  author = {L. Zhu and B. Tung},
  title = {RFC-4556; Public Key Cryptography for Initial Authentication in {Kerberos
	(PKINIT)}},
  month = {June},
  year = {2006},
  owner = {kristjan},
  timestamp = {2010.09.02},
  url = {http://www.ietf.org/rfc/rfc4556.txt}
}

@ARTICLE{zhu2006,
  author = {Sencun Zhu and Sanjeev Setia and Sushil Jajodia},
  title = {{LEAP+}: Efficient security mechanisms for large-scale distributed
	sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2006},
  volume = {2},
  pages = {500--528},
  number = {4},
  abstract = {We describe LEAP&plus; (Localized Encryption and Authentication Protocol),
	a key management protocol for sensor networks that is designed to
	support in-network processing, while at the same time restricting
	the security impact of a node compromise to the immediate network
	neighborhood of the compromised node. The design of the protocol
	is motivated by the observation that different types of messages
	exchanged between sensor nodes have different security requirements,
	and that a single keying mechanism is not suitable for meeting these
	different security requirements. LEAP&plus; supports the establishment
	of four types of keys for each sensor node: an individual key shared
	with the base station, a pairwise key shared with another sensor
	node, a cluster key shared with multiple neighboring nodes, and a
	global key shared by all the nodes in the network. LEAP&plus; also
	supports (weak) local source authentication without precluding in-network
	processing. Our performance analysis shows that LEAP&plus; is very
	efficient in terms of computational, communication, and storage costs.
	We analyze the security of LEAP&plus; under various attack models
	and show that LEAP&plus; is very effective in defending against many
	sophisticated attacks, such as HELLO flood attacks, node cloning
	attacks, and wormhole attacks. A prototype implementation of LEAP&plus;
	on a sensor network testbed is also described.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1218556.1218559},
  file = {:p500-zhu.pdf:PDF},
  issn = {1550-4859},
  keywords = {sensor networks, in-network processing, key management, key establishment,
	cryptography},
  publisher = {ACM},
  review = {see also older paper from 2003.
	
	Key management scheme for sensor networks, supporting in-network aggregation.
	
	See citation by jadia2004.}
}

@INPROCEEDINGS{zhu2003a,
  author = {Zhu, Sencun and Setia, Sanjeev and Jajodia, Sushil},
  title = {{LEAP}: efficient security mechanisms for large-scale distributed
	sensor networks},
  booktitle = {{CCS} '03: Proceedings of the 10th {ACM} conference on Computer and
	communications security},
  year = {2003},
  pages = {62--72},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we describe LEAP (Localized Encryption and Authentication
	Protocol), a key management protocol for sensor networks that is
	designed to support in-network processing, while at the same time
	restricting the security impact of a node compromise to the immediate
	network neighborhood of the compromised node. The design of the protocol
	is motivated by the observation that different types of messages
	exchanged between sensor nodes have different security requirements,
	and that a single keying mechanism is not suitable for meeting these
	different security requirements. LEAP supports the establishment
	of four types of keys for each sensor node -- an individual key shared
	with the base station, a pairwise key shared with another sensor
	node, a cluster key shared with multiple neighboring nodes, and a
	group key that is shared by all the nodes in the network. The protocol
	used for establishing and updating these keys is communication- and
	energy-efficient, and minimizes the involvement of the base station.
	LEAP also includes an efficient protocol for inter-node traffic authentication
	based on the use of one-way key chains. A salient feature of the
	authentication protocol is that it supports source authentication
	without precluding in-network processing and passive participation.
	We analyze the performance and the security of our scheme under various
	attack models and show our schemes are very efficient in defending
	against many attacks.},
  doi = {http://doi.acm.org/10.1145/948109.948120},
  file = {zhu2003a.pdf:zhu2003a.pdf:PDF},
  isbn = {1-58113-738-9},
  keywords = {key management, sensor networks},
  location = {Washington D.C., USA},
  review = {See citation by jadia2004. See newer paper zhu2006 on LEAP+}
}

@ARTICLE{zhu2007,
  author = {Zhu, Sencun and Setia, Sanjeev and Jajodia, Sushil and Ning, Peng},
  title = {Interleaved hop-by-hop authentication against false data injection
	attacks in sensor networks},
  journal = {{ACM Trans. Sen. Netw.}},
  year = {2007},
  volume = {3},
  pages = {14},
  number = {3},
  abstract = {Sensor networks are often deployed in unattended environments, thus
	leaving these networks vulnerable to false data injection attacks
	in which an adversary injects false data into the network with the
	goal of deceiving the base station or depleting the resources of
	the relaying nodes. Standard authentication mechanisms cannot prevent
	this attack if the adversary has compromised one or a small number
	of sensor nodes. We present three interleaved hop-by-hop authentication
	schemes that guarantee that the base station can detect injected
	false data immediately when no more than t nodes are compromised,
	where t is a system design parameter. Moreover, these schemes enable
	an intermediate forwarding node to detect and discard false data
	packets as early as possible. Our performance analysis shows that
	our scheme is efficient with respect to the security it provides,
	and it also allows a tradeoff between security and performance. A
	prototype implementation of our scheme indicates that our scheme
	is practical and can be deployed on the current generation of sensor
	nodes.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1267060.1267062},
  file = {zhu2007.pdf:zhu2007.pdf:PDF},
  issn = {1550-4859},
  publisher = {ACM},
  review = {The authors present three methods, whose objective is to counter false
	data injection (what CPS term local data injection) in sensor networks.
	This is achieved by assuming a clustering of sensor nodes in the
	area of interest and requiring t+1 nodes to concur in order for a
	measurement to be deemed valid. The scheme tolerates up to t (a system
	parameter) malicious nodes.
	
	
	I have so far only skimmed through this paper but it appears to be
	solid. There do however appear to be some assumptions regarding the
	security of the forwarding path -- have to go into this in more detail
	later. The biggest issue with this paper is the assumption of cluster
	of sensing nodes. This is highly dependent on the application schenario
	the authors have in mind. It appears they are only considering consistent
	lying, they do not (apparently) consider equivocation. This is probably
	not a big issue in the case of wireless sensor nodes where the ability
	to project different false results to its neighbors is limited to
	none. Nevertheless, would be interesting to work out the byzantine
	argument in the case of a non-overhearing environment.
	
	
	See note by albath2007: provides protection against messages injected
	by an attacker with the intent to deceive the base station (trusted
	entity).}
}

@INPROCEEDINGS{zhu2003,
  author = {Zhu, Sencun and Xu, Shouhuai and Setia, Sanjeev and Jajodia, Sushil},
  title = {Establishing Pairwise Keys for Secure Communication in Ad Hoc Networks:
	A Probabilistic Approach},
  booktitle = {{ICNP} '03: Proceedings of the 11th {IEEE} International Conference
	on Network Protocols},
  year = {2003},
  pages = {326},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  file = {zhu2003.pdf:zhu2003.pdf:PDF},
  isbn = {0-7695-2024-3},
  keywords = {ad-hoc network, security, key establishment},
  review = {Ref'd by traynor -- key establishment via hash function}
}

@INPROCEEDINGS{zia2006,
  author = {Zia, T. and Zomaya, A.},
  title = {Security Issues in Wireless Sensor Networks},
  booktitle = {{ICSNC '06}. International Conference on Systems and Networks Communications},
  year = {2006},
  pages = {40-40},
  month = {Oct. },
  doi = {10.1109/ICSNC.2006.66},
  file = {zia2006.pdf:zia2006.pdf:PDF}
}

@MISC{zimmer2003,
  author = {David Zimmer},
  title = {Real World XSS},
  howpublished = {[online] http://www.net-security.org/dl/articles/XSS-Paper.txt},
  month = {April},
  year = {2003},
  owner = {kristjan},
  review = {Good intro to XSS by a knowledgeable source:
	
	
	Some topics:
	
	
	* *Stealing of cookies and account hijacking*
	
	
	* *User tracking and collection of browsing statistics*
	
	
	* *User exploitation by using XSS to distribute malware* (rather than
	collecting stats).
	
	
	 "The Sub category of User exploitation is a subtle variation but
	a distinction
	
	worth making. Browser exploits rely on specific security holes in
	specific versions of
	
	web browser software. User exploitation is the act of forcing users
	to take actions on
	
	your behalf. These actions can include privileged actions only then
	can perform like
	
	account modifications, sending email etc, or they can just be used
	to force random 
	
	unsuspecting web users to take general actions and give me an abstraction
	layer in the
	
	chain of evidence."
	
	
	* *Credentialed Misinformation*
	
	
	 "One of the most dangerous, yet often overlooked, is the danger of
	Credentialed 
	
	Misinformation. Once we have active scripting executing in a browser,
	we can pretty much
	
	do anything we could desire with the pages content. If you were a
	large trusted news site,
	
	this could be quite a dangerous thing. Imagine seeing a link on a
	messageboard or email
	
	saying that there were a reactor meltdown on the west coast and thousands
	were dead and
	
	injured? the site was clearly a legitimate large news site and a trusted
	resource. The url
	
	looks legit, is only about 50 characters long and raises no suspecisions.
	When you get to 
	
	the site, you are horrified to read through the pages of graphic detail.
	How can this be?"
	
	
	 "With a XSS vulnerable site...it could quite possible NOT be. Misinformation
	attacks
	
	are not limited to news sites. With but a minor twist and a quick
	jaunt of thought, My 
	
	originally email message could have appeared to have come from some
	popular web site you
	
	have an account with and asking you to visit this page to renew your
	password for
	
	security measures. Again the Url aims directly into the heart of your
	beloved site, so you
	
	think little of it and just fill out the information. What you don�t
	see behind the scenes
	
	is that the crafted url you clicked on got your browser to display
	a phony login page
	
	created by a malicious author and that the form just submitted all
	your login information
	
	to him. Congratulations you have been duped with the help of a XSS
	vulnerable site, and you 
	
	will probably never know it."
	
	
	* *Free information dissemination* by posting a URL carriying a message
	inline or a link to a site
	
	
	* *Other* examples include a *DoS* attack involving posing a img src
	for a small site on a vulnerable smaller site.
	
	
	XSS strengths:
	
	
	* Can affect a large target audience
	
	* Can force a user to take any action he/she is authorized to do -
	and access any information the user is able to access.
	
	* Can be very quiet
	
	* Powerful tool for display and alteration
	
	
	XSS weaknesses:
	
	
	* XSS can be mostly eliminated by proper filtering on user supplied
	data. *WebInspect* from SpiDynamics is one of the XSS scanning tools
	on the market.
	
	
	Injection points:
	
	
	Discussion on methods of injection.
	
	
	* *active* require some user action, e.g. clicking on a link (=reflected?)
	
	
	* *passive* more dangerous and require no user action other than requesting
	a web page containing dangerous code (=stored?). Examples include
	message board systems.
	
	
	Filtering:
	
	
	Filtering discussed, e.g. removing > and < characters in HTML.
	
	Discusses tricks of bypassing filtering by inserting linebreaks or
	javascript line continuation to fool filters.
	
	
	
	Inside info:
	
	
	A useful look at the hacker mentality -- a case study of a exploitation
	(actually an audit) of an actual site.},
  timestamp = {2008.04.14},
  url = {http://www.net-security.org/dl/articles/XSS-Paper.txt}
}

@ARTICLE{Zimmermann1980,
  author = {Hubert Zimmermann},
  title = {{OSI} Reference Model - The {ISO} Model of Architecture for Open
	Systems Interconnection},
  journal = {{IEEE} Transactions on Communications},
  year = {1980},
  volume = {COM-28},
  pages = {425-432},
  number = {4},
  month = {April},
  file = {zimmermann_osi.pdf:zimmermann_osi.pdf:PDF},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@BOOK{Zipf1949,
  title = {Human Behaviour and the Principle of Least Effort},
  publisher = {Addison-Wesley},
  year = {1949},
  author = {G. K. Zipf},
  owner = {kristjan},
  timestamp = {2008.09.19}
}

@INPROCEEDINGS{zou2003,
  author = {Cliff Changchun Zou and Lixin Gao and Weibo Gong and Don Towsley},
  title = {Monitoring and early warning for internet worms},
  booktitle = {CCS '03: Proceedings of the 10th ACM conference on Computer and communications
	security},
  year = {2003},
  pages = {190--199},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {After the Code Red incident in 2001 and the SQL Slammer in January
	2003, it is clear that a simple self-propagating worm can quickly
	spread across the Internet, infects most vulnerable computers before
	people can take effective countermeasures. The fast spreading nature
	of worms calls for a worm monitoring and early warning system. In
	this paper, we propose effective algorithms for early detection of
	the presence of a worm and the corresponding monitoring system. Based
	on epidemic model and observation data from the monitoring system,
	by using the idea of "detecting the trend, not the rate" of monitored
	illegitimated scan traffic, we propose to use a Kalman filter to
	detect a worm's propagation at its early stage in real-time. In addition,
	we can effectively predict the overall vulnerable population size,
	and correct the bias in the observed number of infected hosts. Our
	simulation experiments for Code Red and SQL Slammer show that with
	observation data from a small fraction of IP addresses, we can detect
	the presence of a worm when it infects only 1% to 2% of the vulnerable
	computers on the Internet.},
  doi = {http://doi.acm.org/10.1145/948109.948136},
  file = {zou2003.pdf:zou2003.pdf:PDF},
  isbn = {1-58113-738-9},
  location = {Washington D.C., USA}
}

@INPROCEEDINGS{zou2002,
  author = {Cliff Changchun Zou and Weibo Gong and Don Towsley},
  title = {Code red worm propagation modeling and analysis},
  booktitle = {CCS '02: Proceedings of the 9th ACM conference on Computer and communications
	security},
  year = {2002},
  pages = {138--147},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/586110.586130},
  file = {2002-Code Red Worm Propagation Modeling and Analysis.pdf:2002-Code
	Red Worm Propagation Modeling and Analysis.pdf:PDF},
  isbn = {1-58113-612-9},
  location = {Washington, DC, USA}
}

@ONLINE{online-caida-2009,
  title = {{CAIDA}: Cooperative Association for Internet Data Analysis.},
  url = {http://www.caida.org},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ONLINE{online-internet2-2009,
  title = {{Internet2}},
  url = {http://www.internet2.org},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ONLINE{online-nlanr-2009,
  title = {{NLANR}: National Laboratory for Applied Network Research},
  howpublished = {http://www.nlanr.net},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@MISC{online-omnet-pp,
  title = {{OMNeT++ Discrete Event Simulator}},
  howpublished = {[online] http://www.omnetpp.org},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://www.omnetpp.org}
}

@MISC{online-sans,
  title = {The {SANS} Internet Storm Center},
  owner = {kristjan},
  timestamp = {2009.08.17},
  url = {http://isc.sans.org}
}

@MISC{online-traceroute-at-home,
  title = {traceroute@home},
  owner = {kristjan},
  timestamp = {2009.08.17},
  url = {http://www.tracerouteathome.net}
}

@MISC{online_dimes_project,
  title = {DIMES project},
  howpublished = {http://www.netdimes.org},
  abstract = {What does the Internet look like? How does it evolve?
	
	
	DIMES is a distributed scientific research project, aimed to study
	the structure and topology of the Internet, with the help of a volunteer
	community (similar in spirit to projects such as SETI@Home).
	
	
	Due to the way the Internet is engineered, distributing the Internet
	mapping effort is very important, and the only efficient way to measure
	the Internet structure is by asking you to participate. What we ask
	is not so much your CPU or bandwidth (which we hardly consume), but
	rather, your location. The more places we'll have presence in, the
	more accurate our maps will be. Understanding the structure and function
	of the Internet is an important research task, that will allow to
	make the Internet a better place for all of us.
	
	
	The DIMES agent performs Internet measurements such as TRACEROUTE
	and PING at a low rate, consuming about 1KB/s. The agent DOES NOT
	send any information about its host's activity/personal data, and
	sends ONLY the results of its own measurements. Aside from giving
	a good feeling, running the DIMES agent will also provide you with
	maps of how the Internet looks from your home (currently) and will
	(in the future) provide you with a personalized 'Internet weather
	report' and other user-focused features.
	
	
	We are welcoming DIMES pioneers who want to participate in our initial
	measurement effort and help us discover the Internet. If you want
	to suggest ideas or comment on DIMES you are welcome to visit our
	forums},
  owner = {kristjan},
  review = {Downloadable agent uses low-volume pings and traceroutes to measure
	the local network neighborhood. Results aggregated to form a map
	of the internet.},
  timestamp = {2008.03.03},
  url = {http://www.netdimes.org}
}

@MISC{online_gwt,
  title = {{Google Web Toolkit}},
  howpublished = {http://code.google.com/webtoolkit},
  owner = {kristjan},
  timestamp = {2008.03.05},
  url = {http://code.google.com/webtoolkit/}
}

@MISC{online_json,
  title = {{JSON}},
  howpublished = {http://www.json.org/},
  owner = {kristjan},
  timestamp = {2008.02.15},
  url = {http://www.json.org/}
}

@MISC{online_neti_at_home,
  title = {{NETI@home}},
  howpublished = {http://www.neti.gatech.edu/},
  owner = {kristjan},
  timestamp = {2008.03.03},
  url = {http://www.neti.gatech.edu/}
}

@MISC{owasp_top_ten,
  title = {OWASP Top Ten Project},
  howpublished = {http://www.owasp.org/index.php/Category:OWASP\_Top\_Ten\_Project},
  owner = {kristjan},
  timestamp = {2008.03.08},
  url = {http://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}
}

@MISC{samy_worm,
  title = {The Samy Worm},
  howpublished = {[online] http://namb.la/popular},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://namb.la/popular}
}

@ONLINE{seti-at-home-online,
  title = {SETI@home},
  url = {http://setiathome.ssl.berkeley.edu/},
  owner = {kristjan},
  timestamp = {2009.02.27}
}

@MISC{web_mashups,
  title = {Web Mashups},
  howpublished = {[online] http://www.webmashup.com/},
  owner = {kristjan},
  timestamp = {2008.02.22},
  url = {http://www.webmashup.com/}
}

@ARTICLE{rehr2010,
  title = {John J. Rehr and Fernando D. Vila and Jeffrey P. Gardner and Lucas
	Svec and Micah Prange},
  journal = {Computing in Science \& Engineering},
  year = {2010},
  pages = {34--43},
  abstract = {Large, virtualized pools of computational resources raise the possibility
	of a new, advantageous computing paradigm for scientific research.
	To help achieve this, new tools make the cloud platform behave virtually
	like a local homogeneous computer cluster, giving users access to
	high-performance clusters without requiring them to purchase or maintain
	sophisticated hardware.},
  file = {rehr2010.pdf:rehr2010.pdf:PDF},
  keywords = {scientific cloud computing},
  owner = {kristjan},
  timestamp = {2010.06.24}
}

@ONLINE{online-geant-2009,
  title = {{GEANT}},
  url = {http://www.dante.net},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ONLINE{online-openid-2009,
  title = {What is OpenID?},
  url = {http://openid.net/what/},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.03.11}
}

@ONLINE{online-ripe-2009,
  title = {{RIPE: R\`{e}seaux IP Europ\`{e}ens}},
  url = {http://www.ripe.net},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@ONLINE{online-routeviews-2009,
  title = {{University of Oregon} {RouteViews} Project},
  url = {http://www.routeviews.org},
  year = {2009},
  owner = {kristjan},
  timestamp = {2009.08.12}
}

@MISC{o_wi_pgp,
  title = {Pretty Good Privacy},
  howpublished = {[online] http://en.wikipedia.org/wiki/Pretty\_Good\_Privacy},
  year = {2008},
  owner = {kristjan},
  timestamp = {2008.09.19},
  url = {http://en.wikipedia.org/wiki/Pretty_Good_Privacy}
}

@MISC{symantec-threats-2008,
  title = {Symantec Global Internet Security Threat Report. Trends for July
	to December 07},
  month = {April},
  year = {2008},
  file = {:b-whitepaper_internet_security_threat_report_xiii_04-2008.en-us.pdf:PDF},
  owner = {kristjan},
  timestamp = {2009.02.13}
}

@ONLINE{inet_framework_2006,
  title = {{INET Framework for OMNeT++}},
  url = {http://www.omnetpp.org/doc/INET/neddoc/index.html},
  year = {2006},
  owner = {kristjan},
  timestamp = {2008.11.27}
}

@MISC{NIST-recommended-elliptic-curves-1999,
  title = {RECOMMENDED ELLIPTIC CURVES FOR FEDERAL GOVERNMENT USE},
  month = {July},
  year = {1999},
  file = {NIST-recommended-elliptic-curves-1999.pdf:NIST-recommended-elliptic-curves-1999.pdf:PDF},
  owner = {kristjan},
  timestamp = {2010.09.03}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:anomaly detection;authenticati
on;cryptography;databases;distributed aggregation;exploits;HTTP;Intern
et;intrusion detection;modeling;network management;network measurement
s;networks;overlay networks;peer-to-peer systems;protocols;reputation;
security;sensor networks;simulation;social networks;survey;viruses;web
;web applications;web security;XSS;}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:phd\;0\;;
2 ExplicitGroup:primary\;0\;Castro1999\;Douceur2002\;Karlof2003\;adam2
005\;ahmad2006\;antonatos2008\;castro1999a\;castro2002\;chan2006\;chan
2007\;dam2005\;deligiannakis2004\;garofalakis2007\;gupta2001\;he2007\;
hu2003\;jelasity2002\;jelasity2005\;jurca2009\;keshav2006\;kreitz2009\
;lam2006\;lam2006a\;lamport82\;lesniewski-laas-2008\;levin2009\;levine
2006\;lim2001\;lim2003\;lim2005\;madden2002\;maurer2006\;moallemi2006\
;mortier2005\;newsome2004\;parno2005\;perrig2002\;perrig2004\;prieto20
07\;przydatek2003\;sang2006\;shanmugasundaram2003\;simpson2004\;sit200
2\;slagell2005\;stadler2008\;van_renesse_2003\;wood2002\;wuhib2005\;wu
hib2008\;wuhib2008b\;wuhib2009\;wuhib_tr_2007\;wuhib_tr_2008\;yedidia2
002\;yu2008\;yu2008a\;zhou1999\;;
2 ExplicitGroup:secondary\;0\;anderson1972\;anderson1980\;aurell2009\;
balfe2005\;bazzi2005\;bortnikov2008\;buchegger2009\;carrow2007\;carrow
2007a\;cheng2005\;cheng2006\;cooke2006\;corral2003\;costa_vigilante_20
05\;coull2009\;damiani2002\;danezis2005\;demers1987\;el-zarki-2002\;er
lingsson2007\;erlingsson2007a\;frey2001\;garcia-molina-2006\;gasser198
9\;gibbons2003\;graham1971\;harris2007\;hu2006\;iannaccone2004\;jelasi
ty2004\;jelasity2004a\;jelasity2004b\;kempe2003\;keys2001\;kiciman2007
\;kiciman2007a\;kompella2004\;kumar_witty_2005\;lampson1969\;lampson19
74\;lian2007\;liebeherr2007\;margolin2008\;margolin2008a\;martucci2008
\;massie2004\;merwe2007\;moore2003\;moore2004\;mosk-aoyama-2006\;murra
y2001\;newman2003\;paxson1998\;paxson2001\;shatdal1995\;simpson2004a\;
simpson2006\;simpson2007\;simpson2008\;singh2006\;steiner2007\;sun2007
\;sun2007a\;upadhyayula2007\;van-renesse-2002\;van-renesse-2003\;xie20
05\;xu2005\;yalagandula2004\;yang2005\;yedidia2000\;yedidia2001b\;yegn
eswaran2004\;yu2007\;yu2007a\;yu2008b\;yu2009\;yu2009a\;zhu2006\;;
2 ExplicitGroup:to consider\;0\;Hu2002\;Li2002\;andersen2001\;bolosky2
000\;boyd2006\;clark2003\;deng2003\;deng2006\;dilman2002\;du2003\;esch
enauer2002\;feldman2004\;friedman2007\;fultz\;ganesan2002\;krugel2002\
;kulik2002\;kumar1995\;lin1999\;lincoln2004\;nath2008\;ozdemir2009\;ra
jagopalan2006\;rivest1996\;sastry2003\;saxena2003\;stajano1999\;wawrzo
niak2004\;weaver2004\;zhao2001\;zou2003\;;
2 ExplicitGroup:logic\;0\;Josang1999\;bieber1991\;burrows1990\;glasgow
1992\;mccarthy1969\;mccarthy1979\;mccarthy1979a\;mccarthy1980\;van-der
-meyden-2007\;wang2007\;;
2 ExplicitGroup:General background\;0\;Lazarevic2003\;berr-survey-2008
\;bloedorn2001\;carzaniga2000\;claessens2002\;datta2003\;europol-htc-2
007\;hesse2009\;kienzle2003\;mitre_cve\;needham1977\;rubin1998\;waltz1
990\;weaver2003\;;
1 ExplicitGroup:simulation tools\;0\;;
1 ExplicitGroup:frameworks\;0\;van-renesse-2002\;van-renesse-2003\;;
1 ExplicitGroup:intrusion detection\;0\;bloedorn2001\;;
1 ExplicitGroup:social networks stuff\;0\;;
}

@comment{jabref-entrytype: Online: req[] opt[author;title;url;year;comment;howpublished]}

